#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
HTML æ•°æ®æ¸…æ´—è„šæœ¬
ä» HTML æ–‡ä»¶ä¸­æå–ä¸­è‹±æ–‡å¯¹ç…§å†…å®¹ï¼Œè½¬æ¢ä¸º try ç›®å½•æ‰€éœ€çš„æ ¼å¼
"""

from bs4 import BeautifulSoup
import re
import json
from pathlib import Path


def clean_text(text):
    """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™ç©ºç™½å’Œç‰¹æ®Šå­—ç¬¦"""
    if not text:
        return ""
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    # ç§»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    return text


def extract_chapters_from_html(html_path):
    """
    ä» HTML æ–‡ä»¶ä¸­æå–ç« èŠ‚æ•°æ®
    
    Args:
        html_path: HTML æ–‡ä»¶è·¯å¾„
        
    Returns:
        list: ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å« title å’Œ content
    """
    with open(html_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ç§»é™¤è„šæœ¬ã€æ ·å¼ã€å¯¼èˆªç­‰ä¸éœ€è¦çš„æ ‡ç­¾
    for tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
        tag.decompose()
    
    # æ‰¾åˆ°æ–‡ç« ä¸»ä½“å†…å®¹
    post_body = soup.find('div', class_='post-body')
    if not post_body:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° post-bodyï¼Œå°è¯•æ‰¾å…¶ä»–å¯èƒ½çš„å†…å®¹å®¹å™¨
        post_body = soup.find('article') or soup.find('main') or soup.find('body')
    
    if not post_body:
        raise ValueError("æ— æ³•æ‰¾åˆ°æ–‡ç« ä¸»ä½“å†…å®¹")
    
    chapters = []
    current_chapter = None
    current_content = []
    
    # éå†æ‰€æœ‰å…ƒç´ 
    for element in post_body.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'div']):
        # è·³è¿‡å›¾ç‰‡æ ‡ç­¾
        if element.name == 'p' and element.find('img'):
            continue
        
        # è·³è¿‡é“¾æ¥å’Œå…ƒä¿¡æ¯æ®µè½
        text = element.get_text()
        if any(keyword in text for keyword in ['æ–‡ç« ä½œè€…', 'åšå®¢', 'å£°æ˜', 'ç¿»è¯‘è®ºæ–‡æ±‡æ€»', 'èµ', 'æ‰“èµ']):
            continue
        
        # å¦‚æœæ˜¯æ ‡é¢˜ï¼Œå¼€å§‹æ–°ç« èŠ‚
        if element.name in ['h1', 'h2', 'h3']:
            # ä¿å­˜ä¹‹å‰çš„ç« èŠ‚
            if current_chapter and current_content:
                current_chapter['content'] = '\n\n'.join(current_content)
                chapters.append(current_chapter)
            
            # åˆ›å»ºæ–°ç« èŠ‚
            title = clean_text(text)
            # æå–è‹±æ–‡æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªæ ‡é¢˜ï¼‰
            if title and not re.search(r'[\u4e00-\u9fff]', title):
                # è¿™æ˜¯è‹±æ–‡æ ‡é¢˜
                current_chapter = {
                    'title': title,
                    'level': int(element.name[1]) - 1,  # h1->0, h2->1, h3->2
                    'content': ''
                }
                current_content = []
            elif title and re.search(r'[\u4e00-\u9fff]', title):
                # è¿™æ˜¯ä¸­æ–‡æ ‡é¢˜ï¼Œå¦‚æœå½“å‰ç« èŠ‚æ²¡æœ‰æ ‡é¢˜ï¼Œä½¿ç”¨å®ƒ
                if not current_chapter:
                    current_chapter = {
                        'title': title,
                        'level': int(element.name[1]) - 1,
                        'content': ''
                    }
                    current_content = []
                # å¦åˆ™å°†ä¸­æ–‡æ ‡é¢˜ä¹ŸåŠ å…¥å†…å®¹
                else:
                    current_content.append(title)
        
        # å¦‚æœæ˜¯æ®µè½ï¼Œæ·»åŠ åˆ°å½“å‰ç« èŠ‚å†…å®¹
        elif element.name == 'p' and text.strip():
            cleaned = clean_text(text)
            if cleaned:
                current_content.append(cleaned)
    
    # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
    if current_chapter and current_content:
        current_chapter['content'] = '\n\n'.join(current_content)
        chapters.append(current_chapter)
    
    # è¿‡æ»¤æ‰ç©ºç« èŠ‚
    chapters = [ch for ch in chapters if ch.get('content', '').strip()]
    
    return chapters


def extract_chapters_alternating(html_path):
    """
    æŒ‰ç…§ä¸­è‹±æ–‡äº¤æ›¿çš„æ¨¡å¼æå–
    æ ¼å¼ï¼šè‹±æ–‡æ ‡é¢˜ -> è‹±æ–‡å†…å®¹ -> ä¸­æ–‡æ ‡é¢˜ -> ä¸­æ–‡å†…å®¹ -> ä¸‹ä¸€ä¸ªè‹±æ–‡æ ‡é¢˜...
    """
    with open(html_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
    for tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
        tag.decompose()
    
    post_body = soup.find('div', class_='post-body')
    if not post_body:
        post_body = soup.find('article') or soup.find('main') or soup.find('body')
    
    if not post_body:
        raise ValueError("æ— æ³•æ‰¾åˆ°æ–‡ç« ä¸»ä½“å†…å®¹")
    
    chapters = []
    elements = []
    
    # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å…ƒç´ 
    for element in post_body.find_all(['h1', 'h2', 'h3', 'h4', 'p']):
        # è·³è¿‡å›¾ç‰‡å’Œå…ƒä¿¡æ¯
        if element.find('img'):
            continue
        text = element.get_text().strip()
        if not text or any(kw in text for kw in ['æ–‡ç« ä½œè€…', 'åšå®¢', 'å£°æ˜', 'ç¿»è¯‘è®ºæ–‡æ±‡æ€»', 'èµ', 'æ‰“èµ']):
            continue
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡ï¼ˆåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼‰
        is_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
        
        elements.append({
            'tag': element.name,
            'text': clean_text(text),
            'is_chinese': is_chinese
        })
    
    # æŒ‰ç…§æ ‡é¢˜åˆ†ç»„ï¼Œåˆå¹¶ä¸­è‹±æ–‡å†…å®¹
    current_en_title = None
    current_zh_title = None
    current_en_content = []
    current_zh_content = []
    current_level = 0
    
    i = 0
    while i < len(elements):
        elem = elements[i]
        
        # å¦‚æœæ˜¯æ ‡é¢˜
        if elem['tag'] in ['h1', 'h2', 'h3']:
            # å¦‚æœé‡åˆ°æ–°çš„è‹±æ–‡æ ‡é¢˜ï¼Œä¿å­˜ä¹‹å‰çš„ç« èŠ‚
            if not elem['is_chinese']:
                # ä¿å­˜ä¹‹å‰çš„ç« èŠ‚
                if current_en_title or current_zh_title:
                    content_parts = []
                    if current_en_title:
                        content_parts.append(f"[EN] {current_en_title}")
                    if current_en_content:
                        content_parts.extend([f"[EN] {p}" for p in current_en_content])
                    if current_zh_title:
                        content_parts.append(f"[ZH] {current_zh_title}")
                    if current_zh_content:
                        content_parts.extend([f"[ZH] {p}" for p in current_zh_content])
                    
                    if content_parts:
                        chapters.append({
                            'title': current_en_title or current_zh_title or f"Section {len(chapters) + 1}",
                            'level': current_level,
                            'content': '\n\n'.join(content_parts)
                        })
                
                # å¼€å§‹æ–°ç« èŠ‚
                current_en_title = elem['text']
                current_zh_title = None
                current_en_content = []
                current_zh_content = []
                current_level = 0 if elem['tag'] == 'h1' else (1 if elem['tag'] == 'h2' else 2)
            
            elif elem['is_chinese']:
                # ä¸­æ–‡æ ‡é¢˜
                current_zh_title = elem['text']
        
        # å¦‚æœæ˜¯æ®µè½
        elif elem['tag'] == 'p':
            if elem['is_chinese']:
                current_zh_content.append(elem['text'])
            else:
                current_en_content.append(elem['text'])
        
        i += 1
    
    # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
    if current_en_title or current_zh_title:
        content_parts = []
        if current_en_title:
            content_parts.append(f"[EN] {current_en_title}")
        if current_en_content:
            content_parts.extend([f"[EN] {p}" for p in current_en_content])
        if current_zh_title:
            content_parts.append(f"[ZH] {current_zh_title}")
        if current_zh_content:
            content_parts.extend([f"[ZH] {p}" for p in current_zh_content])
        
        if content_parts:
            chapters.append({
                'title': current_en_title or current_zh_title or f"Section {len(chapters) + 1}",
                'level': current_level,
                'content': '\n\n'.join(content_parts)
            })
    
    return chapters


def save_chapters_json(chapters, output_path):
    """ä¿å­˜ç« èŠ‚æ•°æ®ä¸º JSON æ–‡ä»¶"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(chapters, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ä¿å­˜ {len(chapters)} ä¸ªç« èŠ‚åˆ°: {output_path}")


def remove_newlines(text):
    """å»æ‰æ¢è¡Œç¬¦ï¼Œå°† \n æ›¿æ¢ä¸ºç©ºæ ¼"""
    if not text:
        return ""
    # å°†å¤šä¸ªè¿ç»­çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    text = re.sub(r'\n+', ' ', text)
    # å°†å¤šä¸ªè¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    text = re.sub(r' +', ' ', text)
    return text.strip()


def separate_en_zh_chapters(html_path):
    """
    åˆ†ç¦»ä¸­è‹±æ–‡ç« èŠ‚ï¼Œåˆ†åˆ«æå–è‹±æ–‡å’Œä¸­æ–‡å†…å®¹
    è¿”å›: (en_chapters, zh_chapters)
    """
    with open(html_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ç§»é™¤ä¸éœ€è¦çš„æ ‡ç­¾
    for tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
        tag.decompose()
    
    post_body = soup.find('div', class_='post-body')
    if not post_body:
        post_body = soup.find('article') or soup.find('main') or soup.find('body')
    
    if not post_body:
        raise ValueError("æ— æ³•æ‰¾åˆ°æ–‡ç« ä¸»ä½“å†…å®¹")
    
    en_chapters = []
    zh_chapters = []
    elements = []
    
    # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å…ƒç´ 
    for element in post_body.find_all(['h1', 'h2', 'h3', 'h4', 'p']):
        # è·³è¿‡å›¾ç‰‡å’Œå…ƒä¿¡æ¯
        if element.find('img'):
            continue
        text = element.get_text().strip()
        if not text or any(kw in text for kw in ['æ–‡ç« ä½œè€…', 'åšå®¢', 'å£°æ˜', 'ç¿»è¯‘è®ºæ–‡æ±‡æ€»', 'èµ', 'æ‰“èµ']):
            continue
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡ï¼ˆåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼‰
        is_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
        
        elements.append({
            'tag': element.name,
            'text': clean_text(text),
            'is_chinese': is_chinese
        })
    
    # æŒ‰ç…§æ ‡é¢˜åˆ†ç»„ï¼Œåˆ†åˆ«æ”¶é›†ä¸­è‹±æ–‡å†…å®¹
    current_en_title = None
    current_zh_title = None
    current_en_content = []
    current_zh_content = []
    current_level = 0
    skip_references = False  # æ ‡è®°æ˜¯å¦é‡åˆ°å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
    seen_en_titles = set()  # è®°å½•å·²è§è¿‡çš„è‹±æ–‡æ ‡é¢˜ï¼Œç”¨äºå»é‡
    seen_zh_titles = set()  # è®°å½•å·²è§è¿‡çš„ä¸­æ–‡æ ‡é¢˜ï¼Œç”¨äºå»é‡
    
    i = 0
    while i < len(elements):
        elem = elements[i]
        
        # å¦‚æœæ˜¯æ ‡é¢˜
        if elem['tag'] in ['h1', 'h2', 'h3']:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å‚è€ƒæ–‡çŒ®æ ‡é¢˜
            title_text = elem['text'].strip().lower()
            if 'reference' in title_text:
                skip_references = True
                # ä¿å­˜ä¹‹å‰çš„ç« èŠ‚ï¼ˆå¦‚æœæœ‰ï¼‰
                if current_en_title or current_zh_title:
                    if current_en_title and current_en_title not in seen_en_titles:
                        en_content = ' '.join([current_en_title] + current_en_content) if current_en_content else current_en_title
                        en_content = remove_newlines(en_content)
                        en_chapters.append({
                            'title': remove_newlines(current_en_title),
                            'level': current_level,
                            'content': en_content
                        })
                        seen_en_titles.add(current_en_title)
                    if current_zh_title and current_zh_title not in seen_zh_titles:
                        zh_content = ' '.join([current_zh_title] + current_zh_content) if current_zh_content else current_zh_title
                        zh_content = remove_newlines(zh_content)
                        zh_chapters.append({
                            'title': remove_newlines(current_zh_title),
                            'level': current_level,
                            'content': zh_content
                        })
                        seen_zh_titles.add(current_zh_title)
                # è·³è¿‡å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
                break
            
            # å¦‚æœé‡åˆ°æ–°çš„è‹±æ–‡æ ‡é¢˜ï¼Œä¿å­˜ä¹‹å‰çš„ç« èŠ‚
            if not elem['is_chinese']:
                # ä¿å­˜ä¹‹å‰çš„ç« èŠ‚
                if current_en_title or current_zh_title:
                    # ä¿å­˜è‹±æ–‡ç« èŠ‚ï¼ˆå»é‡ï¼‰
                    if current_en_title and current_en_title not in seen_en_titles:
                        en_content = ' '.join([current_en_title] + current_en_content) if current_en_content else current_en_title
                        en_content = remove_newlines(en_content)  # å»æ‰æ¢è¡Œç¬¦
                        en_chapters.append({
                            'title': remove_newlines(current_en_title),
                            'level': current_level,
                            'content': en_content
                        })
                        seen_en_titles.add(current_en_title)
                    
                    # ä¿å­˜ä¸­æ–‡ç« èŠ‚ï¼ˆå»é‡ï¼‰
                    if current_zh_title and current_zh_title not in seen_zh_titles:
                        zh_content = ' '.join([current_zh_title] + current_zh_content) if current_zh_content else current_zh_title
                        zh_content = remove_newlines(zh_content)  # å»æ‰æ¢è¡Œç¬¦
                        zh_chapters.append({
                            'title': remove_newlines(current_zh_title),
                            'level': current_level,
                            'content': zh_content
                        })
                        seen_zh_titles.add(current_zh_title)
                
                # æ£€æŸ¥æ–°æ ‡é¢˜æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è·³è¿‡
                new_title = elem['text']
                if new_title in seen_en_titles:
                    # æ ‡é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡è¿™ä¸ªç« èŠ‚
                    current_en_title = None
                    current_zh_title = None
                    current_en_content = []
                    current_zh_content = []
                else:
                    # å¼€å§‹æ–°ç« èŠ‚
                    current_en_title = new_title
                    current_zh_title = None
                    current_en_content = []
                    current_zh_content = []
                    current_level = 0 if elem['tag'] == 'h1' else (1 if elem['tag'] == 'h2' else 2)
            
            elif elem['is_chinese']:
                # ä¸­æ–‡æ ‡é¢˜
                new_zh_title = elem['text']
                if new_zh_title in seen_zh_titles:
                    # æ ‡é¢˜å·²å­˜åœ¨ï¼Œè·³è¿‡
                    current_zh_title = None
                    current_zh_content = []
                else:
                    current_zh_title = new_zh_title
        
        # å¦‚æœæ˜¯æ®µè½ï¼Œä¸”ä¸åœ¨å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
        elif elem['tag'] == 'p' and not skip_references:
            if elem['is_chinese']:
                current_zh_content.append(elem['text'])
            else:
                current_en_content.append(elem['text'])
        
        i += 1
    
    # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚ï¼ˆå»é‡ï¼‰
    if current_en_title and current_en_title not in seen_en_titles:
        en_content = ' '.join([current_en_title] + current_en_content) if current_en_content else current_en_title
        en_content = remove_newlines(en_content)  # å»æ‰æ¢è¡Œç¬¦
        en_chapters.append({
            'title': remove_newlines(current_en_title),
            'level': current_level,
            'content': en_content
        })
        seen_en_titles.add(current_en_title)
    
    if current_zh_title and current_zh_title not in seen_zh_titles:
        zh_content = ' '.join([current_zh_title] + current_zh_content) if current_zh_content else current_zh_title
        zh_content = remove_newlines(zh_content)  # å»æ‰æ¢è¡Œç¬¦
        zh_chapters.append({
            'title': remove_newlines(current_zh_title),
            'level': current_level,
            'content': zh_content
        })
        seen_zh_titles.add(current_zh_title)
    
    return en_chapters, zh_chapters


def main():
    """ä¸»å‡½æ•°"""
    html_path = Path(__file__).parent / "1.html"
    output_en = Path(__file__).parent / "1_en.json"
    output_zh = Path(__file__).parent / "1_ch.json"
    
    print(f"ğŸ“– å¼€å§‹å¤„ç† HTML æ–‡ä»¶: {html_path}")
    
    try:
        # åˆ†ç¦»ä¸­è‹±æ–‡å†…å®¹
        print("\n" + "="*60)
        print("æ­£åœ¨åˆ†ç¦»ä¸­è‹±æ–‡å†…å®¹...")
        print("="*60)
        en_chapters, zh_chapters = separate_en_zh_chapters(html_path)
        
        print(f"ğŸ“Š æå–åˆ° {len(en_chapters)} ä¸ªè‹±æ–‡ç« èŠ‚")
        print(f"ğŸ“Š æå–åˆ° {len(zh_chapters)} ä¸ªä¸­æ–‡ç« èŠ‚")
        
        # æ‰“å°å‰å‡ ä¸ªç« èŠ‚çš„æ ‡é¢˜
        print("\nè‹±æ–‡ç« èŠ‚é¢„è§ˆ:")
        for i, ch in enumerate(en_chapters[:3]):
            title_preview = ch['title'][:50] + "..." if len(ch['title']) > 50 else ch['title']
            content_preview = ch['content'][:80] + "..." if len(ch['content']) > 80 else ch['content']
            print(f"  ç« èŠ‚ {i+1}: {title_preview}")
            print(f"    å†…å®¹é¢„è§ˆ: {content_preview}")
        
        print("\nä¸­æ–‡ç« èŠ‚é¢„è§ˆ:")
        for i, ch in enumerate(zh_chapters[:3]):
            title_preview = ch['title'][:50] + "..." if len(ch['title']) > 50 else ch['title']
            content_preview = ch['content'][:80] + "..." if len(ch['content']) > 80 else ch['content']
            print(f"  ç« èŠ‚ {i+1}: {title_preview}")
            print(f"    å†…å®¹é¢„è§ˆ: {content_preview}")
        
        # ä¿å­˜è‹±æ–‡å’Œä¸­æ–‡ç« èŠ‚
        save_chapters_json(en_chapters, output_en)
        save_chapters_json(zh_chapters, output_zh)
        
        print("\n" + "="*60)
        print("âœ… å¤„ç†å®Œæˆï¼")
        print("="*60)
        print(f"ğŸ“ è‹±æ–‡å†…å®¹å·²ä¿å­˜: {output_en}")
        print(f"ğŸ“ ä¸­æ–‡å†…å®¹å·²ä¿å­˜: {output_zh}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

