{
  "book_info": "Artificial Intelligence: A Modern Approach (4th Ed, English)",
  "target_chapters": [
    1,
    2,
    3,
    4,
    5
  ],
  "global_metadata": {
    "total_characters": 485740,
    "total_paragraphs": 1394,
    "total_terms": 6049,
    "total_entities": 2336,
    "total_cultural_words": 1,
    "dominant_domain": "AI_Professional",
    "dominant_style": "Formal_Academic"
  },
  "chapters": [
    {
      "chapter_num": 1,
      "title": "Chapter 1: CHAPTER",
      "paragraphs": [
        {
          "para_id": "chap1_para1",
          "content": "1\nINTRODUCTION\nIn which we try to explain why we consider artificial intelligence to be a subject most worthy of study, and in which we try to decide what exactly it is, this being a good thing to decide before embarking.",
          "sentence_count": 1,
          "char_count": 183,
          "prev_para_id": "None",
          "next_para_id": "chap1_para2",
          "style_metadata": {
            "para_id": "chap1_para1",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 1
          },
          "terminology": {
            "introduction": 1,
            "try": 2,
            "explain": 1,
            "consider": 1,
            "artificial": 1,
            "intelligence": 1,
            "subject": 1,
            "worthy": 1,
            "study": 1,
            "good": 1,
            "thing": 1,
            "decide": 1,
            "embarking": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para2",
          "content": "We call ourselves\nHomo sapiens\n—man the wise—because our\nintelligence\nis so important to us. For thousands of years, we have tried to understand\nhow we think and act\n—that is, how our brain, a mere handful of matter, can perceive, understand, predict, and manipulate a world far larger and more complicated than itself. The field of\nartificial intelligence\n, or AI, is concerned with not just understanding but also\nbuilding\nintelligent entities—machines that can compute how to act effectively and safely in a wide variety of novel situations.",
          "sentence_count": 3,
          "char_count": 466,
          "prev_para_id": "chap1_para1",
          "next_para_id": "chap1_para3",
          "style_metadata": {
            "para_id": "chap1_para2",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.33,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 100,
            "sentence_count": 3
          },
          "terminology": {
            "call": 1,
            "homo": 1,
            "sapiens": 1,
            "—man": 1,
            "wise—because": 1,
            "intelligence": 2,
            "important": 1,
            "thousand": 1,
            "year": 1,
            "tried": 1,
            "understand": 2,
            "think": 1,
            "act": 2,
            "brain": 1,
            "handful": 1,
            "matter": 1,
            "perceive": 1,
            "predict": 1,
            "manipulate": 1,
            "world": 1,
            "larger": 1,
            "complicated": 1,
            "field": 1,
            "artificial": 1,
            "concerned": 1,
            "understanding": 1,
            "building": 1,
            "intelligent": 1,
            "entities—machines": 1,
            "compute": 1,
            "wide": 1,
            "variety": 1,
            "novel": 1,
            "situation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para2",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 362,
              "end_char": 364,
              "context": "itself. The field of\nartificial intelligence\n, or AI, is concerned with not just understanding but als"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para3",
          "content": "Surveys regularly rank AI as one of the most interesting and fastest-growing fields, and it is already generating over a trillion dollars a year in revenue. AI expert Kai-Fu Lee predicts that its impact will be “more than anything in the history of mankind.” Moreover, the intellectual frontiers of AI are wide open. Whereas a student of an older science such as physics might feel that the best ideas have already been discovered by Galileo, Newton, Curie, Einstein, and the rest, AI still has many openings for full-time masterminds.",
          "sentence_count": 3,
          "char_count": 447,
          "prev_para_id": "chap1_para2",
          "next_para_id": "chap1_para4",
          "style_metadata": {
            "para_id": "chap1_para3",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 33.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 101,
            "sentence_count": 3
          },
          "terminology": {
            "survey": 1,
            "rank": 1,
            "interesting": 1,
            "fastest-growing": 1,
            "field": 1,
            "generating": 1,
            "dollar": 1,
            "year": 1,
            "revenue": 1,
            "expert": 1,
            "kai-fu": 1,
            "lee": 1,
            "predicts": 1,
            "impact": 1,
            "anything": 1,
            "history": 1,
            "mankind.": 1,
            "intellectual": 1,
            "frontier": 1,
            "wide": 1,
            "open": 1,
            "whereas": 1,
            "student": 1,
            "older": 1,
            "science": 1,
            "physic": 1,
            "feel": 1,
            "best": 1,
            "idea": 1,
            "discovered": 1,
            "galileo": 1,
            "newton": 1,
            "curie": 1,
            "einstein": 1,
            "rest": 1,
            "many": 1,
            "opening": 1,
            "full-time": 1,
            "mastermind": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para3",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 23,
              "end_char": 25,
              "context": "Surveys regularly rank AI as one of the most interesting and fastest-growin"
            },
            {
              "para_id": "chap1_para3",
              "entity_text": "Kai-Fu Lee",
              "entity_type": "PERSON",
              "start_char": 167,
              "end_char": 177,
              "context": "r a trillion dollars a year in revenue. AI expert Kai-Fu Lee predicts that its impact will be “more than anyth"
            },
            {
              "para_id": "chap1_para3",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 299,
              "end_char": 301,
              "context": "mankind.” Moreover, the intellectual frontiers of AI are wide open. Whereas a student of an older scie"
            },
            {
              "para_id": "chap1_para3",
              "entity_text": "Galileo",
              "entity_type": "PRODUCT",
              "start_char": 434,
              "end_char": 441,
              "context": "at the best ideas have already been discovered by Galileo, Newton, Curie, Einstein, and the rest, AI still "
            },
            {
              "para_id": "chap1_para3",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 443,
              "end_char": 449,
              "context": "st ideas have already been discovered by Galileo, Newton, Curie, Einstein, and the rest, AI still has many"
            },
            {
              "para_id": "chap1_para3",
              "entity_text": "Curie, Einstein",
              "entity_type": "PERSON",
              "start_char": 451,
              "end_char": 466,
              "context": " have already been discovered by Galileo, Newton, Curie, Einstein, and the rest, AI still has many openings for ful"
            },
            {
              "para_id": "chap1_para3",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 482,
              "end_char": 484,
              "context": "y Galileo, Newton, Curie, Einstein, and the rest, AI still has many openings for full-time masterminds"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para4",
          "content": "AI currently encompasses a huge variety of subfields, ranging from the general (learning, reasoning, perception, and so on) to the specific, such as playing chess, proving mathematical theorems, writing poetry, driving a car, or diagnosing diseases. AI is relevant to any intellectual task; it is truly a universal field.",
          "sentence_count": 2,
          "char_count": 273,
          "prev_para_id": "chap1_para3",
          "next_para_id": "chap1_para5",
          "style_metadata": {
            "para_id": "chap1_para4",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "encompasses": 1,
            "huge": 1,
            "variety": 1,
            "subfields": 1,
            "ranging": 1,
            "general": 1,
            "learning": 1,
            "reasoning": 1,
            "perception": 1,
            "specific": 1,
            "playing": 1,
            "chess": 1,
            "proving": 1,
            "mathematical": 1,
            "theorem": 1,
            "writing": 1,
            "poetry": 1,
            "driving": 1,
            "car": 1,
            "diagnosing": 1,
            "disease": 1,
            "relevant": 1,
            "intellectual": 1,
            "task": 1,
            "universal": 1,
            "field": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para4",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 2,
              "context": "AI currently encompasses a huge variety of subfields"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para5",
          "content": "1.1What Is AI?",
          "sentence_count": 1,
          "char_count": 12,
          "prev_para_id": "chap1_para4",
          "next_para_id": "chap1_para6",
          "style_metadata": {
            "para_id": "chap1_para5",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para5",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 11,
              "end_char": 13,
              "context": "1.1What Is AI?"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para6",
          "content": "1.1\nWhat Is AI?",
          "sentence_count": 1,
          "char_count": 13,
          "prev_para_id": "chap1_para5",
          "next_para_id": "chap1_para7",
          "style_metadata": {
            "para_id": "chap1_para6",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 5,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para7",
          "content": "We have claimed that AI is interesting, but we have not said what it\nis.",
          "sentence_count": 1,
          "char_count": 59,
          "prev_para_id": "chap1_para6",
          "next_para_id": "chap1_para8",
          "style_metadata": {
            "para_id": "chap1_para7",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 17,
            "sentence_count": 1
          },
          "terminology": {
            "claimed": 1,
            "interesting": 1,
            "said": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para7",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 21,
              "end_char": 23,
              "context": "We have claimed that AI is interesting, but we have not said what it\nis."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para8",
          "content": "Historically, researchers have pursued several different versions of AI. Some have defined intelligence in terms of fidelity to\nhuman\nperformance, while others prefer an abstract, formal definition of intelligence called\nrationality\n—loosely speaking, doing the “right thing.” The subject matter itself also varies: some consider intelligence to be a property of internal\nthought processes\nand\nreasoning,\nwhile others focus on intelligent\nbehavior,\nan external characterization.",
          "sentence_count": 2,
          "char_count": 424,
          "prev_para_id": "chap1_para7",
          "next_para_id": "chap1_para9",
          "style_metadata": {
            "para_id": "chap1_para8",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 2
          },
          "terminology": {
            "researcher": 1,
            "pursued": 1,
            "several": 1,
            "different": 1,
            "version": 1,
            "defined": 1,
            "intelligence": 3,
            "term": 1,
            "fidelity": 1,
            "human": 1,
            "performance": 1,
            "others": 2,
            "prefer": 1,
            "abstract": 1,
            "formal": 1,
            "definition": 1,
            "called": 1,
            "rationality": 1,
            "speaking": 1,
            "right": 1,
            "thing.": 1,
            "subject": 1,
            "matter": 1,
            "varies": 1,
            "consider": 1,
            "property": 1,
            "internal": 1,
            "thought": 1,
            "process": 1,
            "reasoning": 1,
            "focus": 1,
            "intelligent": 1,
            "behavior": 1,
            "external": 1,
            "characterization": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para8",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 69,
              "end_char": 71,
              "context": "rchers have pursued several different versions of AI. Some have defined intelligence in terms of fidel"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para9",
          "content": "1\nFrom these two dimensions—human vs. rational\n2\nand thought vs. behavior—there are four possible combinations, and there have been adherents and research programs for all\nfour. The methods used are necessarily different: the pursuit of human-like intelligence must be in part an empirical science related to psychology, involving observations and hypotheses about actual human behavior and thought processes; a rationalist approach, on the other hand, involves a combination of mathematics and engineering, and connects to statistics, control theory, and economics. The various groups have both disparaged and helped each other. Let us look at the four approaches in more detail.",
          "sentence_count": 4,
          "char_count": 584,
          "prev_para_id": "chap1_para8",
          "next_para_id": "chap1_para10",
          "style_metadata": {
            "para_id": "chap1_para9",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "dimensions—human": 1,
            "rational": 1,
            "thought": 2,
            "possible": 1,
            "combination": 2,
            "adherent": 1,
            "research": 1,
            "program": 1,
            "method": 1,
            "used": 1,
            "different": 1,
            "pursuit": 1,
            "human-like": 1,
            "intelligence": 1,
            "part": 1,
            "empirical": 1,
            "science": 1,
            "related": 1,
            "psychology": 1,
            "involving": 1,
            "observation": 1,
            "hypothesis": 1,
            "actual": 1,
            "human": 1,
            "behavior": 1,
            "process": 1,
            "rationalist": 1,
            "approach": 2,
            "hand": 1,
            "involves": 1,
            "mathematics": 1,
            "engineering": 1,
            "connects": 1,
            "statistic": 1,
            "control": 1,
            "theory": 1,
            "economics": 1,
            "various": 1,
            "group": 1,
            "disparaged": 1,
            "helped": 1,
            "let": 1,
            "look": 1,
            "detail": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para10",
          "content": "1.1.1\nActing humanly: The Turing test approach\nThe\nTuring test\n, proposed by Alan Turing (1950), was designed as a thought experiment that would sidestep the philosophical vagueness of the question “Can a machine think?” A computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer.",
          "sentence_count": 1,
          "char_count": 332,
          "prev_para_id": "chap1_para9",
          "next_para_id": "chap1_para11",
          "style_metadata": {
            "para_id": "chap1_para10",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 74.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 1
          },
          "terminology": {
            "acting": 1,
            "turing": 3,
            "test": 3,
            "approach": 1,
            "proposed": 1,
            "alan": 1,
            "designed": 1,
            "thought": 1,
            "experiment": 1,
            "sidestep": 1,
            "philosophical": 1,
            "vagueness": 1,
            "question": 2,
            "machine": 1,
            "think": 1,
            "computer": 2,
            "pass": 1,
            "human": 1,
            "interrogator": 1,
            "posing": 1,
            "written": 2,
            "tell": 1,
            "response": 1,
            "come": 1,
            "person": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para10",
              "entity_text": "Alan Turing",
              "entity_type": "PERSON",
              "start_char": 77,
              "end_char": 88,
              "context": "uring test approach\nThe\nTuring test\n, proposed by Alan Turing (1950), was designed as a thought experiment that"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para11",
          "content": "Chapter 28\ndiscusses the details of the test and whether a computer would really be intelligent if it passed. For now, we note that programming a computer to pass a rigorously applied test provides plenty to work on. The computer would need the following capabilities:\n•\nnatural language processing\nto communicate successfully in a human language;\n•\nknowledge representation\nto store what it knows or hears;\n•\nautomated reasoning\nto answer questions and to draw new conclusions;\n•\nmachine learning\nto adapt to new circumstances and to detect and extrapolate patterns.",
          "sentence_count": 3,
          "char_count": 490,
          "prev_para_id": "chap1_para10",
          "next_para_id": "chap1_para12",
          "style_metadata": {
            "para_id": "chap1_para11",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 3
          },
          "terminology": {
            "chapter": 1,
            "discusses": 1,
            "detail": 1,
            "test": 2,
            "computer": 3,
            "intelligent": 1,
            "passed": 1,
            "note": 1,
            "programming": 1,
            "pas": 1,
            "applied": 1,
            "provides": 1,
            "plenty": 1,
            "work": 1,
            "need": 1,
            "following": 1,
            "capability": 1,
            "natural": 1,
            "language": 2,
            "processing": 1,
            "communicate": 1,
            "human": 1,
            "knowledge": 1,
            "representation": 1,
            "store": 1,
            "know": 1,
            "hears": 1,
            "automated": 1,
            "reasoning": 1,
            "answer": 1,
            "question": 1,
            "draw": 1,
            "new": 2,
            "conclusion": 1,
            "machine": 1,
            "learning": 1,
            "adapt": 1,
            "circumstance": 1,
            "detect": 1,
            "extrapolate": 1,
            "pattern": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para12",
          "content": "Turing viewed the\nphysical\nsimulation of a person as unnecessary to demonstrate intelligence. However, other researchers have proposed a\ntotal Turing test\n, which requires interaction with objects and people in the real world. To pass the total Turing test, a robot will need\n•\ncomputer vision\nand speech recognition to perceive the world;\n•\nrobotics\nto manipulate objects and move about.",
          "sentence_count": 3,
          "char_count": 337,
          "prev_para_id": "chap1_para11",
          "next_para_id": "chap1_para13",
          "style_metadata": {
            "para_id": "chap1_para12",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 22.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 68,
            "sentence_count": 3
          },
          "terminology": {
            "turing": 3,
            "viewed": 1,
            "physical": 1,
            "simulation": 1,
            "person": 1,
            "unnecessary": 1,
            "demonstrate": 1,
            "intelligence": 1,
            "researcher": 1,
            "proposed": 1,
            "total": 2,
            "test": 2,
            "requires": 1,
            "interaction": 1,
            "object": 2,
            "people": 1,
            "real": 1,
            "world": 2,
            "pas": 1,
            "robot": 1,
            "need": 1,
            "computer": 1,
            "vision": 1,
            "speech": 1,
            "recognition": 1,
            "perceive": 1,
            "robotics": 1,
            "manipulate": 1,
            "move": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para12",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 245,
              "end_char": 251,
              "context": "s and people in the real world. To pass the total Turing test, a robot will need\n•\ncomputer vision\nand spe"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para13",
          "content": "These six disciplines compose most of AI. Yet AI researchers have devoted little effort to passing the Turing test, believing that it is more important to study the underlying principles of intelligence. The quest for “artificial flight” succeeded when engineers and inventors stopped imitating birds and started using wind tunnels and learning about aerodynamics. Aeronautical engineering texts do not define the goal of their field as making “machines that fly so exactly like pigeons that they can fool even other pigeons.”\n1.1.2\nThinking humanly: The cognitive modeling approach\nTo say that a program thinks like a human, we must know how humans think. We can learn about human thought in three ways:\n•\nintrospection\n—trying to catch our own thoughts as they go by;\n•\npsychological experiments\n—observing a person in action;\n•\nbrain imaging\n—observing the brain in action.",
          "sentence_count": 5,
          "char_count": 749,
          "prev_para_id": "chap1_para12",
          "next_para_id": "chap1_para14",
          "style_metadata": {
            "para_id": "chap1_para13",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 155,
            "sentence_count": 5
          },
          "terminology": {
            "discipline": 1,
            "researcher": 1,
            "devoted": 1,
            "little": 1,
            "effort": 1,
            "passing": 1,
            "turing": 1,
            "test": 1,
            "believing": 1,
            "important": 1,
            "study": 1,
            "underlying": 1,
            "principle": 1,
            "intelligence": 1,
            "quest": 1,
            "artificial": 1,
            "flight": 1,
            "succeeded": 1,
            "engineer": 1,
            "inventor": 1,
            "stopped": 1,
            "imitating": 1,
            "bird": 1,
            "started": 1,
            "using": 1,
            "wind": 1,
            "tunnel": 1,
            "learning": 1,
            "aerodynamics": 1,
            "aeronautical": 1,
            "engineering": 1,
            "text": 1,
            "define": 1,
            "goal": 1,
            "field": 1,
            "making": 1,
            "machine": 1,
            "pigeon": 1,
            "fool": 1,
            "pigeons.": 1,
            "thinking": 1,
            "cognitive": 1,
            "modeling": 1,
            "approach": 1,
            "say": 1,
            "program": 1,
            "think": 2,
            "human": 3,
            "know": 1,
            "learn": 1,
            "thought": 2,
            "way": 1,
            "introspection": 1,
            "—trying": 1,
            "catch": 1,
            "psychological": 1,
            "experiment": 1,
            "—observing": 2,
            "person": 1,
            "action": 2,
            "brain": 2,
            "imaging": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para13",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 38,
              "end_char": 40,
              "context": "These six disciplines compose most of AI. Yet AI researchers have devoted little effort to"
            },
            {
              "para_id": "chap1_para13",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 103,
              "end_char": 109,
              "context": "archers have devoted little effort to passing the Turing test, believing that it is more important to stud"
            },
            {
              "para_id": "chap1_para13",
              "entity_text": "Aeronautical",
              "entity_type": "ORG",
              "start_char": 365,
              "end_char": 377,
              "context": "ing wind tunnels and learning about aerodynamics. Aeronautical engineering texts do not define the goal of their"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para14",
          "content": "Once we have a sufficiently precise theory of the mind, it becomes possible to express the theory as a computer program. If the program’s input–output behavior matches corresponding human behavior, that is evidence that some of the program’s mechanisms could also be operating in humans.",
          "sentence_count": 2,
          "char_count": 243,
          "prev_para_id": "chap1_para13",
          "next_para_id": "chap1_para15",
          "style_metadata": {
            "para_id": "chap1_para14",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 2
          },
          "terminology": {
            "precise": 1,
            "theory": 2,
            "mind": 1,
            "becomes": 1,
            "possible": 1,
            "express": 1,
            "computer": 1,
            "program": 3,
            "input–output": 1,
            "behavior": 2,
            "match": 1,
            "corresponding": 1,
            "human": 2,
            "evidence": 1,
            "mechanism": 1,
            "operating": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para15",
          "content": "For example, Allen Newell and Herbert Simon, who developed GPS, the “General Problem Solver” (Newell and Simon, 1961), were not content merely to have their program solve\nproblems correctly. They were more concerned with comparing the sequence and timing of its reasoning steps to those of human subjects solving the same problems. The interdisciplinary field of\ncognitive science\nbrings together computer models from AI and experimental techniques from psychology to construct precise and testable theories of the human mind.",
          "sentence_count": 3,
          "char_count": 451,
          "prev_para_id": "chap1_para14",
          "next_para_id": "chap1_para16",
          "style_metadata": {
            "para_id": "chap1_para15",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 3
          },
          "terminology": {
            "example": 1,
            "allen": 1,
            "herbert": 1,
            "simon": 2,
            "developed": 1,
            "gps": 1,
            "general": 1,
            "problem": 3,
            "solver": 1,
            "content": 1,
            "program": 1,
            "solve": 1,
            "concerned": 1,
            "comparing": 1,
            "sequence": 1,
            "timing": 1,
            "reasoning": 1,
            "step": 1,
            "human": 2,
            "subject": 1,
            "solving": 1,
            "interdisciplinary": 1,
            "field": 1,
            "cognitive": 1,
            "science": 1,
            "brings": 1,
            "computer": 1,
            "model": 1,
            "experimental": 1,
            "technique": 1,
            "psychology": 1,
            "construct": 1,
            "precise": 1,
            "testable": 1,
            "theory": 1,
            "mind": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para15",
              "entity_text": "Allen Newell",
              "entity_type": "PERSON",
              "start_char": 13,
              "end_char": 25,
              "context": "For example, Allen Newell and Herbert Simon, who developed GPS, the “Genera"
            },
            {
              "para_id": "chap1_para15",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 30,
              "end_char": 43,
              "context": "For example, Allen Newell and Herbert Simon, who developed GPS, the “General Problem Solver” "
            },
            {
              "para_id": "chap1_para15",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 94,
              "end_char": 100,
              "context": " who developed GPS, the “General Problem Solver” (Newell and Simon, 1961), were not content merely to have"
            },
            {
              "para_id": "chap1_para15",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 105,
              "end_char": 110,
              "context": "ped GPS, the “General Problem Solver” (Newell and Simon, 1961), were not content merely to have their pro"
            },
            {
              "para_id": "chap1_para15",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 418,
              "end_char": 420,
              "context": "tive science\nbrings together computer models from AI and experimental techniques from psychology to co"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para16",
          "content": "Cognitive science is a fascinating field in itself, worthy of several textbooks and at least one encyclopedia (Wilson and Keil, 1999). We will occasionally comment on similarities or differences between AI techniques and human cognition. Real cognitive science, however, is necessarily based on experimental investigation of actual humans or animals. We will leave that for other books, as we assume the reader has only a computer for experimentation.",
          "sentence_count": 4,
          "char_count": 384,
          "prev_para_id": "chap1_para15",
          "next_para_id": "chap1_para17",
          "style_metadata": {
            "para_id": "chap1_para16",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 19.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 79,
            "sentence_count": 4
          },
          "terminology": {
            "cognitive": 2,
            "science": 2,
            "fascinating": 1,
            "field": 1,
            "worthy": 1,
            "several": 1,
            "textbook": 1,
            "least": 1,
            "encyclopedia": 1,
            "wilson": 1,
            "keil": 1,
            "comment": 1,
            "similarity": 1,
            "difference": 1,
            "technique": 1,
            "human": 2,
            "cognition": 1,
            "real": 1,
            "based": 1,
            "experimental": 1,
            "investigation": 1,
            "actual": 1,
            "animal": 1,
            "leave": 1,
            "book": 1,
            "assume": 1,
            "reader": 1,
            "computer": 1,
            "experimentation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para16",
              "entity_text": "Wilson",
              "entity_type": "ORG",
              "start_char": 111,
              "end_char": 117,
              "context": " several textbooks and at least one encyclopedia (Wilson and Keil, 1999). We will occasionally comment on "
            },
            {
              "para_id": "chap1_para16",
              "entity_text": "Keil",
              "entity_type": "GPE",
              "start_char": 122,
              "end_char": 126,
              "context": "xtbooks and at least one encyclopedia (Wilson and Keil, 1999). We will occasionally comment on similarit"
            },
            {
              "para_id": "chap1_para16",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 203,
              "end_char": 205,
              "context": "ly comment on similarities or differences between AI techniques and human cognition. Real cognitive sc"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para17",
          "content": "In the early days of AI there was often confusion between the approaches. An author would argue that an algorithm performs well on a task and that it is\ntherefore\na good model of human performance, or vice versa. Modern authors separate the two kinds of claims; this distinction has allowed both AI and cognitive science to develop more rapidly. The two fields fertilize each other, most notably in computer vision, which incorporates neurophysiological evidence into computational models. Recently, the combination of neuroimaging methods combined with machine learning techniques for analyzing such data has led to the beginnings of a capability to “read minds”—that is, to ascertain the semantic content of a person’s inner thoughts. This capability could, in turn, shed further light on how human cognition works.",
          "sentence_count": 6,
          "char_count": 692,
          "prev_para_id": "chap1_para16",
          "next_para_id": "chap1_para18",
          "style_metadata": {
            "para_id": "chap1_para17",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 24.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 147,
            "sentence_count": 6
          },
          "terminology": {
            "early": 1,
            "day": 1,
            "confusion": 1,
            "approach": 1,
            "author": 2,
            "argue": 1,
            "algorithm": 1,
            "performs": 1,
            "good": 1,
            "model": 2,
            "human": 2,
            "performance": 1,
            "vice": 1,
            "versa": 1,
            "modern": 1,
            "separate": 1,
            "kind": 1,
            "claim": 1,
            "distinction": 1,
            "allowed": 1,
            "cognitive": 1,
            "science": 1,
            "develop": 1,
            "field": 1,
            "computer": 1,
            "vision": 1,
            "incorporates": 1,
            "neurophysiological": 1,
            "evidence": 1,
            "computational": 1,
            "combination": 1,
            "neuroimaging": 1,
            "method": 1,
            "combined": 1,
            "machine": 1,
            "learning": 1,
            "technique": 1,
            "analyzing": 1,
            "data": 1,
            "led": 1,
            "beginning": 1,
            "capability": 2,
            "read": 1,
            "mind": 1,
            "ascertain": 1,
            "semantic": 1,
            "content": 1,
            "person": 1,
            "inner": 1,
            "thought": 1,
            "turn": 1,
            "shed": 1,
            "light": 1,
            "cognition": 1,
            "work": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para17",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 21,
              "end_char": 23,
              "context": "In the early days of AI there was often confusion between the approaches."
            },
            {
              "para_id": "chap1_para17",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 296,
              "end_char": 298,
              "context": "inds of claims; this distinction has allowed both AI and cognitive science to develop more rapidly. Th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para18",
          "content": "1.1.3\nThinking rationally: The “laws of thought” approach\nThe Greek philosopher Aristotle was one of the first to attempt to codify “right thinking”—that is, irrefutable reasoning processes. His\nsyllogisms\nprovided patterns for argument structures that always yielded correct conclusions when given correct premises. The canonical example starts with\nSocrates is a man\nand\nall men are mortal\nand concludes that\nSocrates is mortal.",
          "sentence_count": 3,
          "char_count": 377,
          "prev_para_id": "chap1_para17",
          "next_para_id": "chap1_para19",
          "style_metadata": {
            "para_id": "chap1_para18",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 3
          },
          "terminology": {
            "thinking": 2,
            "law": 1,
            "thought": 1,
            "approach": 1,
            "greek": 1,
            "first": 1,
            "attempt": 1,
            "codify": 1,
            "right": 1,
            "irrefutable": 1,
            "reasoning": 1,
            "process": 1,
            "syllogism": 1,
            "provided": 1,
            "pattern": 1,
            "argument": 1,
            "structure": 1,
            "yielded": 1,
            "correct": 2,
            "conclusion": 1,
            "given": 1,
            "premise": 1,
            "canonical": 1,
            "example": 1,
            "start": 1,
            "socrates": 2,
            "man": 1,
            "men": 1,
            "mortal": 2,
            "concludes": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para18",
              "entity_text": "Aristotle",
              "entity_type": "PERSON",
              "start_char": 80,
              "end_char": 89,
              "context": " “laws of thought” approach\nThe Greek philosopher Aristotle was one of the first to attempt to codify “right "
            },
            {
              "para_id": "chap1_para18",
              "entity_text": "Socrates",
              "entity_type": "PRODUCT",
              "start_char": 351,
              "end_char": 359,
              "context": "rrect premises. The canonical example starts with\nSocrates is a man\nand\nall men are mortal\nand concludes tha"
            },
            {
              "para_id": "chap1_para18",
              "entity_text": "Socrates",
              "entity_type": "PRODUCT",
              "start_char": 411,
              "end_char": 419,
              "context": "s a man\nand\nall men are mortal\nand concludes that\nSocrates is mortal."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para19",
          "content": "(This example is probably due to Sextus Empiricus rather than Aristotle.) These laws of thought were supposed to govern the operation of the mind; their study initiated the field called\nlogic\n.",
          "sentence_count": 2,
          "char_count": 164,
          "prev_para_id": "chap1_para18",
          "next_para_id": "chap1_para20",
          "style_metadata": {
            "para_id": "chap1_para19",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.028,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 2
          },
          "terminology": {
            "example": 1,
            "due": 1,
            "sextus": 1,
            "empiricus": 1,
            "aristotle": 1,
            "law": 1,
            "thought": 1,
            "supposed": 1,
            "govern": 1,
            "operation": 1,
            "mind": 1,
            "study": 1,
            "initiated": 1,
            "field": 1,
            "called": 1,
            "logic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para19",
              "entity_text": "Sextus Empiricus",
              "entity_type": "ORG",
              "start_char": 33,
              "end_char": 49,
              "context": "(This example is probably due to Sextus Empiricus rather than Aristotle.) These laws of thought wer"
            },
            {
              "para_id": "chap1_para19",
              "entity_text": "Aristotle",
              "entity_type": "ORG",
              "start_char": 62,
              "end_char": 71,
              "context": "e is probably due to Sextus Empiricus rather than Aristotle.) These laws of thought were supposed to govern t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para20",
          "content": "Logicians in the 19th century developed a precise notation for statements about objects in the world and the relations among them. (Contrast this with ordinary arithmetic notation, which provides only for statements about\nnumbers.",
          "sentence_count": 2,
          "char_count": 198,
          "prev_para_id": "chap1_para19",
          "next_para_id": "chap1_para21",
          "style_metadata": {
            "para_id": "chap1_para20",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "logician": 1,
            "19th": 1,
            "century": 1,
            "developed": 1,
            "precise": 1,
            "notation": 2,
            "statement": 2,
            "object": 1,
            "world": 1,
            "relation": 1,
            "contrast": 1,
            "ordinary": 1,
            "arithmetic": 1,
            "provides": 1,
            "number": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para21",
          "content": ") By 1965, programs could, in principle, solve\nany\nsolvable problem described in logical notation. The so-called\nlogicist\ntradition within artificial intelligence hopes to build on such programs to create intelligent systems.",
          "sentence_count": 2,
          "char_count": 198,
          "prev_para_id": "chap1_para20",
          "next_para_id": "chap1_para22",
          "style_metadata": {
            "para_id": "chap1_para21",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "program": 2,
            "principle": 1,
            "solve": 1,
            "solvable": 1,
            "problem": 1,
            "described": 1,
            "logical": 1,
            "notation": 1,
            "so-called": 1,
            "logicist": 1,
            "tradition": 1,
            "artificial": 1,
            "intelligence": 1,
            "hope": 1,
            "build": 1,
            "create": 1,
            "intelligent": 1,
            "system": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para22",
          "content": "Logic as conventionally understood requires knowledge of the world that is\ncertain\n—a condition that, in reality, is seldom achieved. We simply don’t know the rules of, say, politics or warfare in the same way that we know the rules of chess or arithmetic. The theory of\nprobability\nfills this gap, allowing rigorous reasoning with uncertain information. In principle, it allows the construction of a comprehensive model of rational thought, leading from raw perceptual information to an understanding of how the world works to predictions about the future. What it does not do, is generate intelligent\nbehavior.",
          "sentence_count": 5,
          "char_count": 521,
          "prev_para_id": "chap1_para21",
          "next_para_id": "chap1_para23",
          "style_metadata": {
            "para_id": "chap1_para22",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 5
          },
          "terminology": {
            "logic": 1,
            "understood": 1,
            "requires": 1,
            "knowledge": 1,
            "world": 2,
            "certain": 1,
            "condition": 1,
            "reality": 1,
            "achieved": 1,
            "know": 2,
            "rule": 2,
            "say": 1,
            "politics": 1,
            "warfare": 1,
            "way": 1,
            "arithmetic": 1,
            "theory": 1,
            "probability": 1,
            "fill": 1,
            "gap": 1,
            "allowing": 1,
            "rigorous": 1,
            "reasoning": 1,
            "uncertain": 1,
            "information": 2,
            "principle": 1,
            "allows": 1,
            "construction": 1,
            "comprehensive": 1,
            "model": 1,
            "rational": 1,
            "thought": 1,
            "leading": 1,
            "raw": 1,
            "perceptual": 1,
            "understanding": 1,
            "work": 1,
            "prediction": 1,
            "future": 1,
            "generate": 1,
            "intelligent": 1,
            "behavior": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para23",
          "content": "For that, we need a theory of rational action. Rational thought, by itself, is not enough.",
          "sentence_count": 2,
          "char_count": 75,
          "prev_para_id": "chap1_para22",
          "next_para_id": "chap1_para24",
          "style_metadata": {
            "para_id": "chap1_para23",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 2
          },
          "terminology": {
            "need": 1,
            "theory": 1,
            "rational": 2,
            "action": 1,
            "thought": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para24",
          "content": "1.1.4\nActing rationally: The rational agent approach\nAn\nagent\nis just something that acts (\nagent\ncomes from the Latin\nagere,\nto do). Of course, all computer programs do something, but computer agents are expected to do more: operate autonomously, perceive their environment, persist over a prolonged time period, adapt to\nchange, and create and pursue goals. A\nrational agent\nis one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.",
          "sentence_count": 3,
          "char_count": 417,
          "prev_para_id": "chap1_para23",
          "next_para_id": "chap1_para25",
          "style_metadata": {
            "para_id": "chap1_para24",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 3
          },
          "terminology": {
            "acting": 1,
            "rational": 2,
            "agent": 5,
            "approach": 1,
            "something": 2,
            "act": 2,
            "come": 1,
            "agere": 1,
            "course": 1,
            "computer": 2,
            "program": 1,
            "expected": 2,
            "perceive": 1,
            "environment": 1,
            "persist": 1,
            "prolonged": 1,
            "time": 1,
            "period": 1,
            "change": 1,
            "create": 1,
            "pursue": 1,
            "goal": 1,
            "achieve": 1,
            "best": 2,
            "outcome": 2,
            "uncertainty": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para25",
          "content": "In the “laws of thought” approach to AI, the emphasis was on correct inferences. Making correct inferences is sometimes\npart\nof being a rational agent, because one way to act rationally is to deduce that a given action is best and then to act on that conclusion. On the other hand, there are ways of acting rationally that cannot be said to involve inference. For example, recoiling from a hot stove is a reflex action that is usually more successful than a slower action taken after careful deliberation.",
          "sentence_count": 4,
          "char_count": 420,
          "prev_para_id": "chap1_para24",
          "next_para_id": "chap1_para26",
          "style_metadata": {
            "para_id": "chap1_para25",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 4
          },
          "terminology": {
            "law": 1,
            "thought": 1,
            "approach": 1,
            "emphasis": 1,
            "correct": 2,
            "inference": 3,
            "making": 1,
            "part": 1,
            "rational": 1,
            "agent": 1,
            "way": 2,
            "act": 2,
            "deduce": 1,
            "given": 1,
            "action": 3,
            "best": 1,
            "conclusion": 1,
            "hand": 1,
            "acting": 1,
            "said": 1,
            "involve": 1,
            "example": 1,
            "recoiling": 1,
            "hot": 1,
            "stove": 1,
            "reflex": 1,
            "successful": 1,
            "slower": 1,
            "taken": 1,
            "careful": 1,
            "deliberation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para25",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 37,
              "end_char": 39,
              "context": "In the “laws of thought” approach to AI, the emphasis was on correct inferences. Making c"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para26",
          "content": "All the skills needed for the Turing test also allow an agent to act rationally. Knowledge representation and reasoning enable agents to reach good decisions. We need to be able to generate comprehensible sentences in natural language to get by in a complex society. We need learning not only for erudition, but also because it improves our ability to generate effective behavior, especially in circumstances that are new.",
          "sentence_count": 4,
          "char_count": 355,
          "prev_para_id": "chap1_para25",
          "next_para_id": "chap1_para27",
          "style_metadata": {
            "para_id": "chap1_para26",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 4
          },
          "terminology": {
            "skill": 1,
            "needed": 1,
            "turing": 1,
            "test": 1,
            "allow": 1,
            "agent": 2,
            "act": 1,
            "knowledge": 1,
            "representation": 1,
            "reasoning": 1,
            "enable": 1,
            "reach": 1,
            "good": 1,
            "decision": 1,
            "need": 2,
            "able": 1,
            "generate": 2,
            "comprehensible": 1,
            "sentence": 1,
            "natural": 1,
            "language": 1,
            "get": 1,
            "complex": 1,
            "society": 1,
            "learning": 1,
            "erudition": 1,
            "improves": 1,
            "ability": 1,
            "effective": 1,
            "behavior": 1,
            "circumstance": 1,
            "new": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para26",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 30,
              "end_char": 36,
              "context": "All the skills needed for the Turing test also allow an agent to act rationally. Knowl"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para27",
          "content": "The rational-agent approach to AI has two advantages over the other approaches. First, it is more general than the “laws of thought” approach because correct inference is just one of several possible mechanisms for achieving rationality. Second, it is more amenable to scientific development. The standard of rationality is mathematically well defined and completely general. We can often work back from this specification to derive agent designs that provably achieve it—something that is largely impossible if the goal is to imitate human behavior or thought processes.",
          "sentence_count": 5,
          "char_count": 486,
          "prev_para_id": "chap1_para26",
          "next_para_id": "chap1_para28",
          "style_metadata": {
            "para_id": "chap1_para27",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 5
          },
          "terminology": {
            "rational-agent": 1,
            "approach": 3,
            "advantage": 1,
            "general": 2,
            "law": 1,
            "thought": 2,
            "correct": 1,
            "inference": 1,
            "several": 1,
            "possible": 1,
            "mechanism": 1,
            "achieving": 1,
            "rationality": 2,
            "second": 1,
            "amenable": 1,
            "scientific": 1,
            "development": 1,
            "standard": 1,
            "defined": 1,
            "work": 1,
            "specification": 1,
            "derive": 1,
            "agent": 1,
            "design": 1,
            "achieve": 1,
            "it—something": 1,
            "impossible": 1,
            "goal": 1,
            "imitate": 1,
            "human": 1,
            "behavior": 1,
            "process": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para27",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 31,
              "end_char": 33,
              "context": "The rational-agent approach to AI has two advantages over the other approaches. Fir"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para28",
          "content": "For these reasons, the rational-agent approach to AI has prevailed throughout most of the field’s history. In the early decades, rational agents were built on logical foundations and formed definite plans to achieve specific goals. Later, methods based on probability theory and machine learning allowed the creation of agents that could make decisions under uncertainty to attain the best expected outcome. In a nutshell,\nAI has focused on the study and construction of agents that\ndo the right thing\n.",
          "sentence_count": 4,
          "char_count": 427,
          "prev_para_id": "chap1_para27",
          "next_para_id": "chap1_para29",
          "style_metadata": {
            "para_id": "chap1_para28",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 4
          },
          "terminology": {
            "reason": 1,
            "rational-agent": 1,
            "approach": 1,
            "prevailed": 1,
            "field": 1,
            "history": 1,
            "early": 1,
            "decade": 1,
            "rational": 1,
            "agent": 3,
            "built": 1,
            "logical": 1,
            "foundation": 1,
            "formed": 1,
            "definite": 1,
            "plan": 1,
            "achieve": 1,
            "specific": 1,
            "goal": 1,
            "method": 1,
            "based": 1,
            "probability": 1,
            "theory": 1,
            "machine": 1,
            "learning": 1,
            "allowed": 1,
            "creation": 1,
            "make": 1,
            "decision": 1,
            "uncertainty": 1,
            "attain": 1,
            "expected": 1,
            "outcome": 1,
            "nutshell": 1,
            "focused": 1,
            "study": 1,
            "construction": 1,
            "right": 1,
            "thing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para28",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 50,
              "end_char": 52,
              "context": "For these reasons, the rational-agent approach to AI has prevailed throughout most of the field’s hist"
            },
            {
              "para_id": "chap1_para28",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 423,
              "end_char": 425,
              "context": " attain the best expected outcome. In a nutshell,\nAI has focused on the study and construction of agen"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para29",
          "content": "What counts as the right thing is defined by the objective that we provide to the agent. This general paradigm is so pervasive that we might call it the\nstandard model\n. It prevails not only in AI, but also in control theory, where a controller minimizes a cost function; in operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss function; and in economics, where a decision maker maximizes utility or some measure of social welfare.",
          "sentence_count": 3,
          "char_count": 413,
          "prev_para_id": "chap1_para28",
          "next_para_id": "chap1_para30",
          "style_metadata": {
            "para_id": "chap1_para29",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 3
          },
          "terminology": {
            "count": 1,
            "right": 1,
            "thing": 1,
            "defined": 1,
            "objective": 1,
            "provide": 1,
            "agent": 1,
            "general": 1,
            "paradigm": 1,
            "pervasive": 1,
            "call": 1,
            "standard": 1,
            "model": 1,
            "prevails": 1,
            "control": 1,
            "theory": 1,
            "controller": 1,
            "minimizes": 2,
            "cost": 1,
            "function": 2,
            "operation": 1,
            "research": 1,
            "policy": 1,
            "maximizes": 2,
            "sum": 1,
            "reward": 1,
            "statistic": 1,
            "decision": 2,
            "rule": 1,
            "loss": 1,
            "economics": 1,
            "maker": 1,
            "utility": 1,
            "measure": 1,
            "social": 1,
            "welfare": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para29",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 194,
              "end_char": 196,
              "context": "l it the\nstandard model\n. It prevails not only in AI, but also in control theory, where a controller m"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para30",
          "content": "We need to make one important refinement to the standard model to account for the fact that perfect rationality—always taking the exactly optimal action—is not feasible in complex environments. The computational demands are just too high.",
          "sentence_count": 2,
          "char_count": 203,
          "prev_para_id": "chap1_para29",
          "next_para_id": "chap1_para31",
          "style_metadata": {
            "para_id": "chap1_para30",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "make": 1,
            "important": 1,
            "refinement": 1,
            "standard": 1,
            "model": 1,
            "account": 1,
            "fact": 1,
            "perfect": 1,
            "rationality—always": 1,
            "taking": 1,
            "optimal": 1,
            "action—is": 1,
            "feasible": 1,
            "complex": 1,
            "environment": 1,
            "computational": 1,
            "demand": 1,
            "high": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para31",
          "content": "Chapters 6\nand\n16\ndeal with the issue of\nlimited rationality\n—acting appropriately when there is not enough time to do all the computations one might like. However, perfect rationality often remains a good starting point for theoretical analysis.",
          "sentence_count": 2,
          "char_count": 213,
          "prev_para_id": "chap1_para30",
          "next_para_id": "chap1_para32",
          "style_metadata": {
            "para_id": "chap1_para31",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 42,
            "sentence_count": 2
          },
          "terminology": {
            "chapter": 1,
            "deal": 1,
            "issue": 1,
            "limited": 1,
            "rationality": 2,
            "—acting": 1,
            "enough": 1,
            "time": 1,
            "computation": 1,
            "like": 1,
            "perfect": 1,
            "remains": 1,
            "good": 1,
            "starting": 1,
            "point": 1,
            "theoretical": 1,
            "analysis": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para32",
          "content": "1.1.5\nBeneficial machines\nThe standard model has been a useful guide for AI research since its inception, but it is probably not the right model in the long run. The reason is that the standard model assumes that we will supply a fully specified objective to the machine.",
          "sentence_count": 2,
          "char_count": 226,
          "prev_para_id": "chap1_para31",
          "next_para_id": "chap1_para33",
          "style_metadata": {
            "para_id": "chap1_para32",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 2
          },
          "terminology": {
            "beneficial": 1,
            "machine": 2,
            "standard": 2,
            "model": 3,
            "useful": 1,
            "guide": 1,
            "research": 1,
            "inception": 1,
            "right": 1,
            "long": 1,
            "run": 1,
            "reason": 1,
            "assumes": 1,
            "specified": 1,
            "objective": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para32",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 73,
              "end_char": 75,
              "context": "es\nThe standard model has been a useful guide for AI research since its inception, but it is probably "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para33",
          "content": "For an artificially defined task such as chess or shortest-path computation, the task comes with an objective built in—so the standard model is applicable. As we move into the real world, however, it becomes more and more difficult to specify the objective completely and\ncorrectly. For example, in designing a self-driving car, one might think that the objective is to reach the destination safely. But driving along any road incurs a risk of injury due to other errant drivers, equipment failure, and so on; thus, a strict goal of safety requires staying in the garage. There is a tradeoff between making progress towards the destination and incurring a risk of injury. How should this tradeoff be made? Furthermore, to what extent can we allow the car to take actions that would annoy other drivers? How much should the car moderate its acceleration, steering, and braking to avoid shaking up the passenger? These kinds of questions are difficult to answer a priori. They are particularly problematic in the general area of human–robot interaction, of which the self-driving car is one example.",
          "sentence_count": 10,
          "char_count": 919,
          "prev_para_id": "chap1_para32",
          "next_para_id": "chap1_para34",
          "style_metadata": {
            "para_id": "chap1_para33",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 20.3,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore",
              "however"
            ],
            "word_count": 203,
            "sentence_count": 10
          },
          "terminology": {
            "defined": 1,
            "task": 2,
            "chess": 1,
            "shortest-path": 1,
            "computation": 1,
            "come": 1,
            "objective": 3,
            "built": 1,
            "in—so": 1,
            "standard": 1,
            "model": 1,
            "applicable": 1,
            "move": 1,
            "real": 1,
            "world": 1,
            "becomes": 1,
            "difficult": 2,
            "specify": 1,
            "example": 2,
            "designing": 1,
            "self-driving": 2,
            "car": 4,
            "think": 1,
            "reach": 1,
            "destination": 2,
            "driving": 1,
            "road": 1,
            "incurs": 1,
            "risk": 2,
            "injury": 2,
            "due": 1,
            "errant": 1,
            "driver": 2,
            "equipment": 1,
            "failure": 1,
            "strict": 1,
            "goal": 1,
            "safety": 1,
            "requires": 1,
            "staying": 1,
            "garage": 1,
            "tradeoff": 2,
            "making": 1,
            "progress": 1,
            "towards": 1,
            "incurring": 1,
            "made": 1,
            "extent": 1,
            "allow": 1,
            "take": 1,
            "action": 1,
            "annoy": 1,
            "much": 1,
            "moderate": 1,
            "acceleration": 1,
            "steering": 1,
            "braking": 1,
            "avoid": 1,
            "shaking": 1,
            "passenger": 1,
            "kind": 1,
            "question": 1,
            "answer": 1,
            "problematic": 1,
            "general": 1,
            "area": 1,
            "human–robot": 1,
            "interaction": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para34",
          "content": "The problem of achieving agreement between our true preferences and the objective we put into the machine is called the\nvalue alignment problem\n: the values or objectives put into the machine must be aligned with those of the human. If we are developing an AI system in the lab or in a simulator—as has been the case for most of the field’s history—there is an easy fix for an incorrectly specified objective: reset the system, fix the objective, and try again. As the field progresses towards increasingly capable intelligent systems that are deployed in the real world, this approach is no longer viable. A system deployed with an incorrect objective will have negative consequences. Moreover, the more intelligent the system, the more negative the consequences.",
          "sentence_count": 5,
          "char_count": 641,
          "prev_para_id": "chap1_para33",
          "next_para_id": "chap1_para35",
          "style_metadata": {
            "para_id": "chap1_para34",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 27.8,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 139,
            "sentence_count": 5
          },
          "terminology": {
            "problem": 2,
            "achieving": 1,
            "agreement": 1,
            "true": 1,
            "preference": 1,
            "objective": 5,
            "put": 2,
            "machine": 2,
            "called": 1,
            "value": 2,
            "alignment": 1,
            "aligned": 1,
            "human": 1,
            "developing": 1,
            "system": 5,
            "lab": 1,
            "simulator—as": 1,
            "case": 1,
            "field": 2,
            "easy": 1,
            "fix": 2,
            "specified": 1,
            "reset": 1,
            "try": 1,
            "progress": 1,
            "towards": 1,
            "capable": 1,
            "intelligent": 2,
            "deployed": 2,
            "real": 1,
            "world": 1,
            "approach": 1,
            "viable": 1,
            "incorrect": 1,
            "negative": 2,
            "consequence": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para34",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 257,
              "end_char": 259,
              "context": " with those of the human. If we are developing an AI system in the lab or in a simulator—as has been t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para35",
          "content": "Returning to the apparently unproblematic example of chess, consider what happens if the machine is intelligent enough to reason and act beyond the confines of the chessboard. In that case, it might attempt to increase its chances of winning by such ruses as hypnotizing or blackmailing its opponent or bribing the audience to make rustling noises during its opponent’s thinking time.",
          "sentence_count": 2,
          "char_count": 324,
          "prev_para_id": "chap1_para34",
          "next_para_id": "chap1_para36",
          "style_metadata": {
            "para_id": "chap1_para35",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 2
          },
          "terminology": {
            "returning": 1,
            "unproblematic": 1,
            "example": 1,
            "chess": 1,
            "consider": 1,
            "happens": 1,
            "machine": 1,
            "intelligent": 1,
            "reason": 1,
            "act": 1,
            "confines": 1,
            "chessboard": 1,
            "case": 1,
            "attempt": 1,
            "increase": 1,
            "chance": 1,
            "winning": 1,
            "rus": 1,
            "hypnotizing": 1,
            "blackmailing": 1,
            "opponent": 2,
            "bribing": 1,
            "audience": 1,
            "make": 1,
            "rustling": 1,
            "noise": 1,
            "thinking": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para36",
          "content": "3\nIt might also attempt to hijack additional computing power for itself.",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap1_para35",
          "next_para_id": "chap1_para37",
          "style_metadata": {
            "para_id": "chap1_para36",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "attempt": 1,
            "hijack": 1,
            "additional": 1,
            "computing": 1,
            "power": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para37",
          "content": "These behaviors are not “unintelligent” or “insane”; they are a logical consequence of defining winning as the\nsole\nobjective for the machine.",
          "sentence_count": 1,
          "char_count": 123,
          "prev_para_id": "chap1_para36",
          "next_para_id": "chap1_para38",
          "style_metadata": {
            "para_id": "chap1_para37",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "behavior": 1,
            "unintelligent": 1,
            "insane": 1,
            "logical": 1,
            "consequence": 1,
            "defining": 1,
            "winning": 1,
            "sole": 1,
            "objective": 1,
            "machine": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para38",
          "content": "It is impossible to anticipate all the ways in which a machine pursuing a fixed objective might misbehave. There is good reason, then, to think that the standard model is inadequate. We don’t want machines that are intelligent in the sense of pursuing\ntheir\nobjectives; we want them to pursue\nour\nobjectives. If we cannot transfer those objectives perfectly to the machine, then we need a new formulation—one in which the machine is pursuing our objectives, but is necessarily\nuncertain\nas to what they are. When a machine knows that it doesn’t know the complete objective, it has an incentive to act cautiously, to ask permission, to learn more about our preferences through observation, and to defer to human control. Ultimately, we want agents that are\nprovably beneficial\nto humans. We will return to this topic in\nSection 1.5\n.",
          "sentence_count": 7,
          "char_count": 703,
          "prev_para_id": "chap1_para37",
          "next_para_id": "chap1_para39",
          "style_metadata": {
            "para_id": "chap1_para38",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 161,
            "sentence_count": 7
          },
          "terminology": {
            "impossible": 1,
            "anticipate": 1,
            "way": 1,
            "machine": 5,
            "pursuing": 3,
            "fixed": 1,
            "objective": 6,
            "misbehave": 1,
            "good": 1,
            "reason": 1,
            "think": 1,
            "standard": 1,
            "model": 1,
            "inadequate": 1,
            "want": 3,
            "intelligent": 1,
            "sense": 1,
            "pursue": 1,
            "transfer": 1,
            "need": 1,
            "new": 1,
            "uncertain": 1,
            "know": 2,
            "complete": 1,
            "incentive": 1,
            "act": 1,
            "ask": 1,
            "permission": 1,
            "learn": 1,
            "preference": 1,
            "observation": 1,
            "defer": 1,
            "human": 2,
            "control": 1,
            "agent": 1,
            "beneficial": 1,
            "return": 1,
            "topic": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para39",
          "content": "1.2The Foundations of Artificial Intelligence\n1.2\nThe Foundations of Artificial Intelligence\nIn this section, we provide a brief history of the disciplines that contributed ideas, viewpoints, and techniques to AI. Like any history, this one concentrates on a small number of people, events, and ideas and ignores others that also were important. We organize the history around a series of questions. We certainly would not wish to give the impression that these questions are the only ones the disciplines address or that the disciplines have all been working toward AI as their ultimate fruition.",
          "sentence_count": 4,
          "char_count": 507,
          "prev_para_id": "chap1_para38",
          "next_para_id": "chap1_para40",
          "style_metadata": {
            "para_id": "chap1_para39",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "foundation": 2,
            "artificial": 2,
            "intelligence": 2,
            "section": 1,
            "provide": 1,
            "brief": 1,
            "history": 3,
            "discipline": 3,
            "contributed": 1,
            "idea": 2,
            "viewpoint": 1,
            "technique": 1,
            "concentrate": 1,
            "small": 1,
            "number": 1,
            "people": 1,
            "event": 1,
            "ignores": 1,
            "others": 1,
            "important": 1,
            "organize": 1,
            "series": 1,
            "question": 2,
            "wish": 1,
            "give": 1,
            "impression": 1,
            "one": 1,
            "working": 1,
            "ultimate": 1,
            "fruition": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para39",
              "entity_text": "Foundations of Artificial Intelligence",
              "entity_type": "ORG",
              "start_char": 7,
              "end_char": 45,
              "context": "1.2The Foundations of Artificial Intelligence\n1.2\nThe Foundations of Artificial Intelligence\nIn"
            },
            {
              "para_id": "chap1_para39",
              "entity_text": "The Foundations of Artificial Intelligence",
              "entity_type": "ORG",
              "start_char": 50,
              "end_char": 92,
              "context": "1.2The Foundations of Artificial Intelligence\n1.2\nThe Foundations of Artificial Intelligence\nIn this section, we provide a brief history of th"
            },
            {
              "para_id": "chap1_para39",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 210,
              "end_char": 212,
              "context": " contributed ideas, viewpoints, and techniques to AI. Like any history, this one concentrates on a sma"
            },
            {
              "para_id": "chap1_para39",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 567,
              "end_char": 569,
              "context": "that the disciplines have all been working toward AI as their ultimate fruition."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para40",
          "content": "1.2.1\nPhilosophy\n•\nCan formal rules be used to draw valid conclusions?",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap1_para39",
          "next_para_id": "chap1_para41",
          "style_metadata": {
            "para_id": "chap1_para40",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "philosophy": 1,
            "formal": 1,
            "rule": 1,
            "used": 1,
            "draw": 1,
            "valid": 1,
            "conclusion": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para41",
          "content": "•\nHow does the mind arise from a physical brain?",
          "sentence_count": 1,
          "char_count": 40,
          "prev_para_id": "chap1_para40",
          "next_para_id": "chap1_para42",
          "style_metadata": {
            "para_id": "chap1_para41",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "mind": 1,
            "arise": 1,
            "physical": 1,
            "brain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para42",
          "content": "•\nWhere does knowledge come from?",
          "sentence_count": 1,
          "char_count": 29,
          "prev_para_id": "chap1_para41",
          "next_para_id": "chap1_para43",
          "style_metadata": {
            "para_id": "chap1_para42",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 7,
            "sentence_count": 1
          },
          "terminology": {
            "knowledge": 1,
            "come": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para43",
          "content": "•\nHow does knowledge lead to action?",
          "sentence_count": 1,
          "char_count": 31,
          "prev_para_id": "chap1_para42",
          "next_para_id": "chap1_para44",
          "style_metadata": {
            "para_id": "chap1_para43",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 8,
            "sentence_count": 1
          },
          "terminology": {
            "knowledge": 1,
            "lead": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para44",
          "content": "Aristotle (384–322\nBCE\n) was the first to formulate a precise set of laws governing the rational part of the mind. He developed an informal system of syllogisms for proper reasoning, which in principle allowed one to generate conclusions mechanically, given initial premises.",
          "sentence_count": 2,
          "char_count": 235,
          "prev_para_id": "chap1_para43",
          "next_para_id": "chap1_para45",
          "style_metadata": {
            "para_id": "chap1_para44",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "bce": 1,
            "formulate": 1,
            "precise": 1,
            "set": 1,
            "law": 1,
            "governing": 1,
            "rational": 1,
            "part": 1,
            "mind": 1,
            "developed": 1,
            "informal": 1,
            "system": 1,
            "syllogism": 1,
            "proper": 1,
            "reasoning": 1,
            "principle": 1,
            "allowed": 1,
            "generate": 1,
            "conclusion": 1,
            "given": 1,
            "initial": 1,
            "premise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para44",
              "entity_text": "Aristotle",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 9,
              "context": "Aristotle (384–322\nBCE\n) was the first to formulate a preci"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para45",
          "content": "Ramon Llull (c. 1232–1315) devised a system of reasoning published as\nArs Magna\nor\nThe Great Art\n(1305). Llull tried to implement his system using an actual mechanical device: a set of paper wheels that could be rotated into different permutations.",
          "sentence_count": 2,
          "char_count": 212,
          "prev_para_id": "chap1_para44",
          "next_para_id": "chap1_para46",
          "style_metadata": {
            "para_id": "chap1_para45",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "ramon": 1,
            "llull": 2,
            "devised": 1,
            "system": 2,
            "reasoning": 1,
            "published": 1,
            "ar": 1,
            "great": 1,
            "art": 1,
            "tried": 1,
            "implement": 1,
            "using": 1,
            "actual": 1,
            "mechanical": 1,
            "device": 1,
            "set": 1,
            "paper": 1,
            "wheel": 1,
            "rotated": 1,
            "different": 1,
            "permutation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para45",
              "entity_text": "Ramon Llull",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 11,
              "context": "Ramon Llull (c. 1232–1315) devised a system of reasoning publ"
            },
            {
              "para_id": "chap1_para45",
              "entity_text": "The Great Art",
              "entity_type": "WORK_OF_ART",
              "start_char": 83,
              "end_char": 96,
              "context": "d a system of reasoning published as\nArs Magna\nor\nThe Great Art\n(1305). Llull tried to implement his system using"
            },
            {
              "para_id": "chap1_para45",
              "entity_text": "Llull",
              "entity_type": "PERSON",
              "start_char": 105,
              "end_char": 110,
              "context": "g published as\nArs Magna\nor\nThe Great Art\n(1305). Llull tried to implement his system using an actual mec"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para46",
          "content": "Around 1500, Leonardo da Vinci (1452–1519) designed but did not build a mechanical calculator; recent reconstructions have shown the design to be functional. The first known calculating machine was constructed around 1623 by the German scientist Wilhelm Schickard (1592–1635). Blaise Pascal (1623–1662) built the Pascaline in 1642 and wrote that it “produces effects which appear nearer to thought than all the actions of animals.” Gottfried Wilhelm Leibniz (1646–1716) built a mechanical device intended to carry out operations on concepts rather than numbers, but its scope was rather limited. In his 1651 book\nLeviathan,\nThomas Hobbes (1588–1679) suggested the idea of a thinking machine, an “artificial animal” in his words, arguing “For what is the heart but a spring; and the nerves, but so many strings; and the joints, but so many wheels.” He also suggested that reasoning was like numerical computation: “For ‘reason’ ... is nothing but ‘reckoning,’ that is adding and subtracting.”\nIt’s one thing to say that the mind operates, at least in part, according to logical or numerical rules, and to build physical systems that emulate some of those rules. It’s another to say that the mind itself\nis\nsuch a physical system. René Descartes (1596–1650) gave the first clear discussion of the distinction between mind and matter. He noted that a purely physical conception of the mind seems to leave little room for free will. If the mind is governed entirely by physical laws, then it has no more free will than a rock “deciding” to fall downward. Descartes was a proponent of\ndualism\n. He held that there is a part of the human mind (or soul or spirit) that is outside of nature, exempt from physical laws. Animals, on the other hand, did not possess this dual quality; they could be treated as machines.",
          "sentence_count": 11,
          "char_count": 1516,
          "prev_para_id": "chap1_para45",
          "next_para_id": "chap1_para47",
          "style_metadata": {
            "para_id": "chap1_para46",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.91,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 362,
            "sentence_count": 11
          },
          "terminology": {
            "leonardo": 1,
            "vinci": 1,
            "designed": 1,
            "build": 2,
            "mechanical": 2,
            "calculator": 1,
            "recent": 1,
            "reconstruction": 1,
            "shown": 1,
            "design": 1,
            "functional": 1,
            "first": 2,
            "known": 1,
            "calculating": 1,
            "machine": 3,
            "constructed": 1,
            "german": 1,
            "scientist": 1,
            "wilhelm": 2,
            "schickard": 1,
            "blaise": 1,
            "pascal": 1,
            "built": 2,
            "pascaline": 1,
            "wrote": 1,
            "produce": 1,
            "effect": 1,
            "appear": 1,
            "nearer": 1,
            "thought": 1,
            "action": 1,
            "animals.": 1,
            "gottfried": 1,
            "leibniz": 1,
            "device": 1,
            "intended": 1,
            "carry": 1,
            "operation": 1,
            "concept": 1,
            "number": 1,
            "scope": 1,
            "limited": 1,
            "book": 1,
            "leviathan": 1,
            "thomas": 1,
            "hobbes": 1,
            "suggested": 2,
            "idea": 1,
            "thinking": 1,
            "artificial": 1,
            "animal": 2,
            "word": 1,
            "arguing": 1,
            "heart": 1,
            "spring": 1,
            "nerve": 1,
            "many": 2,
            "string": 1,
            "joint": 1,
            "wheels.": 1,
            "reasoning": 1,
            "numerical": 2,
            "computation": 1,
            "reason": 1,
            "nothing": 1,
            "reckoning": 1,
            "adding": 1,
            "subtracting.": 1,
            "thing": 1,
            "say": 2,
            "mind": 6,
            "operates": 1,
            "least": 1,
            "part": 2,
            "according": 1,
            "logical": 1,
            "rule": 2,
            "physical": 5,
            "system": 2,
            "emulate": 1,
            "rené": 1,
            "descartes": 2,
            "gave": 1,
            "clear": 1,
            "discussion": 1,
            "distinction": 1,
            "matter": 1,
            "noted": 1,
            "conception": 1,
            "seems": 1,
            "leave": 1,
            "little": 1,
            "room": 1,
            "free": 2,
            "governed": 1,
            "law": 2,
            "rock": 1,
            "deciding": 1,
            "fall": 1,
            "proponent": 1,
            "dualism": 1,
            "held": 1,
            "human": 1,
            "soul": 1,
            "spirit": 1,
            "nature": 1,
            "exempt": 1,
            "hand": 1,
            "possess": 1,
            "dual": 1,
            "quality": 1,
            "treated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para46",
              "entity_text": "Leonardo da Vinci",
              "entity_type": "PERSON",
              "start_char": 13,
              "end_char": 30,
              "context": "Around 1500, Leonardo da Vinci (1452–1519) designed but did not build a mechanic"
            },
            {
              "para_id": "chap1_para46",
              "entity_text": "Wilhelm Schickard",
              "entity_type": "PERSON",
              "start_char": 246,
              "end_char": 263,
              "context": "s constructed around 1623 by the German scientist Wilhelm Schickard (1592–1635). Blaise Pascal (1623–1662) built the "
            },
            {
              "para_id": "chap1_para46",
              "entity_text": "Pascaline",
              "entity_type": "ORG",
              "start_char": 313,
              "end_char": 322,
              "context": " (1592–1635). Blaise Pascal (1623–1662) built the Pascaline in 1642 and wrote that it “produces effects which"
            },
            {
              "para_id": "chap1_para46",
              "entity_text": "Gottfried Wilhelm Leibniz",
              "entity_type": "PERSON",
              "start_char": 432,
              "end_char": 457,
              "context": "arer to thought than all the actions of animals.” Gottfried Wilhelm Leibniz (1646–1716) built a mechanical device intended to"
            },
            {
              "para_id": "chap1_para46",
              "entity_text": "Leviathan",
              "entity_type": "GPE",
              "start_char": 613,
              "end_char": 622,
              "context": "ut its scope was rather limited. In his 1651 book\nLeviathan,\nThomas Hobbes (1588–1679) suggested the idea of "
            },
            {
              "para_id": "chap1_para46",
              "entity_text": "Thomas Hobbes",
              "entity_type": "PERSON",
              "start_char": 624,
              "end_char": 637,
              "context": "e was rather limited. In his 1651 book\nLeviathan,\nThomas Hobbes (1588–1679) suggested the idea of a thinking mach"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para47",
          "content": "An alternative to dualism is\nmaterialism\n, which holds that the brain’s operation according to the laws of physics\nconstitutes\nthe mind. Free will is simply the way that the perception of available choices appears to the choosing entity. The terms\nphysicalism\nand\nnaturalism\nare also used to describe this view that stands in contrast to the supernatural.",
          "sentence_count": 3,
          "char_count": 306,
          "prev_para_id": "chap1_para46",
          "next_para_id": "chap1_para48",
          "style_metadata": {
            "para_id": "chap1_para47",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 3
          },
          "terminology": {
            "alternative": 1,
            "dualism": 1,
            "materialism": 1,
            "hold": 1,
            "brain": 1,
            "operation": 1,
            "according": 1,
            "law": 1,
            "physic": 1,
            "constitutes": 1,
            "mind": 1,
            "free": 1,
            "way": 1,
            "perception": 1,
            "available": 1,
            "choice": 1,
            "appears": 1,
            "choosing": 1,
            "entity": 1,
            "term": 1,
            "physicalism": 1,
            "naturalism": 1,
            "used": 1,
            "describe": 1,
            "view": 1,
            "stand": 1,
            "contrast": 1,
            "supernatural": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para48",
          "content": "Given a physical mind that manipulates knowledge, the next problem is to establish the source of knowledge. The\nempiricism\nmovement, starting with Francis Bacon’s (1561–1626)\nNovum Organum\n,\n4\nis characterized by a dictum of John Locke (1632–1704): “Nothing is in the understanding, which was not first in the senses.”\nDavid Hume’s (1711–1776)\nA Treatise of Human Nature\n(Hume, 1739) proposed what is now known as the principle of\ninduction\n: that general rules are acquired by exposure to repeated associations between their elements.",
          "sentence_count": 2,
          "char_count": 463,
          "prev_para_id": "chap1_para47",
          "next_para_id": "chap1_para49",
          "style_metadata": {
            "para_id": "chap1_para48",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 52.5,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 105,
            "sentence_count": 2
          },
          "terminology": {
            "given": 1,
            "physical": 1,
            "mind": 1,
            "manipulates": 1,
            "knowledge": 2,
            "next": 1,
            "problem": 1,
            "establish": 1,
            "source": 1,
            "empiricism": 1,
            "movement": 1,
            "starting": 1,
            "francis": 1,
            "bacon": 1,
            "novum": 1,
            "organum": 1,
            "characterized": 1,
            "dictum": 1,
            "john": 1,
            "locke": 1,
            "nothing": 1,
            "understanding": 1,
            "first": 1,
            "senses.": 1,
            "david": 1,
            "hume": 2,
            "treatise": 1,
            "human": 1,
            "nature": 1,
            "proposed": 1,
            "known": 1,
            "principle": 1,
            "induction": 1,
            "general": 1,
            "rule": 1,
            "acquired": 1,
            "exposure": 1,
            "repeated": 1,
            "association": 1,
            "element": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para48",
              "entity_text": "Francis Bacon’s",
              "entity_type": "PERSON",
              "start_char": 147,
              "end_char": 162,
              "context": "knowledge. The\nempiricism\nmovement, starting with Francis Bacon’s (1561–1626)\nNovum Organum\n,\n4\nis characterized by"
            },
            {
              "para_id": "chap1_para48",
              "entity_text": "Novum Organum",
              "entity_type": "PERSON",
              "start_char": 175,
              "end_char": 188,
              "context": "vement, starting with Francis Bacon’s (1561–1626)\nNovum Organum\n,\n4\nis characterized by a dictum of John Locke (1"
            },
            {
              "para_id": "chap1_para48",
              "entity_text": "John Locke",
              "entity_type": "PERSON",
              "start_char": 225,
              "end_char": 235,
              "context": "Novum Organum\n,\n4\nis characterized by a dictum of John Locke (1632–1704): “Nothing is in the understanding, wh"
            },
            {
              "para_id": "chap1_para48",
              "entity_text": "David Hume’s",
              "entity_type": "PERSON",
              "start_char": 319,
              "end_char": 331,
              "context": "nderstanding, which was not first in the senses.”\nDavid Hume’s (1711–1776)\nA Treatise of Human Nature\n(Hume, 173"
            },
            {
              "para_id": "chap1_para48",
              "entity_text": "A Treatise of Human Nature",
              "entity_type": "ORG",
              "start_char": 344,
              "end_char": 370,
              "context": "ot first in the senses.”\nDavid Hume’s (1711–1776)\nA Treatise of Human Nature\n(Hume, 1739) proposed what is now known as the pr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para49",
          "content": "Building on the work of Ludwig Wittgenstein (1889–1951) and Bertrand Russell (1872–1970), the famous Vienna Circle (Sigmund, 2017), a group of philosophers and mathematicians meeting in Vienna in the 1920s and 1930s, developed the doctrine of\nlogical positivism\n. This doctrine holds that all knowledge can be characterized by logical theories connected, ultimately, to\nobservation sentences\nthat correspond to sensory inputs; thus logical positivism combines rationalism and empiricism.",
          "sentence_count": 2,
          "char_count": 424,
          "prev_para_id": "chap1_para48",
          "next_para_id": "chap1_para50",
          "style_metadata": {
            "para_id": "chap1_para49",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 2
          },
          "terminology": {
            "building": 1,
            "work": 1,
            "ludwig": 1,
            "wittgenstein": 1,
            "bertrand": 1,
            "russell": 1,
            "famous": 1,
            "vienna": 2,
            "circle": 1,
            "sigmund": 1,
            "group": 1,
            "philosopher": 1,
            "mathematician": 1,
            "meeting": 1,
            "developed": 1,
            "doctrine": 2,
            "logical": 3,
            "positivism": 2,
            "hold": 1,
            "knowledge": 1,
            "characterized": 1,
            "theory": 1,
            "connected": 1,
            "observation": 1,
            "sentence": 1,
            "correspond": 1,
            "sensory": 1,
            "input": 1,
            "combine": 1,
            "rationalism": 1,
            "empiricism": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para49",
              "entity_text": "Ludwig Wittgenstein",
              "entity_type": "ORG",
              "start_char": 24,
              "end_char": 43,
              "context": "Building on the work of Ludwig Wittgenstein (1889–1951) and Bertrand Russell (1872–1970), the"
            },
            {
              "para_id": "chap1_para49",
              "entity_text": "Bertrand Russell",
              "entity_type": "PERSON",
              "start_char": 60,
              "end_char": 76,
              "context": "n the work of Ludwig Wittgenstein (1889–1951) and Bertrand Russell (1872–1970), the famous Vienna Circle (Sigmund, 2"
            },
            {
              "para_id": "chap1_para49",
              "entity_text": "Vienna Circle",
              "entity_type": "ORG",
              "start_char": 101,
              "end_char": 114,
              "context": "951) and Bertrand Russell (1872–1970), the famous Vienna Circle (Sigmund, 2017), a group of philosophers and math"
            },
            {
              "para_id": "chap1_para49",
              "entity_text": "Vienna",
              "entity_type": "GPE",
              "start_char": 186,
              "end_char": 192,
              "context": "oup of philosophers and mathematicians meeting in Vienna in the 1920s and 1930s, developed the doctrine of"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para50",
          "content": "The\nconfirmation theory\nof Rudolf Carnap (1891–1970) and Carl Hempel (1905–1997) attempted to analyze the acquisition of knowledge from experience by quantifying the degree of belief that should be assigned to logical sentences based on their connection to observations that confirm or disconfirm them. Carnap’s book\nThe Logical Structure of the World\n(1928) was perhaps the first theory of mind as a computational process.",
          "sentence_count": 2,
          "char_count": 364,
          "prev_para_id": "chap1_para49",
          "next_para_id": "chap1_para51",
          "style_metadata": {
            "para_id": "chap1_para50",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 2
          },
          "terminology": {
            "confirmation": 1,
            "theory": 2,
            "rudolf": 1,
            "carnap": 2,
            "carl": 1,
            "hempel": 1,
            "attempted": 1,
            "analyze": 1,
            "acquisition": 1,
            "knowledge": 1,
            "experience": 1,
            "quantifying": 1,
            "degree": 1,
            "belief": 1,
            "assigned": 1,
            "logical": 2,
            "sentence": 1,
            "based": 1,
            "connection": 1,
            "observation": 1,
            "confirm": 1,
            "disconfirm": 1,
            "book": 1,
            "structure": 1,
            "world": 1,
            "first": 1,
            "mind": 1,
            "computational": 1,
            "process": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para50",
              "entity_text": "Rudolf Carnap",
              "entity_type": "PERSON",
              "start_char": 27,
              "end_char": 40,
              "context": "The\nconfirmation theory\nof Rudolf Carnap (1891–1970) and Carl Hempel (1905–1997) attempted"
            },
            {
              "para_id": "chap1_para50",
              "entity_text": "Carl Hempel",
              "entity_type": "PERSON",
              "start_char": 57,
              "end_char": 68,
              "context": "firmation theory\nof Rudolf Carnap (1891–1970) and Carl Hempel (1905–1997) attempted to analyze the acquisition "
            },
            {
              "para_id": "chap1_para50",
              "entity_text": "Carnap",
              "entity_type": "ORG",
              "start_char": 303,
              "end_char": 309,
              "context": " to observations that confirm or disconfirm them. Carnap’s book\nThe Logical Structure of the World\n(1928) "
            },
            {
              "para_id": "chap1_para50",
              "entity_text": "The Logical Structure of the World",
              "entity_type": "WORK_OF_ART",
              "start_char": 317,
              "end_char": 351,
              "context": "ns that confirm or disconfirm them. Carnap’s book\nThe Logical Structure of the World\n(1928) was perhaps the first theory of mind as a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para51",
          "content": "The final element in the philosophical picture of the mind is the connection between knowledge and action. This question is vital to AI because intelligence requires action as well as reasoning. Moreover, only by understanding how actions are justified can we understand how to build an agent whose actions are justifiable (or rational).",
          "sentence_count": 3,
          "char_count": 285,
          "prev_para_id": "chap1_para50",
          "next_para_id": "chap1_para52",
          "style_metadata": {
            "para_id": "chap1_para51",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 59,
            "sentence_count": 3
          },
          "terminology": {
            "final": 1,
            "element": 1,
            "philosophical": 1,
            "picture": 1,
            "mind": 1,
            "connection": 1,
            "knowledge": 1,
            "action": 4,
            "question": 1,
            "vital": 1,
            "intelligence": 1,
            "requires": 1,
            "reasoning": 1,
            "understanding": 1,
            "justified": 1,
            "understand": 1,
            "build": 1,
            "agent": 1,
            "justifiable": 1,
            "rational": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para51",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 133,
              "end_char": 135,
              "context": "n knowledge and action. This question is vital to AI because intelligence requires action as well as r"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para52",
          "content": "Aristotle argued (in\nDe Motu Animalium\n) that actions are justified by a logical connection between goals and knowledge of the action’s outcome:\nBut how does it happen that thinking is sometimes accompanied by action and sometimes not, sometimes by motion, and sometimes not? It looks as if almost the same thing happens as in the case of reasoning and making inferences about unchanging objects. But in that case the end is a speculative proposition ... whereas here the conclusion which results from the two premises is an action. ... I need covering; a cloak is a covering. I need a cloak. What I need, I have to make; I need a cloak. I have to make a cloak. And the conclusion, the “I have to make a cloak,” is an action.",
          "sentence_count": 9,
          "char_count": 597,
          "prev_para_id": "chap1_para51",
          "next_para_id": "chap1_para53",
          "style_metadata": {
            "para_id": "chap1_para52",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 153,
            "sentence_count": 9
          },
          "terminology": {
            "aristotle": 1,
            "argued": 1,
            "motu": 1,
            "animalium": 1,
            "action": 5,
            "justified": 1,
            "logical": 1,
            "connection": 1,
            "goal": 1,
            "knowledge": 1,
            "outcome": 1,
            "happen": 1,
            "thinking": 1,
            "accompanied": 1,
            "motion": 1,
            "look": 1,
            "thing": 1,
            "happens": 1,
            "case": 2,
            "reasoning": 1,
            "making": 1,
            "inference": 1,
            "unchanging": 1,
            "object": 1,
            "end": 1,
            "speculative": 1,
            "proposition": 1,
            "whereas": 1,
            "conclusion": 2,
            "result": 1,
            "premise": 1,
            "need": 4,
            "covering": 2,
            "cloak": 5,
            "make": 3,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para52",
              "entity_text": "Aristotle",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 9,
              "context": "Aristotle argued (in\nDe Motu Animalium\n) that actions are j"
            },
            {
              "para_id": "chap1_para52",
              "entity_text": "De Motu Animalium",
              "entity_type": "PERSON",
              "start_char": 21,
              "end_char": 38,
              "context": "Aristotle argued (in\nDe Motu Animalium\n) that actions are justified by a logical connect"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para53",
          "content": "In the\nNicomachean Ethics\n(Book III. 3, 1112b), Aristotle further elaborates on this topic, suggesting an algorithm:\nWe deliberate not about ends, but about means. For a doctor does not deliberate whether he shall heal, nor an orator whether he shall persuade, ... They assume the end and consider how and by what means it is attained, and if it seems easily and best produced thereby; while if it is achieved by one means only they consider\nhow\nit will be achieved by this and by what means\nthis\nwill be achieved, till they come to the first cause, ... and what is last in the order of analysis seems to be first in the order of becoming. And if we come on an impossibility, we give up the search, e.g., if we need money and this cannot be got; but if a thing appears possible we try to do it.",
          "sentence_count": 5,
          "char_count": 651,
          "prev_para_id": "chap1_para52",
          "next_para_id": "chap1_para54",
          "style_metadata": {
            "para_id": "chap1_para53",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.6,
            "passive_voice_ratio": 0.012,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 173,
            "sentence_count": 5
          },
          "terminology": {
            "nicomachean": 1,
            "ethic": 1,
            "book": 1,
            "iii": 1,
            "aristotle": 1,
            "elaborates": 1,
            "topic": 1,
            "suggesting": 1,
            "algorithm": 1,
            "deliberate": 2,
            "end": 2,
            "mean": 4,
            "doctor": 1,
            "heal": 1,
            "orator": 1,
            "persuade": 1,
            "assume": 1,
            "consider": 2,
            "attained": 1,
            "seems": 2,
            "produced": 1,
            "achieved": 3,
            "come": 2,
            "cause": 1,
            "last": 1,
            "order": 2,
            "analysis": 1,
            "first": 1,
            "becoming": 1,
            "impossibility": 1,
            "give": 1,
            "search": 1,
            "e.g.": 1,
            "need": 1,
            "money": 1,
            "got": 1,
            "thing": 1,
            "appears": 1,
            "possible": 1,
            "try": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para53",
              "entity_text": "Nicomachean Ethics",
              "entity_type": "ORG",
              "start_char": 7,
              "end_char": 25,
              "context": "In the\nNicomachean Ethics\n(Book III. 3, 1112b), Aristotle further elaborate"
            },
            {
              "para_id": "chap1_para53",
              "entity_text": "Aristotle",
              "entity_type": "ORG",
              "start_char": 48,
              "end_char": 57,
              "context": "In the\nNicomachean Ethics\n(Book III. 3, 1112b), Aristotle further elaborates on this topic, suggesting an a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para54",
          "content": "Aristotle’s algorithm was implemented 2300 years later by Newell and Simon in their\nGeneral Problem Solver\nprogram. We would now call it a greedy regression planning system (see\nChapter 11\n). Methods based on logical planning to achieve definite goals dominated the first few decades of theoretical research in AI.",
          "sentence_count": 3,
          "char_count": 269,
          "prev_para_id": "chap1_para53",
          "next_para_id": "chap1_para55",
          "style_metadata": {
            "para_id": "chap1_para54",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.67,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 56,
            "sentence_count": 3
          },
          "terminology": {
            "aristotle": 1,
            "implemented": 1,
            "year": 1,
            "simon": 1,
            "general": 1,
            "problem": 1,
            "solver": 1,
            "program": 1,
            "call": 1,
            "greedy": 1,
            "regression": 1,
            "planning": 2,
            "system": 1,
            "see": 1,
            "chapter": 1,
            "method": 1,
            "based": 1,
            "logical": 1,
            "achieve": 1,
            "definite": 1,
            "goal": 1,
            "dominated": 1,
            "first": 1,
            "decade": 1,
            "theoretical": 1,
            "research": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para54",
              "entity_text": "Aristotle",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 9,
              "context": "Aristotle’s algorithm was implemented 2300 years later by N"
            },
            {
              "para_id": "chap1_para54",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 58,
              "end_char": 64,
              "context": "e’s algorithm was implemented 2300 years later by Newell and Simon in their\nGeneral Problem Solver\nprogram"
            },
            {
              "para_id": "chap1_para54",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 69,
              "end_char": 74,
              "context": "hm was implemented 2300 years later by Newell and Simon in their\nGeneral Problem Solver\nprogram. We would"
            },
            {
              "para_id": "chap1_para54",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 311,
              "end_char": 313,
              "context": " the first few decades of theoretical research in AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para55",
          "content": "Thinking purely in terms of actions achieving goals is often useful but sometimes inapplicable. For example, if there are several different ways to achieve a goal, there needs to be some way to choose among them. More importantly, it may not be possible to achieve a goal with certainty, but some action must still be taken. How then should one decide? Antoine Arnauld (1662), analyzing the notion of rational decisions in gambling, proposed a quantitative formula for maximizing the expected monetary value of the outcome. Later, Daniel Bernoulli (1738) introduced the more general notion of\nutility\nto capture the internal, subjective value\nof an outcome. The modern notion of rational decision making under uncertainty involves maximizing expected utility, as explained in\nChapter 15\n.",
          "sentence_count": 7,
          "char_count": 670,
          "prev_para_id": "chap1_para54",
          "next_para_id": "chap1_para56",
          "style_metadata": {
            "para_id": "chap1_para55",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 143,
            "sentence_count": 7
          },
          "terminology": {
            "thinking": 1,
            "term": 1,
            "action": 2,
            "achieving": 1,
            "goal": 3,
            "useful": 1,
            "inapplicable": 1,
            "example": 1,
            "several": 1,
            "different": 1,
            "way": 2,
            "achieve": 2,
            "need": 1,
            "choose": 1,
            "possible": 1,
            "certainty": 1,
            "taken": 1,
            "decide": 1,
            "antoine": 1,
            "analyzing": 1,
            "notion": 3,
            "rational": 2,
            "decision": 2,
            "gambling": 1,
            "proposed": 1,
            "quantitative": 1,
            "formula": 1,
            "maximizing": 2,
            "expected": 2,
            "monetary": 1,
            "value": 2,
            "outcome": 2,
            "daniel": 1,
            "bernoulli": 1,
            "introduced": 1,
            "general": 1,
            "utility": 2,
            "capture": 1,
            "internal": 1,
            "subjective": 1,
            "modern": 1,
            "making": 1,
            "uncertainty": 1,
            "involves": 1,
            "explained": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para55",
              "entity_text": "Antoine Arnauld",
              "entity_type": "ORG",
              "start_char": 353,
              "end_char": 368,
              "context": " must still be taken. How then should one decide? Antoine Arnauld (1662), analyzing the notion of rational decision"
            },
            {
              "para_id": "chap1_para55",
              "entity_text": "Daniel Bernoulli",
              "entity_type": "PERSON",
              "start_char": 531,
              "end_char": 547,
              "context": "he expected monetary value of the outcome. Later, Daniel Bernoulli (1738) introduced the more general notion of\nutil"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para56",
          "content": "In matters of ethics and public policy, a decision maker must consider the interests of multiple individuals. Jeremy Bentham (1823) and John Stuart Mill (1863) promoted the idea of\nutilitarianism\n: that rational decision making based on maximizing utility should apply to all spheres of human activity, including public policy decisions made on behalf of many individuals. Utilitarianism is a specific kind of\nconsequentialism\n: the idea that what is right and wrong is determined by the expected outcomes of an action.",
          "sentence_count": 3,
          "char_count": 442,
          "prev_para_id": "chap1_para55",
          "next_para_id": "chap1_para57",
          "style_metadata": {
            "para_id": "chap1_para56",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.33,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 3
          },
          "terminology": {
            "matter": 1,
            "ethic": 1,
            "public": 2,
            "policy": 2,
            "decision": 3,
            "maker": 1,
            "consider": 1,
            "interest": 1,
            "multiple": 1,
            "individual": 2,
            "jeremy": 1,
            "bentham": 1,
            "john": 1,
            "stuart": 1,
            "mill": 1,
            "promoted": 1,
            "idea": 2,
            "utilitarianism": 2,
            "rational": 1,
            "making": 1,
            "based": 1,
            "maximizing": 1,
            "utility": 1,
            "apply": 1,
            "sphere": 1,
            "human": 1,
            "activity": 1,
            "including": 1,
            "made": 1,
            "behalf": 1,
            "many": 1,
            "specific": 1,
            "kind": 1,
            "consequentialism": 1,
            "wrong": 1,
            "determined": 1,
            "expected": 1,
            "outcome": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para56",
              "entity_text": "Jeremy Bentham",
              "entity_type": "PERSON",
              "start_char": 110,
              "end_char": 124,
              "context": "t consider the interests of multiple individuals. Jeremy Bentham (1823) and John Stuart Mill (1863) promoted the i"
            },
            {
              "para_id": "chap1_para56",
              "entity_text": "John Stuart Mill",
              "entity_type": "PERSON",
              "start_char": 136,
              "end_char": 152,
              "context": "f multiple individuals. Jeremy Bentham (1823) and John Stuart Mill (1863) promoted the idea of\nutilitarianism\n: that"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para57",
          "content": "In contrast, Immanuel Kant, in 1785, proposed a theory of rule-based or\ndeontological ethics\n, in which “doing the right thing” is determined not by outcomes but by universal social laws that govern allowable actions, such as “don’t lie” or “don’t kill.” Thus, a utilitarian could tell a white lie if the expected good outweighs the bad, but a Kantian would be bound not to, because lying is inherently wrong. Mill acknowledged the value of rules, but understood them as efficient decision procedures compiled from first-principles reasoning about consequences. Many modern AI systems adopt exactly this approach.",
          "sentence_count": 3,
          "char_count": 519,
          "prev_para_id": "chap1_para56",
          "next_para_id": "chap1_para58",
          "style_metadata": {
            "para_id": "chap1_para57",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.33,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 118,
            "sentence_count": 3
          },
          "terminology": {
            "contrast": 1,
            "immanuel": 1,
            "kant": 1,
            "proposed": 1,
            "theory": 1,
            "rule-based": 1,
            "deontological": 1,
            "ethic": 1,
            "right": 1,
            "thing": 1,
            "determined": 1,
            "outcome": 1,
            "universal": 1,
            "social": 1,
            "law": 1,
            "govern": 1,
            "allowable": 1,
            "action": 1,
            "lie": 2,
            "kill.": 1,
            "utilitarian": 1,
            "tell": 1,
            "white": 1,
            "expected": 1,
            "good": 1,
            "outweighs": 1,
            "bad": 1,
            "kantian": 1,
            "bound": 1,
            "lying": 1,
            "wrong": 1,
            "mill": 1,
            "acknowledged": 1,
            "value": 1,
            "rule": 1,
            "understood": 1,
            "efficient": 1,
            "decision": 1,
            "procedure": 1,
            "compiled": 1,
            "first-principles": 1,
            "reasoning": 1,
            "consequence": 1,
            "many": 1,
            "modern": 1,
            "system": 1,
            "adopt": 1,
            "approach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para57",
              "entity_text": "Immanuel Kant",
              "entity_type": "PERSON",
              "start_char": 13,
              "end_char": 26,
              "context": "In contrast, Immanuel Kant, in 1785, proposed a theory of rule-based or\ndeon"
            },
            {
              "para_id": "chap1_para57",
              "entity_text": "n’t",
              "entity_type": "GPE",
              "start_char": 229,
              "end_char": 232,
              "context": "al laws that govern allowable actions, such as “don’t lie” or “don’t kill.” Thus, a utilitarian could t"
            },
            {
              "para_id": "chap1_para57",
              "entity_text": "Mill",
              "entity_type": "PERSON",
              "start_char": 410,
              "end_char": 414,
              "context": " bound not to, because lying is inherently wrong. Mill acknowledged the value of rules, but understood t"
            },
            {
              "para_id": "chap1_para57",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 574,
              "end_char": 576,
              "context": "nciples reasoning about consequences. Many modern AI systems adopt exactly this approach."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para58",
          "content": "1.2.2\nMathematics\n•\nWhat are the formal rules to draw valid conclusions?",
          "sentence_count": 1,
          "char_count": 64,
          "prev_para_id": "chap1_para57",
          "next_para_id": "chap1_para59",
          "style_metadata": {
            "para_id": "chap1_para58",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "mathematics": 1,
            "formal": 1,
            "rule": 1,
            "draw": 1,
            "valid": 1,
            "conclusion": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para59",
          "content": "•\nWhat can be computed?",
          "sentence_count": 1,
          "char_count": 20,
          "prev_para_id": "chap1_para58",
          "next_para_id": "chap1_para60",
          "style_metadata": {
            "para_id": "chap1_para59",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 6,
            "sentence_count": 1
          },
          "terminology": {
            "computed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para60",
          "content": "•\nHow do we reason with uncertain information?",
          "sentence_count": 1,
          "char_count": 40,
          "prev_para_id": "chap1_para59",
          "next_para_id": "chap1_para61",
          "style_metadata": {
            "para_id": "chap1_para60",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "reason": 1,
            "uncertain": 1,
            "information": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para61",
          "content": "Philosophers staked out some of the fundamental ideas of AI, but the leap to a formal science required the mathematization of logic and probability and the introduction of a new branch of mathematics: computation.",
          "sentence_count": 1,
          "char_count": 180,
          "prev_para_id": "chap1_para60",
          "next_para_id": "chap1_para62",
          "style_metadata": {
            "para_id": "chap1_para61",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 1
          },
          "terminology": {
            "philosopher": 1,
            "staked": 1,
            "fundamental": 1,
            "idea": 1,
            "leap": 1,
            "formal": 1,
            "science": 1,
            "required": 1,
            "mathematization": 1,
            "logic": 1,
            "probability": 1,
            "introduction": 1,
            "new": 1,
            "branch": 1,
            "mathematics": 1,
            "computation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para61",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 57,
              "end_char": 59,
              "context": "phers staked out some of the fundamental ideas of AI, but the leap to a formal science required the ma"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para62",
          "content": "The idea of\nformal logic\ncan be traced back to the philosophers of ancient Greece, India, and China, but its mathematical development really began with the work of George Boole (1815–1864), who worked out the details of propositional, or Boolean, logic (Boole, 1847). In 1879, Gottlob Frege (1848–1925) extended Boole’s logic to include objects and relations, creating the first-order logic that is used today.",
          "sentence_count": 2,
          "char_count": 349,
          "prev_para_id": "chap1_para61",
          "next_para_id": "chap1_para63",
          "style_metadata": {
            "para_id": "chap1_para62",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.5,
            "passive_voice_ratio": 0.012,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 2
          },
          "terminology": {
            "idea": 1,
            "formal": 1,
            "logic": 4,
            "traced": 1,
            "philosopher": 1,
            "ancient": 1,
            "greece": 1,
            "india": 1,
            "china": 1,
            "mathematical": 1,
            "development": 1,
            "began": 1,
            "work": 1,
            "george": 1,
            "boole": 3,
            "worked": 1,
            "detail": 1,
            "propositional": 1,
            "boolean": 1,
            "gottlob": 1,
            "frege": 1,
            "extended": 1,
            "include": 1,
            "object": 1,
            "relation": 1,
            "creating": 1,
            "first-order": 1,
            "used": 1,
            "today": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para62",
              "entity_text": "Greece",
              "entity_type": "GPE",
              "start_char": 75,
              "end_char": 81,
              "context": "can be traced back to the philosophers of ancient Greece, India, and China, but its mathematical developme"
            },
            {
              "para_id": "chap1_para62",
              "entity_text": "India",
              "entity_type": "GPE",
              "start_char": 83,
              "end_char": 88,
              "context": "raced back to the philosophers of ancient Greece, India, and China, but its mathematical development real"
            },
            {
              "para_id": "chap1_para62",
              "entity_text": "China",
              "entity_type": "GPE",
              "start_char": 94,
              "end_char": 99,
              "context": "to the philosophers of ancient Greece, India, and China, but its mathematical development really began wi"
            },
            {
              "para_id": "chap1_para62",
              "entity_text": "George Boole",
              "entity_type": "PERSON",
              "start_char": 164,
              "end_char": 176,
              "context": "matical development really began with the work of George Boole (1815–1864), who worked out the details of propos"
            },
            {
              "para_id": "chap1_para62",
              "entity_text": "Boole",
              "entity_type": "GPE",
              "start_char": 254,
              "end_char": 259,
              "context": " the details of propositional, or Boolean, logic (Boole, 1847). In 1879, Gottlob Frege (1848–1925) extend"
            },
            {
              "para_id": "chap1_para62",
              "entity_text": "Gottlob Frege",
              "entity_type": "PERSON",
              "start_char": 277,
              "end_char": 290,
              "context": "tional, or Boolean, logic (Boole, 1847). In 1879, Gottlob Frege (1848–1925) extended Boole’s logic to include obj"
            },
            {
              "para_id": "chap1_para62",
              "entity_text": "Boole",
              "entity_type": "ORG",
              "start_char": 312,
              "end_char": 317,
              "context": "847). In 1879, Gottlob Frege (1848–1925) extended Boole’s logic to include objects and relations, creatin"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para63",
          "content": "5\nIn addition to its central role in the early period of AI research, first-order logic motivated the work of Gödel and Turing that underpinned computation itself, as we explain below.",
          "sentence_count": 1,
          "char_count": 155,
          "prev_para_id": "chap1_para62",
          "next_para_id": "chap1_para64",
          "style_metadata": {
            "para_id": "chap1_para63",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "addition": 1,
            "central": 1,
            "role": 1,
            "early": 1,
            "period": 1,
            "research": 1,
            "first-order": 1,
            "logic": 1,
            "motivated": 1,
            "work": 1,
            "gödel": 1,
            "turing": 1,
            "underpinned": 1,
            "computation": 1,
            "explain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para63",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 57,
              "end_char": 59,
              "context": "dition to its central role in the early period of AI research, first-order logic motivated the work of"
            },
            {
              "para_id": "chap1_para63",
              "entity_text": "Gödel",
              "entity_type": "ORG",
              "start_char": 110,
              "end_char": 115,
              "context": "research, first-order logic motivated the work of Gödel and Turing that underpinned computation itself, a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para64",
          "content": "The theory of\nprobability\ncan be seen as generalizing logic to situations with uncertain information—a consideration of great importance for AI. Gerolamo Cardano (1501–1576) first framed the idea of probability, describing it in terms of the possible outcomes of gambling events. In 1654, Blaise Pascal (1623–1662), in a letter to Pierre Fermat (1601–1665), showed how to predict the future of an unfinished gambling game and assign average payoffs to the gamblers. Probability quickly became an invaluable part of the quantitative sciences, helping to deal with uncertain measurements and incomplete theories. Jacob Bernoulli (1654–1705, uncle of Daniel), Pierre Laplace (1749–1827), and others advanced the theory and introduced new statistical methods. Thomas Bayes (1702–1761) proposed a rule for updating probabilities in the light of new evidence; Bayes’ rule is a crucial tool for AI systems.",
          "sentence_count": 6,
          "char_count": 769,
          "prev_para_id": "chap1_para63",
          "next_para_id": "chap1_para65",
          "style_metadata": {
            "para_id": "chap1_para64",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 161,
            "sentence_count": 6
          },
          "terminology": {
            "theory": 3,
            "probability": 4,
            "seen": 1,
            "generalizing": 1,
            "logic": 1,
            "situation": 1,
            "uncertain": 2,
            "information—a": 1,
            "consideration": 1,
            "great": 1,
            "importance": 1,
            "gerolamo": 1,
            "cardano": 1,
            "first": 1,
            "framed": 1,
            "idea": 1,
            "describing": 1,
            "term": 1,
            "possible": 1,
            "outcome": 1,
            "gambling": 2,
            "event": 1,
            "blaise": 1,
            "pascal": 1,
            "letter": 1,
            "pierre": 2,
            "fermat": 1,
            "showed": 1,
            "predict": 1,
            "future": 1,
            "unfinished": 1,
            "game": 1,
            "assign": 1,
            "average": 1,
            "payoff": 1,
            "gambler": 1,
            "became": 1,
            "invaluable": 1,
            "part": 1,
            "quantitative": 1,
            "science": 1,
            "helping": 1,
            "deal": 1,
            "measurement": 1,
            "incomplete": 1,
            "jacob": 1,
            "bernoulli": 1,
            "uncle": 1,
            "daniel": 1,
            "laplace": 1,
            "others": 1,
            "advanced": 1,
            "introduced": 1,
            "new": 2,
            "statistical": 1,
            "method": 1,
            "thomas": 1,
            "proposed": 1,
            "rule": 2,
            "updating": 1,
            "light": 1,
            "evidence": 1,
            "bayes": 1,
            "crucial": 1,
            "tool": 1,
            "system": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para64",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 141,
              "end_char": 143,
              "context": "formation—a consideration of great importance for AI. Gerolamo Cardano (1501–1576) first framed the id"
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Gerolamo Cardano",
              "entity_type": "PERSON",
              "start_char": 145,
              "end_char": 161,
              "context": "ation—a consideration of great importance for AI. Gerolamo Cardano (1501–1576) first framed the idea of probability,"
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Pierre Fermat",
              "entity_type": "PERSON",
              "start_char": 331,
              "end_char": 344,
              "context": "n 1654, Blaise Pascal (1623–1662), in a letter to Pierre Fermat (1601–1665), showed how to predict the future of "
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Jacob Bernoulli",
              "entity_type": "PERSON",
              "start_char": 611,
              "end_char": 626,
              "context": "h uncertain measurements and incomplete theories. Jacob Bernoulli (1654–1705, uncle of Daniel), Pierre Laplace (174"
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Daniel",
              "entity_type": "PERSON",
              "start_char": 648,
              "end_char": 654,
              "context": "te theories. Jacob Bernoulli (1654–1705, uncle of Daniel), Pierre Laplace (1749–1827), and others advanced"
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Pierre Laplace",
              "entity_type": "PERSON",
              "start_char": 657,
              "end_char": 671,
              "context": "es. Jacob Bernoulli (1654–1705, uncle of Daniel), Pierre Laplace (1749–1827), and others advanced the theory and i"
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Thomas Bayes",
              "entity_type": "PERSON",
              "start_char": 756,
              "end_char": 768,
              "context": "he theory and introduced new statistical methods. Thomas Bayes (1702–1761) proposed a rule for updating probabil"
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "Bayes",
              "entity_type": "ORG",
              "start_char": 854,
              "end_char": 859,
              "context": "ating probabilities in the light of new evidence; Bayes’ rule is a crucial tool for AI systems."
            },
            {
              "para_id": "chap1_para64",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 888,
              "end_char": 890,
              "context": "f new evidence; Bayes’ rule is a crucial tool for AI systems."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para65",
          "content": "The formalization of probability, combined with the availability of data, led to the emergence of\nstatistics\nas a field. One of the first uses was John Graunt’s analysis of London\ncensus data in 1662. Ronald Fisher is considered the first modern statistician (Fisher, 1922). He brought together the ideas of probability, experiment design, analysis of data, and computing—in 1919, he insisted that he couldn’t do his work without a mechanical calculator called the M\nILLIONAIRE\n(the first calculator that could do multiplication), even though the cost of the calculator was more than his annual salary (Ross, 2012).",
          "sentence_count": 4,
          "char_count": 524,
          "prev_para_id": "chap1_para64",
          "next_para_id": "chap1_para66",
          "style_metadata": {
            "para_id": "chap1_para65",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.75,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 119,
            "sentence_count": 4
          },
          "terminology": {
            "formalization": 1,
            "probability": 2,
            "combined": 1,
            "availability": 1,
            "data": 3,
            "led": 1,
            "emergence": 1,
            "statistic": 1,
            "field": 1,
            "first": 2,
            "us": 1,
            "john": 1,
            "graunt": 1,
            "analysis": 2,
            "london": 1,
            "census": 1,
            "ronald": 1,
            "fisher": 2,
            "considered": 1,
            "modern": 1,
            "statistician": 1,
            "brought": 1,
            "idea": 1,
            "experiment": 1,
            "design": 1,
            "computing—in": 1,
            "insisted": 1,
            "work": 1,
            "mechanical": 1,
            "calculator": 3,
            "called": 1,
            "illionaire": 1,
            "multiplication": 1,
            "cost": 1,
            "annual": 1,
            "salary": 1,
            "ross": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para65",
              "entity_text": "John Graunt’s",
              "entity_type": "PERSON",
              "start_char": 147,
              "end_char": 160,
              "context": "\nstatistics\nas a field. One of the first uses was John Graunt’s analysis of London\ncensus data in 1662. Ronald Fi"
            },
            {
              "para_id": "chap1_para65",
              "entity_text": "London",
              "entity_type": "GPE",
              "start_char": 173,
              "end_char": 179,
              "context": "e of the first uses was John Graunt’s analysis of London\ncensus data in 1662. Ronald Fisher is considered "
            },
            {
              "para_id": "chap1_para65",
              "entity_text": "Ronald Fisher",
              "entity_type": "PERSON",
              "start_char": 201,
              "end_char": 214,
              "context": " Graunt’s analysis of London\ncensus data in 1662. Ronald Fisher is considered the first modern statistician (Fish"
            },
            {
              "para_id": "chap1_para65",
              "entity_text": "Fisher",
              "entity_type": "GPE",
              "start_char": 260,
              "end_char": 266,
              "context": "sher is considered the first modern statistician (Fisher, 1922). He brought together the ideas of probabil"
            },
            {
              "para_id": "chap1_para65",
              "entity_text": "Ross",
              "entity_type": "PERSON",
              "start_char": 603,
              "end_char": 607,
              "context": "f the calculator was more than his annual salary (Ross, 2012)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para66",
          "content": "The history of computation is as old as the history of numbers, but the first nontrivial\nalgorithm\nis thought to be Euclid’s algorithm for computing greatest common divisors. The word\nalgorithm\ncomes from Muhammad ibn Musa al-Khwarizmi, a 9th century mathematician, whose writings also introduced Arabic numerals and algebra to Europe. Boole and others discussed algorithms for logical deduction, and, by the late 19th century, efforts were under way to formalize general mathematical reasoning as logical deduction.",
          "sentence_count": 3,
          "char_count": 444,
          "prev_para_id": "chap1_para65",
          "next_para_id": "chap1_para67",
          "style_metadata": {
            "para_id": "chap1_para66",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "history": 2,
            "computation": 1,
            "old": 1,
            "number": 1,
            "nontrivial": 1,
            "algorithm": 4,
            "thought": 1,
            "euclid": 1,
            "computing": 1,
            "greatest": 1,
            "common": 1,
            "divisor": 1,
            "word": 1,
            "come": 1,
            "muhammad": 1,
            "ibn": 1,
            "musa": 1,
            "al-khwarizmi": 1,
            "century": 2,
            "mathematician": 1,
            "writing": 1,
            "introduced": 1,
            "arabic": 1,
            "numeral": 1,
            "europe": 1,
            "boole": 1,
            "others": 1,
            "discussed": 1,
            "logical": 2,
            "deduction": 2,
            "19th": 1,
            "effort": 1,
            "way": 1,
            "formalize": 1,
            "general": 1,
            "mathematical": 1,
            "reasoning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para66",
              "entity_text": "Euclid’s",
              "entity_type": "ORG",
              "start_char": 116,
              "end_char": 124,
              "context": "t the first nontrivial\nalgorithm\nis thought to be Euclid’s algorithm for computing greatest common divisors."
            },
            {
              "para_id": "chap1_para66",
              "entity_text": "Muhammad",
              "entity_type": "PERSON",
              "start_char": 205,
              "end_char": 213,
              "context": "st common divisors. The word\nalgorithm\ncomes from Muhammad ibn Musa al-Khwarizmi, a 9th century mathematicia"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para67",
          "content": "Kurt Gӧdel (1906–1978) showed that there exists an effective procedure to prove any true statement in the first-order logic of Frege and Russell, but that first-order logic could not capture the principle of mathematical induction needed to characterize the natural numbers. In 1931, Gӧdel showed that limits on deduction do exist. His\nincompleteness theorem\nshowed that in any formal theory as strong as Peano arithmetic (the elementary theory of natural numbers), there are necessarily true statements that have no proof within the theory.",
          "sentence_count": 3,
          "char_count": 461,
          "prev_para_id": "chap1_para66",
          "next_para_id": "chap1_para68",
          "style_metadata": {
            "para_id": "chap1_para67",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 93,
            "sentence_count": 3
          },
          "terminology": {
            "kurt": 1,
            "gӧdel": 2,
            "showed": 3,
            "exists": 1,
            "effective": 1,
            "procedure": 1,
            "prove": 1,
            "true": 2,
            "statement": 2,
            "first-order": 2,
            "logic": 2,
            "frege": 1,
            "russell": 1,
            "capture": 1,
            "principle": 1,
            "mathematical": 1,
            "induction": 1,
            "needed": 1,
            "characterize": 1,
            "natural": 2,
            "number": 2,
            "limit": 1,
            "deduction": 1,
            "exist": 1,
            "incompleteness": 1,
            "theorem": 1,
            "formal": 1,
            "theory": 3,
            "strong": 1,
            "peano": 1,
            "arithmetic": 1,
            "elementary": 1,
            "proof": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para67",
              "entity_text": "Kurt Gӧdel",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 10,
              "context": "Kurt Gӧdel (1906–1978) showed that there exists an effective"
            },
            {
              "para_id": "chap1_para67",
              "entity_text": "Frege",
              "entity_type": "ORG",
              "start_char": 127,
              "end_char": 132,
              "context": "ve any true statement in the first-order logic of Frege and Russell, but that first-order logic could not"
            },
            {
              "para_id": "chap1_para67",
              "entity_text": "Russell",
              "entity_type": "PERSON",
              "start_char": 137,
              "end_char": 144,
              "context": "e statement in the first-order logic of Frege and Russell, but that first-order logic could not capture the"
            },
            {
              "para_id": "chap1_para67",
              "entity_text": "Gӧdel",
              "entity_type": "PERSON",
              "start_char": 284,
              "end_char": 289,
              "context": "ded to characterize the natural numbers. In 1931, Gӧdel showed that limits on deduction do exist. His\ninc"
            },
            {
              "para_id": "chap1_para67",
              "entity_text": "Peano",
              "entity_type": "ORG",
              "start_char": 405,
              "end_char": 410,
              "context": "rem\nshowed that in any formal theory as strong as Peano arithmetic (the elementary theory of natural numb"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para68",
          "content": "This fundamental result can also be interpreted as showing that some functions on the integers cannot be represented by an algorithm—that is, they cannot be computed. This motivated Alan Turing (1912–1954) to try to characterize exactly which functions\nare\ncomputable\n—capable of being computed by an effective procedure. The Church–Turing thesis proposes to identify the general notion of computability with functions computed by a Turing machine (Turing, 1936). Turing also showed that there were some functions that no Turing machine can compute. For example, no machine can tell\nin general\nwhether a given program will return an answer on a given input or run forever.",
          "sentence_count": 5,
          "char_count": 573,
          "prev_para_id": "chap1_para67",
          "next_para_id": "chap1_para69",
          "style_metadata": {
            "para_id": "chap1_para68",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 119,
            "sentence_count": 5
          },
          "terminology": {
            "fundamental": 1,
            "result": 1,
            "interpreted": 1,
            "showing": 1,
            "function": 4,
            "integer": 1,
            "represented": 1,
            "computed": 3,
            "motivated": 1,
            "alan": 1,
            "turing": 5,
            "try": 1,
            "characterize": 1,
            "computable": 1,
            "—capable": 1,
            "effective": 1,
            "procedure": 1,
            "church–turing": 1,
            "thesis": 1,
            "proposes": 1,
            "identify": 1,
            "general": 2,
            "notion": 1,
            "computability": 1,
            "machine": 3,
            "showed": 1,
            "compute": 1,
            "example": 1,
            "tell": 1,
            "given": 2,
            "program": 1,
            "return": 1,
            "answer": 1,
            "input": 1,
            "run": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para68",
              "entity_text": "Alan Turing",
              "entity_type": "PERSON",
              "start_char": 182,
              "end_char": 193,
              "context": "—that is, they cannot be computed. This motivated Alan Turing (1912–1954) to try to characterize exactly which "
            },
            {
              "para_id": "chap1_para68",
              "entity_text": "Church",
              "entity_type": "ORG",
              "start_char": 326,
              "end_char": 332,
              "context": " of being computed by an effective procedure. The Church–Turing thesis proposes to identify the general no"
            },
            {
              "para_id": "chap1_para68",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 433,
              "end_char": 439,
              "context": "ion of computability with functions computed by a Turing machine (Turing, 1936). Turing also showed that t"
            },
            {
              "para_id": "chap1_para68",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 449,
              "end_char": 455,
              "context": "lity with functions computed by a Turing machine (Turing, 1936). Turing also showed that there were some f"
            },
            {
              "para_id": "chap1_para68",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 522,
              "end_char": 528,
              "context": "lso showed that there were some functions that no Turing machine can compute. For example, no machine can "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para69",
          "content": "Although computability is important to an understanding of computation, the notion of\ntractability\nhas had an even greater impact on AI. Roughly speaking, a problem is called intractable if the time required to solve instances of the problem grows exponentially with the size of the instances. The distinction between polynomial and exponential growth in complexity was first emphasized in the mid-1960s (Cobham, 1964; Edmonds, 1965). It is important because exponential growth means that even moderately large instances cannot be solved in any reasonable time.",
          "sentence_count": 4,
          "char_count": 480,
          "prev_para_id": "chap1_para68",
          "next_para_id": "chap1_para70",
          "style_metadata": {
            "para_id": "chap1_para69",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 4
          },
          "terminology": {
            "computability": 1,
            "important": 2,
            "understanding": 1,
            "computation": 1,
            "notion": 1,
            "tractability": 1,
            "greater": 1,
            "impact": 1,
            "speaking": 1,
            "problem": 2,
            "called": 1,
            "intractable": 1,
            "time": 2,
            "required": 1,
            "instance": 3,
            "grows": 1,
            "size": 1,
            "distinction": 1,
            "polynomial": 1,
            "exponential": 2,
            "growth": 2,
            "complexity": 1,
            "emphasized": 1,
            "mid-1960s": 1,
            "cobham": 1,
            "edmonds": 1,
            "mean": 1,
            "large": 1,
            "solved": 1,
            "reasonable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para69",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 133,
              "end_char": 135,
              "context": "of\ntractability\nhas had an even greater impact on AI. Roughly speaking, a problem is called intractabl"
            },
            {
              "para_id": "chap1_para69",
              "entity_text": "Cobham",
              "entity_type": "ORG",
              "start_char": 405,
              "end_char": 411,
              "context": "complexity was first emphasized in the mid-1960s (Cobham, 1964; Edmonds, 1965). It is important because ex"
            },
            {
              "para_id": "chap1_para69",
              "entity_text": "Edmonds",
              "entity_type": "PERSON",
              "start_char": 419,
              "end_char": 426,
              "context": " first emphasized in the mid-1960s (Cobham, 1964; Edmonds, 1965). It is important because exponential growt"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para70",
          "content": "The theory of\nNP-completeness\n, pioneered by Cook (1971) and Karp (1972), provides a basis for analyzing the tractability of problems: any problem class to which the class of NP-complete problems can be reduced is likely to be intractable. (Although it has not been proved that NP-complete problems are necessarily intractable, most theoreticians believe it.) These results contrast with the optimism with which the popular press greeted the first computers—“Electronic Super-Brains” that were “Faster than Einstein!” Despite the increasing speed of computers, careful use of resources and necessary imperfection will characterize intelligent systems. Put crudely, the world is an\nextremely\nlarge problem instance!",
          "sentence_count": 4,
          "char_count": 616,
          "prev_para_id": "chap1_para69",
          "next_para_id": "chap1_para71",
          "style_metadata": {
            "para_id": "chap1_para70",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 124,
            "sentence_count": 4
          },
          "terminology": {
            "theory": 1,
            "np-completeness": 1,
            "pioneered": 1,
            "cook": 1,
            "karp": 1,
            "provides": 1,
            "basis": 1,
            "analyzing": 1,
            "tractability": 1,
            "problem": 5,
            "class": 2,
            "np-complete": 2,
            "reduced": 1,
            "intractable": 2,
            "proved": 1,
            "theoretician": 1,
            "believe": 1,
            "result": 1,
            "contrast": 1,
            "optimism": 1,
            "popular": 1,
            "press": 1,
            "greeted": 1,
            "first": 1,
            "computers—": 1,
            "electronic": 1,
            "super-brains": 1,
            "increasing": 1,
            "speed": 1,
            "computer": 1,
            "careful": 1,
            "use": 1,
            "resource": 1,
            "necessary": 1,
            "imperfection": 1,
            "characterize": 1,
            "intelligent": 1,
            "system": 1,
            "put": 1,
            "world": 1,
            "large": 1,
            "instance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para70",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 14,
              "end_char": 16,
              "context": "The theory of\nNP-completeness\n, pioneered by Cook (1971) and Karp "
            },
            {
              "para_id": "chap1_para70",
              "entity_text": "Cook",
              "entity_type": "PERSON",
              "start_char": 45,
              "end_char": 49,
              "context": "The theory of\nNP-completeness\n, pioneered by Cook (1971) and Karp (1972), provides a basis for anal"
            },
            {
              "para_id": "chap1_para70",
              "entity_text": "Karp",
              "entity_type": "PERSON",
              "start_char": 61,
              "end_char": 65,
              "context": "of\nNP-completeness\n, pioneered by Cook (1971) and Karp (1972), provides a basis for analyzing the tracta"
            },
            {
              "para_id": "chap1_para70",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 175,
              "end_char": 177,
              "context": "problems: any problem class to which the class of NP-complete problems can be reduced is likely to be "
            },
            {
              "para_id": "chap1_para70",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 278,
              "end_char": 280,
              "context": "ntractable. (Although it has not been proved that NP-complete problems are necessarily intractable, mo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para71",
          "content": "1.2.3\nEconomics\n•\nHow should we make decisions in accordance with our preferences?",
          "sentence_count": 1,
          "char_count": 73,
          "prev_para_id": "chap1_para70",
          "next_para_id": "chap1_para72",
          "style_metadata": {
            "para_id": "chap1_para71",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "economics": 1,
            "make": 1,
            "decision": 1,
            "accordance": 1,
            "preference": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para72",
          "content": "•\nHow should we do this when others may not go along?",
          "sentence_count": 1,
          "char_count": 43,
          "prev_para_id": "chap1_para71",
          "next_para_id": "chap1_para73",
          "style_metadata": {
            "para_id": "chap1_para72",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "others": 1,
            "along": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para73",
          "content": "•\nHow should we do this when the payoff may be far in the future?",
          "sentence_count": 1,
          "char_count": 52,
          "prev_para_id": "chap1_para72",
          "next_para_id": "chap1_para74",
          "style_metadata": {
            "para_id": "chap1_para73",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "payoff": 1,
            "future": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para74",
          "content": "The science of economics originated in 1776, when Adam Smith (1723–1790) published\nAn Inquiry into the Nature and Causes of the Wealth of Nations.",
          "sentence_count": 1,
          "char_count": 124,
          "prev_para_id": "chap1_para73",
          "next_para_id": "chap1_para75",
          "style_metadata": {
            "para_id": "chap1_para74",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "science": 1,
            "economics": 1,
            "originated": 1,
            "smith": 1,
            "published": 1,
            "inquiry": 1,
            "nature": 1,
            "cause": 1,
            "wealth": 1,
            "nation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para74",
              "entity_text": "Adam Smith",
              "entity_type": "PERSON",
              "start_char": 50,
              "end_char": 60,
              "context": "The science of economics originated in 1776, when Adam Smith (1723–1790) published\nAn Inquiry into the Nature "
            },
            {
              "para_id": "chap1_para74",
              "entity_text": "An Inquiry",
              "entity_type": "WORK_OF_ART",
              "start_char": 83,
              "end_char": 93,
              "context": "ed in 1776, when Adam Smith (1723–1790) published\nAn Inquiry into the Nature and Causes of the Wealth of Natio"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para75",
          "content": "Smith proposed to analyze economies as consisting of many individual agents attending to their own interests. Smith was not, however, advocating financial greed as a moral position: his earlier (1759) book\nThe Theory of Moral Sentiments\nbegins by pointing out that concern for the well-being of others is an essential component of the interests of every individual.",
          "sentence_count": 2,
          "char_count": 311,
          "prev_para_id": "chap1_para74",
          "next_para_id": "chap1_para76",
          "style_metadata": {
            "para_id": "chap1_para75",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 64,
            "sentence_count": 2
          },
          "terminology": {
            "smith": 2,
            "proposed": 1,
            "analyze": 1,
            "economy": 1,
            "consisting": 1,
            "many": 1,
            "individual": 2,
            "agent": 1,
            "attending": 1,
            "interest": 2,
            "advocating": 1,
            "financial": 1,
            "greed": 1,
            "moral": 2,
            "position": 1,
            "book": 1,
            "theory": 1,
            "sentiment": 1,
            "begin": 1,
            "pointing": 1,
            "concern": 1,
            "well-being": 1,
            "others": 1,
            "essential": 1,
            "component": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para75",
              "entity_text": "Smith",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 5,
              "context": "Smith proposed to analyze economies as consisting of ma"
            },
            {
              "para_id": "chap1_para75",
              "entity_text": "Smith",
              "entity_type": "PERSON",
              "start_char": 110,
              "end_char": 115,
              "context": "dividual agents attending to their own interests. Smith was not, however, advocating financial greed as a"
            },
            {
              "para_id": "chap1_para75",
              "entity_text": "The Theory of Moral Sentiments",
              "entity_type": "WORK_OF_ART",
              "start_char": 206,
              "end_char": 236,
              "context": "reed as a moral position: his earlier (1759) book\nThe Theory of Moral Sentiments\nbegins by pointing out that concern for the well-"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para76",
          "content": "Most people think of economics as being about money, and indeed the first mathematical analysis of decisions under uncertainty, the maximum-expected-value formula of Arnauld (1662), dealt with the monetary value of bets. Daniel Bernoulli (1738) noticed that this formula didn’t seem to work well for larger amounts of money, such as investments in maritime trading expeditions. He proposed instead a principle based on maximization of expected utility, and explained human investment choices by proposing that the marginal utility of an additional quantity of money diminished as one acquired more money.",
          "sentence_count": 3,
          "char_count": 515,
          "prev_para_id": "chap1_para75",
          "next_para_id": "chap1_para77",
          "style_metadata": {
            "para_id": "chap1_para76",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 3
          },
          "terminology": {
            "people": 1,
            "think": 1,
            "economics": 1,
            "money": 4,
            "mathematical": 1,
            "analysis": 1,
            "decision": 1,
            "uncertainty": 1,
            "maximum-expected-value": 1,
            "formula": 2,
            "arnauld": 1,
            "dealt": 1,
            "monetary": 1,
            "value": 1,
            "bet": 1,
            "daniel": 1,
            "bernoulli": 1,
            "noticed": 1,
            "seem": 1,
            "work": 1,
            "larger": 1,
            "amount": 1,
            "investment": 2,
            "trading": 1,
            "expedition": 1,
            "proposed": 1,
            "principle": 1,
            "based": 1,
            "maximization": 1,
            "expected": 1,
            "utility": 2,
            "explained": 1,
            "human": 1,
            "choice": 1,
            "proposing": 1,
            "marginal": 1,
            "additional": 1,
            "quantity": 1,
            "diminished": 1,
            "acquired": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para76",
              "entity_text": "Arnauld",
              "entity_type": "PERSON",
              "start_char": 166,
              "end_char": 173,
              "context": "ncertainty, the maximum-expected-value formula of Arnauld (1662), dealt with the monetary value of bets. Da"
            },
            {
              "para_id": "chap1_para76",
              "entity_text": "Daniel Bernoulli",
              "entity_type": "PERSON",
              "start_char": 221,
              "end_char": 237,
              "context": "ld (1662), dealt with the monetary value of bets. Daniel Bernoulli (1738) noticed that this formula didn’t seem to w"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para77",
          "content": "Léon Walras (pronounced “Valrasse”) (1834–1910) gave utility theory a more general foundation in terms of preferences between gambles on any outcomes (not just monetary outcomes). The theory was improved by Ramsey (1931) and later by John von Neumann and Oskar Morgenstern in their book\nThe Theory of Games and Economic Behavior\n(1944). Economics is no longer the study of money; rather it is the study of desires and preferences.",
          "sentence_count": 3,
          "char_count": 364,
          "prev_para_id": "chap1_para76",
          "next_para_id": "chap1_para78",
          "style_metadata": {
            "para_id": "chap1_para77",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.33,
            "passive_voice_ratio": 0.012,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 3
          },
          "terminology": {
            "léon": 1,
            "walras": 1,
            "pronounced": 1,
            "valrasse": 1,
            "gave": 1,
            "utility": 1,
            "theory": 3,
            "general": 1,
            "foundation": 1,
            "term": 1,
            "preference": 2,
            "gamble": 1,
            "monetary": 1,
            "outcome": 1,
            "improved": 1,
            "ramsey": 1,
            "john": 1,
            "von": 1,
            "oskar": 1,
            "morgenstern": 1,
            "book": 1,
            "game": 1,
            "economic": 1,
            "behavior": 1,
            "economics": 1,
            "study": 2,
            "money": 1,
            "desire": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para77",
              "entity_text": "Léon Walras",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 11,
              "context": "Léon Walras (pronounced “Valrasse”) (1834–1910) gave utility "
            },
            {
              "para_id": "chap1_para77",
              "entity_text": "Ramsey",
              "entity_type": "PERSON",
              "start_char": 207,
              "end_char": 213,
              "context": "st monetary outcomes). The theory was improved by Ramsey (1931) and later by John von Neumann and Oskar Mo"
            },
            {
              "para_id": "chap1_para77",
              "entity_text": "John von Neumann",
              "entity_type": "PERSON",
              "start_char": 234,
              "end_char": 250,
              "context": "theory was improved by Ramsey (1931) and later by John von Neumann and Oskar Morgenstern in their book\nThe Theory of"
            },
            {
              "para_id": "chap1_para77",
              "entity_text": "Oskar Morgenstern",
              "entity_type": "PERSON",
              "start_char": 255,
              "end_char": 272,
              "context": "y Ramsey (1931) and later by John von Neumann and Oskar Morgenstern in their book\nThe Theory of Games and Economic Be"
            },
            {
              "para_id": "chap1_para77",
              "entity_text": "The Theory of Games and Economic Behavior",
              "entity_type": "WORK_OF_ART",
              "start_char": 287,
              "end_char": 328,
              "context": "n von Neumann and Oskar Morgenstern in their book\nThe Theory of Games and Economic Behavior\n(1944). Economics is no longer the study of money"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para78",
          "content": "Decision theory\n, which combines probability theory with utility theory, provides a formal and complete framework for individual decisions (economic or otherwise) made under uncertainty—that is, in cases where probabilistic descriptions appropriately capture the decision maker’s environment. This is suitable for “large” economies where each agent need pay no attention to the actions of other agents as individuals. For “small” economies, the situation is much more like a\ngame\n: the actions of one player can significantly affect the utility of another (either positively or negatively). Von Neumann and Morgenstern’s development of\ngame theory\n(see also Luce and Raiffa, 1957) included the surprising result that, for some games, a rational agent should adopt policies that are (or least appear to be) randomized. Unlike decision theory, game theory does not offer an unambiguous prescription for selecting actions. In AI, decisions involving multiple agents are studied under the heading of\nmultiagent systems\n(\nChapter 17\n).",
          "sentence_count": 6,
          "char_count": 886,
          "prev_para_id": "chap1_para77",
          "next_para_id": "chap1_para79",
          "style_metadata": {
            "para_id": "chap1_para78",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 184,
            "sentence_count": 6
          },
          "terminology": {
            "decision": 5,
            "theory": 6,
            "combine": 1,
            "probability": 1,
            "utility": 2,
            "provides": 1,
            "formal": 1,
            "complete": 1,
            "framework": 1,
            "individual": 2,
            "economic": 1,
            "made": 1,
            "uncertainty—that": 1,
            "case": 1,
            "probabilistic": 1,
            "description": 1,
            "capture": 1,
            "maker": 1,
            "environment": 1,
            "suitable": 1,
            "large": 1,
            "economy": 2,
            "agent": 4,
            "pay": 1,
            "attention": 1,
            "action": 3,
            "small": 1,
            "situation": 1,
            "game": 4,
            "player": 1,
            "affect": 1,
            "von": 1,
            "neumann": 1,
            "morgenstern": 1,
            "development": 1,
            "see": 1,
            "luce": 1,
            "raiffa": 1,
            "included": 1,
            "surprising": 1,
            "result": 1,
            "rational": 1,
            "adopt": 1,
            "policy": 1,
            "least": 1,
            "appear": 1,
            "randomized": 1,
            "offer": 1,
            "unambiguous": 1,
            "prescription": 1,
            "selecting": 1,
            "involving": 1,
            "multiple": 1,
            "studied": 1,
            "heading": 1,
            "multiagent": 1,
            "system": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para78",
              "entity_text": "Von Neumann",
              "entity_type": "PERSON",
              "start_char": 591,
              "end_char": 602,
              "context": "ity of another (either positively or negatively). Von Neumann and Morgenstern’s development of\ngame theory\n(see"
            },
            {
              "para_id": "chap1_para78",
              "entity_text": "Morgenstern’s",
              "entity_type": "ORG",
              "start_char": 607,
              "end_char": 620,
              "context": "either positively or negatively). Von Neumann and Morgenstern’s development of\ngame theory\n(see also Luce and Rai"
            },
            {
              "para_id": "chap1_para78",
              "entity_text": "Luce",
              "entity_type": "PRODUCT",
              "start_char": 658,
              "end_char": 662,
              "context": "orgenstern’s development of\ngame theory\n(see also Luce and Raiffa, 1957) included the surprising result "
            },
            {
              "para_id": "chap1_para78",
              "entity_text": "Raiffa",
              "entity_type": "PERSON",
              "start_char": 667,
              "end_char": 673,
              "context": "n’s development of\ngame theory\n(see also Luce and Raiffa, 1957) included the surprising result that, for s"
            },
            {
              "para_id": "chap1_para78",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 923,
              "end_char": 925,
              "context": "nambiguous prescription for selecting actions. In AI, decisions involving multiple agents are studied "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para79",
          "content": "Economists, with some exceptions, did not address the third question listed above: how to make rational decisions when payoffs from actions are not immediate but instead result from several actions taken\nin sequence.",
          "sentence_count": 1,
          "char_count": 185,
          "prev_para_id": "chap1_para78",
          "next_para_id": "chap1_para80",
          "style_metadata": {
            "para_id": "chap1_para79",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 1
          },
          "terminology": {
            "economist": 1,
            "exception": 1,
            "address": 1,
            "third": 1,
            "question": 1,
            "listed": 1,
            "make": 1,
            "rational": 1,
            "decision": 1,
            "payoff": 1,
            "action": 2,
            "immediate": 1,
            "result": 1,
            "several": 1,
            "taken": 1,
            "sequence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para80",
          "content": "This topic was pursued in the field of\noperations research\n, which emerged in World War II from efforts in Britain to optimize radar installations, and later found innumerable civilian applications. The work of Richard Bellman (1957) formalized a class of sequential decision problems called\nMarkov decision processes\n, which we study in\nChapter 16\nand, under the heading of\nreinforcement learning\n, in\nChapter 23\n.",
          "sentence_count": 2,
          "char_count": 359,
          "prev_para_id": "chap1_para79",
          "next_para_id": "chap1_para81",
          "style_metadata": {
            "para_id": "chap1_para80",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 2
          },
          "terminology": {
            "topic": 1,
            "pursued": 1,
            "field": 1,
            "operation": 1,
            "research": 1,
            "emerged": 1,
            "world": 1,
            "war": 1,
            "effort": 1,
            "britain": 1,
            "optimize": 1,
            "radar": 1,
            "installation": 1,
            "found": 1,
            "innumerable": 1,
            "civilian": 1,
            "application": 1,
            "work": 1,
            "bellman": 1,
            "formalized": 1,
            "class": 1,
            "sequential": 1,
            "decision": 2,
            "problem": 1,
            "called": 1,
            "markov": 1,
            "process": 1,
            "study": 1,
            "chapter": 2,
            "heading": 1,
            "reinforcement": 1,
            "learning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para80",
              "entity_text": "World War II",
              "entity_type": "EVENT",
              "start_char": 78,
              "end_char": 90,
              "context": "e field of\noperations research\n, which emerged in World War II from efforts in Britain to optimize radar install"
            },
            {
              "para_id": "chap1_para80",
              "entity_text": "Britain",
              "entity_type": "GPE",
              "start_char": 107,
              "end_char": 114,
              "context": "h\n, which emerged in World War II from efforts in Britain to optimize radar installations, and later found "
            },
            {
              "para_id": "chap1_para80",
              "entity_text": "Richard Bellman",
              "entity_type": "PERSON",
              "start_char": 211,
              "end_char": 226,
              "context": "nd innumerable civilian applications. The work of Richard Bellman (1957) formalized a class of sequential decision "
            },
            {
              "para_id": "chap1_para80",
              "entity_text": "Markov",
              "entity_type": "PERSON",
              "start_char": 292,
              "end_char": 298,
              "context": "ed a class of sequential decision problems called\nMarkov decision processes\n, which we study in\nChapter 16"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para81",
          "content": "Work in economics and operations research has contributed much to our notion of rational agents, yet for many years AI research developed along entirely separate paths. One reason was the apparent complexity of making rational decisions. The pioneering AI researcher Herbert Simon (1916–2001) won the Nobel Prize in economics in 1978 for his early work showing that models based on\nsatisficing\n—making decisions that are “good enough,” rather than laboriously calculating an optimal decision—gave a better description of actual human behavior (Simon, 1947). Since the 1990s, there has been a resurgence of interest in decision-theoretic techniques for AI.",
          "sentence_count": 4,
          "char_count": 560,
          "prev_para_id": "chap1_para80",
          "next_para_id": "chap1_para82",
          "style_metadata": {
            "para_id": "chap1_para81",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 4
          },
          "terminology": {
            "work": 2,
            "economics": 2,
            "operation": 1,
            "research": 2,
            "contributed": 1,
            "much": 1,
            "notion": 1,
            "rational": 2,
            "agent": 1,
            "many": 1,
            "year": 1,
            "developed": 1,
            "separate": 1,
            "path": 1,
            "reason": 1,
            "apparent": 1,
            "complexity": 1,
            "making": 1,
            "decision": 2,
            "pioneering": 1,
            "researcher": 1,
            "herbert": 1,
            "simon": 2,
            "nobel": 1,
            "prize": 1,
            "early": 1,
            "showing": 1,
            "model": 1,
            "based": 1,
            "satisficing": 1,
            "—making": 1,
            "good": 1,
            "calculating": 1,
            "optimal": 1,
            "decision—gave": 1,
            "better": 1,
            "description": 1,
            "actual": 1,
            "human": 1,
            "behavior": 1,
            "resurgence": 1,
            "interest": 1,
            "decision-theoretic": 1,
            "technique": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para81",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 253,
              "end_char": 255,
              "context": "xity of making rational decisions. The pioneering AI researcher Herbert Simon (1916–2001) won the Nobe"
            },
            {
              "para_id": "chap1_para81",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 267,
              "end_char": 280,
              "context": " rational decisions. The pioneering AI researcher Herbert Simon (1916–2001) won the Nobel Prize in economics in 1"
            },
            {
              "para_id": "chap1_para81",
              "entity_text": "the Nobel Prize",
              "entity_type": "WORK_OF_ART",
              "start_char": 297,
              "end_char": 312,
              "context": "ering AI researcher Herbert Simon (1916–2001) won the Nobel Prize in economics in 1978 for his early work showing t"
            },
            {
              "para_id": "chap1_para81",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 544,
              "end_char": 549,
              "context": "ve a better description of actual human behavior (Simon, 1947). Since the 1990s, there has been a resurge"
            },
            {
              "para_id": "chap1_para81",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 652,
              "end_char": 654,
              "context": " of interest in decision-theoretic techniques for AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para82",
          "content": "1.2.4\nNeuroscience\n•\nHow do brains process information?",
          "sentence_count": 1,
          "char_count": 51,
          "prev_para_id": "chap1_para81",
          "next_para_id": "chap1_para83",
          "style_metadata": {
            "para_id": "chap1_para82",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "neuroscience": 1,
            "brain": 1,
            "process": 1,
            "information": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para83",
          "content": "Neuroscience\nis the study of the nervous system, particularly the brain. Although the exact way in which the brain enables thought is one of the great mysteries of science, the fact that it\ndoes\nenable thought has been appreciated for thousands of years because of the evidence that strong blows to the head can lead to mental incapacitation. It has also long been known that human brains are somehow different; in about 335\nBCE\nAristotle wrote, “Of all the animals, man has the largest brain in proportion to his size.”\n6\nStill, it was not until the middle of the 18th century that the brain was widely recognized as the seat of consciousness. Before then, candidate locations included the heart and the spleen.",
          "sentence_count": 4,
          "char_count": 597,
          "prev_para_id": "chap1_para82",
          "next_para_id": "chap1_para84",
          "style_metadata": {
            "para_id": "chap1_para83",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 4
          },
          "terminology": {
            "neuroscience": 1,
            "study": 1,
            "nervous": 1,
            "system": 1,
            "brain": 5,
            "exact": 1,
            "way": 1,
            "enables": 1,
            "thought": 2,
            "great": 1,
            "mystery": 1,
            "science": 1,
            "fact": 1,
            "enable": 1,
            "appreciated": 1,
            "thousand": 1,
            "year": 1,
            "evidence": 1,
            "strong": 1,
            "blow": 1,
            "head": 1,
            "lead": 1,
            "mental": 1,
            "incapacitation": 1,
            "known": 1,
            "human": 1,
            "somehow": 1,
            "different": 1,
            "bce": 1,
            "aristotle": 1,
            "wrote": 1,
            "animal": 1,
            "man": 1,
            "largest": 1,
            "proportion": 1,
            "size.": 1,
            "middle": 1,
            "18th": 1,
            "century": 1,
            "recognized": 1,
            "seat": 1,
            "consciousness": 1,
            "candidate": 1,
            "location": 1,
            "included": 1,
            "heart": 1,
            "spleen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para83",
              "entity_text": "Aristotle",
              "entity_type": "PERSON",
              "start_char": 429,
              "end_char": 438,
              "context": "an brains are somehow different; in about 335\nBCE\nAristotle wrote, “Of all the animals, man has the largest b"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para84",
          "content": "Paul Broca’s (1824–1880) investigation of aphasia (speech deficit) in brain-damaged patients in 1861 initiated the study of the brain’s functional organization by identifying a localized area in the left hemisphere—now called Broca’s area—that is responsible for speech production.",
          "sentence_count": 1,
          "char_count": 244,
          "prev_para_id": "chap1_para83",
          "next_para_id": "chap1_para85",
          "style_metadata": {
            "para_id": "chap1_para84",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 1
          },
          "terminology": {
            "paul": 1,
            "broca": 2,
            "investigation": 1,
            "aphasia": 1,
            "speech": 2,
            "deficit": 1,
            "brain-damaged": 1,
            "patient": 1,
            "initiated": 1,
            "study": 1,
            "brain": 1,
            "functional": 1,
            "organization": 1,
            "identifying": 1,
            "localized": 1,
            "area": 1,
            "left": 1,
            "hemisphere—now": 1,
            "called": 1,
            "responsible": 1,
            "production": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para84",
              "entity_text": "Paul Broca’s",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 12,
              "context": "Paul Broca’s (1824–1880) investigation of aphasia (speech defi"
            },
            {
              "para_id": "chap1_para84",
              "entity_text": "aphasia",
              "entity_type": "ORG",
              "start_char": 42,
              "end_char": 49,
              "context": "Paul Broca’s (1824–1880) investigation of aphasia (speech deficit) in brain-damaged patients in 186"
            },
            {
              "para_id": "chap1_para84",
              "entity_text": "Broca’s",
              "entity_type": "ORG",
              "start_char": 226,
              "end_char": 233,
              "context": " localized area in the left hemisphere—now called Broca’s area—that is responsible for speech production."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para85",
          "content": "7\nBy that time, it was known that the brain consisted largely of nerve cells, or\nneurons\n, but it was not until 1873 that Camillo Golgi (1843–1926) developed a staining technique allowing the observation of individual neurons (see\nFigure 1.1\n). This technique was used by Santiago Ramon y Cajal (1852–1934) in his pioneering studies of neuronal organization.",
          "sentence_count": 2,
          "char_count": 305,
          "prev_para_id": "chap1_para84",
          "next_para_id": "chap1_para86",
          "style_metadata": {
            "para_id": "chap1_para85",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 2
          },
          "terminology": {
            "time": 1,
            "known": 1,
            "brain": 1,
            "consisted": 1,
            "nerve": 1,
            "cell": 1,
            "neuron": 2,
            "camillo": 1,
            "golgi": 1,
            "developed": 1,
            "staining": 1,
            "technique": 2,
            "allowing": 1,
            "observation": 1,
            "individual": 1,
            "see": 1,
            "figure": 1,
            "used": 1,
            "ramon": 1,
            "cajal": 1,
            "pioneering": 1,
            "study": 1,
            "neuronal": 1,
            "organization": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para85",
              "entity_text": "Camillo Golgi",
              "entity_type": "ORG",
              "start_char": 122,
              "end_char": 135,
              "context": "ells, or\nneurons\n, but it was not until 1873 that Camillo Golgi (1843–1926) developed a staining technique allowi"
            },
            {
              "para_id": "chap1_para85",
              "entity_text": "Santiago Ramon y Cajal",
              "entity_type": "PERSON",
              "start_char": 272,
              "end_char": 294,
              "context": "ons (see\nFigure 1.1\n). This technique was used by Santiago Ramon y Cajal (1852–1934) in his pioneering studies of neuronal"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para86",
          "content": "8\nIt is now widely accepted that cognitive functions result from the electrochemical operation of these structures. That is,\na collection of simple cells can lead to thought, action, and consciousness.",
          "sentence_count": 2,
          "char_count": 173,
          "prev_para_id": "chap1_para85",
          "next_para_id": "chap1_para87",
          "style_metadata": {
            "para_id": "chap1_para86",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 2
          },
          "terminology": {
            "accepted": 1,
            "cognitive": 1,
            "function": 1,
            "result": 1,
            "electrochemical": 1,
            "operation": 1,
            "structure": 1,
            "collection": 1,
            "simple": 1,
            "cell": 1,
            "lead": 1,
            "thought": 1,
            "action": 1,
            "consciousness": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para87",
          "content": "In the pithy words of John Searle (1992),\nbrains cause minds.",
          "sentence_count": 1,
          "char_count": 52,
          "prev_para_id": "chap1_para86",
          "next_para_id": "chap1_para88",
          "style_metadata": {
            "para_id": "chap1_para87",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "pithy": 1,
            "word": 1,
            "john": 1,
            "searle": 1,
            "brain": 1,
            "cause": 1,
            "mind": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para87",
              "entity_text": "John Searle",
              "entity_type": "PERSON",
              "start_char": 22,
              "end_char": 33,
              "context": "In the pithy words of John Searle (1992),\nbrains cause minds."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para88",
          "content": "Description\nThe neuron consists of a cell body, which is also labeled Soma. The nucleus is present at the center of the cell body. Finger-like fibers labeled dendrites extend out from the cell body. A single long fiber extends into a tubular structure labeled axon. The other end of the axon branches further as tree-like projections labeled Axonal arborization. An axon from another neuron cell is shown to be in contact with one of the dendrites of the neuron cell in view. The region or junction of contact between the dendrite and one of the tree-like projections from another axon is labeled the synapse. Two of such synapses are shown at the end of the tree-like projections from the neuron in view.",
          "sentence_count": 8,
          "char_count": 585,
          "prev_para_id": "chap1_para87",
          "next_para_id": "chap1_para89",
          "style_metadata": {
            "para_id": "chap1_para88",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.38,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 131,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "neuron": 2,
            "consists": 1,
            "cell": 5,
            "body": 3,
            "labeled": 5,
            "soma": 1,
            "nucleus": 1,
            "present": 1,
            "center": 1,
            "finger-like": 1,
            "fiber": 2,
            "dendrite": 3,
            "extend": 1,
            "single": 1,
            "long": 1,
            "extends": 1,
            "tubular": 1,
            "structure": 1,
            "axon": 3,
            "end": 2,
            "branch": 1,
            "tree-like": 3,
            "projection": 3,
            "axonal": 1,
            "arborization": 1,
            "shown": 2,
            "contact": 2,
            "view": 2,
            "region": 1,
            "junction": 1,
            "synapse": 1,
            "synapsis": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para88",
              "entity_text": "Soma",
              "entity_type": "ORG",
              "start_char": 70,
              "end_char": 74,
              "context": "on consists of a cell body, which is also labeled Soma. The nucleus is present at the center of the cell"
            },
            {
              "para_id": "chap1_para88",
              "entity_text": "Axonal",
              "entity_type": "ORG",
              "start_char": 342,
              "end_char": 348,
              "context": "branches further as tree-like projections labeled Axonal arborization. An axon from another neuron cell is"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para89",
          "content": "×\nFigure 1.1\nThe parts of a nerve cell or neuron. Each neuron consists of a cell body, or soma, that contains a cell nucleus. Branching out from the cell body are a number of fibers called dendrites and a single long fiber called the axon. The axon stretches out for a long distance, much longer than the scale in this diagram indicates. Typically, an axon is 1 cm long (100 times the diameter of the cell body), but can reach up to 1 meter. A neuron makes connections with 10 to 100,000 other neurons at junctions called synapses. Signals are propagated from neuron to neuron by a complicated electrochemical reaction. The signals control brain activity in the short term and also enable long-term changes in the connectivity of neurons. These mechanisms are thought to form the basis for learning in the brain. Most information processing goes on in the cerebral cortex, the outer layer of the brain. The basic organizational unit appears to be a column of tissue about 0.5 mm in diameter, containing about 20,000 neurons and extending the full depth of the cortex (about 4 mm in humans).",
          "sentence_count": 11,
          "char_count": 902,
          "prev_para_id": "chap1_para88",
          "next_para_id": "chap1_para90",
          "style_metadata": {
            "para_id": "chap1_para89",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.36,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 213,
            "sentence_count": 11
          },
          "terminology": {
            "figure": 1,
            "part": 1,
            "cell": 5,
            "neuron": 6,
            "consists": 1,
            "body": 3,
            "soma": 1,
            "contains": 1,
            "branching": 1,
            "number": 1,
            "fiber": 2,
            "called": 3,
            "dendrite": 1,
            "single": 1,
            "long": 2,
            "axon": 1,
            "stretch": 1,
            "scale": 1,
            "diagram": 1,
            "indicates": 1,
            "reach": 1,
            "meter": 1,
            "make": 1,
            "connection": 1,
            "junction": 1,
            "synapsis": 1,
            "signal": 2,
            "propagated": 1,
            "complicated": 1,
            "electrochemical": 1,
            "reaction": 1,
            "control": 1,
            "brain": 3,
            "activity": 1,
            "short": 1,
            "term": 1,
            "enable": 1,
            "long-term": 1,
            "change": 1,
            "connectivity": 1,
            "mechanism": 1,
            "thought": 1,
            "form": 1,
            "basis": 1,
            "learning": 1,
            "information": 1,
            "processing": 1,
            "go": 1,
            "cerebral": 1,
            "cortex": 2,
            "outer": 1,
            "layer": 1,
            "basic": 1,
            "organizational": 1,
            "unit": 1,
            "appears": 1,
            "column": 1,
            "tissue": 1,
            "diameter": 1,
            "containing": 1,
            "extending": 1,
            "full": 1,
            "depth": 1,
            "human": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para89",
              "entity_text": "neuron",
              "entity_type": "GPE",
              "start_char": 560,
              "end_char": 566,
              "context": "ions called synapses. Signals are propagated from neuron to neuron by a complicated electrochemical reacti"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para90",
          "content": "We now have some data on the mapping between areas of the brain and the parts of the body that they control or from which they receive sensory input. Such mappings are able to change radically over the course of a few weeks, and some animals seem to have multiple maps. Moreover, we do not fully understand how other areas can take over functions when one area is damaged. There is almost no theory on how an individual memory is stored or on how higher-level cognitive functions operate.",
          "sentence_count": 4,
          "char_count": 401,
          "prev_para_id": "chap1_para89",
          "next_para_id": "chap1_para91",
          "style_metadata": {
            "para_id": "chap1_para90",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.021,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 94,
            "sentence_count": 4
          },
          "terminology": {
            "data": 1,
            "mapping": 2,
            "area": 3,
            "brain": 1,
            "part": 1,
            "body": 1,
            "control": 1,
            "receive": 1,
            "sensory": 1,
            "input": 1,
            "able": 1,
            "change": 1,
            "course": 1,
            "week": 1,
            "animal": 1,
            "seem": 1,
            "multiple": 1,
            "map": 1,
            "understand": 1,
            "take": 1,
            "function": 2,
            "damaged": 1,
            "theory": 1,
            "individual": 1,
            "memory": 1,
            "stored": 1,
            "higher-level": 1,
            "cognitive": 1,
            "operate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para91",
          "content": "The measurement of intact brain activity began in 1929 with the invention by Hans Berger of the electroencephalograph (EEG). The development of functional magnetic resonance imaging (fMRI) (Ogawa\net al.,\n1990; Cabeza and Nyberg, 2001) is giving neuroscientists unprecedentedly detailed images of brain activity, enabling measurements that correspond in interesting ways to ongoing cognitive processes. These are augmented by advances in single-cell electrical recording of neuron activity and by the methods of\noptogenetics\n(Crick, 1999; Zemelman\net al.,\n2002; Han and Boyden, 2007), which allow both measurement and control of individual neurons modified to be light-sensitive.",
          "sentence_count": 3,
          "char_count": 589,
          "prev_para_id": "chap1_para90",
          "next_para_id": "chap1_para92",
          "style_metadata": {
            "para_id": "chap1_para91",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 117,
            "sentence_count": 3
          },
          "terminology": {
            "measurement": 3,
            "intact": 1,
            "brain": 2,
            "activity": 3,
            "began": 1,
            "invention": 1,
            "han": 2,
            "berger": 1,
            "electroencephalograph": 1,
            "eeg": 1,
            "development": 1,
            "functional": 1,
            "magnetic": 1,
            "resonance": 1,
            "imaging": 1,
            "fmri": 1,
            "ogawa": 1,
            "al.": 2,
            "cabeza": 1,
            "giving": 1,
            "neuroscientist": 1,
            "detailed": 1,
            "image": 1,
            "enabling": 1,
            "correspond": 1,
            "interesting": 1,
            "way": 1,
            "ongoing": 1,
            "cognitive": 1,
            "process": 1,
            "augmented": 1,
            "advance": 1,
            "single-cell": 1,
            "electrical": 1,
            "recording": 1,
            "neuron": 2,
            "method": 1,
            "optogenetics": 1,
            "crick": 1,
            "zemelman": 1,
            "boyden": 1,
            "allow": 1,
            "control": 1,
            "individual": 1,
            "modified": 1,
            "light-sensitive": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para91",
              "entity_text": "Hans Berger",
              "entity_type": "PERSON",
              "start_char": 77,
              "end_char": 88,
              "context": "rain activity began in 1929 with the invention by Hans Berger of the electroencephalograph (EEG). The developme"
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "Ogawa",
              "entity_type": "PERSON",
              "start_char": 190,
              "end_char": 195,
              "context": " of functional magnetic resonance imaging (fMRI) (Ogawa\net al.,\n1990; Cabeza and Nyberg, 2001) is giving "
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 199,
              "end_char": 202,
              "context": "ional magnetic resonance imaging (fMRI) (Ogawa\net al.,\n1990; Cabeza and Nyberg, 2001) is giving neurosc"
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "Cabeza",
              "entity_type": "ORG",
              "start_char": 210,
              "end_char": 216,
              "context": "tic resonance imaging (fMRI) (Ogawa\net al.,\n1990; Cabeza and Nyberg, 2001) is giving neuroscientists unpre"
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "Nyberg",
              "entity_type": "ORG",
              "start_char": 221,
              "end_char": 227,
              "context": "ce imaging (fMRI) (Ogawa\net al.,\n1990; Cabeza and Nyberg, 2001) is giving neuroscientists unprecedentedly "
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "Crick",
              "entity_type": "ORG",
              "start_char": 525,
              "end_char": 530,
              "context": "uron activity and by the methods of\noptogenetics\n(Crick, 1999; Zemelman\net al.,\n2002; Han and Boyden, 200"
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "Zemelman",
              "entity_type": "ORG",
              "start_char": 538,
              "end_char": 546,
              "context": " and by the methods of\noptogenetics\n(Crick, 1999; Zemelman\net al.,\n2002; Han and Boyden, 2007), which allow "
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 550,
              "end_char": 553,
              "context": "methods of\noptogenetics\n(Crick, 1999; Zemelman\net al.,\n2002; Han and Boyden, 2007), which allow both me"
            },
            {
              "para_id": "chap1_para91",
              "entity_text": "Boyden",
              "entity_type": "GPE",
              "start_char": 569,
              "end_char": 575,
              "context": "tics\n(Crick, 1999; Zemelman\net al.,\n2002; Han and Boyden, 2007), which allow both measurement and control "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para92",
          "content": "The development of\nbrain-machine interfaces\n(Lebedev and Nicolelis, 2006) for both sensing and motor control not only promises to restore function to disabled individuals, but also sheds light on many aspects of neural systems. A remarkable finding from this work is that the brain is able to adjust itself to interface successfully with an external device, treating it in effect like another sensory organ or limb.",
          "sentence_count": 2,
          "char_count": 352,
          "prev_para_id": "chap1_para91",
          "next_para_id": "chap1_para93",
          "style_metadata": {
            "para_id": "chap1_para92",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 2
          },
          "terminology": {
            "development": 1,
            "brain-machine": 1,
            "interface": 2,
            "lebedev": 1,
            "nicolelis": 1,
            "sensing": 1,
            "motor": 1,
            "control": 1,
            "promise": 1,
            "restore": 1,
            "function": 1,
            "disabled": 1,
            "individual": 1,
            "shed": 1,
            "light": 1,
            "many": 1,
            "aspect": 1,
            "neural": 1,
            "system": 1,
            "remarkable": 1,
            "finding": 1,
            "work": 1,
            "brain": 1,
            "able": 1,
            "adjust": 1,
            "external": 1,
            "device": 1,
            "treating": 1,
            "effect": 1,
            "sensory": 1,
            "organ": 1,
            "limb": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para92",
              "entity_text": "Lebedev",
              "entity_type": "PERSON",
              "start_char": 45,
              "end_char": 52,
              "context": "The development of\nbrain-machine interfaces\n(Lebedev and Nicolelis, 2006) for both sensing and motor c"
            },
            {
              "para_id": "chap1_para92",
              "entity_text": "Nicolelis",
              "entity_type": "GPE",
              "start_char": 57,
              "end_char": 66,
              "context": "elopment of\nbrain-machine interfaces\n(Lebedev and Nicolelis, 2006) for both sensing and motor control not onl"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para93",
          "content": "Brains and digital computers have somewhat different properties.",
          "sentence_count": 1,
          "char_count": 57,
          "prev_para_id": "chap1_para92",
          "next_para_id": "chap1_para94",
          "style_metadata": {
            "para_id": "chap1_para93",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "brain": 1,
            "digital": 1,
            "computer": 1,
            "different": 1,
            "property": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para94",
          "content": "Figure 1.2\nshows that computers have a cycle time that is a million times faster than a brain. The brain makes up for that with far more storage and interconnection than even a high-end personal computer, although the largest supercomputers match the brain on some metrics. Futurists make much of these numbers, pointing to an approaching\nsingularity\nat which computers reach a superhuman level of performance (Vinge, 1993; Kurzweil, 2005; Doctorow and Stross, 2012), and then rapidly improve themselves even further. But the comparisons of raw numbers are not especially informative. Even with a computer of virtually unlimited capacity, we still require further conceptual breakthroughs in our understanding of intelligence (see\nChapter 29\n). Crudely put, without the right theory, faster machines just give you the wrong answer faster.",
          "sentence_count": 6,
          "char_count": 715,
          "prev_para_id": "chap1_para93",
          "next_para_id": "chap1_para95",
          "style_metadata": {
            "para_id": "chap1_para94",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 149,
            "sentence_count": 6
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "computer": 4,
            "cycle": 1,
            "time": 2,
            "brain": 3,
            "make": 2,
            "storage": 1,
            "interconnection": 1,
            "high-end": 1,
            "personal": 1,
            "largest": 1,
            "supercomputer": 1,
            "match": 1,
            "metric": 1,
            "futurist": 1,
            "much": 1,
            "number": 2,
            "pointing": 1,
            "approaching": 1,
            "singularity": 1,
            "reach": 1,
            "superhuman": 1,
            "level": 1,
            "performance": 1,
            "vinge": 1,
            "kurzweil": 1,
            "doctorow": 1,
            "stross": 1,
            "improve": 1,
            "comparison": 1,
            "raw": 1,
            "informative": 1,
            "unlimited": 1,
            "capacity": 1,
            "require": 1,
            "conceptual": 1,
            "breakthrough": 1,
            "understanding": 1,
            "intelligence": 1,
            "see": 1,
            "chapter": 1,
            "put": 1,
            "right": 1,
            "theory": 1,
            "machine": 1,
            "give": 1,
            "wrong": 1,
            "answer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para94",
              "entity_text": "Vinge",
              "entity_type": "ORG",
              "start_char": 411,
              "end_char": 416,
              "context": "omputers reach a superhuman level of performance (Vinge, 1993; Kurzweil, 2005; Doctorow and Stross, 2012)"
            },
            {
              "para_id": "chap1_para94",
              "entity_text": "Kurzweil",
              "entity_type": "GPE",
              "start_char": 424,
              "end_char": 432,
              "context": "h a superhuman level of performance (Vinge, 1993; Kurzweil, 2005; Doctorow and Stross, 2012), and then rapid"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para95",
          "content": "Description\nThe blocks are rectangular, pyramidal, and square in shape. A thin-walled transparent box with its top open is shown. The largest rectangular and pyramidal blocks are kept inside the transparent box. A small square block, two blocks of similar sizes, and a rectangular block that is slightly larger than the two square blocks are kept outside the transparent box. A pyramidal block is kept on the small square block and another pyramidal block is kept on one of the two similar-sized blocks.",
          "sentence_count": 5,
          "char_count": 422,
          "prev_para_id": "chap1_para94",
          "next_para_id": "chap1_para96",
          "style_metadata": {
            "para_id": "chap1_para95",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 92,
            "sentence_count": 5
          },
          "terminology": {
            "description": 1,
            "block": 10,
            "rectangular": 3,
            "pyramidal": 4,
            "square": 4,
            "shape": 1,
            "thin-walled": 1,
            "transparent": 3,
            "box": 3,
            "top": 1,
            "open": 1,
            "shown": 1,
            "largest": 1,
            "kept": 4,
            "small": 2,
            "similar": 1,
            "size": 1,
            "larger": 1,
            "outside": 1,
            "similar-sized": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para96",
          "content": "×\nFigure 1.2\nA crude comparison of a leading supercomputer, Summit (Feldman, 2017); a typical personal computer of 2019; and the human brain. Human brain power has not changed much in thousands of years, whereas supercomputers have improved from megaFLOPs in the 1960s to gigaFLOPs in the 1980s, teraFLOPs in the 1990s, petaFLOPs in 2008, and exaFLOPs in 2018 (1 exaFLOP = 10\n18\nfloating point operations per second).",
          "sentence_count": 2,
          "char_count": 353,
          "prev_para_id": "chap1_para95",
          "next_para_id": "chap1_para97",
          "style_metadata": {
            "para_id": "chap1_para96",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "crude": 1,
            "comparison": 1,
            "leading": 1,
            "supercomputer": 2,
            "summit": 1,
            "feldman": 1,
            "typical": 1,
            "personal": 1,
            "computer": 1,
            "human": 2,
            "brain": 2,
            "power": 1,
            "changed": 1,
            "much": 1,
            "thousand": 1,
            "year": 1,
            "whereas": 1,
            "improved": 1,
            "megaflop": 1,
            "gigaflops": 1,
            "teraflop": 1,
            "petaflops": 1,
            "exaflop": 1,
            "floating": 1,
            "point": 1,
            "operation": 1,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para96",
              "entity_text": "Summit",
              "entity_type": "ORG",
              "start_char": 60,
              "end_char": 66,
              "context": ".2\nA crude comparison of a leading supercomputer, Summit (Feldman, 2017); a typical personal computer of 2"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para97",
          "content": "1.2.5\nPsychology\n•\nHow do humans and animals think and act?",
          "sentence_count": 1,
          "char_count": 52,
          "prev_para_id": "chap1_para96",
          "next_para_id": "chap1_para98",
          "style_metadata": {
            "para_id": "chap1_para97",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "psychology": 1,
            "human": 1,
            "animal": 1,
            "think": 1,
            "act": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para98",
          "content": "The origins of scientific psychology are usually traced to the work of the German physicist Hermann von Helmholtz (1821–1894) and his student Wilhelm Wundt (1832–1920). Helmholtz applied the scientific method to the study of human vision, and his\nHandbook of Physiological Optics\nhas been described as “the single most important treatise on the physics and physiology of human vision” (Nalwa, 1993, p.15). In 1879, Wundt opened the first laboratory of experimental psychology, at the University of Leipzig. Wundt insisted on carefully\ncontrolled experiments in which his workers would perform a perceptual or associative task while introspecting on their thought processes. The careful controls went a long way toward making psychology a science, but the subjective nature of the data made it unlikely that experimenters would ever disconfirm their own theories.",
          "sentence_count": 5,
          "char_count": 736,
          "prev_para_id": "chap1_para97",
          "next_para_id": "chap1_para99",
          "style_metadata": {
            "para_id": "chap1_para98",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 149,
            "sentence_count": 5
          },
          "terminology": {
            "origin": 1,
            "scientific": 2,
            "psychology": 3,
            "traced": 1,
            "work": 1,
            "german": 1,
            "physicist": 1,
            "hermann": 1,
            "von": 1,
            "helmholtz": 2,
            "student": 1,
            "wilhelm": 1,
            "wundt": 3,
            "applied": 1,
            "method": 1,
            "study": 1,
            "human": 2,
            "vision": 2,
            "handbook": 1,
            "physiological": 1,
            "optic": 1,
            "described": 1,
            "single": 1,
            "important": 1,
            "treatise": 1,
            "physic": 1,
            "physiology": 1,
            "nalwa": 1,
            "p.15": 1,
            "opened": 1,
            "first": 1,
            "laboratory": 1,
            "experimental": 1,
            "university": 1,
            "leipzig": 1,
            "insisted": 1,
            "controlled": 1,
            "experiment": 1,
            "worker": 1,
            "perform": 1,
            "perceptual": 1,
            "associative": 1,
            "task": 1,
            "introspecting": 1,
            "thought": 1,
            "process": 1,
            "careful": 1,
            "control": 1,
            "went": 1,
            "long": 1,
            "way": 1,
            "making": 1,
            "science": 1,
            "subjective": 1,
            "nature": 1,
            "data": 1,
            "made": 1,
            "unlikely": 1,
            "experimenter": 1,
            "disconfirm": 1,
            "theory": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para98",
              "entity_text": "Hermann von Helmholtz",
              "entity_type": "PERSON",
              "start_char": 92,
              "end_char": 113,
              "context": "sually traced to the work of the German physicist Hermann von Helmholtz (1821–1894) and his student Wilhelm Wundt (1832–1"
            },
            {
              "para_id": "chap1_para98",
              "entity_text": "Wilhelm Wundt",
              "entity_type": "PERSON",
              "start_char": 142,
              "end_char": 155,
              "context": "Hermann von Helmholtz (1821–1894) and his student Wilhelm Wundt (1832–1920). Helmholtz applied the scientific met"
            },
            {
              "para_id": "chap1_para98",
              "entity_text": "Handbook of Physiological Optics",
              "entity_type": "WORK_OF_ART",
              "start_char": 247,
              "end_char": 279,
              "context": "ific method to the study of human vision, and his\nHandbook of Physiological Optics\nhas been described as “the single most important "
            },
            {
              "para_id": "chap1_para98",
              "entity_text": "Nalwa",
              "entity_type": "PERSON",
              "start_char": 386,
              "end_char": 391,
              "context": "e on the physics and physiology of human vision” (Nalwa, 1993, p.15). In 1879, Wundt opened the first lab"
            },
            {
              "para_id": "chap1_para98",
              "entity_text": "p.15",
              "entity_type": "PERSON",
              "start_char": 399,
              "end_char": 403,
              "context": "ics and physiology of human vision” (Nalwa, 1993, p.15). In 1879, Wundt opened the first laboratory of e"
            },
            {
              "para_id": "chap1_para98",
              "entity_text": "Wundt",
              "entity_type": "PERSON",
              "start_char": 415,
              "end_char": 420,
              "context": "gy of human vision” (Nalwa, 1993, p.15). In 1879, Wundt opened the first laboratory of experimental psych"
            },
            {
              "para_id": "chap1_para98",
              "entity_text": "the University of Leipzig",
              "entity_type": "ORG",
              "start_char": 480,
              "end_char": 505,
              "context": "e first laboratory of experimental psychology, at the University of Leipzig. Wundt insisted on carefully\ncontrolled experimen"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para99",
          "content": "Biologists studying animal behavior, on the other hand, lacked introspective data and developed an objective methodology, as described by H. S. Jennings (1906) in his influential work\nBehavior of the Lower Organisms.",
          "sentence_count": 1,
          "char_count": 186,
          "prev_para_id": "chap1_para98",
          "next_para_id": "chap1_para100",
          "style_metadata": {
            "para_id": "chap1_para99",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 1
          },
          "terminology": {
            "biologist": 1,
            "studying": 1,
            "animal": 1,
            "behavior": 2,
            "hand": 1,
            "lacked": 1,
            "introspective": 1,
            "data": 1,
            "developed": 1,
            "objective": 1,
            "methodology": 1,
            "described": 1,
            "jennings": 1,
            "influential": 1,
            "work": 1,
            "organism": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para99",
              "entity_text": "H. S. Jennings",
              "entity_type": "PERSON",
              "start_char": 138,
              "end_char": 152,
              "context": "veloped an objective methodology, as described by H. S. Jennings (1906) in his influential work\nBehavior of the Lo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para100",
          "content": "Applying this viewpoint to humans, the\nbehaviorism\nmovement, led by John Watson (1878–1958), rejected\nany\ntheory involving mental processes on the grounds that introspection could not provide reliable evidence. Behaviorists insisted on studying only objective measures of the percepts (or\nstimulus\n) given to an animal and its resulting actions (or\nresponse\n). Behaviorism discovered a lot about rats and pigeons but had less success at understanding humans.",
          "sentence_count": 3,
          "char_count": 399,
          "prev_para_id": "chap1_para99",
          "next_para_id": "chap1_para101",
          "style_metadata": {
            "para_id": "chap1_para100",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "applying": 1,
            "viewpoint": 1,
            "human": 2,
            "behaviorism": 2,
            "movement": 1,
            "led": 1,
            "john": 1,
            "watson": 1,
            "rejected": 1,
            "theory": 1,
            "involving": 1,
            "mental": 1,
            "process": 1,
            "ground": 1,
            "introspection": 1,
            "provide": 1,
            "reliable": 1,
            "evidence": 1,
            "behaviorist": 1,
            "insisted": 1,
            "studying": 1,
            "objective": 1,
            "measure": 1,
            "percept": 1,
            "stimulus": 1,
            "given": 1,
            "animal": 1,
            "resulting": 1,
            "action": 1,
            "response": 1,
            "discovered": 1,
            "lot": 1,
            "rat": 1,
            "pigeon": 1,
            "less": 1,
            "success": 1,
            "understanding": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para100",
              "entity_text": "John Watson",
              "entity_type": "PERSON",
              "start_char": 68,
              "end_char": 79,
              "context": "point to humans, the\nbehaviorism\nmovement, led by John Watson (1878–1958), rejected\nany\ntheory involving mental"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para101",
          "content": "Cognitive psychology\n, which views the brain as an information-processing device, can be traced back at least to the works of William James (1842–1910). Helmholtz also insisted that perception involved a form of unconscious logical inference. The cognitive viewpoint was largely eclipsed by behaviorism in the United States, but at Cambridge’s Applied Psychology Unit, directed by Frederic Bartlett (1886–1969), cognitive modeling was able to flourish.",
          "sentence_count": 3,
          "char_count": 389,
          "prev_para_id": "chap1_para100",
          "next_para_id": "chap1_para102",
          "style_metadata": {
            "para_id": "chap1_para101",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "cognitive": 3,
            "psychology": 2,
            "view": 1,
            "brain": 1,
            "information-processing": 1,
            "device": 1,
            "traced": 1,
            "least": 1,
            "work": 1,
            "william": 1,
            "james": 1,
            "helmholtz": 1,
            "insisted": 1,
            "perception": 1,
            "involved": 1,
            "unconscious": 1,
            "logical": 1,
            "inference": 1,
            "viewpoint": 1,
            "eclipsed": 1,
            "behaviorism": 1,
            "united": 1,
            "state": 1,
            "cambridge": 1,
            "applied": 1,
            "unit": 1,
            "directed": 1,
            "frederic": 1,
            "bartlett": 1,
            "modeling": 1,
            "able": 1,
            "flourish": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para101",
              "entity_text": "William James",
              "entity_type": "PERSON",
              "start_char": 126,
              "end_char": 139,
              "context": "vice, can be traced back at least to the works of William James (1842–1910). Helmholtz also insisted that percept"
            },
            {
              "para_id": "chap1_para101",
              "entity_text": "the United States",
              "entity_type": "GPE",
              "start_char": 306,
              "end_char": 323,
              "context": " viewpoint was largely eclipsed by behaviorism in the United States, but at Cambridge’s Applied Psychology Unit, dire"
            },
            {
              "para_id": "chap1_para101",
              "entity_text": "Cambridge’s Applied Psychology Unit",
              "entity_type": "ORG",
              "start_char": 332,
              "end_char": 367,
              "context": "ipsed by behaviorism in the United States, but at Cambridge’s Applied Psychology Unit, directed by Frederic Bartlett (1886–1969), cogni"
            },
            {
              "para_id": "chap1_para101",
              "entity_text": "Frederic Bartlett",
              "entity_type": "PERSON",
              "start_char": 381,
              "end_char": 398,
              "context": " Cambridge’s Applied Psychology Unit, directed by Frederic Bartlett (1886–1969), cognitive modeling was able to flour"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para102",
          "content": "The Nature of Explanation,\nby Bartlett’s student and successor Kenneth Craik (1943), forcefully reestablished the legitimacy of such “mental” terms as beliefs and goals, arguing that they are just as scientific as, say, using pressure and temperature to talk about gases, despite gasses being made of molecules that have neither.",
          "sentence_count": 1,
          "char_count": 281,
          "prev_para_id": "chap1_para101",
          "next_para_id": "chap1_para103",
          "style_metadata": {
            "para_id": "chap1_para102",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 63.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 1
          },
          "terminology": {
            "nature": 1,
            "explanation": 1,
            "bartlett": 1,
            "student": 1,
            "successor": 1,
            "kenneth": 1,
            "craik": 1,
            "reestablished": 1,
            "legitimacy": 1,
            "mental": 1,
            "term": 1,
            "belief": 1,
            "goal": 1,
            "arguing": 1,
            "scientific": 1,
            "say": 1,
            "using": 1,
            "pressure": 1,
            "temperature": 1,
            "talk": 1,
            "gas": 2,
            "made": 1,
            "molecule": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para102",
              "entity_text": "The Nature of Explanation",
              "entity_type": "WORK_OF_ART",
              "start_char": 0,
              "end_char": 25,
              "context": "The Nature of Explanation,\nby Bartlett’s student and successor Kenneth Crai"
            },
            {
              "para_id": "chap1_para102",
              "entity_text": "Bartlett",
              "entity_type": "PERSON",
              "start_char": 30,
              "end_char": 38,
              "context": "The Nature of Explanation,\nby Bartlett’s student and successor Kenneth Craik (1943), for"
            },
            {
              "para_id": "chap1_para102",
              "entity_text": "Kenneth Craik",
              "entity_type": "PERSON",
              "start_char": 63,
              "end_char": 76,
              "context": " Explanation,\nby Bartlett’s student and successor Kenneth Craik (1943), forcefully reestablished the legitimacy o"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para103",
          "content": "Craik specified the three key steps of a knowledge-based agent: (1) the stimulus must be translated into an internal representation, (2) the representation is manipulated by cognitive processes to derive new internal representations, and (3) these are in turn retranslated back into action. He clearly explained why this was a good design for an agent:\nIf the organism carries a “small-scale model” of external reality and of its own possible actions within its head, it is able to try out various alternatives, conclude which is the best of them, react to future situations before they arise, utilize the knowledge of past events in dealing with the present and future, and in every way to react in a much fuller, safer, and more competent manner to the emergencies which face it. (Craik, 1943)\nAfter Craik’s death in a bicycle accident in 1945, his work was continued by Donald Broadbent, whose book\nPerception and Communication\n(1958) was one of the first works to model psychological phenomena as information processing. Meanwhile, in the United States, the development of computer modeling led to the creation of the field of\ncognitive science\n. The field can be said to have started at a workshop in September 1956 at MIT—just two months after the conference at which AI itself was “born.”\nAt the workshop, George Miller presented\nThe Magic Number Seven,\nNoam Chomsky presented\nThree Models of Language,\nand Allen Newell and Herbert Simon presented\nThe Logic Theory Machine.",
          "sentence_count": 5,
          "char_count": 1250,
          "prev_para_id": "chap1_para102",
          "next_para_id": "chap1_para104",
          "style_metadata": {
            "para_id": "chap1_para103",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 56.4,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 282,
            "sentence_count": 5
          },
          "terminology": {
            "craik": 3,
            "specified": 1,
            "key": 1,
            "step": 1,
            "knowledge-based": 1,
            "agent": 2,
            "stimulus": 1,
            "translated": 1,
            "internal": 2,
            "representation": 3,
            "manipulated": 1,
            "cognitive": 2,
            "process": 1,
            "derive": 1,
            "new": 1,
            "turn": 1,
            "retranslated": 1,
            "action": 2,
            "explained": 1,
            "good": 1,
            "design": 1,
            "organism": 1,
            "carry": 1,
            "small-scale": 1,
            "model": 2,
            "external": 1,
            "reality": 1,
            "possible": 1,
            "head": 1,
            "able": 1,
            "try": 1,
            "various": 1,
            "alternative": 1,
            "conclude": 1,
            "best": 1,
            "react": 2,
            "future": 2,
            "situation": 1,
            "arise": 1,
            "utilize": 1,
            "knowledge": 1,
            "event": 1,
            "dealing": 1,
            "present": 1,
            "way": 1,
            "much": 1,
            "fuller": 1,
            "safer": 1,
            "competent": 1,
            "manner": 1,
            "emergency": 1,
            "face": 1,
            "death": 1,
            "bicycle": 1,
            "accident": 1,
            "work": 2,
            "continued": 1,
            "donald": 1,
            "broadbent": 1,
            "book": 1,
            "perception": 1,
            "communication": 1,
            "first": 1,
            "psychological": 1,
            "phenomenon": 1,
            "information": 1,
            "processing": 1,
            "united": 1,
            "state": 1,
            "development": 1,
            "computer": 1,
            "modeling": 1,
            "led": 1,
            "creation": 1,
            "field": 2,
            "science": 1,
            "said": 1,
            "started": 1,
            "workshop": 2,
            "september": 1,
            "mit—just": 1,
            "month": 1,
            "conference": 1,
            "born.": 1,
            "george": 1,
            "miller": 1,
            "presented": 3,
            "magic": 1,
            "number": 1,
            "noam": 1,
            "chomsky": 1,
            "language": 1,
            "allen": 1,
            "herbert": 1,
            "simon": 1,
            "logic": 1,
            "theory": 1,
            "machine": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para103",
              "entity_text": "Craik",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 5,
              "context": "Craik specified the three key steps of a knowledge-base"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Craik",
              "entity_type": "ORG",
              "start_char": 783,
              "end_char": 788,
              "context": "mpetent manner to the emergencies which face it. (Craik, 1943)\nAfter Craik’s death in a bicycle accident "
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Craik",
              "entity_type": "ORG",
              "start_char": 802,
              "end_char": 807,
              "context": "he emergencies which face it. (Craik, 1943)\nAfter Craik’s death in a bicycle accident in 1945, his work w"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Donald Broadbent",
              "entity_type": "PERSON",
              "start_char": 873,
              "end_char": 889,
              "context": "cycle accident in 1945, his work was continued by Donald Broadbent, whose book\nPerception and Communication\n(1958) w"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Perception and Communication",
              "entity_type": "WORK_OF_ART",
              "start_char": 902,
              "end_char": 930,
              "context": "ork was continued by Donald Broadbent, whose book\nPerception and Communication\n(1958) was one of the first works to model psycho"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "the United States",
              "entity_type": "GPE",
              "start_char": 1039,
              "end_char": 1056,
              "context": "henomena as information processing. Meanwhile, in the United States, the development of computer modeling led to the "
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "MIT",
              "entity_type": "ORG",
              "start_char": 1224,
              "end_char": 1227,
              "context": "o have started at a workshop in September 1956 at MIT—just two months after the conference at which AI "
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 1274,
              "end_char": 1276,
              "context": "MIT—just two months after the conference at which AI itself was “born.”\nAt the workshop, George Miller"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "George Miller",
              "entity_type": "PERSON",
              "start_char": 1313,
              "end_char": 1326,
              "context": "e at which AI itself was “born.”\nAt the workshop, George Miller presented\nThe Magic Number Seven,\nNoam Chomsky pr"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "The Magic Number Seven",
              "entity_type": "WORK_OF_ART",
              "start_char": 1337,
              "end_char": 1359,
              "context": " “born.”\nAt the workshop, George Miller presented\nThe Magic Number Seven,\nNoam Chomsky presented\nThree Models of Language,"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Noam Chomsky",
              "entity_type": "PERSON",
              "start_char": 1361,
              "end_char": 1373,
              "context": ", George Miller presented\nThe Magic Number Seven,\nNoam Chomsky presented\nThree Models of Language,\nand Allen New"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Allen Newell",
              "entity_type": "PERSON",
              "start_char": 1414,
              "end_char": 1426,
              "context": "m Chomsky presented\nThree Models of Language,\nand Allen Newell and Herbert Simon presented\nThe Logic Theory Mach"
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 1431,
              "end_char": 1444,
              "context": "ed\nThree Models of Language,\nand Allen Newell and Herbert Simon presented\nThe Logic Theory Machine."
            },
            {
              "para_id": "chap1_para103",
              "entity_text": "The Logic Theory Machine",
              "entity_type": "ORG",
              "start_char": 1455,
              "end_char": 1479,
              "context": "age,\nand Allen Newell and Herbert Simon presented\nThe Logic Theory Machine."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para104",
          "content": "These three influential papers showed how computer models could be used to address the psychology of memory, language, and logical thinking, respectively. It is now a common (although far from universal) view among psychologists that “a cognitive theory should be like a computer program” (Anderson, 1980); that is, it should describe the operation of a cognitive function in terms of the processing of information.",
          "sentence_count": 2,
          "char_count": 352,
          "prev_para_id": "chap1_para103",
          "next_para_id": "chap1_para105",
          "style_metadata": {
            "para_id": "chap1_para104",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 2
          },
          "terminology": {
            "influential": 1,
            "paper": 1,
            "showed": 1,
            "computer": 2,
            "model": 1,
            "used": 1,
            "psychology": 1,
            "memory": 1,
            "language": 1,
            "logical": 1,
            "thinking": 1,
            "common": 1,
            "universal": 1,
            "view": 1,
            "psychologist": 1,
            "cognitive": 2,
            "theory": 1,
            "program": 1,
            "anderson": 1,
            "describe": 1,
            "operation": 1,
            "function": 1,
            "term": 1,
            "processing": 1,
            "information": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para104",
              "entity_text": "Anderson",
              "entity_type": "PERSON",
              "start_char": 290,
              "end_char": 298,
              "context": "nitive theory should be like a computer program” (Anderson, 1980); that is, it should describe the operation"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para105",
          "content": "For purposes of this review, we will count the field of\nhuman–computer interaction\n(HCI) under psychology. Doug Engelbart, one of the pioneers of HCI, championed the idea of\nintelligence augmentation\n—IA rather than AI. He believed that computers should augment human abilities rather than automate away human tasks. In 1968, Engelbart’s “mother of all demos” showed off for the first time the computer mouse, a windowing system, hypertext, and video conferencing—all in an effort to demonstrate what human knowledge workers could collectively accomplish with some intelligence augmentation.",
          "sentence_count": 4,
          "char_count": 509,
          "prev_para_id": "chap1_para104",
          "next_para_id": "chap1_para106",
          "style_metadata": {
            "para_id": "chap1_para105",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "purpose": 1,
            "review": 1,
            "count": 1,
            "field": 1,
            "human–computer": 1,
            "interaction": 1,
            "hci": 2,
            "psychology": 1,
            "doug": 1,
            "pioneer": 1,
            "championed": 1,
            "idea": 1,
            "intelligence": 2,
            "augmentation": 2,
            "—ia": 1,
            "believed": 1,
            "computer": 2,
            "augment": 1,
            "human": 3,
            "ability": 1,
            "automate": 1,
            "task": 1,
            "engelbart": 1,
            "mother": 1,
            "demo": 1,
            "showed": 1,
            "first": 1,
            "time": 1,
            "mouse": 1,
            "windowing": 1,
            "system": 1,
            "hypertext": 1,
            "video": 1,
            "conferencing—all": 1,
            "effort": 1,
            "demonstrate": 1,
            "knowledge": 1,
            "worker": 1,
            "accomplish": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para105",
              "entity_text": "Doug Engelbart",
              "entity_type": "PERSON",
              "start_char": 107,
              "end_char": 121,
              "context": "uman–computer interaction\n(HCI) under psychology. Doug Engelbart, one of the pioneers of HCI, championed the idea "
            },
            {
              "para_id": "chap1_para105",
              "entity_text": "HCI",
              "entity_type": "PERSON",
              "start_char": 146,
              "end_char": 149,
              "context": "sychology. Doug Engelbart, one of the pioneers of HCI, championed the idea of\nintelligence augmentation"
            },
            {
              "para_id": "chap1_para105",
              "entity_text": "IA",
              "entity_type": "GPE",
              "start_char": 201,
              "end_char": 203,
              "context": "championed the idea of\nintelligence augmentation\n—IA rather than AI. He believed that computers should"
            },
            {
              "para_id": "chap1_para105",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 216,
              "end_char": 218,
              "context": "idea of\nintelligence augmentation\n—IA rather than AI. He believed that computers should augment human "
            },
            {
              "para_id": "chap1_para105",
              "entity_text": "Engelbart",
              "entity_type": "ORG",
              "start_char": 326,
              "end_char": 335,
              "context": "s rather than automate away human tasks. In 1968, Engelbart’s “mother of all demos” showed off for the first "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para106",
          "content": "Today we are more likely to see IA and AI as two sides of the same coin, with the former emphasizing human control and the latter emphasizing intelligent behavior on the part of the machine. Both are needed for machines to be useful to humans.",
          "sentence_count": 2,
          "char_count": 199,
          "prev_para_id": "chap1_para105",
          "next_para_id": "chap1_para107",
          "style_metadata": {
            "para_id": "chap1_para106",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "today": 1,
            "likely": 1,
            "see": 1,
            "side": 1,
            "coin": 1,
            "former": 1,
            "emphasizing": 2,
            "human": 2,
            "control": 1,
            "intelligent": 1,
            "behavior": 1,
            "part": 1,
            "machine": 2,
            "needed": 1,
            "useful": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para106",
              "entity_text": "IA",
              "entity_type": "GPE",
              "start_char": 32,
              "end_char": 34,
              "context": "Today we are more likely to see IA and AI as two sides of the same coin, with the fo"
            },
            {
              "para_id": "chap1_para106",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 39,
              "end_char": 41,
              "context": "Today we are more likely to see IA and AI as two sides of the same coin, with the former em"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para107",
          "content": "1.2.6\nComputer engineering\n•\nHow can we build an efficient computer?",
          "sentence_count": 1,
          "char_count": 61,
          "prev_para_id": "chap1_para106",
          "next_para_id": "chap1_para108",
          "style_metadata": {
            "para_id": "chap1_para107",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "computer": 2,
            "engineering": 1,
            "build": 1,
            "efficient": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para108",
          "content": "The modern digital electronic computer was invented independently and almost simultaneously by scientists in three countries embattled in World War II. The first\noperational\ncomputer was the electromechanical Heath Robinson,\n9\nbuilt in 1943 by Alan Turing’s team for a single purpose: deciphering German messages. In 1943, the same group developed the Colossus, a powerful general-purpose machine based on vacuum tubes.",
          "sentence_count": 3,
          "char_count": 363,
          "prev_para_id": "chap1_para107",
          "next_para_id": "chap1_para109",
          "style_metadata": {
            "para_id": "chap1_para108",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.33,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 3
          },
          "terminology": {
            "modern": 1,
            "digital": 1,
            "electronic": 1,
            "computer": 2,
            "invented": 1,
            "scientist": 1,
            "country": 1,
            "embattled": 1,
            "world": 1,
            "war": 1,
            "first": 1,
            "operational": 1,
            "electromechanical": 1,
            "heath": 1,
            "robinson": 1,
            "built": 1,
            "alan": 1,
            "turing": 1,
            "team": 1,
            "single": 1,
            "purpose": 1,
            "deciphering": 1,
            "german": 1,
            "message": 1,
            "group": 1,
            "developed": 1,
            "colossus": 1,
            "powerful": 1,
            "general-purpose": 1,
            "machine": 1,
            "based": 1,
            "vacuum": 1,
            "tube": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para108",
              "entity_text": "World War II",
              "entity_type": "EVENT",
              "start_char": 138,
              "end_char": 150,
              "context": "sly by scientists in three countries embattled in World War II. The first\noperational\ncomputer was the electrome"
            },
            {
              "para_id": "chap1_para108",
              "entity_text": "Heath Robinson",
              "entity_type": "PERSON",
              "start_char": 209,
              "end_char": 223,
              "context": "st\noperational\ncomputer was the electromechanical Heath Robinson,\n9\nbuilt in 1943 by Alan Turing’s team for a sing"
            },
            {
              "para_id": "chap1_para108",
              "entity_text": "Alan Turing’s",
              "entity_type": "PERSON",
              "start_char": 244,
              "end_char": 257,
              "context": "ctromechanical Heath Robinson,\n9\nbuilt in 1943 by Alan Turing’s team for a single purpose: deciphering German mes"
            },
            {
              "para_id": "chap1_para108",
              "entity_text": "Colossus",
              "entity_type": "ORG",
              "start_char": 352,
              "end_char": 360,
              "context": "n messages. In 1943, the same group developed the Colossus, a powerful general-purpose machine based on vacu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para109",
          "content": "10\nThe first operational\nprogrammable\ncomputer was the Z-3, the invention of Konrad Zuse in Germany in 1941. Zuse also invented floating-point numbers and the first high-level programming language, Plankalkül. The first\nelectronic\ncomputer, the ABC, was assembled by John Atanasoff and his student Clifford Berry between 1940 and 1942 at Iowa State University. Atanasoff’s research received little support or recognition; it was the ENIAC, developed as part of a secret military project at the University of Pennsylvania by a team including John Mauchly and J. Presper Eckert, that proved to be the most influential forerunner of modern computers.",
          "sentence_count": 4,
          "char_count": 554,
          "prev_para_id": "chap1_para108",
          "next_para_id": "chap1_para110",
          "style_metadata": {
            "para_id": "chap1_para109",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.75,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 111,
            "sentence_count": 4
          },
          "terminology": {
            "first": 2,
            "operational": 1,
            "programmable": 1,
            "computer": 3,
            "z-3": 1,
            "invention": 1,
            "konrad": 1,
            "zuse": 2,
            "germany": 1,
            "invented": 1,
            "floating-point": 1,
            "number": 1,
            "high-level": 1,
            "programming": 1,
            "language": 1,
            "plankalkül": 1,
            "electronic": 1,
            "abc": 1,
            "assembled": 1,
            "john": 2,
            "student": 1,
            "clifford": 1,
            "berry": 1,
            "iowa": 1,
            "state": 1,
            "university": 2,
            "atanasoff": 1,
            "research": 1,
            "received": 1,
            "little": 1,
            "support": 1,
            "recognition": 1,
            "eniac": 1,
            "developed": 1,
            "part": 1,
            "secret": 1,
            "military": 1,
            "project": 1,
            "pennsylvania": 1,
            "team": 1,
            "including": 1,
            "eckert": 1,
            "proved": 1,
            "influential": 1,
            "forerunner": 1,
            "modern": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para109",
              "entity_text": "Konrad Zuse",
              "entity_type": "PERSON",
              "start_char": 77,
              "end_char": 88,
              "context": "ogrammable\ncomputer was the Z-3, the invention of Konrad Zuse in Germany in 1941. Zuse also invented floating-p"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "Germany",
              "entity_type": "GPE",
              "start_char": 92,
              "end_char": 99,
              "context": "uter was the Z-3, the invention of Konrad Zuse in Germany in 1941. Zuse also invented floating-point number"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "Plankalkül",
              "entity_type": "GPE",
              "start_char": 198,
              "end_char": 208,
              "context": "rs and the first high-level programming language, Plankalkül. The first\nelectronic\ncomputer, the ABC, was asse"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "ABC",
              "entity_type": "ORG",
              "start_char": 245,
              "end_char": 248,
              "context": "e, Plankalkül. The first\nelectronic\ncomputer, the ABC, was assembled by John Atanasoff and his student "
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "John Atanasoff",
              "entity_type": "PERSON",
              "start_char": 267,
              "end_char": 281,
              "context": "st\nelectronic\ncomputer, the ABC, was assembled by John Atanasoff and his student Clifford Berry between 1940 and 1"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "Clifford Berry",
              "entity_type": "PERSON",
              "start_char": 298,
              "end_char": 312,
              "context": ", was assembled by John Atanasoff and his student Clifford Berry between 1940 and 1942 at Iowa State University. A"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "Iowa State University",
              "entity_type": "ORG",
              "start_char": 338,
              "end_char": 359,
              "context": "s student Clifford Berry between 1940 and 1942 at Iowa State University. Atanasoff’s research received little support or "
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "Atanasoff",
              "entity_type": "ORG",
              "start_char": 361,
              "end_char": 370,
              "context": "y between 1940 and 1942 at Iowa State University. Atanasoff’s research received little support or recognition"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "ENIAC",
              "entity_type": "ORG",
              "start_char": 433,
              "end_char": 438,
              "context": "eceived little support or recognition; it was the ENIAC, developed as part of a secret military project a"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "the University of Pennsylvania",
              "entity_type": "ORG",
              "start_char": 490,
              "end_char": 520,
              "context": "developed as part of a secret military project at the University of Pennsylvania by a team including John Mauchly and J. Presper E"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "John Mauchly",
              "entity_type": "PERSON",
              "start_char": 541,
              "end_char": 553,
              "context": "he University of Pennsylvania by a team including John Mauchly and J. Presper Eckert, that proved to be the most"
            },
            {
              "para_id": "chap1_para109",
              "entity_text": "J. Presper Eckert",
              "entity_type": "PERSON",
              "start_char": 558,
              "end_char": 575,
              "context": "Pennsylvania by a team including John Mauchly and J. Presper Eckert, that proved to be the most influential forerunne"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para110",
          "content": "Since that time, each generation of computer hardware has brought an increase in speed and capacity and a decrease in price—a trend captured in\nMoore’s law\n. Performance doubled every 18 months or so until around 2005, when power dissipation problems led manufacturers\nto start multiplying the number of CPU cores rather than the clock speed. Current expectations are that future increases in functionality will come from massive parallelism—a curious convergence with the properties of the brain. We also see new hardware designs based on the idea that in dealing with an uncertain world, we don’t need 64 bits of precision in our numbers; just 16 bits (as in the\nbfloat16\nformat) or even 8 bits will be enough, and will enable faster processing.",
          "sentence_count": 4,
          "char_count": 629,
          "prev_para_id": "chap1_para109",
          "next_para_id": "chap1_para111",
          "style_metadata": {
            "para_id": "chap1_para110",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 138,
            "sentence_count": 4
          },
          "terminology": {
            "time": 1,
            "generation": 1,
            "computer": 1,
            "hardware": 2,
            "brought": 1,
            "increase": 2,
            "speed": 2,
            "capacity": 1,
            "decrease": 1,
            "price—a": 1,
            "trend": 1,
            "captured": 1,
            "law": 1,
            "performance": 1,
            "doubled": 1,
            "month": 1,
            "power": 1,
            "dissipation": 1,
            "problem": 1,
            "led": 1,
            "manufacturer": 1,
            "start": 1,
            "multiplying": 1,
            "number": 2,
            "cpu": 1,
            "core": 1,
            "clock": 1,
            "current": 1,
            "expectation": 1,
            "future": 1,
            "functionality": 1,
            "come": 1,
            "massive": 1,
            "parallelism—a": 1,
            "curious": 1,
            "convergence": 1,
            "property": 1,
            "brain": 1,
            "see": 1,
            "new": 1,
            "design": 1,
            "based": 1,
            "idea": 1,
            "dealing": 1,
            "uncertain": 1,
            "world": 1,
            "need": 1,
            "bit": 3,
            "precision": 1,
            "bfloat16": 1,
            "enough": 1,
            "enable": 1,
            "processing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para110",
              "entity_text": "CPU",
              "entity_type": "ORG",
              "start_char": 304,
              "end_char": 307,
              "context": " manufacturers\nto start multiplying the number of CPU cores rather than the clock speed. Current expect"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para111",
          "content": "We are just beginning to see hardware tuned for AI applications, such as the graphics processing unit (GPU), tensor processing unit (TPU), and wafer scale engine (WSE). From the 1960s to about 2012, the amount of computing power used to train top machine learning applications followed Moore’s law. Beginning in 2012, things changed: from 2012 to 2018 there was a 300,000-fold increase, which works out to a doubling every 100 days or so (Amodei and Hernandez, 2018). A machine learning model that took a full day to train in 2014 takes only two minutes in 2018 (Ying\net al.,\n2018). Although it is not yet practical,\nquantum computing\nholds out the promise of far greater accelerations for some important subclasses of AI algorithms.",
          "sentence_count": 5,
          "char_count": 615,
          "prev_para_id": "chap1_para110",
          "next_para_id": "chap1_para112",
          "style_metadata": {
            "para_id": "chap1_para111",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 5
          },
          "terminology": {
            "beginning": 2,
            "see": 1,
            "hardware": 1,
            "tuned": 1,
            "application": 2,
            "graphic": 1,
            "processing": 2,
            "unit": 2,
            "gpu": 1,
            "tensor": 1,
            "tpu": 1,
            "wafer": 1,
            "scale": 1,
            "engine": 1,
            "wse": 1,
            "amount": 1,
            "computing": 2,
            "power": 1,
            "used": 1,
            "train": 2,
            "top": 1,
            "machine": 2,
            "learning": 2,
            "followed": 1,
            "law": 1,
            "thing": 1,
            "changed": 1,
            "300,000-fold": 1,
            "increase": 1,
            "work": 1,
            "doubling": 1,
            "day": 2,
            "amodei": 1,
            "hernandez": 1,
            "model": 1,
            "took": 1,
            "full": 1,
            "take": 1,
            "minute": 1,
            "ying": 1,
            "al.": 1,
            "practical": 1,
            "quantum": 1,
            "hold": 1,
            "promise": 1,
            "greater": 1,
            "acceleration": 1,
            "important": 1,
            "subclass": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para111",
              "entity_text": "GPU",
              "entity_type": "ORG",
              "start_char": 103,
              "end_char": 106,
              "context": "plications, such as the graphics processing unit (GPU), tensor processing unit (TPU), and wafer scale e"
            },
            {
              "para_id": "chap1_para111",
              "entity_text": "TPU",
              "entity_type": "ORG",
              "start_char": 133,
              "end_char": 136,
              "context": "cs processing unit (GPU), tensor processing unit (TPU), and wafer scale engine (WSE). From the 1960s to"
            },
            {
              "para_id": "chap1_para111",
              "entity_text": "Moore",
              "entity_type": "PRODUCT",
              "start_char": 286,
              "end_char": 291,
              "context": " train top machine learning applications followed Moore’s law. Beginning in 2012, things changed: from 20"
            },
            {
              "para_id": "chap1_para111",
              "entity_text": "Amodei and Hernandez",
              "entity_type": "ORG",
              "start_char": 439,
              "end_char": 459,
              "context": "ich works out to a doubling every 100 days or so (Amodei and Hernandez, 2018). A machine learning model that took a full"
            },
            {
              "para_id": "chap1_para111",
              "entity_text": "Ying",
              "entity_type": "PERSON",
              "start_char": 563,
              "end_char": 567,
              "context": " to train in 2014 takes only two minutes in 2018 (Ying\net al.,\n2018). Although it is not yet practical,\n"
            },
            {
              "para_id": "chap1_para111",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 571,
              "end_char": 574,
              "context": "n in 2014 takes only two minutes in 2018 (Ying\net al.,\n2018). Although it is not yet practical,\nquantum"
            },
            {
              "para_id": "chap1_para111",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 719,
              "end_char": 721,
              "context": "er accelerations for some important subclasses of AI algorithms."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para112",
          "content": "Of course, there were calculating devices before the electronic computer. The earliest automated machines, dating from the 17th century, were discussed on\npage 24\n. The first\nprogrammable\nmachine was a loom, devised in 1805 by Joseph Marie Jacquard (1752–1834), that used punched cards to store instructions for the pattern to be woven.",
          "sentence_count": 3,
          "char_count": 288,
          "prev_para_id": "chap1_para111",
          "next_para_id": "chap1_para113",
          "style_metadata": {
            "para_id": "chap1_para112",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.67,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 3
          },
          "terminology": {
            "course": 1,
            "calculating": 1,
            "device": 1,
            "electronic": 1,
            "computer": 1,
            "earliest": 1,
            "automated": 1,
            "machine": 2,
            "dating": 1,
            "17th": 1,
            "century": 1,
            "discussed": 1,
            "page": 1,
            "programmable": 1,
            "loom": 1,
            "devised": 1,
            "joseph": 1,
            "marie": 1,
            "jacquard": 1,
            "used": 1,
            "punched": 1,
            "card": 1,
            "store": 1,
            "instruction": 1,
            "pattern": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para112",
              "entity_text": "Joseph Marie Jacquard",
              "entity_type": "PERSON",
              "start_char": 227,
              "end_char": 248,
              "context": "ogrammable\nmachine was a loom, devised in 1805 by Joseph Marie Jacquard (1752–1834), that used punched cards to store ins"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para113",
          "content": "In the mid-19th century, Charles Babbage (1792–1871) designed two computing machines, neither of which he completed. The Difference Engine was intended to compute mathematical tables for engineering and scientific projects. It was finally built and shown to work in 1991 (Swade, 2000). Babbage’s Analytical Engine was far more ambitious: it included addressable memory, stored programs based on Jacquard’s punched cards, and conditional jumps. It was the first machine capable of universal computation.",
          "sentence_count": 5,
          "char_count": 431,
          "prev_para_id": "chap1_para112",
          "next_para_id": "chap1_para114",
          "style_metadata": {
            "para_id": "chap1_para113",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.2,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 5
          },
          "terminology": {
            "mid-19th": 1,
            "century": 1,
            "charles": 1,
            "babbage": 2,
            "designed": 1,
            "computing": 1,
            "machine": 2,
            "completed": 1,
            "difference": 1,
            "engine": 2,
            "intended": 1,
            "compute": 1,
            "mathematical": 1,
            "table": 1,
            "engineering": 1,
            "scientific": 1,
            "project": 1,
            "built": 1,
            "shown": 1,
            "work": 1,
            "swade": 1,
            "analytical": 1,
            "ambitious": 1,
            "included": 1,
            "addressable": 1,
            "memory": 1,
            "stored": 1,
            "program": 1,
            "based": 1,
            "punched": 1,
            "card": 1,
            "conditional": 1,
            "jump": 1,
            "capable": 1,
            "universal": 1,
            "computation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para113",
              "entity_text": "Charles Babbage",
              "entity_type": "PERSON",
              "start_char": 25,
              "end_char": 40,
              "context": "In the mid-19th century, Charles Babbage (1792–1871) designed two computing machines, neit"
            },
            {
              "para_id": "chap1_para113",
              "entity_text": "Babbage’s Analytical Engine",
              "entity_type": "ORG",
              "start_char": 286,
              "end_char": 313,
              "context": "ly built and shown to work in 1991 (Swade, 2000). Babbage’s Analytical Engine was far more ambitious: it included addressable m"
            },
            {
              "para_id": "chap1_para113",
              "entity_text": "Jacquard’s",
              "entity_type": "PERSON",
              "start_char": 395,
              "end_char": 405,
              "context": "uded addressable memory, stored programs based on Jacquard’s punched cards, and conditional jumps. It was the "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para114",
          "content": "Babbage’s colleague Ada Lovelace, daughter of the poet Lord Byron, understood its potential, describing it as “a thinking or ... a reasoning machine,” one capable of reasoning about “all subjects in the universe” (Lovelace, 1843). She also anticipated AI’s hype cycles, writing, “It is desirable to guard against the possibility of exaggerated ideas that might arise as to the powers of the Analytical Engine.” Unfortunately, Babbage’s machines and Lovelace’s ideas were largely forgotten.",
          "sentence_count": 2,
          "char_count": 417,
          "prev_para_id": "chap1_para113",
          "next_para_id": "chap1_para115",
          "style_metadata": {
            "para_id": "chap1_para114",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 2
          },
          "terminology": {
            "babbage": 2,
            "colleague": 1,
            "ada": 1,
            "lovelace": 3,
            "daughter": 1,
            "poet": 1,
            "lord": 1,
            "byron": 1,
            "understood": 1,
            "potential": 1,
            "describing": 1,
            "thinking": 1,
            "reasoning": 2,
            "machine": 2,
            "capable": 1,
            "subject": 1,
            "universe": 1,
            "anticipated": 1,
            "hype": 1,
            "cycle": 1,
            "writing": 1,
            "desirable": 1,
            "guard": 1,
            "possibility": 1,
            "exaggerated": 1,
            "idea": 2,
            "arise": 1,
            "power": 1,
            "analytical": 1,
            "engine.": 1,
            "unfortunately": 1,
            "forgotten": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para114",
              "entity_text": "Babbage",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 7,
              "context": "Babbage’s colleague Ada Lovelace, daughter of the poet Lo"
            },
            {
              "para_id": "chap1_para114",
              "entity_text": "Ada Lovelace",
              "entity_type": "PERSON",
              "start_char": 20,
              "end_char": 32,
              "context": "Babbage’s colleague Ada Lovelace, daughter of the poet Lord Byron, understood its "
            },
            {
              "para_id": "chap1_para114",
              "entity_text": "Lovelace",
              "entity_type": "PERSON",
              "start_char": 214,
              "end_char": 222,
              "context": "f reasoning about “all subjects in the universe” (Lovelace, 1843). She also anticipated AI’s hype cycles, wr"
            },
            {
              "para_id": "chap1_para114",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 252,
              "end_char": 254,
              "context": " universe” (Lovelace, 1843). She also anticipated AI’s hype cycles, writing, “It is desirable to guard"
            },
            {
              "para_id": "chap1_para114",
              "entity_text": "the Analytical Engine",
              "entity_type": "ORG",
              "start_char": 387,
              "end_char": 408,
              "context": "erated ideas that might arise as to the powers of the Analytical Engine.” Unfortunately, Babbage’s machines and Lovelace’"
            },
            {
              "para_id": "chap1_para114",
              "entity_text": "Babbage",
              "entity_type": "ORG",
              "start_char": 426,
              "end_char": 433,
              "context": " powers of the Analytical Engine.” Unfortunately, Babbage’s machines and Lovelace’s ideas were largely forg"
            },
            {
              "para_id": "chap1_para114",
              "entity_text": "Lovelace",
              "entity_type": "ORG",
              "start_char": 449,
              "end_char": 457,
              "context": "al Engine.” Unfortunately, Babbage’s machines and Lovelace’s ideas were largely forgotten."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para115",
          "content": "AI also owes a debt to the software side of computer science, which has supplied the operating systems, programming languages, and tools needed to write modern programs (and papers about them). But this is one area where the debt has been repaid: work in AI has pioneered many ideas that have made their way back to mainstream computer science, including time sharing, interactive interpreters, personal computers with windows and mice, rapid development environments, the linked-list data type, automatic storage management, and key concepts of symbolic, functional, declarative, and object-oriented programming.",
          "sentence_count": 2,
          "char_count": 524,
          "prev_para_id": "chap1_para114",
          "next_para_id": "chap1_para116",
          "style_metadata": {
            "para_id": "chap1_para115",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 54.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 108,
            "sentence_count": 2
          },
          "terminology": {
            "owes": 1,
            "debt": 2,
            "software": 1,
            "side": 1,
            "computer": 3,
            "science": 2,
            "supplied": 1,
            "operating": 1,
            "system": 1,
            "programming": 2,
            "language": 1,
            "tool": 1,
            "needed": 1,
            "write": 1,
            "modern": 1,
            "program": 1,
            "paper": 1,
            "area": 1,
            "repaid": 1,
            "work": 1,
            "pioneered": 1,
            "many": 1,
            "idea": 1,
            "made": 1,
            "way": 1,
            "mainstream": 1,
            "including": 1,
            "time": 1,
            "sharing": 1,
            "interactive": 1,
            "interpreter": 1,
            "personal": 1,
            "window": 1,
            "mouse": 1,
            "rapid": 1,
            "development": 1,
            "environment": 1,
            "linked-list": 1,
            "data": 1,
            "type": 1,
            "automatic": 1,
            "storage": 1,
            "management": 1,
            "key": 1,
            "concept": 1,
            "symbolic": 1,
            "functional": 1,
            "declarative": 1,
            "object-oriented": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para115",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 2,
              "context": "AI also owes a debt to the software side of computer"
            },
            {
              "para_id": "chap1_para115",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 255,
              "end_char": 257,
              "context": " one area where the debt has been repaid: work in AI has pioneered many ideas that have made their way"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para116",
          "content": "1.2.7\nControl theory and cybernetics\n•\nHow can artifacts operate under their own control?",
          "sentence_count": 1,
          "char_count": 79,
          "prev_para_id": "chap1_para115",
          "next_para_id": "chap1_para117",
          "style_metadata": {
            "para_id": "chap1_para116",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "control": 2,
            "theory": 1,
            "cybernetics": 1,
            "artifact": 1,
            "operate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para117",
          "content": "Ktesibios of Alexandria (c. 250\nBCE\n) built the first self-controlling machine: a water clock with a regulator that maintained a constant flow rate. This invention changed the definition of what an artifact could do. Previously, only living things could modify their behavior in response to changes in the environment. Other examples of self-regulating feedback control\nsystems include the steam engine governor, created by James Watt (1736–1819), and the thermostat, invented by Cornelis Drebbel (1572–1633), who also invented the submarine. James Clerk Maxwell (1868) initiated the mathematical theory of control systems.",
          "sentence_count": 5,
          "char_count": 536,
          "prev_para_id": "chap1_para116",
          "next_para_id": "chap1_para118",
          "style_metadata": {
            "para_id": "chap1_para117",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 109,
            "sentence_count": 5
          },
          "terminology": {
            "ktesibios": 1,
            "alexandria": 1,
            "bce": 1,
            "built": 1,
            "first": 1,
            "self-controlling": 1,
            "machine": 1,
            "water": 1,
            "clock": 1,
            "regulator": 1,
            "maintained": 1,
            "constant": 1,
            "flow": 1,
            "rate": 1,
            "invention": 1,
            "changed": 1,
            "definition": 1,
            "artifact": 1,
            "living": 1,
            "thing": 1,
            "modify": 1,
            "behavior": 1,
            "response": 1,
            "change": 1,
            "environment": 1,
            "example": 1,
            "self-regulating": 1,
            "feedback": 1,
            "control": 2,
            "system": 2,
            "include": 1,
            "steam": 1,
            "engine": 1,
            "governor": 1,
            "created": 1,
            "james": 2,
            "watt": 1,
            "thermostat": 1,
            "invented": 2,
            "cornelis": 1,
            "drebbel": 1,
            "submarine": 1,
            "clerk": 1,
            "initiated": 1,
            "mathematical": 1,
            "theory": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para117",
              "entity_text": "Ktesibios",
              "entity_type": "GPE",
              "start_char": 0,
              "end_char": 9,
              "context": "Ktesibios of Alexandria (c. 250\nBCE\n) built the first self-"
            },
            {
              "para_id": "chap1_para117",
              "entity_text": "Alexandria",
              "entity_type": "GPE",
              "start_char": 13,
              "end_char": 23,
              "context": "Ktesibios of Alexandria (c. 250\nBCE\n) built the first self-controlling ma"
            },
            {
              "para_id": "chap1_para117",
              "entity_text": "James Watt",
              "entity_type": "PERSON",
              "start_char": 424,
              "end_char": 434,
              "context": "ems include the steam engine governor, created by James Watt (1736–1819), and the thermostat, invented by Corn"
            },
            {
              "para_id": "chap1_para117",
              "entity_text": "Cornelis Drebbel",
              "entity_type": "PERSON",
              "start_char": 480,
              "end_char": 496,
              "context": "Watt (1736–1819), and the thermostat, invented by Cornelis Drebbel (1572–1633), who also invented the submarine. Jam"
            },
            {
              "para_id": "chap1_para117",
              "entity_text": "James Clerk Maxwell",
              "entity_type": "PERSON",
              "start_char": 543,
              "end_char": 562,
              "context": "bel (1572–1633), who also invented the submarine. James Clerk Maxwell (1868) initiated the mathematical theory of contr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para118",
          "content": "A central figure in the post-war development of\ncontrol theory\nwas Norbert Wiener (1894–1964). Wiener was a brilliant mathematician who worked with Bertrand Russell, among others, before developing an interest in biological and mechanical control systems and their connection to cognition. Like Craik (who also used control systems as psychological models), Wiener and his colleagues Arturo Rosenblueth and Julian Bigelow challenged the behaviorist orthodoxy (Rosenblueth\net al.,\n1943). They viewed purposive behavior as arising from a regulatory mechanism trying to minimize “error”—the difference between current state and goal state. In the late 1940s, Wiener, along with Warren McCulloch, Walter Pitts, and John von Neumann, organized a series of influential conferences that explored the new mathematical and computational models of cognition. Wiener’s book\nCybernetics\n(1948) became a bestseller and awoke the public to the possibility of artificially intelligent machines.",
          "sentence_count": 6,
          "char_count": 848,
          "prev_para_id": "chap1_para117",
          "next_para_id": "chap1_para119",
          "style_metadata": {
            "para_id": "chap1_para118",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 166,
            "sentence_count": 6
          },
          "terminology": {
            "central": 1,
            "figure": 1,
            "post-war": 1,
            "development": 1,
            "control": 3,
            "theory": 1,
            "norbert": 1,
            "wiener": 4,
            "brilliant": 1,
            "mathematician": 1,
            "worked": 1,
            "bertrand": 1,
            "russell": 1,
            "others": 1,
            "developing": 1,
            "interest": 1,
            "biological": 1,
            "mechanical": 1,
            "system": 2,
            "connection": 1,
            "cognition": 2,
            "craik": 1,
            "used": 1,
            "psychological": 1,
            "model": 2,
            "colleague": 1,
            "arturo": 1,
            "rosenblueth": 2,
            "julian": 1,
            "bigelow": 1,
            "challenged": 1,
            "behaviorist": 1,
            "orthodoxy": 1,
            "al.": 1,
            "viewed": 1,
            "purposive": 1,
            "behavior": 1,
            "arising": 1,
            "regulatory": 1,
            "mechanism": 1,
            "trying": 1,
            "minimize": 1,
            "error": 1,
            "—the": 1,
            "difference": 1,
            "current": 1,
            "state": 2,
            "goal": 1,
            "late": 1,
            "warren": 1,
            "mcculloch": 1,
            "walter": 1,
            "pitt": 1,
            "john": 1,
            "von": 1,
            "organized": 1,
            "series": 1,
            "influential": 1,
            "conference": 1,
            "explored": 1,
            "new": 1,
            "mathematical": 1,
            "computational": 1,
            "book": 1,
            "cybernetics": 1,
            "became": 1,
            "bestseller": 1,
            "awoke": 1,
            "public": 1,
            "possibility": 1,
            "intelligent": 1,
            "machine": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para118",
              "entity_text": "Norbert Wiener",
              "entity_type": "PERSON",
              "start_char": 67,
              "end_char": 81,
              "context": "in the post-war development of\ncontrol theory\nwas Norbert Wiener (1894–1964). Wiener was a brilliant mathematician"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Wiener",
              "entity_type": "PERSON",
              "start_char": 95,
              "end_char": 101,
              "context": "of\ncontrol theory\nwas Norbert Wiener (1894–1964). Wiener was a brilliant mathematician who worked with Ber"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Bertrand Russell",
              "entity_type": "PERSON",
              "start_char": 148,
              "end_char": 164,
              "context": "ner was a brilliant mathematician who worked with Bertrand Russell, among others, before developing an interest in b"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Craik",
              "entity_type": "PERSON",
              "start_char": 295,
              "end_char": 300,
              "context": "l systems and their connection to cognition. Like Craik (who also used control systems as psychological m"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Wiener",
              "entity_type": "PERSON",
              "start_char": 358,
              "end_char": 364,
              "context": "so used control systems as psychological models), Wiener and his colleagues Arturo Rosenblueth and Julian "
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Arturo Rosenblueth",
              "entity_type": "PERSON",
              "start_char": 384,
              "end_char": 402,
              "context": " psychological models), Wiener and his colleagues Arturo Rosenblueth and Julian Bigelow challenged the behaviorist ort"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Julian Bigelow",
              "entity_type": "PERSON",
              "start_char": 407,
              "end_char": 421,
              "context": " Wiener and his colleagues Arturo Rosenblueth and Julian Bigelow challenged the behaviorist orthodoxy (Rosenblueth"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Rosenblueth",
              "entity_type": "PERSON",
              "start_char": 460,
              "end_char": 471,
              "context": "ian Bigelow challenged the behaviorist orthodoxy (Rosenblueth\net al.,\n1943). They viewed purposive behavior as "
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 475,
              "end_char": 478,
              "context": "llenged the behaviorist orthodoxy (Rosenblueth\net al.,\n1943). They viewed purposive behavior as arising"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Wiener",
              "entity_type": "PERSON",
              "start_char": 656,
              "end_char": 662,
              "context": " current state and goal state. In the late 1940s, Wiener, along with Warren McCulloch, Walter Pitts, and J"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Warren McCulloch",
              "entity_type": "PERSON",
              "start_char": 675,
              "end_char": 691,
              "context": "goal state. In the late 1940s, Wiener, along with Warren McCulloch, Walter Pitts, and John von Neumann, organized a "
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Walter Pitts",
              "entity_type": "PERSON",
              "start_char": 693,
              "end_char": 705,
              "context": " late 1940s, Wiener, along with Warren McCulloch, Walter Pitts, and John von Neumann, organized a series of infl"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "John von Neumann",
              "entity_type": "PERSON",
              "start_char": 711,
              "end_char": 727,
              "context": "r, along with Warren McCulloch, Walter Pitts, and John von Neumann, organized a series of influential conferences th"
            },
            {
              "para_id": "chap1_para118",
              "entity_text": "Wiener",
              "entity_type": "ORG",
              "start_char": 849,
              "end_char": 855,
              "context": "thematical and computational models of cognition. Wiener’s book\nCybernetics\n(1948) became a bestseller and"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para119",
          "content": "Meanwhile, in Britain, W. Ross Ashby pioneered similar ideas (Ashby, 1940). Ashby, Alan Turing, Grey Walter, and others formed the Ratio Club for “those who had Wiener’s ideas before Wiener’s book appeared.” Ashby’s\nDesign for a Brain\n(1948, 1952) elaborated on his idea that intelligence could be created by the use of\nhomeostatic\ndevices containing appropriate feedback loops to achieve stable adaptive behavior.",
          "sentence_count": 2,
          "char_count": 356,
          "prev_para_id": "chap1_para118",
          "next_para_id": "chap1_para120",
          "style_metadata": {
            "para_id": "chap1_para119",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 2
          },
          "terminology": {
            "britain": 1,
            "ross": 1,
            "ashby": 4,
            "pioneered": 1,
            "similar": 1,
            "idea": 3,
            "alan": 1,
            "turing": 1,
            "grey": 1,
            "walter": 1,
            "others": 1,
            "formed": 1,
            "ratio": 1,
            "club": 1,
            "wiener": 2,
            "book": 1,
            "appeared.": 1,
            "design": 1,
            "brain": 1,
            "elaborated": 1,
            "intelligence": 1,
            "created": 1,
            "use": 1,
            "homeostatic": 1,
            "device": 1,
            "containing": 1,
            "appropriate": 1,
            "feedback": 1,
            "loop": 1,
            "achieve": 1,
            "stable": 1,
            "adaptive": 1,
            "behavior": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para119",
              "entity_text": "Britain",
              "entity_type": "GPE",
              "start_char": 14,
              "end_char": 21,
              "context": "Meanwhile, in Britain, W. Ross Ashby pioneered similar ideas (Ashby, 19"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "W. Ross Ashby",
              "entity_type": "PERSON",
              "start_char": 23,
              "end_char": 36,
              "context": "Meanwhile, in Britain, W. Ross Ashby pioneered similar ideas (Ashby, 1940). Ashby, Ala"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Ashby",
              "entity_type": "ORG",
              "start_char": 62,
              "end_char": 67,
              "context": "n Britain, W. Ross Ashby pioneered similar ideas (Ashby, 1940). Ashby, Alan Turing, Grey Walter, and othe"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Ashby",
              "entity_type": "ORG",
              "start_char": 76,
              "end_char": 81,
              "context": "Ross Ashby pioneered similar ideas (Ashby, 1940). Ashby, Alan Turing, Grey Walter, and others formed the "
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Alan Turing",
              "entity_type": "PERSON",
              "start_char": 83,
              "end_char": 94,
              "context": "hby pioneered similar ideas (Ashby, 1940). Ashby, Alan Turing, Grey Walter, and others formed the Ratio Club fo"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Grey Walter",
              "entity_type": "ORG",
              "start_char": 96,
              "end_char": 107,
              "context": " similar ideas (Ashby, 1940). Ashby, Alan Turing, Grey Walter, and others formed the Ratio Club for “those who "
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "the Ratio Club",
              "entity_type": "ORG",
              "start_char": 127,
              "end_char": 141,
              "context": "shby, Alan Turing, Grey Walter, and others formed the Ratio Club for “those who had Wiener’s ideas before Wiener’s"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Wiener",
              "entity_type": "PERSON",
              "start_char": 161,
              "end_char": 167,
              "context": "d others formed the Ratio Club for “those who had Wiener’s ideas before Wiener’s book appeared.” Ashby’s\nD"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Wiener",
              "entity_type": "ORG",
              "start_char": 183,
              "end_char": 189,
              "context": "tio Club for “those who had Wiener’s ideas before Wiener’s book appeared.” Ashby’s\nDesign for a Brain\n(194"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Ashby",
              "entity_type": "ORG",
              "start_char": 208,
              "end_char": 213,
              "context": "ad Wiener’s ideas before Wiener’s book appeared.” Ashby’s\nDesign for a Brain\n(1948, 1952) elaborated on h"
            },
            {
              "para_id": "chap1_para119",
              "entity_text": "Brain",
              "entity_type": "ORG",
              "start_char": 229,
              "end_char": 234,
              "context": "ore Wiener’s book appeared.” Ashby’s\nDesign for a Brain\n(1948, 1952) elaborated on his idea that intellig"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para120",
          "content": "Modern control theory, especially the branch known as stochastic optimal control, has as its goal the design of systems that minimize a\ncost function\nover time. This roughly matches the standard model of AI: designing systems that behave optimally. Why, then, are AI and control theory two different fields, despite the close connections among their founders? The answer lies in the close coupling between the mathematical techniques that were familiar to the participants and the corresponding sets of problems that were encompassed in each world view. Calculus and matrix algebra, the tools of control theory, lend themselves to systems that are describable by fixed sets of continuous variables, whereas AI was founded in part as a way to escape from these perceived limitations. The tools of logical inference and computation allowed AI researchers to consider problems such as language, vision, and symbolic planning that fell completely outside the control theorist’s purview.",
          "sentence_count": 6,
          "char_count": 834,
          "prev_para_id": "chap1_para119",
          "next_para_id": "chap1_para121",
          "style_metadata": {
            "para_id": "chap1_para120",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.33,
            "passive_voice_ratio": 0.012,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 170,
            "sentence_count": 6
          },
          "terminology": {
            "modern": 1,
            "control": 5,
            "theory": 3,
            "branch": 1,
            "known": 1,
            "stochastic": 1,
            "optimal": 1,
            "goal": 1,
            "design": 1,
            "system": 3,
            "minimize": 1,
            "cost": 1,
            "function": 1,
            "time": 1,
            "match": 1,
            "standard": 1,
            "model": 1,
            "designing": 1,
            "behave": 1,
            "different": 1,
            "field": 1,
            "close": 2,
            "connection": 1,
            "founder": 1,
            "answer": 1,
            "lie": 1,
            "coupling": 1,
            "mathematical": 1,
            "technique": 1,
            "familiar": 1,
            "participant": 1,
            "corresponding": 1,
            "set": 2,
            "problem": 2,
            "encompassed": 1,
            "world": 1,
            "view": 1,
            "calculus": 1,
            "matrix": 1,
            "algebra": 1,
            "tool": 2,
            "lend": 1,
            "describable": 1,
            "fixed": 1,
            "continuous": 1,
            "variable": 1,
            "whereas": 1,
            "founded": 1,
            "part": 1,
            "way": 1,
            "escape": 1,
            "perceived": 1,
            "limitation": 1,
            "logical": 1,
            "inference": 1,
            "computation": 1,
            "allowed": 1,
            "researcher": 1,
            "consider": 1,
            "language": 1,
            "vision": 1,
            "symbolic": 1,
            "planning": 1,
            "fell": 1,
            "outside": 1,
            "theorist": 1,
            "purview": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para120",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 204,
              "end_char": 206,
              "context": " time. This roughly matches the standard model of AI: designing systems that behave optimally. Why, th"
            },
            {
              "para_id": "chap1_para120",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 264,
              "end_char": 266,
              "context": "ing systems that behave optimally. Why, then, are AI and control theory two different fields, despite "
            },
            {
              "para_id": "chap1_para120",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 707,
              "end_char": 709,
              "context": "le by fixed sets of continuous variables, whereas AI was founded in part as a way to escape from these"
            },
            {
              "para_id": "chap1_para120",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 838,
              "end_char": 840,
              "context": "ools of logical inference and computation allowed AI researchers to consider problems such as language"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para121",
          "content": "1.2.8\nLinguistics\n•\nHow does language relate to thought?",
          "sentence_count": 1,
          "char_count": 51,
          "prev_para_id": "chap1_para120",
          "next_para_id": "chap1_para122",
          "style_metadata": {
            "para_id": "chap1_para121",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "linguistics": 1,
            "language": 1,
            "relate": 1,
            "thought": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para122",
          "content": "In 1957, B. F. Skinner published\nVerbal Behavior.",
          "sentence_count": 1,
          "char_count": 43,
          "prev_para_id": "chap1_para121",
          "next_para_id": "chap1_para123",
          "style_metadata": {
            "para_id": "chap1_para122",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "skinner": 1,
            "published": 1,
            "verbal": 1,
            "behavior": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para122",
              "entity_text": "B. F. Skinner",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 22,
              "context": "In 1957, B. F. Skinner published\nVerbal Behavior."
            },
            {
              "para_id": "chap1_para122",
              "entity_text": "Verbal Behavior",
              "entity_type": "ORG",
              "start_char": 33,
              "end_char": 48,
              "context": "In 1957, B. F. Skinner published\nVerbal Behavior."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para123",
          "content": "This was a comprehensive, detailed account of the behaviorist approach to language learning, written by the foremost expert in the field. But curiously, a review of the book became as well known as the book itself, and served to almost kill off interest in behaviorism. The author of the review was the linguist Noam Chomsky, who had just published a book on his own theory,\nSyntactic Structures.",
          "sentence_count": 3,
          "char_count": 331,
          "prev_para_id": "chap1_para122",
          "next_para_id": "chap1_para124",
          "style_metadata": {
            "para_id": "chap1_para123",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "comprehensive": 1,
            "detailed": 1,
            "account": 1,
            "behaviorist": 1,
            "approach": 1,
            "language": 1,
            "learning": 1,
            "written": 1,
            "foremost": 1,
            "expert": 1,
            "field": 1,
            "review": 2,
            "book": 3,
            "became": 1,
            "known": 1,
            "served": 1,
            "kill": 1,
            "interest": 1,
            "behaviorism": 1,
            "author": 1,
            "linguist": 1,
            "chomsky": 1,
            "published": 1,
            "theory": 1,
            "syntactic": 1,
            "structure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para123",
              "entity_text": "Noam Chomsky",
              "entity_type": "PERSON",
              "start_char": 312,
              "end_char": 324,
              "context": "iorism. The author of the review was the linguist Noam Chomsky, who had just published a book on his own theory,"
            },
            {
              "para_id": "chap1_para123",
              "entity_text": "Syntactic Structures",
              "entity_type": "PERSON",
              "start_char": 375,
              "end_char": 395,
              "context": " who had just published a book on his own theory,\nSyntactic Structures."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para124",
          "content": "Chomsky pointed out that the behaviorist theory did not address the notion of creativity in language—it did not explain how children could understand and make up sentences that they had never heard before. Chomsky’s theory—based on syntactic models going back to the Indian linguist Panini (c. 350\nBCE\n)—could explain this, and unlike previous theories, it was formal enough that it could in principle be programmed.",
          "sentence_count": 2,
          "char_count": 353,
          "prev_para_id": "chap1_para123",
          "next_para_id": "chap1_para125",
          "style_metadata": {
            "para_id": "chap1_para124",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 2
          },
          "terminology": {
            "chomsky": 2,
            "pointed": 1,
            "behaviorist": 1,
            "theory": 2,
            "address": 1,
            "notion": 1,
            "creativity": 1,
            "language—it": 1,
            "explain": 2,
            "child": 1,
            "understand": 1,
            "make": 1,
            "sentence": 1,
            "heard": 1,
            "theory—based": 1,
            "syntactic": 1,
            "model": 1,
            "going": 1,
            "indian": 1,
            "linguist": 1,
            "panini": 1,
            "bce": 1,
            "previous": 1,
            "formal": 1,
            "principle": 1,
            "programmed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para124",
              "entity_text": "Chomsky",
              "entity_type": "ORG",
              "start_char": 206,
              "end_char": 213,
              "context": "ke up sentences that they had never heard before. Chomsky’s theory—based on syntactic models going back to "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para125",
          "content": "Modern linguistics and AI, then, were “born” at about the same time, and grew up together, intersecting in a hybrid field called\ncomputational linguistics\nor\nnatural language\nprocessing\n. The problem of understanding language turned out to be considerably more complex than it seemed in 1957. Understanding language requires an understanding of the subject matter and context, not just an understanding of the structure of sentences. This might seem obvious, but it was not widely appreciated until the 1960s. Much of the early work in\nknowledge representation\n(the study of how to put knowledge into a form that a computer can reason with) was tied to language and informed by research in linguistics, which was connected in turn to decades of work on the philosophical analysis of language.",
          "sentence_count": 5,
          "char_count": 672,
          "prev_para_id": "chap1_para124",
          "next_para_id": "chap1_para126",
          "style_metadata": {
            "para_id": "chap1_para125",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.4,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 142,
            "sentence_count": 5
          },
          "terminology": {
            "modern": 1,
            "linguistics": 3,
            "born": 1,
            "time": 1,
            "grew": 1,
            "intersecting": 1,
            "hybrid": 1,
            "field": 1,
            "called": 1,
            "computational": 1,
            "natural": 1,
            "language": 5,
            "processing": 1,
            "problem": 1,
            "understanding": 4,
            "turned": 1,
            "complex": 1,
            "seemed": 1,
            "requires": 1,
            "subject": 1,
            "matter": 1,
            "context": 1,
            "structure": 1,
            "sentence": 1,
            "seem": 1,
            "obvious": 1,
            "appreciated": 1,
            "early": 1,
            "work": 2,
            "knowledge": 1,
            "representation": 1,
            "study": 1,
            "put": 1,
            "form": 1,
            "computer": 1,
            "reason": 1,
            "tied": 1,
            "informed": 1,
            "research": 1,
            "connected": 1,
            "turn": 1,
            "decade": 1,
            "philosophical": 1,
            "analysis": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para125",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 23,
              "end_char": 25,
              "context": "Modern linguistics and AI, then, were “born” at about the same time, and gr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para126",
          "content": "1.3The History of Artificial Intelligence\n1.3\nThe History of Artificial Intelligence\nOne quick way to summarize the milestones in AI history is to list the Turing Award winners: Marvin Minsky (1969) and John McCarthy (1971) for defining the foundations of the field based on representation and reasoning; Allen Newell and Herbert Simon (1975) for symbolic models of problem solving and human cognition; Ed Feigenbaum and Raj Reddy (1994) for developing expert systems that encode human knowledge to solve real-world problems; Judea Pearl (2011) for developing probabilistic reasoning techniques that deal with uncertainty in a principled manner; and finally Yoshua Bengio, Geoffrey Hinton, and Yann LeCun (2019) for making “deep learning” (multilayer neural networks) a critical part of modern computing. The rest of this section goes into more detail on each phase of AI history.",
          "sentence_count": 2,
          "char_count": 750,
          "prev_para_id": "chap1_para125",
          "next_para_id": "chap1_para127",
          "style_metadata": {
            "para_id": "chap1_para126",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 79.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 159,
            "sentence_count": 2
          },
          "terminology": {
            "history": 4,
            "artificial": 2,
            "intelligence": 2,
            "quick": 1,
            "way": 1,
            "summarize": 1,
            "milestone": 1,
            "list": 1,
            "turing": 1,
            "award": 1,
            "winner": 1,
            "marvin": 1,
            "minsky": 1,
            "john": 1,
            "mccarthy": 1,
            "defining": 1,
            "foundation": 1,
            "field": 1,
            "based": 1,
            "representation": 1,
            "reasoning": 2,
            "allen": 1,
            "herbert": 1,
            "simon": 1,
            "symbolic": 1,
            "model": 1,
            "problem": 2,
            "solving": 1,
            "human": 2,
            "cognition": 1,
            "feigenbaum": 1,
            "raj": 1,
            "reddy": 1,
            "developing": 2,
            "expert": 1,
            "system": 1,
            "encode": 1,
            "knowledge": 1,
            "solve": 1,
            "real-world": 1,
            "judea": 1,
            "probabilistic": 1,
            "technique": 1,
            "deal": 1,
            "uncertainty": 1,
            "principled": 1,
            "manner": 1,
            "yoshua": 1,
            "bengio": 1,
            "geoffrey": 1,
            "hinton": 1,
            "yann": 1,
            "lecun": 1,
            "making": 1,
            "deep": 1,
            "learning": 1,
            "multilayer": 1,
            "neural": 1,
            "network": 1,
            "critical": 1,
            "part": 1,
            "modern": 1,
            "computing": 1,
            "rest": 1,
            "section": 1,
            "go": 1,
            "detail": 1,
            "phase": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para126",
              "entity_text": "The History of Artificial Intelligence\nOne",
              "entity_type": "WORK_OF_ART",
              "start_char": 46,
              "end_char": 88,
              "context": "1.3The History of Artificial Intelligence\n1.3\nThe History of Artificial Intelligence\nOne quick way to summarize the milestones in AI histo"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 130,
              "end_char": 132,
              "context": "ence\nOne quick way to summarize the milestones in AI history is to list the Turing Award winners: Marv"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Marvin Minsky",
              "entity_type": "PERSON",
              "start_char": 178,
              "end_char": 191,
              "context": "n AI history is to list the Turing Award winners: Marvin Minsky (1969) and John McCarthy (1971) for defining the "
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "John McCarthy",
              "entity_type": "PERSON",
              "start_char": 203,
              "end_char": 216,
              "context": "he Turing Award winners: Marvin Minsky (1969) and John McCarthy (1971) for defining the foundations of the field "
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Allen Newell",
              "entity_type": "PERSON",
              "start_char": 305,
              "end_char": 317,
              "context": " the field based on representation and reasoning; Allen Newell and Herbert Simon (1975) for symbolic models of p"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 322,
              "end_char": 335,
              "context": "on representation and reasoning; Allen Newell and Herbert Simon (1975) for symbolic models of problem solving and"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Ed Feigenbaum",
              "entity_type": "PERSON",
              "start_char": 403,
              "end_char": 416,
              "context": "ic models of problem solving and human cognition; Ed Feigenbaum and Raj Reddy (1994) for developing expert system"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Raj Reddy",
              "entity_type": "PERSON",
              "start_char": 421,
              "end_char": 430,
              "context": "em solving and human cognition; Ed Feigenbaum and Raj Reddy (1994) for developing expert systems that encode "
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Judea Pearl",
              "entity_type": "PERSON",
              "start_char": 526,
              "end_char": 537,
              "context": "ode human knowledge to solve real-world problems; Judea Pearl (2011) for developing probabilistic reasoning tec"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Yoshua Bengio",
              "entity_type": "PERSON",
              "start_char": 658,
              "end_char": 671,
              "context": "h uncertainty in a principled manner; and finally Yoshua Bengio, Geoffrey Hinton, and Yann LeCun (2019) for makin"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Geoffrey Hinton",
              "entity_type": "PERSON",
              "start_char": 673,
              "end_char": 688,
              "context": "n a principled manner; and finally Yoshua Bengio, Geoffrey Hinton, and Yann LeCun (2019) for making “deep learning”"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "Yann LeCun",
              "entity_type": "PERSON",
              "start_char": 694,
              "end_char": 704,
              "context": "; and finally Yoshua Bengio, Geoffrey Hinton, and Yann LeCun (2019) for making “deep learning” (multilayer neu"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "multilayer neural networks",
              "entity_type": "ORG",
              "start_char": 740,
              "end_char": 766,
              "context": "and Yann LeCun (2019) for making “deep learning” (multilayer neural networks) a critical part of modern computing. The rest of"
            },
            {
              "para_id": "chap1_para126",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 869,
              "end_char": 871,
              "context": "is section goes into more detail on each phase of AI history."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para127",
          "content": "1.3.1\nThe inception of artificial intelligence (1943–1956)\nThe first work that is now generally recognized as AI was done by Warren McCulloch and Walter Pitts (1943). Inspired by the mathematical modeling work of Pitts’s advisor Nicolas Rashevsky (1936, 1938), they drew on three sources: knowledge of the basic physiology and function of neurons in the brain; a formal analysis of propositional logic due to Russell and Whitehead; and Turing’s theory of computation. They proposed a model of artificial neurons in which each neuron is characterized as being “on” or “off,” with a switch to “on” occurring in response to stimulation by a sufficient number of neighboring neurons. The state of a neuron was conceived of as “factually equivalent to a proposition which proposed its adequate stimulus.” They showed, for example, that any computable function could be computed by some network of connected neurons, and that all the logical connectives (\nAND\n,\nOR\n,\nNOT\n, etc.) could be implemented by simple network structures. McCulloch and Pitts also suggested that suitably defined networks could learn. Donald Hebb (1949) demonstrated a simple updating rule for modifying the connection strengths between neurons. His rule, now called\nHebbian learning\n, remains an influential model to this day.",
          "sentence_count": 8,
          "char_count": 1102,
          "prev_para_id": "chap1_para126",
          "next_para_id": "chap1_para128",
          "style_metadata": {
            "para_id": "chap1_para127",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.38,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 243,
            "sentence_count": 8
          },
          "terminology": {
            "inception": 1,
            "artificial": 2,
            "intelligence": 1,
            "first": 1,
            "work": 2,
            "recognized": 1,
            "done": 1,
            "warren": 1,
            "mcculloch": 2,
            "walter": 1,
            "pitt": 3,
            "inspired": 1,
            "mathematical": 1,
            "modeling": 1,
            "advisor": 1,
            "nicolas": 1,
            "rashevsky": 1,
            "drew": 1,
            "source": 1,
            "knowledge": 1,
            "basic": 1,
            "physiology": 1,
            "function": 2,
            "neuron": 7,
            "brain": 1,
            "formal": 1,
            "analysis": 1,
            "propositional": 1,
            "logic": 1,
            "due": 1,
            "russell": 1,
            "whitehead": 1,
            "turing": 1,
            "theory": 1,
            "computation": 1,
            "proposed": 2,
            "model": 2,
            "characterized": 1,
            "switch": 1,
            "occurring": 1,
            "response": 1,
            "stimulation": 1,
            "sufficient": 1,
            "number": 1,
            "neighboring": 1,
            "state": 1,
            "conceived": 1,
            "equivalent": 1,
            "proposition": 1,
            "adequate": 1,
            "stimulus.": 1,
            "showed": 1,
            "example": 1,
            "computable": 1,
            "computed": 1,
            "network": 3,
            "connected": 1,
            "logical": 1,
            "connective": 1,
            "implemented": 1,
            "simple": 2,
            "structure": 1,
            "suggested": 1,
            "defined": 1,
            "learn": 1,
            "donald": 1,
            "hebb": 1,
            "demonstrated": 1,
            "updating": 1,
            "rule": 2,
            "modifying": 1,
            "connection": 1,
            "strength": 1,
            "called": 1,
            "hebbian": 1,
            "learning": 1,
            "remains": 1,
            "influential": 1,
            "day": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para127",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 110,
              "end_char": 112,
              "context": "he first work that is now generally recognized as AI was done by Warren McCulloch and Walter Pitts (19"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Warren McCulloch",
              "entity_type": "PERSON",
              "start_char": 125,
              "end_char": 141,
              "context": "hat is now generally recognized as AI was done by Warren McCulloch and Walter Pitts (1943). Inspired by the mathemat"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Walter Pitts",
              "entity_type": "PERSON",
              "start_char": 146,
              "end_char": 158,
              "context": "recognized as AI was done by Warren McCulloch and Walter Pitts (1943). Inspired by the mathematical modeling wor"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Pitts’s",
              "entity_type": "ORG",
              "start_char": 213,
              "end_char": 220,
              "context": "3). Inspired by the mathematical modeling work of Pitts’s advisor Nicolas Rashevsky (1936, 1938), they drew"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Nicolas Rashevsky",
              "entity_type": "PERSON",
              "start_char": 229,
              "end_char": 246,
              "context": "the mathematical modeling work of Pitts’s advisor Nicolas Rashevsky (1936, 1938), they drew on three sources: knowled"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Russell",
              "entity_type": "PERSON",
              "start_char": 409,
              "end_char": 416,
              "context": "; a formal analysis of propositional logic due to Russell and Whitehead; and Turing’s theory of computation"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Whitehead",
              "entity_type": "ORG",
              "start_char": 421,
              "end_char": 430,
              "context": "nalysis of propositional logic due to Russell and Whitehead; and Turing’s theory of computation. They propose"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 436,
              "end_char": 442,
              "context": "ositional logic due to Russell and Whitehead; and Turing’s theory of computation. They proposed a model of"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Pitts",
              "entity_type": "GPE",
              "start_char": 1038,
              "end_char": 1043,
              "context": "ented by simple network structures. McCulloch and Pitts also suggested that suitably defined networks cou"
            },
            {
              "para_id": "chap1_para127",
              "entity_text": "Donald Hebb",
              "entity_type": "PERSON",
              "start_char": 1103,
              "end_char": 1114,
              "context": "ested that suitably defined networks could learn. Donald Hebb (1949) demonstrated a simple updating rule for mo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para128",
          "content": "Two undergraduate students at Harvard, Marvin Minsky (1927–2016) and Dean Edmonds, built the first neural network computer in 1950. The S\nNARC\n, as it was called, used 3000 vacuum tubes and a surplus automatic pilot mechanism from a B-24 bomber to simulate a network of 40 neurons. Later, at Princeton, Minsky studied universal computation in neural networks. His Ph.D. committee was skeptical about whether this kind of work should be considered mathematics, but von Neumann reportedly said, “If it isn’t now, it will be someday.”\nThere were a number of other examples of early work that can be characterized as AI, including two checkers-playing programs developed independently in 1952 by Christopher Strachey at the University of Manchester and by Arthur Samuel at IBM. However, Alan Turing’s vision was the most influential. He gave lectures on the topic as early as 1947 at the London Mathematical Society and articulated a persuasive agenda in his 1950 article “Computing\nMachinery and Intelligence.” Therein, he introduced the Turing test, machine learning, genetic algorithms, and reinforcement learning. He dealt with many of the objections raised to the possibility of AI, as described in\nChapter 28\n. He also suggested that it would be easier to create human-level AI by developing learning algorithms and then teaching the machine rather than by programming its intelligence by hand. In subsequent lectures he warned that achieving this goal might not be the best thing for the human race.",
          "sentence_count": 9,
          "char_count": 1269,
          "prev_para_id": "chap1_para127",
          "next_para_id": "chap1_para129",
          "style_metadata": {
            "para_id": "chap1_para128",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 30.22,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 272,
            "sentence_count": 9
          },
          "terminology": {
            "undergraduate": 1,
            "student": 1,
            "harvard": 1,
            "marvin": 1,
            "minsky": 2,
            "dean": 1,
            "edmonds": 1,
            "built": 1,
            "neural": 2,
            "network": 3,
            "computer": 1,
            "narc": 1,
            "called": 1,
            "used": 1,
            "vacuum": 1,
            "tube": 1,
            "automatic": 1,
            "pilot": 1,
            "mechanism": 1,
            "b-24": 1,
            "bomber": 1,
            "simulate": 1,
            "neuron": 1,
            "princeton": 1,
            "studied": 1,
            "universal": 1,
            "computation": 1,
            "ph.d.": 1,
            "committee": 1,
            "skeptical": 1,
            "kind": 1,
            "work": 2,
            "considered": 1,
            "mathematics": 1,
            "von": 1,
            "said": 1,
            "someday.": 1,
            "number": 1,
            "example": 1,
            "characterized": 1,
            "including": 1,
            "checkers-playing": 1,
            "program": 1,
            "developed": 1,
            "christopher": 1,
            "strachey": 1,
            "university": 1,
            "manchester": 1,
            "arthur": 1,
            "samuel": 1,
            "ibm": 1,
            "alan": 1,
            "turing": 2,
            "vision": 1,
            "influential": 1,
            "gave": 1,
            "lecture": 2,
            "topic": 1,
            "early": 1,
            "london": 1,
            "mathematical": 1,
            "society": 1,
            "articulated": 1,
            "persuasive": 1,
            "agenda": 1,
            "article": 1,
            "computing": 1,
            "machinery": 1,
            "intelligence.": 1,
            "therein": 1,
            "introduced": 1,
            "test": 1,
            "machine": 2,
            "learning": 3,
            "genetic": 1,
            "algorithm": 2,
            "reinforcement": 1,
            "dealt": 1,
            "many": 1,
            "objection": 1,
            "raised": 1,
            "possibility": 1,
            "described": 1,
            "chapter": 1,
            "suggested": 1,
            "easier": 1,
            "create": 1,
            "human-level": 1,
            "developing": 1,
            "teaching": 1,
            "programming": 1,
            "intelligence": 1,
            "hand": 1,
            "subsequent": 1,
            "warned": 1,
            "achieving": 1,
            "goal": 1,
            "best": 1,
            "thing": 1,
            "human": 1,
            "race": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para128",
              "entity_text": "Harvard",
              "entity_type": "ORG",
              "start_char": 30,
              "end_char": 37,
              "context": "Two undergraduate students at Harvard, Marvin Minsky (1927–2016) and Dean Edmonds, buil"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Marvin Minsky",
              "entity_type": "PERSON",
              "start_char": 39,
              "end_char": 52,
              "context": "Two undergraduate students at Harvard, Marvin Minsky (1927–2016) and Dean Edmonds, built the first neu"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Dean Edmonds",
              "entity_type": "PERSON",
              "start_char": 69,
              "end_char": 81,
              "context": "tudents at Harvard, Marvin Minsky (1927–2016) and Dean Edmonds, built the first neural network computer in 1950."
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "The S\nNARC",
              "entity_type": "ORG",
              "start_char": 132,
              "end_char": 142,
              "context": " built the first neural network computer in 1950. The S\nNARC\n, as it was called, used 3000 vacuum tubes and a "
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "B-24",
              "entity_type": "PRODUCT",
              "start_char": 233,
              "end_char": 237,
              "context": "es and a surplus automatic pilot mechanism from a B-24 bomber to simulate a network of 40 neurons. Later"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Princeton",
              "entity_type": "GPE",
              "start_char": 292,
              "end_char": 301,
              "context": "er to simulate a network of 40 neurons. Later, at Princeton, Minsky studied universal computation in neural n"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Minsky",
              "entity_type": "PERSON",
              "start_char": 303,
              "end_char": 309,
              "context": "ate a network of 40 neurons. Later, at Princeton, Minsky studied universal computation in neural networks."
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Ph.D.",
              "entity_type": "PERSON",
              "start_char": 364,
              "end_char": 369,
              "context": "ied universal computation in neural networks. His Ph.D. committee was skeptical about whether this kind o"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "von Neumann",
              "entity_type": "PERSON",
              "start_char": 464,
              "end_char": 475,
              "context": "ind of work should be considered mathematics, but von Neumann reportedly said, “If it isn’t now, it will be som"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 613,
              "end_char": 615,
              "context": "amples of early work that can be characterized as AI, including two checkers-playing programs develope"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Christopher Strachey",
              "entity_type": "PERSON",
              "start_char": 692,
              "end_char": 712,
              "context": "aying programs developed independently in 1952 by Christopher Strachey at the University of Manchester and by Arthur Sam"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "the University of Manchester",
              "entity_type": "ORG",
              "start_char": 716,
              "end_char": 744,
              "context": " independently in 1952 by Christopher Strachey at the University of Manchester and by Arthur Samuel at IBM. However, Alan Turing"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Arthur Samuel",
              "entity_type": "PERSON",
              "start_char": 752,
              "end_char": 765,
              "context": "r Strachey at the University of Manchester and by Arthur Samuel at IBM. However, Alan Turing’s vision was the mos"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "IBM",
              "entity_type": "ORG",
              "start_char": 769,
              "end_char": 772,
              "context": " University of Manchester and by Arthur Samuel at IBM. However, Alan Turing’s vision was the most influ"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Alan Turing’s",
              "entity_type": "PERSON",
              "start_char": 783,
              "end_char": 796,
              "context": " Manchester and by Arthur Samuel at IBM. However, Alan Turing’s vision was the most influential. He gave lectures"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "the London Mathematical Society",
              "entity_type": "ORG",
              "start_char": 880,
              "end_char": 911,
              "context": "He gave lectures on the topic as early as 1947 at the London Mathematical Society and articulated a persuasive agenda in his 1950 a"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Computing\nMachinery and Intelligence",
              "entity_type": "WORK_OF_ART",
              "start_char": 969,
              "end_char": 1005,
              "context": "iculated a persuasive agenda in his 1950 article “Computing\nMachinery and Intelligence.” Therein, he introduced the Turing test, machine"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 1035,
              "end_char": 1041,
              "context": "ery and Intelligence.” Therein, he introduced the Turing test, machine learning, genetic algorithms, and r"
            },
            {
              "para_id": "chap1_para128",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 1180,
              "end_char": 1182,
              "context": "ny of the objections raised to the possibility of AI, as described in\nChapter 28\n. He also suggested t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para129",
          "content": "In 1955, John McCarthy of Dartmouth College convinced Minsky, Claude Shannon, and Nathaniel Rochester to help him bring together U.S. researchers interested in automata theory, neural nets, and the study of intelligence. They organized a two-month workshop at Dartmouth in the summer of 1956. There were 10 attendees in all, including Allen Newell and Herbert Simon from Carnegie Tech,\n11\nTrenchard More from Princeton, Arthur Samuel from IBM, and Ray Solomonoff and Oliver Selfridge from MIT. The proposal states:\n12\nWe propose that a 2 month, 10 man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.",
          "sentence_count": 7,
          "char_count": 1014,
          "prev_para_id": "chap1_para128",
          "next_para_id": "chap1_para130",
          "style_metadata": {
            "para_id": "chap1_para129",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 224,
            "sentence_count": 7
          },
          "terminology": {
            "john": 1,
            "mccarthy": 1,
            "dartmouth": 3,
            "college": 2,
            "convinced": 1,
            "minsky": 1,
            "claude": 1,
            "shannon": 1,
            "nathaniel": 1,
            "rochester": 1,
            "help": 1,
            "bring": 1,
            "u.s.": 1,
            "researcher": 1,
            "interested": 1,
            "theory": 1,
            "neural": 1,
            "net": 1,
            "study": 3,
            "intelligence": 3,
            "organized": 1,
            "two-month": 1,
            "workshop": 1,
            "summer": 3,
            "attendee": 1,
            "including": 1,
            "allen": 1,
            "herbert": 1,
            "simon": 1,
            "carnegie": 1,
            "tech": 1,
            "princeton": 1,
            "arthur": 1,
            "samuel": 1,
            "ibm": 1,
            "ray": 1,
            "solomonoff": 1,
            "selfridge": 1,
            "mit": 1,
            "proposal": 1,
            "state": 1,
            "propose": 1,
            "month": 1,
            "man": 1,
            "artificial": 1,
            "carried": 1,
            "hanover": 1,
            "new": 1,
            "hampshire": 1,
            "proceed": 1,
            "basis": 1,
            "conjecture": 1,
            "aspect": 1,
            "learning": 1,
            "feature": 1,
            "principle": 1,
            "described": 1,
            "machine": 2,
            "made": 3,
            "simulate": 1,
            "attempt": 1,
            "find": 1,
            "make": 1,
            "use": 1,
            "language": 1,
            "form": 1,
            "abstraction": 1,
            "concept": 1,
            "solve": 1,
            "kind": 1,
            "problem": 2,
            "reserved": 1,
            "human": 1,
            "improve": 1,
            "think": 1,
            "significant": 1,
            "advance": 1,
            "selected": 1,
            "group": 1,
            "scientist": 1,
            "work": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para129",
              "entity_text": "John McCarthy",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 22,
              "context": "In 1955, John McCarthy of Dartmouth College convinced Minsky, Claude Sha"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Dartmouth College",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 43,
              "context": "In 1955, John McCarthy of Dartmouth College convinced Minsky, Claude Shannon, and Nathaniel R"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Claude Shannon",
              "entity_type": "PERSON",
              "start_char": 62,
              "end_char": 76,
              "context": "n McCarthy of Dartmouth College convinced Minsky, Claude Shannon, and Nathaniel Rochester to help him bring togeth"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Nathaniel Rochester",
              "entity_type": "PERSON",
              "start_char": 82,
              "end_char": 101,
              "context": "uth College convinced Minsky, Claude Shannon, and Nathaniel Rochester to help him bring together U.S. researchers inter"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 129,
              "end_char": 133,
              "context": "nd Nathaniel Rochester to help him bring together U.S. researchers interested in automata theory, neural"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Dartmouth",
              "entity_type": "ORG",
              "start_char": 260,
              "end_char": 269,
              "context": "elligence. They organized a two-month workshop at Dartmouth in the summer of 1956. There were 10 attendees in"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Allen Newell",
              "entity_type": "PERSON",
              "start_char": 335,
              "end_char": 347,
              "context": "f 1956. There were 10 attendees in all, including Allen Newell and Herbert Simon from Carnegie Tech,\n11\nTrenchar"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 352,
              "end_char": 365,
              "context": "e 10 attendees in all, including Allen Newell and Herbert Simon from Carnegie Tech,\n11\nTrenchard More from Prince"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Carnegie Tech",
              "entity_type": "ORG",
              "start_char": 371,
              "end_char": 384,
              "context": "ll, including Allen Newell and Herbert Simon from Carnegie Tech,\n11\nTrenchard More from Princeton, Arthur Samuel "
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Princeton",
              "entity_type": "GPE",
              "start_char": 409,
              "end_char": 418,
              "context": " Simon from Carnegie Tech,\n11\nTrenchard More from Princeton, Arthur Samuel from IBM, and Ray Solomonoff and O"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Arthur Samuel",
              "entity_type": "PERSON",
              "start_char": 420,
              "end_char": 433,
              "context": " Carnegie Tech,\n11\nTrenchard More from Princeton, Arthur Samuel from IBM, and Ray Solomonoff and Oliver Selfridge"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "IBM",
              "entity_type": "ORG",
              "start_char": 439,
              "end_char": 442,
              "context": "Trenchard More from Princeton, Arthur Samuel from IBM, and Ray Solomonoff and Oliver Selfridge from MIT"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Ray Solomonoff",
              "entity_type": "PERSON",
              "start_char": 448,
              "end_char": 462,
              "context": " More from Princeton, Arthur Samuel from IBM, and Ray Solomonoff and Oliver Selfridge from MIT. The proposal state"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Oliver Selfridge",
              "entity_type": "PERSON",
              "start_char": 467,
              "end_char": 483,
              "context": "n, Arthur Samuel from IBM, and Ray Solomonoff and Oliver Selfridge from MIT. The proposal states:\n12\nWe propose that"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "MIT",
              "entity_type": "ORG",
              "start_char": 489,
              "end_char": 492,
              "context": "IBM, and Ray Solomonoff and Oliver Selfridge from MIT. The proposal states:\n12\nWe propose that a 2 mont"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Dartmouth College",
              "entity_type": "ORG",
              "start_char": 629,
              "end_char": 646,
              "context": "gence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to procee"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "Hanover",
              "entity_type": "GPE",
              "start_char": 650,
              "end_char": 657,
              "context": "during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the ba"
            },
            {
              "para_id": "chap1_para129",
              "entity_text": "New Hampshire",
              "entity_type": "GPE",
              "start_char": 659,
              "end_char": 672,
              "context": "e summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conj"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para130",
          "content": "Despite this optimistic prediction, the Dartmouth workshop did not lead to any breakthroughs. Newell and Simon presented perhaps the most mature work, a mathematical theorem-proving system called the Logic Theorist (LT). Simon claimed, “We have invented a computer program capable of thinking non-numerically, and thereby solved the venerable mind–body problem.”\n13\nSoon after the workshop, the program was able to prove most of the theorems in\nChapter 2\nof Russell and Whitehead’s\nPrincipia Mathematica.",
          "sentence_count": 3,
          "char_count": 436,
          "prev_para_id": "chap1_para129",
          "next_para_id": "chap1_para131",
          "style_metadata": {
            "para_id": "chap1_para130",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "optimistic": 1,
            "prediction": 1,
            "dartmouth": 1,
            "workshop": 2,
            "lead": 1,
            "breakthrough": 1,
            "presented": 1,
            "mature": 1,
            "work": 1,
            "mathematical": 1,
            "theorem-proving": 1,
            "system": 1,
            "called": 1,
            "logic": 1,
            "theorist": 1,
            "simon": 1,
            "claimed": 1,
            "invented": 1,
            "computer": 1,
            "program": 2,
            "capable": 1,
            "thinking": 1,
            "solved": 1,
            "venerable": 1,
            "mind–body": 1,
            "problem.": 1,
            "able": 1,
            "prove": 1,
            "theorem": 1,
            "chapter": 1,
            "russell": 1,
            "whitehead": 1,
            "principia": 1,
            "mathematica": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para130",
              "entity_text": "Dartmouth",
              "entity_type": "ORG",
              "start_char": 40,
              "end_char": 49,
              "context": "Despite this optimistic prediction, the Dartmouth workshop did not lead to any breakthroughs. Newel"
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "Newell",
              "entity_type": "PERSON",
              "start_char": 94,
              "end_char": 100,
              "context": "mouth workshop did not lead to any breakthroughs. Newell and Simon presented perhaps the most mature work,"
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 105,
              "end_char": 110,
              "context": "hop did not lead to any breakthroughs. Newell and Simon presented perhaps the most mature work, a mathema"
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "the Logic Theorist",
              "entity_type": "ORG",
              "start_char": 196,
              "end_char": 214,
              "context": "ork, a mathematical theorem-proving system called the Logic Theorist (LT). Simon claimed, “We have invented a computer"
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 221,
              "end_char": 226,
              "context": "em-proving system called the Logic Theorist (LT). Simon claimed, “We have invented a computer program cap"
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "Russell",
              "entity_type": "PERSON",
              "start_char": 458,
              "end_char": 465,
              "context": "ble to prove most of the theorems in\nChapter 2\nof Russell and Whitehead’s\nPrincipia Mathematica."
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "Whitehead",
              "entity_type": "ORG",
              "start_char": 470,
              "end_char": 479,
              "context": " most of the theorems in\nChapter 2\nof Russell and Whitehead’s\nPrincipia Mathematica."
            },
            {
              "para_id": "chap1_para130",
              "entity_text": "Principia Mathematica",
              "entity_type": "ORG",
              "start_char": 482,
              "end_char": 503,
              "context": " theorems in\nChapter 2\nof Russell and Whitehead’s\nPrincipia Mathematica."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para131",
          "content": "Russell was reportedly delighted when told that LT had come up with a proof for one theorem that was shorter than the one in\nPrincipia.",
          "sentence_count": 1,
          "char_count": 112,
          "prev_para_id": "chap1_para130",
          "next_para_id": "chap1_para132",
          "style_metadata": {
            "para_id": "chap1_para131",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "russell": 1,
            "delighted": 1,
            "told": 1,
            "come": 1,
            "theorem": 1,
            "shorter": 1,
            "principia": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para131",
              "entity_text": "Russell",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 7,
              "context": "Russell was reportedly delighted when told that LT had co"
            },
            {
              "para_id": "chap1_para131",
              "entity_text": "Principia",
              "entity_type": "ORG",
              "start_char": 125,
              "end_char": 134,
              "context": " for one theorem that was shorter than the one in\nPrincipia."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para132",
          "content": "The editors of the\nJournal of Symbolic Logic\nwere less impressed; they rejected a paper coauthored by Newell, Simon, and Logic Theorist.",
          "sentence_count": 1,
          "char_count": 117,
          "prev_para_id": "chap1_para131",
          "next_para_id": "chap1_para133",
          "style_metadata": {
            "para_id": "chap1_para132",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "editor": 1,
            "journal": 1,
            "symbolic": 1,
            "logic": 2,
            "impressed": 1,
            "rejected": 1,
            "paper": 1,
            "coauthored": 1,
            "simon": 1,
            "theorist": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para132",
              "entity_text": "Journal of Symbolic Logic",
              "entity_type": "ORG",
              "start_char": 19,
              "end_char": 44,
              "context": "The editors of the\nJournal of Symbolic Logic\nwere less impressed; they rejected a paper coauth"
            },
            {
              "para_id": "chap1_para132",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 102,
              "end_char": 108,
              "context": "ss impressed; they rejected a paper coauthored by Newell, Simon, and Logic Theorist."
            },
            {
              "para_id": "chap1_para132",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 110,
              "end_char": 115,
              "context": "ssed; they rejected a paper coauthored by Newell, Simon, and Logic Theorist."
            },
            {
              "para_id": "chap1_para132",
              "entity_text": "Logic Theorist",
              "entity_type": "ORG",
              "start_char": 121,
              "end_char": 135,
              "context": "rejected a paper coauthored by Newell, Simon, and Logic Theorist."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para133",
          "content": "1.3.2\nEarly enthusiasm, great expectations (1952–1969)\nThe intellectual establishment of the 1950s, by and large, preferred to believe that “a machine can never do\nX\n.” (See\nChapter 28\nfor a long list of\nX\n’s gathered by Turing.) AI researchers naturally responded by demonstrating one\nX\nafter another. They focused in particular on tasks considered indicative of intelligence in humans, including games, puzzles, mathematics, and IQ tests. John McCarthy referred to this period as the “Look, Ma, no hands!” era.",
          "sentence_count": 4,
          "char_count": 442,
          "prev_para_id": "chap1_para132",
          "next_para_id": "chap1_para134",
          "style_metadata": {
            "para_id": "chap1_para133",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "early": 1,
            "enthusiasm": 1,
            "great": 1,
            "expectation": 1,
            "intellectual": 1,
            "establishment": 1,
            "large": 1,
            "preferred": 1,
            "believe": 1,
            "machine": 1,
            "see": 1,
            "chapter": 1,
            "long": 1,
            "list": 1,
            "gathered": 1,
            "turing": 1,
            "researcher": 1,
            "responded": 1,
            "demonstrating": 1,
            "focused": 1,
            "particular": 1,
            "task": 1,
            "considered": 1,
            "indicative": 1,
            "intelligence": 1,
            "human": 1,
            "including": 1,
            "game": 1,
            "puzzle": 1,
            "mathematics": 1,
            "test": 1,
            "john": 1,
            "mccarthy": 1,
            "referred": 1,
            "period": 1,
            "look": 1,
            "hand": 1,
            "era": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para133",
              "entity_text": "Turing",
              "entity_type": "GPE",
              "start_char": 221,
              "end_char": 227,
              "context": "ee\nChapter 28\nfor a long list of\nX\n’s gathered by Turing.) AI researchers naturally responded by demonstra"
            },
            {
              "para_id": "chap1_para133",
              "entity_text": "John McCarthy",
              "entity_type": "PERSON",
              "start_char": 441,
              "end_char": 454,
              "context": "luding games, puzzles, mathematics, and IQ tests. John McCarthy referred to this period as the “Look, Ma, no hand"
            },
            {
              "para_id": "chap1_para133",
              "entity_text": "Look, Ma",
              "entity_type": "WORK_OF_ART",
              "start_char": 487,
              "end_char": 495,
              "context": "ts. John McCarthy referred to this period as the “Look, Ma, no hands!” era."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para134",
          "content": "Newell and Simon followed up their success with LT with the General Problem Solver, or GPS. Unlike LT, this program was designed from the start to imitate human problem-solving protocols. Within the limited class of puzzles it could handle, it turned out that the order in which the program considered subgoals and possible actions was similar to that in which humans approached the same problems. Thus, GPS was probably the first program to embody the “thinking humanly” approach. The success of GPS and subsequent programs as models of cognition led Newell and Simon (1976) to formulate the famous\nphysical symbol system\nhypothesis, which states that “a physical symbol system has the necessary and sufficient means for general intelligent action.” What they meant is that any system (human or machine) exhibiting intelligence must operate by manipulating data structures composed of symbols. We will see later that this hypothesis has been challenged from many directions.",
          "sentence_count": 6,
          "char_count": 825,
          "prev_para_id": "chap1_para133",
          "next_para_id": "chap1_para135",
          "style_metadata": {
            "para_id": "chap1_para134",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.67,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 172,
            "sentence_count": 6
          },
          "terminology": {
            "simon": 2,
            "followed": 1,
            "success": 2,
            "general": 2,
            "problem": 2,
            "solver": 1,
            "gps": 2,
            "program": 4,
            "designed": 1,
            "start": 1,
            "imitate": 1,
            "human": 3,
            "problem-solving": 1,
            "protocol": 1,
            "limited": 1,
            "class": 1,
            "puzzle": 1,
            "handle": 1,
            "turned": 1,
            "order": 1,
            "considered": 1,
            "subgoals": 1,
            "possible": 1,
            "action": 1,
            "similar": 1,
            "approached": 1,
            "first": 1,
            "embody": 1,
            "thinking": 1,
            "approach": 1,
            "subsequent": 1,
            "model": 1,
            "cognition": 1,
            "led": 1,
            "formulate": 1,
            "famous": 1,
            "physical": 2,
            "symbol": 3,
            "system": 3,
            "hypothesis": 1,
            "state": 1,
            "necessary": 1,
            "sufficient": 1,
            "mean": 1,
            "intelligent": 1,
            "action.": 1,
            "meant": 1,
            "machine": 1,
            "exhibiting": 1,
            "intelligence": 1,
            "operate": 1,
            "manipulating": 1,
            "data": 1,
            "structure": 1,
            "composed": 1,
            "see": 1,
            "challenged": 1,
            "many": 1,
            "direction": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para134",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 6,
              "context": "Newell and Simon followed up their success with LT with "
            },
            {
              "para_id": "chap1_para134",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 11,
              "end_char": 16,
              "context": "Newell and Simon followed up their success with LT with the Genera"
            },
            {
              "para_id": "chap1_para134",
              "entity_text": "the General Problem Solver",
              "entity_type": "ORG",
              "start_char": 56,
              "end_char": 82,
              "context": " and Simon followed up their success with LT with the General Problem Solver, or GPS. Unlike LT, this program was designed fro"
            },
            {
              "para_id": "chap1_para134",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 552,
              "end_char": 558,
              "context": "nd subsequent programs as models of cognition led Newell and Simon (1976) to formulate the famous\nphysical"
            },
            {
              "para_id": "chap1_para134",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 563,
              "end_char": 568,
              "context": "nt programs as models of cognition led Newell and Simon (1976) to formulate the famous\nphysical symbol sy"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para135",
          "content": "At IBM, Nathaniel Rochester and his colleagues produced some of the first AI programs. Herbert Gelernter (1959) constructed the Geometry Theorem Prover, which was able to prove theorems that many students of mathematics would find quite tricky. This work was a precursor of modern mathematical theorem provers.",
          "sentence_count": 3,
          "char_count": 264,
          "prev_para_id": "chap1_para134",
          "next_para_id": "chap1_para136",
          "style_metadata": {
            "para_id": "chap1_para135",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 3
          },
          "terminology": {
            "ibm": 1,
            "nathaniel": 1,
            "rochester": 1,
            "colleague": 1,
            "produced": 1,
            "first": 1,
            "program": 1,
            "herbert": 1,
            "constructed": 1,
            "geometry": 1,
            "theorem": 3,
            "prover": 1,
            "able": 1,
            "prove": 1,
            "many": 1,
            "student": 1,
            "mathematics": 1,
            "find": 1,
            "quite": 1,
            "tricky": 1,
            "work": 1,
            "precursor": 1,
            "modern": 1,
            "mathematical": 1,
            "provers": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para135",
              "entity_text": "IBM",
              "entity_type": "ORG",
              "start_char": 3,
              "end_char": 6,
              "context": "At IBM, Nathaniel Rochester and his colleagues produced "
            },
            {
              "para_id": "chap1_para135",
              "entity_text": "Nathaniel Rochester",
              "entity_type": "PERSON",
              "start_char": 8,
              "end_char": 27,
              "context": "At IBM, Nathaniel Rochester and his colleagues produced some of the first AI "
            },
            {
              "para_id": "chap1_para135",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 74,
              "end_char": 76,
              "context": "ter and his colleagues produced some of the first AI programs. Herbert Gelernter (1959) constructed th"
            },
            {
              "para_id": "chap1_para135",
              "entity_text": "Herbert Gelernter",
              "entity_type": "PERSON",
              "start_char": 87,
              "end_char": 104,
              "context": "olleagues produced some of the first AI programs. Herbert Gelernter (1959) constructed the Geometry Theorem Prover, w"
            },
            {
              "para_id": "chap1_para135",
              "entity_text": "the Geometry Theorem Prover",
              "entity_type": "ORG",
              "start_char": 124,
              "end_char": 151,
              "context": "AI programs. Herbert Gelernter (1959) constructed the Geometry Theorem Prover, which was able to prove theorems that many stude"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para136",
          "content": "Of all the exploratory work done during this period, perhaps the most influential in the long run was that of Arthur Samuel on checkers (draughts). Using methods that we now call reinforcement learning (see\nChapter 23\n), Samuel’s programs learned to play at a strong amateur level. He thereby disproved the idea that computers can do only what they are told to: his program quickly learned to play a better game than its creator. The program was demonstrated on television in 1956, creating a strong impression. Like Turing, Samuel had trouble finding computer time. Working at night, he used machines that were still on the testing floor at IBM’s manufacturing plant. Samuel’s program was the precursor of later systems such as TD-G\nAMMON\n(Tesauro, 1992), which was among the world’s best backgammon players, and A\nLPHA\nG\nO\n(Silver\net al.,\n2016), which shocked the world by defeating the human world champion at Go (see\nChapter 6\n).",
          "sentence_count": 7,
          "char_count": 788,
          "prev_para_id": "chap1_para135",
          "next_para_id": "chap1_para137",
          "style_metadata": {
            "para_id": "chap1_para136",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.43,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 192,
            "sentence_count": 7
          },
          "terminology": {
            "exploratory": 1,
            "work": 1,
            "done": 1,
            "period": 1,
            "influential": 1,
            "long": 1,
            "run": 1,
            "samuel": 4,
            "checker": 1,
            "draught": 1,
            "using": 1,
            "method": 1,
            "call": 1,
            "reinforcement": 1,
            "learning": 1,
            "see": 2,
            "chapter": 2,
            "program": 4,
            "learned": 2,
            "play": 2,
            "strong": 2,
            "amateur": 1,
            "level": 1,
            "disproved": 1,
            "idea": 1,
            "computer": 2,
            "told": 1,
            "better": 1,
            "game": 1,
            "creator": 1,
            "demonstrated": 1,
            "television": 1,
            "creating": 1,
            "impression": 1,
            "turing": 1,
            "trouble": 1,
            "finding": 1,
            "time": 1,
            "working": 1,
            "night": 1,
            "used": 1,
            "machine": 1,
            "testing": 1,
            "floor": 1,
            "ibm": 1,
            "manufacturing": 1,
            "plant": 1,
            "precursor": 1,
            "system": 1,
            "td-g": 1,
            "ammon": 1,
            "tesauro": 1,
            "world": 3,
            "best": 1,
            "backgammon": 1,
            "player": 1,
            "lpha": 1,
            "shocked": 1,
            "defeating": 1,
            "human": 1,
            "champion": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para136",
              "entity_text": "Arthur Samuel",
              "entity_type": "PERSON",
              "start_char": 110,
              "end_char": 123,
              "context": " the most influential in the long run was that of Arthur Samuel on checkers (draughts). Using methods that we now"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "Samuel",
              "entity_type": "PERSON",
              "start_char": 221,
              "end_char": 227,
              "context": "ow call reinforcement learning (see\nChapter 23\n), Samuel’s programs learned to play at a strong amateur le"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "Samuel",
              "entity_type": "PERSON",
              "start_char": 525,
              "end_char": 531,
              "context": " 1956, creating a strong impression. Like Turing, Samuel had trouble finding computer time. Working at nig"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "IBM",
              "entity_type": "ORG",
              "start_char": 642,
              "end_char": 645,
              "context": " machines that were still on the testing floor at IBM’s manufacturing plant. Samuel’s program was the p"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "Samuel",
              "entity_type": "PERSON",
              "start_char": 669,
              "end_char": 675,
              "context": "n the testing floor at IBM’s manufacturing plant. Samuel’s program was the precursor of later systems such"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "TD",
              "entity_type": "ORG",
              "start_char": 729,
              "end_char": 731,
              "context": "rogram was the precursor of later systems such as TD-G\nAMMON\n(Tesauro, 1992), which was among the worl"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "Tesauro",
              "entity_type": "PERSON",
              "start_char": 741,
              "end_char": 748,
              "context": "he precursor of later systems such as TD-G\nAMMON\n(Tesauro, 1992), which was among the world’s best backgamm"
            },
            {
              "para_id": "chap1_para136",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 836,
              "end_char": 839,
              "context": "est backgammon players, and A\nLPHA\nG\nO\n(Silver\net al.,\n2016), which shocked the world by defeating the "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para137",
          "content": "In 1958, John McCarthy made two important contributions to AI. In MIT AI Lab Memo No. 1, he defined the high-level language\nLisp\n, which was to become the dominant AI programming language for the next 30 years. In a paper entitled\nPrograms with Common Sense,\nhe advanced a conceptual proposal for AI systems based on knowledge and reasoning. The paper describes the Advice Taker, a hypothetical program that would embody general knowledge of the world and could use it to derive plans of action. The concept was illustrated with simple logical axioms that suffice to generate a plan to drive to the airport. The program was also designed to accept new axioms in the normal course of operation, thereby allowing it to achieve competence in new areas\nwithout being reprogrammed\n. The Advice Taker thus embodied the central principles of knowledge representation and reasoning: that it is useful to have a formal, explicit representation of the world and its workings and to be able to manipulate that representation with deductive processes. The paper influenced the course of AI and remains relevant today.",
          "sentence_count": 9,
          "char_count": 929,
          "prev_para_id": "chap1_para136",
          "next_para_id": "chap1_para138",
          "style_metadata": {
            "para_id": "chap1_para137",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 198,
            "sentence_count": 9
          },
          "terminology": {
            "john": 1,
            "mccarthy": 1,
            "made": 1,
            "important": 1,
            "contribution": 1,
            "mit": 1,
            "lab": 1,
            "memo": 1,
            "defined": 1,
            "high-level": 1,
            "language": 2,
            "lisp": 1,
            "become": 1,
            "dominant": 1,
            "programming": 1,
            "next": 1,
            "year": 1,
            "paper": 3,
            "entitled": 1,
            "program": 3,
            "common": 1,
            "sense": 1,
            "advanced": 1,
            "conceptual": 1,
            "proposal": 1,
            "system": 1,
            "based": 1,
            "knowledge": 3,
            "reasoning": 2,
            "describes": 1,
            "advice": 2,
            "taker": 2,
            "hypothetical": 1,
            "embody": 1,
            "general": 1,
            "world": 2,
            "use": 1,
            "derive": 1,
            "plan": 2,
            "action": 1,
            "concept": 1,
            "illustrated": 1,
            "simple": 1,
            "logical": 1,
            "axiom": 2,
            "suffice": 1,
            "generate": 1,
            "drive": 1,
            "airport": 1,
            "designed": 1,
            "new": 2,
            "normal": 1,
            "course": 2,
            "operation": 1,
            "allowing": 1,
            "achieve": 1,
            "competence": 1,
            "area": 1,
            "reprogrammed": 1,
            "embodied": 1,
            "central": 1,
            "principle": 1,
            "representation": 3,
            "useful": 1,
            "formal": 1,
            "explicit": 1,
            "working": 1,
            "able": 1,
            "manipulate": 1,
            "deductive": 1,
            "process": 1,
            "influenced": 1,
            "remains": 1,
            "relevant": 1,
            "today": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para137",
              "entity_text": "John McCarthy",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 22,
              "context": "In 1958, John McCarthy made two important contributions to AI. In MIT AI"
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 59,
              "end_char": 61,
              "context": "John McCarthy made two important contributions to AI. In MIT AI Lab Memo No. 1, he defined the high-le"
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 164,
              "end_char": 166,
              "context": " language\nLisp\n, which was to become the dominant AI programming language for the next 30 years. In a "
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "Common Sense",
              "entity_type": "PERSON",
              "start_char": 245,
              "end_char": 257,
              "context": " next 30 years. In a paper entitled\nPrograms with Common Sense,\nhe advanced a conceptual proposal for AI systems"
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 297,
              "end_char": 299,
              "context": "mmon Sense,\nhe advanced a conceptual proposal for AI systems based on knowledge and reasoning. The pap"
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "the Advice Taker",
              "entity_type": "ORG",
              "start_char": 362,
              "end_char": 378,
              "context": "d on knowledge and reasoning. The paper describes the Advice Taker, a hypothetical program that would embody general"
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "The Advice Taker",
              "entity_type": "ORG",
              "start_char": 778,
              "end_char": 794,
              "context": "petence in new areas\nwithout being reprogrammed\n. The Advice Taker thus embodied the central principles of knowledge"
            },
            {
              "para_id": "chap1_para137",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 1075,
              "end_char": 1077,
              "context": "ive processes. The paper influenced the course of AI and remains relevant today."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para138",
          "content": "1958 also marked the year that Marvin Minsky moved to MIT. His initial collaboration with McCarthy did not last, however. McCarthy stressed representation and reasoning in formal logic, whereas Minsky was more interested in getting programs to work and eventually developed an anti-logic outlook. In 1963, McCarthy started the AI lab at Stanford. His plan to use logic to build the ultimate Advice Taker was advanced by J. A. Robinson’s discovery in 1965 of the resolution method (a complete theorem-proving algorithm for first-order\nlogic; see\nChapter 9\n). Work at Stanford emphasized general-purpose methods for logical reasoning. Applications of logic included Cordell Green’s question-answering and planning systems (Green, 1969b) and the Shakey robotics project at the Stanford Research Institute (SRI). The latter project, discussed further in\nChapter 26\n, was the first to demonstrate the complete integration of logical reasoning and physical activity.",
          "sentence_count": 9,
          "char_count": 823,
          "prev_para_id": "chap1_para137",
          "next_para_id": "chap1_para139",
          "style_metadata": {
            "para_id": "chap1_para138",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 18.44,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 166,
            "sentence_count": 9
          },
          "terminology": {
            "marked": 1,
            "year": 1,
            "marvin": 1,
            "minsky": 2,
            "moved": 1,
            "mit": 1,
            "initial": 1,
            "collaboration": 1,
            "mccarthy": 3,
            "last": 1,
            "stressed": 1,
            "representation": 1,
            "reasoning": 3,
            "formal": 1,
            "logic": 3,
            "whereas": 1,
            "interested": 1,
            "getting": 1,
            "program": 1,
            "work": 2,
            "developed": 1,
            "anti-logic": 1,
            "outlook": 1,
            "started": 1,
            "lab": 1,
            "stanford": 3,
            "plan": 1,
            "use": 1,
            "build": 1,
            "ultimate": 1,
            "advice": 1,
            "taker": 1,
            "advanced": 1,
            "robinson": 1,
            "discovery": 1,
            "resolution": 1,
            "method": 2,
            "complete": 2,
            "theorem-proving": 1,
            "algorithm": 1,
            "first-order": 1,
            "see": 1,
            "chapter": 2,
            "emphasized": 1,
            "general-purpose": 1,
            "logical": 2,
            "application": 1,
            "included": 1,
            "cordell": 1,
            "green": 2,
            "question-answering": 1,
            "planning": 1,
            "system": 1,
            "shakey": 1,
            "robotics": 1,
            "project": 2,
            "research": 1,
            "institute": 1,
            "sri": 1,
            "latter": 1,
            "discussed": 1,
            "demonstrate": 1,
            "integration": 1,
            "physical": 1,
            "activity": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para138",
              "entity_text": "Marvin Minsky",
              "entity_type": "PERSON",
              "start_char": 31,
              "end_char": 44,
              "context": "1958 also marked the year that Marvin Minsky moved to MIT. His initial collaboration with McCa"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "MIT",
              "entity_type": "ORG",
              "start_char": 54,
              "end_char": 57,
              "context": " also marked the year that Marvin Minsky moved to MIT. His initial collaboration with McCarthy did not "
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 90,
              "end_char": 98,
              "context": "nsky moved to MIT. His initial collaboration with McCarthy did not last, however. McCarthy stressed represen"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 122,
              "end_char": 130,
              "context": "ollaboration with McCarthy did not last, however. McCarthy stressed representation and reasoning in formal l"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "Minsky",
              "entity_type": "PERSON",
              "start_char": 194,
              "end_char": 200,
              "context": "esentation and reasoning in formal logic, whereas Minsky was more interested in getting programs to work a"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 306,
              "end_char": 314,
              "context": "ntually developed an anti-logic outlook. In 1963, McCarthy started the AI lab at Stanford. His plan to use l"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 327,
              "end_char": 329,
              "context": "anti-logic outlook. In 1963, McCarthy started the AI lab at Stanford. His plan to use logic to build t"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "Stanford",
              "entity_type": "ORG",
              "start_char": 337,
              "end_char": 345,
              "context": " outlook. In 1963, McCarthy started the AI lab at Stanford. His plan to use logic to build the ultimate Advi"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "Advice Taker",
              "entity_type": "ORG",
              "start_char": 391,
              "end_char": 403,
              "context": "ford. His plan to use logic to build the ultimate Advice Taker was advanced by J. A. Robinson’s discovery in 196"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "J. A. Robinson’s",
              "entity_type": "PERSON",
              "start_char": 420,
              "end_char": 436,
              "context": "o build the ultimate Advice Taker was advanced by J. A. Robinson’s discovery in 1965 of the resolution method (a com"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "Stanford",
              "entity_type": "ORG",
              "start_char": 566,
              "end_char": 574,
              "context": "m for first-order\nlogic; see\nChapter 9\n). Work at Stanford emphasized general-purpose methods for logical re"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "Cordell Green’s",
              "entity_type": "ORG",
              "start_char": 664,
              "end_char": 679,
              "context": "logical reasoning. Applications of logic included Cordell Green’s question-answering and planning systems (Green, 1"
            },
            {
              "para_id": "chap1_para138",
              "entity_text": "the Stanford Research Institute",
              "entity_type": "ORG",
              "start_char": 770,
              "end_char": 801,
              "context": "(Green, 1969b) and the Shakey robotics project at the Stanford Research Institute (SRI). The latter project, discussed further in\nC"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para139",
          "content": "At MIT, Minsky supervised a series of students who chose limited problems that appeared to require intelligence to solve. These limited domains became known as\nmicroworlds\n. James Slagle’s S\nAINT\nprogram (1963) was able to solve closed-form calculus integration problems typical of first-year college courses. Tom Evans’s A\nNALOGY\nprogram (1968) solved geometric analogy problems that appear in IQ tests. Daniel Bobrow’s S\nTUDENT\nprogram (1967) solved algebra story problems, such as the following:\nIf the number of customers Tom gets is twice the square of 20 percent of the number of advertisements he runs, and the number of advertisements he runs is 45, what is the number of customers Tom gets?",
          "sentence_count": 5,
          "char_count": 596,
          "prev_para_id": "chap1_para138",
          "next_para_id": "chap1_para140",
          "style_metadata": {
            "para_id": "chap1_para139",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 5
          },
          "terminology": {
            "mit": 1,
            "minsky": 1,
            "supervised": 1,
            "series": 1,
            "student": 1,
            "chose": 1,
            "limited": 2,
            "problem": 4,
            "appeared": 1,
            "require": 1,
            "intelligence": 1,
            "solve": 2,
            "domain": 1,
            "became": 1,
            "known": 1,
            "microworlds": 1,
            "james": 1,
            "slagle": 1,
            "aint": 1,
            "program": 3,
            "able": 1,
            "closed-form": 1,
            "calculus": 1,
            "integration": 1,
            "typical": 1,
            "first-year": 1,
            "college": 1,
            "course": 1,
            "tom": 3,
            "evans": 1,
            "nalogy": 1,
            "solved": 2,
            "geometric": 1,
            "analogy": 1,
            "appear": 1,
            "test": 1,
            "daniel": 1,
            "bobrow": 1,
            "tudent": 1,
            "algebra": 1,
            "story": 1,
            "following": 1,
            "number": 4,
            "customer": 2,
            "get": 2,
            "square": 1,
            "percent": 1,
            "advertisement": 2,
            "run": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para139",
              "entity_text": "MIT",
              "entity_type": "ORG",
              "start_char": 3,
              "end_char": 6,
              "context": "At MIT, Minsky supervised a series of students who chose"
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "Minsky",
              "entity_type": "PERSON",
              "start_char": 8,
              "end_char": 14,
              "context": "At MIT, Minsky supervised a series of students who chose limited"
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "James Slagle’s S",
              "entity_type": "PERSON",
              "start_char": 174,
              "end_char": 190,
              "context": "ese limited domains became known as\nmicroworlds\n. James Slagle’s S\nAINT\nprogram (1963) was able to solve closed-form"
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "AINT",
              "entity_type": "ORG",
              "start_char": 191,
              "end_char": 195,
              "context": "ns became known as\nmicroworlds\n. James Slagle’s S\nAINT\nprogram (1963) was able to solve closed-form calc"
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "Tom Evans’s",
              "entity_type": "PERSON",
              "start_char": 310,
              "end_char": 321,
              "context": "n problems typical of first-year college courses. Tom Evans’s A\nNALOGY\nprogram (1968) solved geometric analogy "
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "NALOGY",
              "entity_type": "ORG",
              "start_char": 324,
              "end_char": 330,
              "context": "ical of first-year college courses. Tom Evans’s A\nNALOGY\nprogram (1968) solved geometric analogy problems "
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "Daniel Bobrow’s",
              "entity_type": "PERSON",
              "start_char": 405,
              "end_char": 420,
              "context": "ometric analogy problems that appear in IQ tests. Daniel Bobrow’s S\nTUDENT\nprogram (1967) solved algebra story prob"
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "Tom",
              "entity_type": "PERSON",
              "start_char": 526,
              "end_char": 529,
              "context": "such as the following:\nIf the number of customers Tom gets is twice the square of 20 percent of the num"
            },
            {
              "para_id": "chap1_para139",
              "entity_text": "Tom",
              "entity_type": "PERSON",
              "start_char": 690,
              "end_char": 693,
              "context": "ts he runs is 45, what is the number of customers Tom gets?"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para140",
          "content": "The most famous microworld is the\nblocks world\n, which consists of a set of solid blocks placed on a tabletop (or more often, a simulation of a tabletop), as shown in\nFigure 1.3\n. A typical task in this world is to rearrange the blocks in a certain way, using a robot hand that can pick up one block at a time. The blocks world was home to the vision project of David Huffman (1971), the vision and constraint-propagation work of David Waltz (1975), the learning theory of Patrick Winston (1970), the natural-language-understanding program of Terry Winograd (1972), and the planner of Scott Fahlman (1974).",
          "sentence_count": 3,
          "char_count": 505,
          "prev_para_id": "chap1_para139",
          "next_para_id": "chap1_para141",
          "style_metadata": {
            "para_id": "chap1_para140",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 127,
            "sentence_count": 3
          },
          "terminology": {
            "famous": 1,
            "microworld": 1,
            "block": 5,
            "world": 3,
            "consists": 1,
            "set": 1,
            "solid": 1,
            "placed": 1,
            "simulation": 1,
            "tabletop": 1,
            "shown": 1,
            "figure": 1,
            "typical": 1,
            "task": 1,
            "rearrange": 1,
            "certain": 1,
            "way": 1,
            "using": 1,
            "robot": 1,
            "hand": 1,
            "pick": 1,
            "time": 1,
            "home": 1,
            "vision": 2,
            "project": 1,
            "david": 2,
            "huffman": 1,
            "constraint-propagation": 1,
            "work": 1,
            "learning": 1,
            "theory": 1,
            "patrick": 1,
            "winston": 1,
            "natural-language-understanding": 1,
            "program": 1,
            "terry": 1,
            "winograd": 1,
            "planner": 1,
            "scott": 1,
            "fahlman": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para140",
              "entity_text": "David Huffman",
              "entity_type": "PERSON",
              "start_char": 362,
              "end_char": 375,
              "context": "he blocks world was home to the vision project of David Huffman (1971), the vision and constraint-propagation wor"
            },
            {
              "para_id": "chap1_para140",
              "entity_text": "David Waltz",
              "entity_type": "PERSON",
              "start_char": 430,
              "end_char": 441,
              "context": "1), the vision and constraint-propagation work of David Waltz (1975), the learning theory of Patrick Winston (1"
            },
            {
              "para_id": "chap1_para140",
              "entity_text": "Patrick Winston",
              "entity_type": "PERSON",
              "start_char": 473,
              "end_char": 488,
              "context": "ork of David Waltz (1975), the learning theory of Patrick Winston (1970), the natural-language-understanding progra"
            },
            {
              "para_id": "chap1_para140",
              "entity_text": "Terry Winograd",
              "entity_type": "PERSON",
              "start_char": 543,
              "end_char": 557,
              "context": "0), the natural-language-understanding program of Terry Winograd (1972), and the planner of Scott Fahlman (1974)."
            },
            {
              "para_id": "chap1_para140",
              "entity_text": "Scott Fahlman",
              "entity_type": "PERSON",
              "start_char": 585,
              "end_char": 598,
              "context": "gram of Terry Winograd (1972), and the planner of Scott Fahlman (1974)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para141",
          "content": "×\nFigure 1.3\nA scene from the blocks world. S\nHRDLU\n(Winograd, 1972) has just completed the command “Find a block which is taller than the one you are holding and put it in the box.”\nEarly work building on the neural networks of McCulloch and Pitts also flourished. The work of Shmuel Winograd and Jack Cowan (1963) showed how a large number of elements\ncould collectively represent an individual concept, with a corresponding increase in robustness and parallelism. Hebb’s learning methods were enhanced by Bernie Widrow (Widrow and Hoff, 1960; Widrow, 1962), who called his networks\nadalines\n, and by Frank Rosenblatt (1962) with his\nperceptrons\n. The\nperceptron convergence theorem\n(Block\net al.,\n1962) says that the learning algorithm can adjust the connection strengths of a perceptron to match any input data, provided such a match exists.",
          "sentence_count": 5,
          "char_count": 721,
          "prev_para_id": "chap1_para140",
          "next_para_id": "chap1_para142",
          "style_metadata": {
            "para_id": "chap1_para141",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [
              "perceptron"
            ],
            "formal_keywords": [],
            "word_count": 165,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "scene": 1,
            "block": 3,
            "world": 1,
            "hrdlu": 1,
            "winograd": 1,
            "completed": 1,
            "command": 1,
            "find": 1,
            "taller": 1,
            "holding": 1,
            "put": 1,
            "early": 1,
            "work": 2,
            "building": 1,
            "neural": 1,
            "network": 2,
            "mcculloch": 1,
            "pitt": 1,
            "flourished": 1,
            "shmuel": 1,
            "jack": 1,
            "cowan": 1,
            "showed": 1,
            "large": 1,
            "number": 1,
            "element": 1,
            "represent": 1,
            "individual": 1,
            "concept": 1,
            "corresponding": 1,
            "increase": 1,
            "robustness": 1,
            "parallelism": 1,
            "hebb": 1,
            "learning": 2,
            "method": 1,
            "enhanced": 1,
            "bernie": 1,
            "widrow": 3,
            "hoff": 1,
            "called": 1,
            "adalines": 1,
            "frank": 1,
            "rosenblatt": 1,
            "perceptrons": 1,
            "perceptron": 3,
            "convergence": 1,
            "theorem": 1,
            "al.": 1,
            "say": 1,
            "algorithm": 1,
            "adjust": 1,
            "connection": 1,
            "strength": 1,
            "match": 2,
            "input": 1,
            "data": 1,
            "provided": 1,
            "exists": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para141",
              "entity_text": "Winograd",
              "entity_type": "GPE",
              "start_char": 53,
              "end_char": 61,
              "context": "igure 1.3\nA scene from the blocks world. S\nHRDLU\n(Winograd, 1972) has just completed the command “Find a blo"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "McCulloch",
              "entity_type": "GPE",
              "start_char": 229,
              "end_char": 238,
              "context": "x.”\nEarly work building on the neural networks of McCulloch and Pitts also flourished. The work of Shmuel Win"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Pitts",
              "entity_type": "GPE",
              "start_char": 243,
              "end_char": 248,
              "context": " building on the neural networks of McCulloch and Pitts also flourished. The work of Shmuel Winograd and "
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Shmuel Winograd",
              "entity_type": "PERSON",
              "start_char": 278,
              "end_char": 293,
              "context": " McCulloch and Pitts also flourished. The work of Shmuel Winograd and Jack Cowan (1963) showed how a large number o"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Jack Cowan",
              "entity_type": "PERSON",
              "start_char": 298,
              "end_char": 308,
              "context": " also flourished. The work of Shmuel Winograd and Jack Cowan (1963) showed how a large number of elements\ncoul"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Bernie Widrow",
              "entity_type": "PERSON",
              "start_char": 508,
              "end_char": 521,
              "context": "llelism. Hebb’s learning methods were enhanced by Bernie Widrow (Widrow and Hoff, 1960; Widrow, 1962), who called"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Widrow",
              "entity_type": "GPE",
              "start_char": 523,
              "end_char": 529,
              "context": " learning methods were enhanced by Bernie Widrow (Widrow and Hoff, 1960; Widrow, 1962), who called his net"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Hoff",
              "entity_type": "GPE",
              "start_char": 534,
              "end_char": 538,
              "context": "ethods were enhanced by Bernie Widrow (Widrow and Hoff, 1960; Widrow, 1962), who called his networks\nada"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Widrow",
              "entity_type": "GPE",
              "start_char": 546,
              "end_char": 552,
              "context": "enhanced by Bernie Widrow (Widrow and Hoff, 1960; Widrow, 1962), who called his networks\nadalines\n, and by"
            },
            {
              "para_id": "chap1_para141",
              "entity_text": "Frank Rosenblatt",
              "entity_type": "PERSON",
              "start_char": 603,
              "end_char": 619,
              "context": " 1962), who called his networks\nadalines\n, and by Frank Rosenblatt (1962) with his\nperceptrons\n. The\nperceptron conv"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para142",
          "content": "1.3.3\nA dose of reality (1966–1973)\nFrom the beginning, AI researchers were not shy about making predictions of their coming successes. The following statement by Herbert Simon in 1957 is often quoted:\nIt is not my aim to surprise or shock you—but the simplest way I can summarize is to say that there are now in the world machines that think, that learn and that create. Moreover, their ability to do these things is going to increase rapidly until—in a visible future—the range of problems they can handle will be coextensive with the range to which the human mind has been applied.",
          "sentence_count": 3,
          "char_count": 486,
          "prev_para_id": "chap1_para141",
          "next_para_id": "chap1_para143",
          "style_metadata": {
            "para_id": "chap1_para142",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 111,
            "sentence_count": 3
          },
          "terminology": {
            "dose": 1,
            "reality": 1,
            "beginning": 1,
            "researcher": 1,
            "shy": 1,
            "making": 1,
            "prediction": 1,
            "coming": 1,
            "success": 1,
            "following": 1,
            "statement": 1,
            "herbert": 1,
            "simon": 1,
            "quoted": 1,
            "aim": 1,
            "surprise": 1,
            "shock": 1,
            "you—but": 1,
            "simplest": 1,
            "way": 1,
            "summarize": 1,
            "say": 1,
            "world": 1,
            "machine": 1,
            "think": 1,
            "learn": 1,
            "create": 1,
            "ability": 1,
            "thing": 1,
            "going": 1,
            "increase": 1,
            "until—in": 1,
            "visible": 1,
            "future—the": 1,
            "range": 2,
            "problem": 1,
            "handle": 1,
            "coextensive": 1,
            "human": 1,
            "mind": 1,
            "applied": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para142",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 163,
              "end_char": 176,
              "context": "heir coming successes. The following statement by Herbert Simon in 1957 is often quoted:\nIt is not my aim to surp"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para143",
          "content": "The term “visible future” is vague, but Simon also made more concrete predictions: that within 10 years a computer would be chess champion and a significant mathematical theorem would be proved by machine. These predictions came true (or approximately true) within 40 years rather than 10. Simon’s overconfidence was due to the promising performance of early AI systems on simple examples. In almost all cases, however, these early systems failed on more difficult problems.",
          "sentence_count": 4,
          "char_count": 401,
          "prev_para_id": "chap1_para142",
          "next_para_id": "chap1_para144",
          "style_metadata": {
            "para_id": "chap1_para143",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 21.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 87,
            "sentence_count": 4
          },
          "terminology": {
            "term": 1,
            "visible": 1,
            "future": 1,
            "vague": 1,
            "simon": 2,
            "made": 1,
            "concrete": 1,
            "prediction": 2,
            "year": 2,
            "computer": 1,
            "chess": 1,
            "champion": 1,
            "significant": 1,
            "mathematical": 1,
            "theorem": 1,
            "proved": 1,
            "machine": 1,
            "came": 1,
            "true": 2,
            "overconfidence": 1,
            "due": 1,
            "promising": 1,
            "performance": 1,
            "system": 2,
            "simple": 1,
            "example": 1,
            "case": 1,
            "failed": 1,
            "difficult": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para143",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 40,
              "end_char": 45,
              "context": "The term “visible future” is vague, but Simon also made more concrete predictions: that within "
            },
            {
              "para_id": "chap1_para143",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 290,
              "end_char": 295,
              "context": "proximately true) within 40 years rather than 10. Simon’s overconfidence was due to the promising perform"
            },
            {
              "para_id": "chap1_para143",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 359,
              "end_char": 361,
              "context": "nce was due to the promising performance of early AI systems on simple examples. In almost all cases, "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para144",
          "content": "There were two main reasons for this failure. The first was that many early AI systems were based primarily on “informed introspection” as to how humans perform a task, rather than on a careful analysis of the task, what it means to be a solution, and what an algorithm would need to do to reliably produce such solutions.",
          "sentence_count": 2,
          "char_count": 265,
          "prev_para_id": "chap1_para143",
          "next_para_id": "chap1_para145",
          "style_metadata": {
            "para_id": "chap1_para144",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.5,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 2
          },
          "terminology": {
            "main": 1,
            "reason": 1,
            "failure": 1,
            "many": 1,
            "early": 1,
            "system": 1,
            "based": 1,
            "informed": 1,
            "introspection": 1,
            "human": 1,
            "perform": 1,
            "task": 2,
            "careful": 1,
            "analysis": 1,
            "mean": 1,
            "solution": 2,
            "algorithm": 1,
            "need": 1,
            "produce": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para144",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 76,
              "end_char": 78,
              "context": "s for this failure. The first was that many early AI systems were based primarily on “informed introsp"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para145",
          "content": "The second reason for failure was a lack of appreciation of the intractability of many of the problems that AI was attempting to solve. Most of the early problem-solving systems worked by trying out different combinations of steps until the solution was found. This strategy worked initially because microworlds contained very few objects and hence very few possible actions and very short solution sequences. Before the theory of computational complexity was developed, it was widely thought that “scaling up” to larger problems was simply a matter of faster hardware and larger memories. The optimism that accompanied the development of resolution theorem proving, for example, was soon dampened when researchers failed to prove theorems involving more than a few dozen facts.",
          "sentence_count": 5,
          "char_count": 659,
          "prev_para_id": "chap1_para144",
          "next_para_id": "chap1_para146",
          "style_metadata": {
            "para_id": "chap1_para145",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 130,
            "sentence_count": 5
          },
          "terminology": {
            "second": 1,
            "reason": 1,
            "failure": 1,
            "lack": 1,
            "appreciation": 1,
            "intractability": 1,
            "many": 1,
            "problem": 2,
            "attempting": 1,
            "solve": 1,
            "early": 1,
            "problem-solving": 1,
            "system": 1,
            "worked": 2,
            "trying": 1,
            "different": 1,
            "combination": 1,
            "step": 1,
            "solution": 2,
            "found": 1,
            "strategy": 1,
            "microworlds": 1,
            "contained": 1,
            "object": 1,
            "possible": 1,
            "action": 1,
            "short": 1,
            "sequence": 1,
            "theory": 1,
            "computational": 1,
            "complexity": 1,
            "developed": 1,
            "thought": 1,
            "scaling": 1,
            "larger": 2,
            "matter": 1,
            "faster": 1,
            "hardware": 1,
            "memory": 1,
            "optimism": 1,
            "accompanied": 1,
            "development": 1,
            "resolution": 1,
            "theorem": 2,
            "proving": 1,
            "example": 1,
            "dampened": 1,
            "researcher": 1,
            "failed": 1,
            "involving": 1,
            "dozen": 1,
            "fact": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para145",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 108,
              "end_char": 110,
              "context": "f the intractability of many of the problems that AI was attempting to solve. Most of the early proble"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para146",
          "content": "The fact that a program can find a solution in principle does not mean that the program contains any of the mechanisms needed to find it in practice.",
          "sentence_count": 1,
          "char_count": 122,
          "prev_para_id": "chap1_para145",
          "next_para_id": "chap1_para147",
          "style_metadata": {
            "para_id": "chap1_para146",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "fact": 1,
            "program": 2,
            "find": 2,
            "solution": 1,
            "principle": 1,
            "mean": 1,
            "contains": 1,
            "mechanism": 1,
            "needed": 1,
            "practice": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para147",
          "content": "The illusion of unlimited computational power was not confined to problem-solving programs. Early experiments in\nmachine evolution\n(now called\ngenetic programming\n) (Friedberg, 1958; Friedberg\net al.,\n1959) were based on the undoubtedly correct belief that by making an appropriate series of small mutations to a machine-code program, one can generate a program with good performance for any particular task. The idea, then, was to try random mutations with a selection process to preserve mutations that seemed useful. Despite thousands of hours of CPU time, almost no progress was demonstrated.",
          "sentence_count": 4,
          "char_count": 513,
          "prev_para_id": "chap1_para146",
          "next_para_id": "chap1_para148",
          "style_metadata": {
            "para_id": "chap1_para147",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.019,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "illusion": 1,
            "unlimited": 1,
            "computational": 1,
            "power": 1,
            "confined": 1,
            "problem-solving": 1,
            "program": 3,
            "early": 1,
            "experiment": 1,
            "machine": 1,
            "evolution": 1,
            "called": 1,
            "genetic": 1,
            "programming": 1,
            "friedberg": 2,
            "al.": 1,
            "based": 1,
            "correct": 1,
            "belief": 1,
            "making": 1,
            "appropriate": 1,
            "series": 1,
            "small": 1,
            "mutation": 3,
            "machine-code": 1,
            "generate": 1,
            "good": 1,
            "performance": 1,
            "particular": 1,
            "task": 1,
            "idea": 1,
            "try": 1,
            "random": 1,
            "selection": 1,
            "process": 1,
            "preserve": 1,
            "seemed": 1,
            "useful": 1,
            "thousand": 1,
            "hour": 1,
            "cpu": 1,
            "time": 1,
            "progress": 1,
            "demonstrated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para147",
              "entity_text": "Friedberg",
              "entity_type": "GPE",
              "start_char": 166,
              "end_char": 175,
              "context": "hine evolution\n(now called\ngenetic programming\n) (Friedberg, 1958; Friedberg\net al.,\n1959) were based on the "
            },
            {
              "para_id": "chap1_para147",
              "entity_text": "Friedberg",
              "entity_type": "GPE",
              "start_char": 183,
              "end_char": 192,
              "context": "ow called\ngenetic programming\n) (Friedberg, 1958; Friedberg\net al.,\n1959) were based on the undoubtedly corre"
            },
            {
              "para_id": "chap1_para147",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 196,
              "end_char": 199,
              "context": "etic programming\n) (Friedberg, 1958; Friedberg\net al.,\n1959) were based on the undoubtedly correct beli"
            },
            {
              "para_id": "chap1_para147",
              "entity_text": "CPU",
              "entity_type": "ORG",
              "start_char": 550,
              "end_char": 553,
              "context": "that seemed useful. Despite thousands of hours of CPU time, almost no progress was demonstrated."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para148",
          "content": "Failure to come to grips with the “combinatorial explosion” was one of the main criticisms of AI contained in the Lighthill report (Lighthill, 1973), which formed the basis for the\ndecision by the British government to end support for AI research in all but two universities. (Oral tradition paints a somewhat different and more colorful picture, with political ambitions and personal animosities whose description is beside the point.)\nA third difficulty arose because of some fundamental limitations on the basic structures being used to generate intelligent behavior. For example, Minsky and Papert’s book\nPerceptrons\n(1969) proved that, although perceptrons (a simple form of neural network) could be shown to learn anything they were capable of representing, they could represent very little. In particular, a two-input perceptron could not be trained to recognize when its two inputs were different. Although their results did not apply to more complex, multilayer networks, research funding for neural-net research soon dwindled to almost nothing. Ironically, the new back-propagation learning algorithms that were to cause an enormous resurgence in neural-net research in the late 1980s and again in the 2010s had already been developed in other contexts in the early 1960s (Kelley, 1960; Bryson, 1962).",
          "sentence_count": 7,
          "char_count": 1117,
          "prev_para_id": "chap1_para147",
          "next_para_id": "chap1_para149",
          "style_metadata": {
            "para_id": "chap1_para148",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.29,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [
              "perceptron"
            ],
            "formal_keywords": [],
            "word_count": 233,
            "sentence_count": 7
          },
          "terminology": {
            "failure": 1,
            "come": 1,
            "grip": 1,
            "combinatorial": 1,
            "explosion": 1,
            "main": 1,
            "criticism": 1,
            "contained": 1,
            "lighthill": 2,
            "report": 1,
            "formed": 1,
            "basis": 1,
            "decision": 1,
            "british": 1,
            "government": 1,
            "end": 1,
            "support": 1,
            "research": 4,
            "university": 1,
            "oral": 1,
            "tradition": 1,
            "paint": 1,
            "different": 2,
            "colorful": 1,
            "picture": 1,
            "political": 1,
            "ambition": 1,
            "personal": 1,
            "animosity": 1,
            "description": 1,
            "point": 1,
            "third": 1,
            "difficulty": 1,
            "arose": 1,
            "fundamental": 1,
            "limitation": 1,
            "basic": 1,
            "structure": 1,
            "used": 1,
            "generate": 1,
            "intelligent": 1,
            "behavior": 1,
            "example": 1,
            "minsky": 1,
            "papert": 1,
            "book": 1,
            "perceptrons": 2,
            "proved": 1,
            "simple": 1,
            "form": 1,
            "neural": 1,
            "network": 2,
            "shown": 1,
            "learn": 1,
            "anything": 1,
            "capable": 1,
            "representing": 1,
            "represent": 1,
            "little": 1,
            "particular": 1,
            "two-input": 1,
            "perceptron": 2,
            "trained": 1,
            "recognize": 1,
            "input": 1,
            "result": 1,
            "apply": 1,
            "complex": 1,
            "multilayer": 1,
            "funding": 1,
            "neural-net": 2,
            "dwindled": 1,
            "nothing": 1,
            "new": 1,
            "back-propagation": 1,
            "learning": 1,
            "algorithm": 1,
            "cause": 1,
            "enormous": 1,
            "resurgence": 1,
            "late": 1,
            "developed": 1,
            "context": 1,
            "early": 1,
            "kelley": 1,
            "bryson": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para148",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 94,
              "end_char": 96,
              "context": "rial explosion” was one of the main criticisms of AI contained in the Lighthill report (Lighthill, 197"
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "Lighthill",
              "entity_type": "ORG",
              "start_char": 114,
              "end_char": 123,
              "context": "one of the main criticisms of AI contained in the Lighthill report (Lighthill, 1973), which formed the basis "
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 235,
              "end_char": 237,
              "context": "sion by the British government to end support for AI research in all but two universities. (Oral tradi"
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "Minsky",
              "entity_type": "PERSON",
              "start_char": 584,
              "end_char": 590,
              "context": "ed to generate intelligent behavior. For example, Minsky and Papert’s book\nPerceptrons\n(1969) proved that,"
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "Papert",
              "entity_type": "PERSON",
              "start_char": 595,
              "end_char": 601,
              "context": "ate intelligent behavior. For example, Minsky and Papert’s book\nPerceptrons\n(1969) proved that, although p"
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "multilayer networks",
              "entity_type": "ORG",
              "start_char": 960,
              "end_char": 979,
              "context": "ough their results did not apply to more complex, multilayer networks, research funding for neural-net research soon dw"
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "Kelley",
              "entity_type": "PERSON",
              "start_char": 1283,
              "end_char": 1289,
              "context": "n developed in other contexts in the early 1960s (Kelley, 1960; Bryson, 1962)."
            },
            {
              "para_id": "chap1_para148",
              "entity_text": "Bryson",
              "entity_type": "PERSON",
              "start_char": 1297,
              "end_char": 1303,
              "context": " other contexts in the early 1960s (Kelley, 1960; Bryson, 1962)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para149",
          "content": "1.3.4\nExpert systems (1969–1986)\nThe picture of problem solving that had arisen during the first decade of AI research was of a general-purpose search mechanism trying to string together elementary reasoning steps to find complete solutions. Such approaches have been called\nweak methods\nbecause, although general, they do not scale up to large or difficult problem instances. The alternative to weak methods is to use more powerful, domain-specific knowledge that allows larger reasoning steps and can more easily handle typically occurring cases in narrow areas of expertise. One might say that to solve a hard problem, you have to almost know the answer already.",
          "sentence_count": 4,
          "char_count": 566,
          "prev_para_id": "chap1_para148",
          "next_para_id": "chap1_para150",
          "style_metadata": {
            "para_id": "chap1_para149",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "expert": 1,
            "system": 1,
            "picture": 1,
            "problem": 3,
            "solving": 1,
            "arisen": 1,
            "decade": 1,
            "research": 1,
            "general-purpose": 1,
            "search": 1,
            "mechanism": 1,
            "trying": 1,
            "string": 1,
            "elementary": 1,
            "reasoning": 2,
            "step": 2,
            "find": 1,
            "complete": 1,
            "solution": 1,
            "approach": 1,
            "called": 1,
            "weak": 2,
            "method": 2,
            "general": 1,
            "scale": 1,
            "large": 1,
            "difficult": 1,
            "instance": 1,
            "alternative": 1,
            "use": 1,
            "powerful": 1,
            "domain-specific": 1,
            "knowledge": 1,
            "allows": 1,
            "larger": 1,
            "handle": 1,
            "occurring": 1,
            "case": 1,
            "narrow": 1,
            "area": 1,
            "expertise": 1,
            "say": 1,
            "solve": 1,
            "hard": 1,
            "know": 1,
            "answer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para149",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 107,
              "end_char": 109,
              "context": "olving that had arisen during the first decade of AI research was of a general-purpose search mechanis"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para150",
          "content": "The D\nENDRAL\nprogram (Buchanan\net al.,\n1969) was an early example of this approach. It was developed at Stanford, where Ed Feigenbaum (a former student of Herbert Simon), Bruce Buchanan (a philosopher turned computer scientist), and Joshua Lederberg (a Nobel laureate geneticist) teamed up to solve the problem of inferring molecular structure from the information provided by a mass spectrometer. The input to the program consists of the elementary formula of the molecule (e.g., C\n6\nH\n13\nNO\n2\n) and the mass spectrum giving the masses of the various fragments of the molecule generated when it is bombarded by an electron beam. For example, the mass spectrum might contain a peak at\nm =\n15, corresponding to the mass of a methyl (CH\n3\n) fragment.",
          "sentence_count": 4,
          "char_count": 634,
          "prev_para_id": "chap1_para149",
          "next_para_id": "chap1_para151",
          "style_metadata": {
            "para_id": "chap1_para150",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.5,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 4
          },
          "terminology": {
            "endral": 1,
            "program": 2,
            "buchanan": 2,
            "al.": 1,
            "early": 1,
            "example": 2,
            "approach": 1,
            "developed": 1,
            "stanford": 1,
            "feigenbaum": 1,
            "former": 1,
            "student": 1,
            "herbert": 1,
            "simon": 1,
            "bruce": 1,
            "philosopher": 1,
            "turned": 1,
            "computer": 1,
            "scientist": 1,
            "joshua": 1,
            "lederberg": 1,
            "nobel": 1,
            "laureate": 1,
            "geneticist": 1,
            "teamed": 1,
            "solve": 1,
            "problem": 1,
            "inferring": 1,
            "molecular": 1,
            "structure": 1,
            "information": 1,
            "provided": 1,
            "mass": 5,
            "spectrometer": 1,
            "input": 1,
            "consists": 1,
            "elementary": 1,
            "formula": 1,
            "molecule": 2,
            "e.g.": 1,
            "spectrum": 2,
            "giving": 1,
            "various": 1,
            "fragment": 2,
            "generated": 1,
            "bombarded": 1,
            "electron": 1,
            "beam": 1,
            "contain": 1,
            "peak": 1,
            "corresponding": 1,
            "methyl": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para150",
              "entity_text": "Buchanan",
              "entity_type": "PERSON",
              "start_char": 22,
              "end_char": 30,
              "context": "The D\nENDRAL\nprogram (Buchanan\net al.,\n1969) was an early example of this approa"
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 34,
              "end_char": 37,
              "context": "The D\nENDRAL\nprogram (Buchanan\net al.,\n1969) was an early example of this approach. It "
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "Stanford",
              "entity_type": "ORG",
              "start_char": 104,
              "end_char": 112,
              "context": "rly example of this approach. It was developed at Stanford, where Ed Feigenbaum (a former student of Herbert"
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "Ed Feigenbaum",
              "entity_type": "PERSON",
              "start_char": 120,
              "end_char": 133,
              "context": "his approach. It was developed at Stanford, where Ed Feigenbaum (a former student of Herbert Simon), Bruce Buchan"
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "Herbert Simon",
              "entity_type": "PERSON",
              "start_char": 155,
              "end_char": 168,
              "context": "tanford, where Ed Feigenbaum (a former student of Herbert Simon), Bruce Buchanan (a philosopher turned computer s"
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "Bruce Buchanan",
              "entity_type": "PERSON",
              "start_char": 171,
              "end_char": 185,
              "context": "d Feigenbaum (a former student of Herbert Simon), Bruce Buchanan (a philosopher turned computer scientist), and Jo"
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "Joshua Lederberg",
              "entity_type": "PERSON",
              "start_char": 233,
              "end_char": 249,
              "context": "an (a philosopher turned computer scientist), and Joshua Lederberg (a Nobel laureate geneticist) teamed up to solve "
            },
            {
              "para_id": "chap1_para150",
              "entity_text": "Nobel",
              "entity_type": "WORK_OF_ART",
              "start_char": 253,
              "end_char": 258,
              "context": "rned computer scientist), and Joshua Lederberg (a Nobel laureate geneticist) teamed up to solve the probl"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para151",
          "content": "The naive version of the program generated all possible structures consistent with the formula, and then predicted what mass spectrum would be observed for each, comparing this with the actual spectrum. As one might expect, this is intractable for even moderate-sized molecules. The D\nENDRAL\nresearchers consulted analytical chemists and found that they worked by looking for well-known patterns of peaks in the spectrum that suggested common substructures in the molecule. For example, the following rule is used to recognize a ketone (C=O) subgroup (which weighs 28):\nif\nM\nis the mass of the whole molecule and there are two peaks at\nx\n1\nand\nx\n2\nsuch that (a)\nx\n1\n+\nx\n2\n=\nM +\n28; (b)\nx\n1\n– 28 is a high peak; (c)\nx\n2\n– 28 is a high peak; and (d) At least one of\nx\n1 and\nx\n2 is high\nthen\nthere is a ketone subgroup.",
          "sentence_count": 4,
          "char_count": 692,
          "prev_para_id": "chap1_para150",
          "next_para_id": "chap1_para152",
          "style_metadata": {
            "para_id": "chap1_para151",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.0,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 180,
            "sentence_count": 4
          },
          "terminology": {
            "naive": 1,
            "version": 1,
            "program": 1,
            "generated": 1,
            "possible": 1,
            "structure": 1,
            "consistent": 1,
            "formula": 1,
            "predicted": 1,
            "mass": 2,
            "spectrum": 2,
            "observed": 1,
            "comparing": 1,
            "actual": 1,
            "expect": 1,
            "intractable": 1,
            "moderate-sized": 1,
            "molecule": 3,
            "endral": 1,
            "researcher": 1,
            "consulted": 1,
            "analytical": 1,
            "chemist": 1,
            "found": 1,
            "worked": 1,
            "looking": 1,
            "well-known": 1,
            "pattern": 1,
            "peak": 4,
            "suggested": 1,
            "common": 1,
            "substructure": 1,
            "example": 1,
            "following": 1,
            "rule": 1,
            "used": 1,
            "recognize": 1,
            "ketone": 2,
            "c=o": 1,
            "subgroup": 2,
            "weighs": 1,
            "whole": 1,
            "high": 3,
            "least": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para152",
          "content": "Recognizing that the molecule contains a particular substructure reduces the number of possible candidates enormously. According to its authors, D\nENDRAL\nwas powerful because it embodied the relevant knowledge of mass spectroscopy not in the form of first principles but\nin efficient “cookbook recipes” (Feigenbaum\net al.,\n1971). The significance of D\nENDRAL\nwas that it was the first successful\nknowledge-intensive\nsystem: its expertise derived from large numbers of special-purpose rules. In 1971, Feigenbaum and others at Stanford began the Heuristic Programming Project (HPP) to investigate the extent to which the new methodology of\nexpert systems\ncould be applied to other areas.",
          "sentence_count": 4,
          "char_count": 595,
          "prev_para_id": "chap1_para151",
          "next_para_id": "chap1_para153",
          "style_metadata": {
            "para_id": "chap1_para152",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 116,
            "sentence_count": 4
          },
          "terminology": {
            "recognizing": 1,
            "molecule": 1,
            "contains": 1,
            "particular": 1,
            "substructure": 1,
            "reduces": 1,
            "number": 2,
            "possible": 1,
            "candidate": 1,
            "according": 1,
            "author": 1,
            "endral": 2,
            "powerful": 1,
            "embodied": 1,
            "relevant": 1,
            "knowledge": 1,
            "mass": 1,
            "spectroscopy": 1,
            "form": 1,
            "first": 1,
            "principle": 1,
            "efficient": 1,
            "cookbook": 1,
            "recipe": 1,
            "feigenbaum": 2,
            "al.": 1,
            "significance": 1,
            "successful": 1,
            "knowledge-intensive": 1,
            "system": 2,
            "expertise": 1,
            "derived": 1,
            "large": 1,
            "special-purpose": 1,
            "rule": 1,
            "others": 1,
            "stanford": 1,
            "began": 1,
            "heuristic": 1,
            "programming": 1,
            "project": 1,
            "hpp": 1,
            "investigate": 1,
            "extent": 1,
            "new": 1,
            "methodology": 1,
            "expert": 1,
            "applied": 1,
            "area": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para152",
              "entity_text": "Feigenbaum",
              "entity_type": "ORG",
              "start_char": 304,
              "end_char": 314,
              "context": "t principles but\nin efficient “cookbook recipes” (Feigenbaum\net al.,\n1971). The significance of D\nENDRAL\nwas t"
            },
            {
              "para_id": "chap1_para152",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 318,
              "end_char": 321,
              "context": "ut\nin efficient “cookbook recipes” (Feigenbaum\net al.,\n1971). The significance of D\nENDRAL\nwas that it "
            },
            {
              "para_id": "chap1_para152",
              "entity_text": "Feigenbaum",
              "entity_type": "ORG",
              "start_char": 500,
              "end_char": 510,
              "context": " large numbers of special-purpose rules. In 1971, Feigenbaum and others at Stanford began the Heuristic Progra"
            },
            {
              "para_id": "chap1_para152",
              "entity_text": "Stanford",
              "entity_type": "ORG",
              "start_char": 525,
              "end_char": 533,
              "context": "-purpose rules. In 1971, Feigenbaum and others at Stanford began the Heuristic Programming Project (HPP) to "
            },
            {
              "para_id": "chap1_para152",
              "entity_text": "the Heuristic Programming Project",
              "entity_type": "ORG",
              "start_char": 540,
              "end_char": 573,
              "context": " In 1971, Feigenbaum and others at Stanford began the Heuristic Programming Project (HPP) to investigate the extent to which the new "
            },
            {
              "para_id": "chap1_para152",
              "entity_text": "HPP",
              "entity_type": "ORG",
              "start_char": 575,
              "end_char": 578,
              "context": "Stanford began the Heuristic Programming Project (HPP) to investigate the extent to which the new metho"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para153",
          "content": "The next major effort was the M\nYCIN\nsystem for diagnosing blood infections. With about 450 rules, M\nYCIN\nwas able to perform as well as some experts, and considerably better than junior doctors. It also contained two major differences from D\nENDRAL\n. First, unlike the D\nENDRAL\nrules, no general theoretical model existed from which the M\nYCIN\nrules could be deduced. They had to be acquired from extensive interviewing of experts. Second, the rules had to reflect the uncertainty associated with medical knowledge. M\nYCIN\nincorporated a calculus of uncertainty called\ncertainty factors\n(see\nChapter 13\n), which seemed (at the time) to fit well with how doctors assessed the impact of evidence on the diagnosis.",
          "sentence_count": 7,
          "char_count": 610,
          "prev_para_id": "chap1_para152",
          "next_para_id": "chap1_para154",
          "style_metadata": {
            "para_id": "chap1_para153",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.14,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 7
          },
          "terminology": {
            "next": 1,
            "major": 2,
            "effort": 1,
            "ycin": 4,
            "system": 1,
            "diagnosing": 1,
            "blood": 1,
            "infection": 1,
            "rule": 4,
            "able": 1,
            "perform": 1,
            "expert": 2,
            "junior": 1,
            "doctor": 2,
            "contained": 1,
            "difference": 1,
            "endral": 2,
            "general": 1,
            "theoretical": 1,
            "model": 1,
            "existed": 1,
            "deduced": 1,
            "acquired": 1,
            "extensive": 1,
            "interviewing": 1,
            "second": 1,
            "reflect": 1,
            "uncertainty": 2,
            "associated": 1,
            "medical": 1,
            "knowledge": 1,
            "incorporated": 1,
            "calculus": 1,
            "called": 1,
            "certainty": 1,
            "factor": 1,
            "see": 1,
            "chapter": 1,
            "seemed": 1,
            "time": 1,
            "fit": 1,
            "well": 1,
            "assessed": 1,
            "impact": 1,
            "evidence": 1,
            "diagnosis": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para153",
              "entity_text": "the M\nYCIN",
              "entity_type": "PRODUCT",
              "start_char": 26,
              "end_char": 36,
              "context": "The next major effort was the M\nYCIN\nsystem for diagnosing blood infections. With abou"
            },
            {
              "para_id": "chap1_para153",
              "entity_text": "the M\nYCIN",
              "entity_type": "PRODUCT",
              "start_char": 334,
              "end_char": 344,
              "context": ", no general theoretical model existed from which the M\nYCIN\nrules could be deduced. They had to be acquired f"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para154",
          "content": "The first successful commercial expert system, R1, began operation at the Digital Equipment Corporation (McDermott, 1982). The program helped configure orders for new computer systems; by 1986, it was saving the company an estimated $40 million a year. By 1988, DEC’s AI group had 40 expert systems deployed, with more on the way. DuPont had 100 in use and 500 in development. Nearly every major U.S. corporation had its own AI group and was either using or investigating expert systems.",
          "sentence_count": 5,
          "char_count": 408,
          "prev_para_id": "chap1_para153",
          "next_para_id": "chap1_para155",
          "style_metadata": {
            "para_id": "chap1_para154",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 97,
            "sentence_count": 5
          },
          "terminology": {
            "successful": 1,
            "commercial": 1,
            "expert": 3,
            "system": 4,
            "began": 1,
            "operation": 1,
            "digital": 1,
            "equipment": 1,
            "corporation": 2,
            "mcdermott": 1,
            "program": 1,
            "helped": 1,
            "configure": 1,
            "order": 1,
            "new": 1,
            "computer": 1,
            "saving": 1,
            "company": 1,
            "estimated": 1,
            "year": 1,
            "dec": 1,
            "group": 2,
            "deployed": 1,
            "way": 1,
            "dupont": 1,
            "use": 1,
            "development": 1,
            "major": 1,
            "u.s.": 1,
            "using": 1,
            "investigating": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para154",
              "entity_text": "the Digital Equipment Corporation",
              "entity_type": "ORG",
              "start_char": 70,
              "end_char": 103,
              "context": " commercial expert system, R1, began operation at the Digital Equipment Corporation (McDermott, 1982). The program helped configure o"
            },
            {
              "para_id": "chap1_para154",
              "entity_text": "McDermott",
              "entity_type": "PERSON",
              "start_char": 105,
              "end_char": 114,
              "context": "n operation at the Digital Equipment Corporation (McDermott, 1982). The program helped configure orders for n"
            },
            {
              "para_id": "chap1_para154",
              "entity_text": "DEC",
              "entity_type": "ORG",
              "start_char": 262,
              "end_char": 265,
              "context": "company an estimated $40 million a year. By 1988, DEC’s AI group had 40 expert systems deployed, with m"
            },
            {
              "para_id": "chap1_para154",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 268,
              "end_char": 270,
              "context": "y an estimated $40 million a year. By 1988, DEC’s AI group had 40 expert systems deployed, with more o"
            },
            {
              "para_id": "chap1_para154",
              "entity_text": "DuPont",
              "entity_type": "ORG",
              "start_char": 331,
              "end_char": 337,
              "context": "40 expert systems deployed, with more on the way. DuPont had 100 in use and 500 in development. Nearly eve"
            },
            {
              "para_id": "chap1_para154",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 396,
              "end_char": 400,
              "context": "in use and 500 in development. Nearly every major U.S. corporation had its own AI group and was either u"
            },
            {
              "para_id": "chap1_para154",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 425,
              "end_char": 427,
              "context": ". Nearly every major U.S. corporation had its own AI group and was either using or investigating exper"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para155",
          "content": "The importance of domain knowledge was also apparent in the area of natural language understanding. Despite the success of Winograd’s S\nHRDLU\nsystem, its methods did not extend to more general tasks: for problems such as ambiguity resolution it used simple rules that relied on the tiny scope of the blocks world.",
          "sentence_count": 2,
          "char_count": 264,
          "prev_para_id": "chap1_para154",
          "next_para_id": "chap1_para156",
          "style_metadata": {
            "para_id": "chap1_para155",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "importance": 1,
            "domain": 1,
            "knowledge": 1,
            "apparent": 1,
            "area": 1,
            "natural": 1,
            "language": 1,
            "understanding": 1,
            "success": 1,
            "winograd": 1,
            "hrdlu": 1,
            "system": 1,
            "method": 1,
            "extend": 1,
            "general": 1,
            "task": 1,
            "problem": 1,
            "ambiguity": 1,
            "resolution": 1,
            "used": 1,
            "simple": 1,
            "rule": 1,
            "relied": 1,
            "tiny": 1,
            "scope": 1,
            "block": 1,
            "world": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para155",
              "entity_text": "Winograd’s S\nHRDLU",
              "entity_type": "ORG",
              "start_char": 123,
              "end_char": 141,
              "context": "al language understanding. Despite the success of Winograd’s S\nHRDLU\nsystem, its methods did not extend to more genera"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para156",
          "content": "Several researchers, including Eugene Charniak at MIT and Roger Schank at Yale, suggested that robust language understanding would require general knowledge about the world and a general method for using that knowledge. (Schank went further, claiming, “There is no such thing as syntax,” which upset a lot of linguists but did serve to start a useful discussion.) Schank and his students built a series of programs (Schank and Abelson, 1977; Wilensky, 1978; Schank and Riesbeck, 1981) that all had the task of understanding natural language. The emphasis, however, was less on language\nper se\nand more on the problems of representing and reasoning with the knowledge required for language understanding.",
          "sentence_count": 4,
          "char_count": 596,
          "prev_para_id": "chap1_para155",
          "next_para_id": "chap1_para157",
          "style_metadata": {
            "para_id": "chap1_para156",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 132,
            "sentence_count": 4
          },
          "terminology": {
            "several": 1,
            "researcher": 1,
            "including": 1,
            "eugene": 1,
            "charniak": 1,
            "mit": 1,
            "roger": 1,
            "schank": 5,
            "yale": 1,
            "suggested": 1,
            "robust": 1,
            "language": 4,
            "understanding": 3,
            "require": 1,
            "general": 2,
            "knowledge": 3,
            "world": 1,
            "method": 1,
            "using": 1,
            "went": 1,
            "claiming": 1,
            "thing": 1,
            "syntax": 1,
            "upset": 1,
            "lot": 1,
            "linguist": 1,
            "serve": 1,
            "useful": 1,
            "discussion": 1,
            "student": 1,
            "built": 1,
            "series": 1,
            "program": 1,
            "abelson": 1,
            "wilensky": 1,
            "riesbeck": 1,
            "task": 1,
            "natural": 1,
            "emphasis": 1,
            "less": 1,
            "problem": 1,
            "representing": 1,
            "reasoning": 1,
            "required": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para156",
              "entity_text": "Eugene Charniak",
              "entity_type": "PERSON",
              "start_char": 31,
              "end_char": 46,
              "context": "Several researchers, including Eugene Charniak at MIT and Roger Schank at Yale, suggested that r"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "MIT",
              "entity_type": "ORG",
              "start_char": 50,
              "end_char": 53,
              "context": "Several researchers, including Eugene Charniak at MIT and Roger Schank at Yale, suggested that robust l"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Roger Schank",
              "entity_type": "PERSON",
              "start_char": 58,
              "end_char": 70,
              "context": "researchers, including Eugene Charniak at MIT and Roger Schank at Yale, suggested that robust language understan"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Yale",
              "entity_type": "ORG",
              "start_char": 74,
              "end_char": 78,
              "context": "luding Eugene Charniak at MIT and Roger Schank at Yale, suggested that robust language understanding wou"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Schank",
              "entity_type": "PRODUCT",
              "start_char": 416,
              "end_char": 422,
              "context": "hank and his students built a series of programs (Schank and Abelson, 1977; Wilensky, 1978; Schank and Rie"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Abelson",
              "entity_type": "PERSON",
              "start_char": 427,
              "end_char": 434,
              "context": "s students built a series of programs (Schank and Abelson, 1977; Wilensky, 1978; Schank and Riesbeck, 1981)"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Wilensky",
              "entity_type": "PERSON",
              "start_char": 442,
              "end_char": 450,
              "context": "t a series of programs (Schank and Abelson, 1977; Wilensky, 1978; Schank and Riesbeck, 1981) that all had th"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Schank",
              "entity_type": "PERSON",
              "start_char": 458,
              "end_char": 464,
              "context": "ograms (Schank and Abelson, 1977; Wilensky, 1978; Schank and Riesbeck, 1981) that all had the task of unde"
            },
            {
              "para_id": "chap1_para156",
              "entity_text": "Riesbeck",
              "entity_type": "PERSON",
              "start_char": 469,
              "end_char": 477,
              "context": "ank and Abelson, 1977; Wilensky, 1978; Schank and Riesbeck, 1981) that all had the task of understanding nat"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para157",
          "content": "The widespread growth of applications to real-world problems led to the development of a wide range of representation and reasoning tools. Some were based on logic—for example, the Prolog language became popular in Europe and Japan, and the P\nLANNER\nfamily in the United States. Others, following Minsky’s idea of\nframes\n(1975), adopted a more structured approach, assembling facts about particular object and event types and arranging the types into a large taxonomic hierarchy analogous to a biological taxonomy.",
          "sentence_count": 3,
          "char_count": 440,
          "prev_para_id": "chap1_para156",
          "next_para_id": "chap1_para158",
          "style_metadata": {
            "para_id": "chap1_para157",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.33,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 3
          },
          "terminology": {
            "widespread": 1,
            "growth": 1,
            "application": 1,
            "real-world": 1,
            "problem": 1,
            "led": 1,
            "development": 1,
            "wide": 1,
            "range": 1,
            "representation": 1,
            "reasoning": 1,
            "tool": 1,
            "based": 1,
            "logic—for": 1,
            "example": 1,
            "prolog": 1,
            "language": 1,
            "became": 1,
            "popular": 1,
            "europe": 1,
            "japan": 1,
            "lanner": 1,
            "family": 1,
            "united": 1,
            "state": 1,
            "others": 1,
            "following": 1,
            "minsky": 1,
            "idea": 1,
            "adopted": 1,
            "structured": 1,
            "approach": 1,
            "assembling": 1,
            "fact": 1,
            "particular": 1,
            "object": 1,
            "event": 1,
            "type": 2,
            "arranging": 1,
            "large": 1,
            "taxonomic": 1,
            "hierarchy": 1,
            "analogous": 1,
            "biological": 1,
            "taxonomy": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para157",
              "entity_text": "Japan",
              "entity_type": "GPE",
              "start_char": 226,
              "end_char": 231,
              "context": " the Prolog language became popular in Europe and Japan, and the P\nLANNER\nfamily in the United States. Ot"
            },
            {
              "para_id": "chap1_para157",
              "entity_text": "the United States",
              "entity_type": "GPE",
              "start_char": 260,
              "end_char": 277,
              "context": "r in Europe and Japan, and the P\nLANNER\nfamily in the United States. Others, following Minsky’s idea of\nframes\n(1975)"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para158",
          "content": "In 1981, the Japanese government announced the “Fifth Generation” project, a 10-year plan to build massively parallel, intelligent computers running Prolog. The budget was to exceed a $1.3 billion in today’s money. In response, the United States formed the Microelectronics and Computer Technology Corporation (MCC), a consortium designed to assure national competitiveness. In both cases, AI was part of a broad effort, including chip design and human-interface research. In Britain, the Alvey report reinstated the funding removed by the Lighthill report. However, none of these projects ever met its ambitious goals in terms of new AI capabilities or economic impact.",
          "sentence_count": 6,
          "char_count": 571,
          "prev_para_id": "chap1_para157",
          "next_para_id": "chap1_para159",
          "style_metadata": {
            "para_id": "chap1_para158",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 20.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 122,
            "sentence_count": 6
          },
          "terminology": {
            "japanese": 1,
            "government": 1,
            "announced": 1,
            "fifth": 1,
            "generation": 1,
            "project": 2,
            "10-year": 1,
            "plan": 1,
            "build": 1,
            "parallel": 1,
            "intelligent": 1,
            "computer": 2,
            "running": 1,
            "prolog": 1,
            "budget": 1,
            "exceed": 1,
            "today": 1,
            "money": 1,
            "response": 1,
            "united": 1,
            "state": 1,
            "formed": 1,
            "microelectronics": 1,
            "technology": 1,
            "corporation": 1,
            "consortium": 1,
            "designed": 1,
            "assure": 1,
            "national": 1,
            "competitiveness": 1,
            "case": 1,
            "part": 1,
            "broad": 1,
            "effort": 1,
            "including": 1,
            "chip": 1,
            "design": 1,
            "human-interface": 1,
            "research": 1,
            "britain": 1,
            "alvey": 1,
            "report": 2,
            "reinstated": 1,
            "funding": 1,
            "removed": 1,
            "lighthill": 1,
            "none": 1,
            "met": 1,
            "ambitious": 1,
            "goal": 1,
            "term": 1,
            "new": 1,
            "capability": 1,
            "economic": 1,
            "impact": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para158",
              "entity_text": "the “Fifth Generation",
              "entity_type": "ORG",
              "start_char": 43,
              "end_char": 64,
              "context": "In 1981, the Japanese government announced the “Fifth Generation” project, a 10-year plan to build massively paral"
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "the United States",
              "entity_type": "GPE",
              "start_char": 228,
              "end_char": 245,
              "context": "eed a $1.3 billion in today’s money. In response, the United States formed the Microelectronics and Computer Technolo"
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "the Microelectronics and Computer Technology Corporation",
              "entity_type": "ORG",
              "start_char": 253,
              "end_char": 309,
              "context": "ay’s money. In response, the United States formed the Microelectronics and Computer Technology Corporation (MCC), a consortium designed to assure national c"
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 390,
              "end_char": 392,
              "context": "o assure national competitiveness. In both cases, AI was part of a broad effort, including chip design"
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "Britain",
              "entity_type": "GPE",
              "start_char": 476,
              "end_char": 483,
              "context": "ding chip design and human-interface research. In Britain, the Alvey report reinstated the funding removed "
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "Alvey",
              "entity_type": "ORG",
              "start_char": 489,
              "end_char": 494,
              "context": "ign and human-interface research. In Britain, the Alvey report reinstated the funding removed by the Ligh"
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "Lighthill",
              "entity_type": "ORG",
              "start_char": 540,
              "end_char": 549,
              "context": "lvey report reinstated the funding removed by the Lighthill report. However, none of these projects ever met "
            },
            {
              "para_id": "chap1_para158",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 635,
              "end_char": 637,
              "context": "ects ever met its ambitious goals in terms of new AI capabilities or economic impact."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para159",
          "content": "Overall, the AI industry boomed from a few million dollars in 1980 to billions of dollars in 1988, including hundreds of companies building expert systems, vision systems, robots, and software and hardware specialized for these purposes.",
          "sentence_count": 1,
          "char_count": 202,
          "prev_para_id": "chap1_para158",
          "next_para_id": "chap1_para160",
          "style_metadata": {
            "para_id": "chap1_para159",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 1
          },
          "terminology": {
            "overall": 1,
            "industry": 1,
            "boomed": 1,
            "dollar": 2,
            "billion": 1,
            "including": 1,
            "hundred": 1,
            "company": 1,
            "building": 1,
            "expert": 1,
            "system": 2,
            "vision": 1,
            "robot": 1,
            "software": 1,
            "hardware": 1,
            "specialized": 1,
            "purpose": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para159",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 13,
              "end_char": 15,
              "context": "Overall, the AI industry boomed from a few million dollars in 198"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para160",
          "content": "Soon after that came a period called the “AI winter,” in which many companies fell by the wayside as they failed to deliver on extravagant promises. It turned out to be difficult to build and maintain expert systems for complex domains, in part because the reasoning methods used by the systems broke down in the face of uncertainty and in part because the systems could not learn from experience.",
          "sentence_count": 2,
          "char_count": 329,
          "prev_para_id": "chap1_para159",
          "next_para_id": "chap1_para161",
          "style_metadata": {
            "para_id": "chap1_para160",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 2
          },
          "terminology": {
            "came": 1,
            "period": 1,
            "called": 1,
            "many": 1,
            "company": 1,
            "fell": 1,
            "failed": 1,
            "deliver": 1,
            "extravagant": 1,
            "promise": 1,
            "turned": 1,
            "difficult": 1,
            "build": 1,
            "maintain": 1,
            "expert": 1,
            "system": 3,
            "complex": 1,
            "domain": 1,
            "part": 2,
            "reasoning": 1,
            "method": 1,
            "used": 1,
            "broke": 1,
            "face": 1,
            "uncertainty": 1,
            "learn": 1,
            "experience": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para160",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 42,
              "end_char": 44,
              "context": "Soon after that came a period called the “AI winter,” in which many companies fell by the ways"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para161",
          "content": "1.3.5\nThe return of neural networks (1986–present)\nIn the mid-1980s at least four different groups reinvented the\nback-propagation\nlearning algorithm first developed in the early 1960s. The algorithm was applied to many learning problems in computer science and psychology, and the widespread dissemination of the results in the collection\nParallel Distributed Processing\n(Rumelhart and McClelland, 1986) caused great excitement.",
          "sentence_count": 2,
          "char_count": 377,
          "prev_para_id": "chap1_para160",
          "next_para_id": "chap1_para162",
          "style_metadata": {
            "para_id": "chap1_para161",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.5,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 2
          },
          "terminology": {
            "return": 1,
            "neural": 1,
            "network": 1,
            "mid-1980s": 1,
            "different": 1,
            "group": 1,
            "reinvented": 1,
            "back-propagation": 1,
            "learning": 2,
            "algorithm": 2,
            "developed": 1,
            "early": 1,
            "applied": 1,
            "many": 1,
            "problem": 1,
            "computer": 1,
            "science": 1,
            "psychology": 1,
            "widespread": 1,
            "dissemination": 1,
            "result": 1,
            "collection": 1,
            "distributed": 1,
            "processing": 1,
            "rumelhart": 1,
            "mcclelland": 1,
            "caused": 1,
            "great": 1,
            "excitement": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para161",
              "entity_text": "Parallel Distributed Processing",
              "entity_type": "WORK_OF_ART",
              "start_char": 340,
              "end_char": 371,
              "context": "ad dissemination of the results in the collection\nParallel Distributed Processing\n(Rumelhart and McClelland, 1986) caused great exc"
            },
            {
              "para_id": "chap1_para161",
              "entity_text": "Rumelhart",
              "entity_type": "ORG",
              "start_char": 373,
              "end_char": 382,
              "context": "n the collection\nParallel Distributed Processing\n(Rumelhart and McClelland, 1986) caused great excitement."
            },
            {
              "para_id": "chap1_para161",
              "entity_text": "McClelland",
              "entity_type": "ORG",
              "start_char": 387,
              "end_char": 397,
              "context": "on\nParallel Distributed Processing\n(Rumelhart and McClelland, 1986) caused great excitement."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para162",
          "content": "These so-called\nconnectionist\nmodels were seen by some as direct competitors both to the symbolic models promoted by Newell and Simon and to the logicist approach of McCarthy and others. It might seem obvious that at some level humans manipulate symbols—in fact, the anthropologist Terrence Deacon’s book\nThe Symbolic Species\n(1997) suggests that this is the\ndefining characteristic\nof humans. Against this, Geoff Hinton, a leading figure in the resurgence of neural networks in the 1980s and 2010s, has described symbols as the “luminiferous aether of AI”—a reference to the non-existent medium through which many 19th-century physicists believed that electromagnetic waves propagated. Certainly, many concepts that we name in language fail, on closer inspection, to have the kind of logically defined necessary and sufficient conditions that early AI researchers hoped to capture in axiomatic form. It may be that connectionist models form internal concepts in a more fluid and imprecise way that is better suited to the messiness of the real world. They also have the capability to learn from examples—they can compare their predicted output value to the true value on a problem and modify their parameters to decrease the difference, making them more likely to perform well on future examples.",
          "sentence_count": 6,
          "char_count": 1102,
          "prev_para_id": "chap1_para161",
          "next_para_id": "chap1_para163",
          "style_metadata": {
            "para_id": "chap1_para162",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 223,
            "sentence_count": 6
          },
          "terminology": {
            "so-called": 1,
            "connectionist": 2,
            "model": 3,
            "seen": 1,
            "direct": 1,
            "competitor": 1,
            "symbolic": 2,
            "promoted": 1,
            "simon": 1,
            "logicist": 1,
            "approach": 1,
            "mccarthy": 1,
            "others": 1,
            "seem": 1,
            "obvious": 1,
            "level": 1,
            "human": 2,
            "manipulate": 1,
            "symbols—in": 1,
            "fact": 1,
            "anthropologist": 1,
            "terrence": 1,
            "deacon": 1,
            "book": 1,
            "specie": 1,
            "suggests": 1,
            "defining": 1,
            "characteristic": 1,
            "geoff": 1,
            "hinton": 1,
            "leading": 1,
            "figure": 1,
            "resurgence": 1,
            "neural": 1,
            "network": 1,
            "described": 1,
            "symbol": 1,
            "luminiferous": 1,
            "reference": 1,
            "non-existent": 1,
            "medium": 1,
            "many": 2,
            "19th-century": 1,
            "physicist": 1,
            "believed": 1,
            "electromagnetic": 1,
            "wave": 1,
            "propagated": 1,
            "concept": 2,
            "name": 1,
            "language": 1,
            "fail": 1,
            "closer": 1,
            "inspection": 1,
            "kind": 1,
            "defined": 1,
            "necessary": 1,
            "sufficient": 1,
            "condition": 1,
            "early": 1,
            "researcher": 1,
            "hoped": 1,
            "capture": 1,
            "axiomatic": 1,
            "form": 2,
            "internal": 1,
            "fluid": 1,
            "imprecise": 1,
            "way": 1,
            "suited": 1,
            "messiness": 1,
            "real": 1,
            "world": 1,
            "capability": 1,
            "learn": 1,
            "examples—they": 1,
            "compare": 1,
            "predicted": 1,
            "output": 1,
            "value": 2,
            "true": 1,
            "problem": 1,
            "modify": 1,
            "parameter": 1,
            "decrease": 1,
            "difference": 1,
            "making": 1,
            "likely": 1,
            "perform": 1,
            "future": 1,
            "example": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para162",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 123,
              "context": "mpetitors both to the symbolic models promoted by Newell and Simon and to the logicist approach of McCarth"
            },
            {
              "para_id": "chap1_para162",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 128,
              "end_char": 133,
              "context": "oth to the symbolic models promoted by Newell and Simon and to the logicist approach of McCarthy and othe"
            },
            {
              "para_id": "chap1_para162",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 166,
              "end_char": 174,
              "context": " Newell and Simon and to the logicist approach of McCarthy and others. It might seem obvious that at some le"
            },
            {
              "para_id": "chap1_para162",
              "entity_text": "Terrence Deacon",
              "entity_type": "PERSON",
              "start_char": 282,
              "end_char": 297,
              "context": "ns manipulate symbols—in fact, the anthropologist Terrence Deacon’s book\nThe Symbolic Species\n(1997) suggests that "
            },
            {
              "para_id": "chap1_para162",
              "entity_text": "The Symbolic Species",
              "entity_type": "WORK_OF_ART",
              "start_char": 305,
              "end_char": 325,
              "context": "n fact, the anthropologist Terrence Deacon’s book\nThe Symbolic Species\n(1997) suggests that this is the\ndefining charact"
            },
            {
              "para_id": "chap1_para162",
              "entity_text": "Geoff Hinton",
              "entity_type": "PERSON",
              "start_char": 408,
              "end_char": 420,
              "context": "\ndefining characteristic\nof humans. Against this, Geoff Hinton, a leading figure in the resurgence of neural net"
            },
            {
              "para_id": "chap1_para162",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 850,
              "end_char": 852,
              "context": "ed necessary and sufficient conditions that early AI researchers hoped to capture in axiomatic form. I"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para163",
          "content": "1.3.6\nProbabilistic reasoning and machine learning (1987–present)\nThe brittleness of expert systems led to a new, more scientific approach incorporating probability rather than Boolean logic, machine learning rather than hand-coding, and experimental results rather than philosophical claims.",
          "sentence_count": 1,
          "char_count": 258,
          "prev_para_id": "chap1_para162",
          "next_para_id": "chap1_para164",
          "style_metadata": {
            "para_id": "chap1_para163",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 43.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 43,
            "sentence_count": 1
          },
          "terminology": {
            "probabilistic": 1,
            "reasoning": 1,
            "machine": 2,
            "learning": 2,
            "brittleness": 1,
            "expert": 1,
            "system": 1,
            "led": 1,
            "new": 1,
            "scientific": 1,
            "approach": 1,
            "incorporating": 1,
            "probability": 1,
            "boolean": 1,
            "logic": 1,
            "hand-coding": 1,
            "experimental": 1,
            "result": 1,
            "philosophical": 1,
            "claim": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para164",
          "content": "14\nIt became more common to build on existing theories than to propose brand-new ones, to base claims on rigorous theorems or solid experimental methodology (Cohen, 1995) rather than on intuition, and to show relevance to real-world applications rather than toy examples.",
          "sentence_count": 1,
          "char_count": 231,
          "prev_para_id": "chap1_para163",
          "next_para_id": "chap1_para165",
          "style_metadata": {
            "para_id": "chap1_para164",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 48.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 1
          },
          "terminology": {
            "became": 1,
            "common": 1,
            "build": 1,
            "existing": 1,
            "theory": 1,
            "propose": 1,
            "brand-new": 1,
            "one": 1,
            "base": 1,
            "claim": 1,
            "rigorous": 1,
            "theorem": 1,
            "solid": 1,
            "experimental": 1,
            "methodology": 1,
            "cohen": 1,
            "intuition": 1,
            "show": 1,
            "relevance": 1,
            "real-world": 1,
            "application": 1,
            "toy": 1,
            "example": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para164",
              "entity_text": "Cohen",
              "entity_type": "PERSON",
              "start_char": 158,
              "end_char": 163,
              "context": "orous theorems or solid experimental methodology (Cohen, 1995) rather than on intuition, and to show rele"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para165",
          "content": "Shared benchmark problem sets became the norm for demonstrating progress, including the UC Irvine repository for machine learning data sets, the International Planning Competition\nfor planning algorithms, the LibriSpeech corpus for speech recognition, the MNIST data set for handwritten digit recognition, ImageNet and COCO for image object recognition, SQ\nU\nAD for natural language question answering, the WMT competition for machine translation, and the International SAT Competitions for Boolean satisfiability solvers.",
          "sentence_count": 1,
          "char_count": 455,
          "prev_para_id": "chap1_para164",
          "next_para_id": "chap1_para166",
          "style_metadata": {
            "para_id": "chap1_para165",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 80.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 1
          },
          "terminology": {
            "shared": 1,
            "benchmark": 1,
            "problem": 1,
            "set": 3,
            "became": 1,
            "norm": 1,
            "demonstrating": 1,
            "progress": 1,
            "including": 1,
            "irvine": 1,
            "repository": 1,
            "machine": 2,
            "learning": 1,
            "data": 2,
            "international": 2,
            "planning": 2,
            "competition": 3,
            "algorithm": 1,
            "librispeech": 1,
            "corpus": 1,
            "speech": 1,
            "recognition": 3,
            "mnist": 1,
            "handwritten": 1,
            "digit": 1,
            "imagenet": 1,
            "coco": 1,
            "image": 1,
            "object": 1,
            "natural": 1,
            "language": 1,
            "question": 1,
            "answering": 1,
            "wmt": 1,
            "translation": 1,
            "sat": 1,
            "boolean": 1,
            "satisfiability": 1,
            "solver": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para165",
              "entity_text": "UC",
              "entity_type": "GPE",
              "start_char": 88,
              "end_char": 90,
              "context": "he norm for demonstrating progress, including the UC Irvine repository for machine learning data sets,"
            },
            {
              "para_id": "chap1_para165",
              "entity_text": "Irvine",
              "entity_type": "PERSON",
              "start_char": 91,
              "end_char": 97,
              "context": "norm for demonstrating progress, including the UC Irvine repository for machine learning data sets, the In"
            },
            {
              "para_id": "chap1_para165",
              "entity_text": "the International Planning Competition",
              "entity_type": "ORG",
              "start_char": 141,
              "end_char": 179,
              "context": "Irvine repository for machine learning data sets, the International Planning Competition\nfor planning algorithms, the LibriSpeech corpus f"
            },
            {
              "para_id": "chap1_para165",
              "entity_text": "LibriSpeech",
              "entity_type": "ORG",
              "start_char": 209,
              "end_char": 220,
              "context": "Planning Competition\nfor planning algorithms, the LibriSpeech corpus for speech recognition, the MNIST data set"
            },
            {
              "para_id": "chap1_para165",
              "entity_text": "ImageNet",
              "entity_type": "ORG",
              "start_char": 306,
              "end_char": 314,
              "context": "MNIST data set for handwritten digit recognition, ImageNet and COCO for image object recognition, SQ\nU\nAD fo"
            },
            {
              "para_id": "chap1_para165",
              "entity_text": "WMT",
              "entity_type": "ORG",
              "start_char": 407,
              "end_char": 410,
              "context": "U\nAD for natural language question answering, the WMT competition for machine translation, and the Inte"
            },
            {
              "para_id": "chap1_para165",
              "entity_text": "the International SAT Competitions",
              "entity_type": "ORG",
              "start_char": 452,
              "end_char": 486,
              "context": " the WMT competition for machine translation, and the International SAT Competitions for Boolean satisfiability solvers."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para166",
          "content": "AI was founded in part as a rebellion against the limitations of existing fields like control theory and statistics, but in this period it embraced the positive results of those fields. As David McAllester (1998) put it:\nIn the early period of AI it seemed plausible that new forms of symbolic computation, e.g., frames and semantic networks, made much of classical theory obsolete. This led to a form of isolationism in which AI became largely separated from the rest of computer science. This isolationism is currently being abandoned. There is a recognition that machine learning should not be isolated from information theory, that uncertain reasoning should not be isolated from stochastic modeling, that search should not be isolated from classical optimization and control, and that automated reasoning should not be isolated from formal methods and static analysis.",
          "sentence_count": 5,
          "char_count": 738,
          "prev_para_id": "chap1_para165",
          "next_para_id": "chap1_para167",
          "style_metadata": {
            "para_id": "chap1_para166",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.4,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 152,
            "sentence_count": 5
          },
          "terminology": {
            "founded": 1,
            "part": 1,
            "rebellion": 1,
            "limitation": 1,
            "existing": 1,
            "field": 2,
            "control": 2,
            "theory": 3,
            "statistic": 1,
            "period": 2,
            "embraced": 1,
            "positive": 1,
            "result": 1,
            "david": 1,
            "mcallester": 1,
            "put": 1,
            "early": 1,
            "seemed": 1,
            "plausible": 1,
            "new": 1,
            "form": 2,
            "symbolic": 1,
            "computation": 1,
            "e.g.": 1,
            "frame": 1,
            "semantic": 1,
            "network": 1,
            "made": 1,
            "much": 1,
            "classical": 2,
            "obsolete": 1,
            "led": 1,
            "isolationism": 2,
            "became": 1,
            "separated": 1,
            "rest": 1,
            "computer": 1,
            "science": 1,
            "abandoned": 1,
            "recognition": 1,
            "machine": 1,
            "learning": 1,
            "isolated": 4,
            "information": 1,
            "uncertain": 1,
            "reasoning": 2,
            "stochastic": 1,
            "modeling": 1,
            "search": 1,
            "optimization": 1,
            "automated": 1,
            "formal": 1,
            "method": 1,
            "static": 1,
            "analysis": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para166",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 0,
              "end_char": 2,
              "context": "AI was founded in part as a rebellion against the li"
            },
            {
              "para_id": "chap1_para166",
              "entity_text": "David McAllester",
              "entity_type": "PERSON",
              "start_char": 189,
              "end_char": 205,
              "context": "embraced the positive results of those fields. As David McAllester (1998) put it:\nIn the early period of AI it seeme"
            },
            {
              "para_id": "chap1_para166",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 244,
              "end_char": 246,
              "context": " McAllester (1998) put it:\nIn the early period of AI it seemed plausible that new forms of symbolic co"
            },
            {
              "para_id": "chap1_para166",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 427,
              "end_char": 429,
              "context": "lete. This led to a form of isolationism in which AI became largely separated from the rest of compute"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para167",
          "content": "The field of speech recognition illustrates the pattern. In the 1970s, a wide variety of different architectures and approaches were tried. Many of these were rather ad hoc and fragile, and worked on only a few carefully selected examples. In the 1980s, approaches using\nhidden Markov models\n(HMMs) came to dominate the area. Two aspects of HMMs are relevant. First, they are based on a rigorous mathematical theory. This allowed speech researchers to build on several decades of mathematical results developed in other fields. Second, they are generated by a process of training on a large corpus of real speech data. This ensures that the performance is robust, and in rigorous blind tests HMMs improved their scores steadily. As a result, speech technology and the related field of handwritten character recognition made the transition to widespread industrial and consumer applications. Note that there was no scientific claim that humans use HMMs to recognize speech; rather, HMMs provided a mathematical framework for understanding and solving the problem. We will see in\nSection 1.3.8\n, however, that deep learning has rather upset this comfortable narrative.",
          "sentence_count": 12,
          "char_count": 988,
          "prev_para_id": "chap1_para166",
          "next_para_id": "chap1_para168",
          "style_metadata": {
            "para_id": "chap1_para167",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 17.25,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 207,
            "sentence_count": 12
          },
          "terminology": {
            "field": 3,
            "speech": 5,
            "recognition": 2,
            "illustrates": 1,
            "pattern": 1,
            "wide": 1,
            "variety": 1,
            "different": 1,
            "architecture": 1,
            "approach": 2,
            "tried": 1,
            "many": 1,
            "hoc": 1,
            "fragile": 1,
            "worked": 1,
            "selected": 1,
            "example": 1,
            "using": 1,
            "hidden": 1,
            "markov": 1,
            "model": 1,
            "hmms": 5,
            "came": 1,
            "dominate": 1,
            "area": 1,
            "aspect": 1,
            "relevant": 1,
            "first": 1,
            "based": 1,
            "rigorous": 2,
            "mathematical": 3,
            "theory": 1,
            "allowed": 1,
            "researcher": 1,
            "build": 1,
            "several": 1,
            "decade": 1,
            "result": 2,
            "developed": 1,
            "second": 1,
            "generated": 1,
            "process": 1,
            "training": 1,
            "large": 1,
            "corpus": 1,
            "real": 1,
            "data": 1,
            "ensures": 1,
            "performance": 1,
            "robust": 1,
            "blind": 1,
            "test": 1,
            "improved": 1,
            "score": 1,
            "technology": 1,
            "related": 1,
            "handwritten": 1,
            "character": 1,
            "made": 1,
            "transition": 1,
            "widespread": 1,
            "industrial": 1,
            "consumer": 1,
            "application": 1,
            "note": 1,
            "scientific": 1,
            "claim": 1,
            "human": 1,
            "use": 1,
            "recognize": 1,
            "provided": 1,
            "framework": 1,
            "understanding": 1,
            "solving": 1,
            "problem": 1,
            "see": 1,
            "section": 1,
            "deep": 1,
            "learning": 1,
            "upset": 1,
            "comfortable": 1,
            "narrative": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para167",
              "entity_text": "Markov",
              "entity_type": "PERSON",
              "start_char": 278,
              "end_char": 284,
              "context": "d examples. In the 1980s, approaches using\nhidden Markov models\n(HMMs) came to dominate the area. Two aspe"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para168",
          "content": "1988 was an important year for the connection between AI and other fields, including statistics, operations research, decision theory, and control theory. Judea Pearl’s (1988)\nProbabilistic Reasoning in Intelligent Systems\nled to a new acceptance of probability and decision theory in AI. Pearl’s development of\nBayesian networks\nyielded a rigorous and efficient formalism for representing uncertain knowledge as well as practical algorithms for probabilistic reasoning.",
          "sentence_count": 3,
          "char_count": 410,
          "prev_para_id": "chap1_para167",
          "next_para_id": "chap1_para169",
          "style_metadata": {
            "para_id": "chap1_para168",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "important": 1,
            "year": 1,
            "connection": 1,
            "field": 1,
            "including": 1,
            "statistic": 1,
            "operation": 1,
            "research": 1,
            "decision": 2,
            "theory": 3,
            "control": 1,
            "judea": 1,
            "probabilistic": 2,
            "reasoning": 2,
            "intelligent": 1,
            "system": 1,
            "led": 1,
            "new": 1,
            "acceptance": 1,
            "probability": 1,
            "pearl": 1,
            "development": 1,
            "bayesian": 1,
            "network": 1,
            "yielded": 1,
            "rigorous": 1,
            "efficient": 1,
            "formalism": 1,
            "representing": 1,
            "uncertain": 1,
            "knowledge": 1,
            "practical": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para168",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 54,
              "end_char": 56,
              "context": " was an important year for the connection between AI and other fields, including statistics, operation"
            },
            {
              "para_id": "chap1_para168",
              "entity_text": "Judea Pearl’s",
              "entity_type": "PERSON",
              "start_char": 155,
              "end_char": 168,
              "context": "ns research, decision theory, and control theory. Judea Pearl’s (1988)\nProbabilistic Reasoning in Intelligent Sys"
            },
            {
              "para_id": "chap1_para168",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 285,
              "end_char": 287,
              "context": " acceptance of probability and decision theory in AI. Pearl’s development of\nBayesian networks\nyielded"
            },
            {
              "para_id": "chap1_para168",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 289,
              "end_char": 294,
              "context": "eptance of probability and decision theory in AI. Pearl’s development of\nBayesian networks\nyielded a rigo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para169",
          "content": "Chapters 12\n,\n13\n,\n14\n,\n15\n, and\n18\ncover this area, in addition to more recent developments that have greatly increased the expressive power of probabilistic formalisms;\nChapter 21\ndescribes methods for learning Bayesian networks and related models from data.",
          "sentence_count": 1,
          "char_count": 229,
          "prev_para_id": "chap1_para168",
          "next_para_id": "chap1_para170",
          "style_metadata": {
            "para_id": "chap1_para169",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 46.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 1
          },
          "terminology": {
            "chapter": 2,
            "cover": 1,
            "area": 1,
            "addition": 1,
            "recent": 1,
            "development": 1,
            "increased": 1,
            "expressive": 1,
            "power": 1,
            "probabilistic": 1,
            "formalism": 1,
            "describes": 1,
            "method": 1,
            "learning": 1,
            "bayesian": 1,
            "network": 1,
            "related": 1,
            "model": 1,
            "data": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para170",
          "content": "A second major contribution in 1988 was Rich Sutton’s work connecting reinforcement learning—which had been used in Arthur Samuel’s checker-playing program in the 1950s—to the theory of Markov decision processes (MDPs) developed in the field of operations research. A flood of work followed connecting AI planning research to MDPs, and the field of reinforcement learning found applications in robotics and process control as well as acquiring deep theoretical foundations.",
          "sentence_count": 2,
          "char_count": 405,
          "prev_para_id": "chap1_para169",
          "next_para_id": "chap1_para171",
          "style_metadata": {
            "para_id": "chap1_para170",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 2
          },
          "terminology": {
            "second": 1,
            "major": 1,
            "contribution": 1,
            "rich": 1,
            "sutton": 1,
            "work": 2,
            "connecting": 2,
            "reinforcement": 2,
            "learning—which": 1,
            "used": 1,
            "samuel": 1,
            "checker-playing": 1,
            "program": 1,
            "theory": 1,
            "markov": 1,
            "decision": 1,
            "process": 2,
            "developed": 1,
            "field": 2,
            "operation": 1,
            "research": 2,
            "flood": 1,
            "followed": 1,
            "planning": 1,
            "mdps": 1,
            "learning": 1,
            "found": 1,
            "application": 1,
            "robotics": 1,
            "control": 1,
            "acquiring": 1,
            "deep": 1,
            "theoretical": 1,
            "foundation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para170",
              "entity_text": "Rich Sutton’s",
              "entity_type": "PERSON",
              "start_char": 40,
              "end_char": 53,
              "context": "A second major contribution in 1988 was Rich Sutton’s work connecting reinforcement learning—which had "
            },
            {
              "para_id": "chap1_para170",
              "entity_text": "Arthur Samuel’s",
              "entity_type": "PERSON",
              "start_char": 116,
              "end_char": 131,
              "context": "ing reinforcement learning—which had been used in Arthur Samuel’s checker-playing program in the 1950s—to the theor"
            },
            {
              "para_id": "chap1_para170",
              "entity_text": "Markov",
              "entity_type": "PERSON",
              "start_char": 186,
              "end_char": 192,
              "context": "ker-playing program in the 1950s—to the theory of Markov decision processes (MDPs) developed in the field "
            },
            {
              "para_id": "chap1_para170",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 302,
              "end_char": 304,
              "context": "ons research. A flood of work followed connecting AI planning research to MDPs, and the field of reinf"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para171",
          "content": "One consequence of AI’s newfound appreciation for data, statistical modeling, optimization, and machine learning was the gradual reunification of subfields such as computer vision, robotics, speech recognition, multiagent systems, and natural language processing that had\nbecome somewhat separate from core AI. The process of reintegration has yielded significant benefits both in terms of applications—for example, the deployment of practical robots expanded greatly during this period—and in a better theoretical understanding of the core problems of AI.",
          "sentence_count": 2,
          "char_count": 482,
          "prev_para_id": "chap1_para170",
          "next_para_id": "chap1_para172",
          "style_metadata": {
            "para_id": "chap1_para171",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 2
          },
          "terminology": {
            "consequence": 1,
            "newfound": 1,
            "appreciation": 1,
            "data": 1,
            "statistical": 1,
            "modeling": 1,
            "optimization": 1,
            "machine": 1,
            "learning": 1,
            "gradual": 1,
            "reunification": 1,
            "subfields": 1,
            "computer": 1,
            "vision": 1,
            "robotics": 1,
            "speech": 1,
            "recognition": 1,
            "multiagent": 1,
            "system": 1,
            "natural": 1,
            "language": 1,
            "processing": 1,
            "become": 1,
            "separate": 1,
            "core": 2,
            "process": 1,
            "reintegration": 1,
            "yielded": 1,
            "significant": 1,
            "benefit": 1,
            "term": 1,
            "applications—for": 1,
            "example": 1,
            "deployment": 1,
            "practical": 1,
            "robot": 1,
            "expanded": 1,
            "period—and": 1,
            "theoretical": 1,
            "understanding": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para171",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 19,
              "end_char": 21,
              "context": "One consequence of AI’s newfound appreciation for data, statistical mod"
            },
            {
              "para_id": "chap1_para171",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 307,
              "end_char": 309,
              "context": "ssing that had\nbecome somewhat separate from core AI. The process of reintegration has yielded signifi"
            },
            {
              "para_id": "chap1_para171",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 553,
              "end_char": 555,
              "context": "theoretical understanding of the core problems of AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para172",
          "content": "1.3.7\nBig data (2001–present)\nRemarkable advances in computing power and the creation of the World Wide Web have facilitated the creation of very large data sets—a phenomenon sometimes known as\nbig data\n. These data sets include trillions of words of text, billions of images, and billions of hours of speech and video, as well as vast amounts of genomic data, vehicle tracking data, clickstream data, social network data, and so on.",
          "sentence_count": 2,
          "char_count": 366,
          "prev_para_id": "chap1_para171",
          "next_para_id": "chap1_para173",
          "style_metadata": {
            "para_id": "chap1_para172",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 2
          },
          "terminology": {
            "big": 2,
            "data": 8,
            "remarkable": 1,
            "advance": 1,
            "computing": 1,
            "power": 1,
            "creation": 2,
            "world": 1,
            "wide": 1,
            "web": 1,
            "facilitated": 1,
            "large": 1,
            "sets—a": 1,
            "phenomenon": 1,
            "known": 1,
            "set": 1,
            "include": 1,
            "trillion": 1,
            "word": 1,
            "text": 1,
            "billion": 2,
            "image": 1,
            "hour": 1,
            "speech": 1,
            "vast": 1,
            "amount": 1,
            "genomic": 1,
            "vehicle": 1,
            "tracking": 1,
            "clickstream": 1,
            "social": 1,
            "network": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para172",
              "entity_text": "the World Wide Web",
              "entity_type": "EVENT",
              "start_char": 89,
              "end_char": 107,
              "context": "e advances in computing power and the creation of the World Wide Web have facilitated the creation of very large data "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para173",
          "content": "This has led to the development of learning algorithms specially designed to take advantage of very large data sets. Often, the vast majority of examples in such data sets are\nunlabeled;\nfor example, in Yarowsky’s (1995) influential work on word-sense disambiguation, occurrences of a word such as “plant” are not labeled in the data set to indicate whether they refer to flora or factory. With large enough data sets, however, suitable learning algorithms can achieve an accuracy of over 96% on the task of identifying which sense was intended in a sentence. Moreover, Banko and Brill (2001) argued that the improvement in performance obtained from increasing the size of the data set by two or three orders of magnitude outweighs any improvement that can be obtained from tweaking the algorithm.",
          "sentence_count": 4,
          "char_count": 670,
          "prev_para_id": "chap1_para172",
          "next_para_id": "chap1_para174",
          "style_metadata": {
            "para_id": "chap1_para173",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 9.0,
            "avg_sentence_length": 37.5,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover",
              "however"
            ],
            "word_count": 150,
            "sentence_count": 4
          },
          "terminology": {
            "led": 1,
            "development": 1,
            "learning": 2,
            "algorithm": 3,
            "designed": 1,
            "take": 1,
            "advantage": 1,
            "large": 2,
            "data": 5,
            "set": 5,
            "vast": 1,
            "majority": 1,
            "example": 2,
            "unlabeled": 1,
            "yarowsky": 1,
            "influential": 1,
            "work": 1,
            "word-sense": 1,
            "disambiguation": 1,
            "occurrence": 1,
            "word": 1,
            "plant": 1,
            "labeled": 1,
            "indicate": 1,
            "refer": 1,
            "flora": 1,
            "factory": 1,
            "suitable": 1,
            "achieve": 1,
            "accuracy": 1,
            "task": 1,
            "identifying": 1,
            "sense": 1,
            "intended": 1,
            "sentence": 1,
            "moreover": 1,
            "banko": 1,
            "brill": 1,
            "argued": 1,
            "improvement": 2,
            "performance": 1,
            "obtained": 2,
            "increasing": 1,
            "size": 1,
            "order": 1,
            "magnitude": 1,
            "outweighs": 1,
            "tweaking": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para173",
              "entity_text": "Yarowsky",
              "entity_type": "PERSON",
              "start_char": 203,
              "end_char": 211,
              "context": " in such data sets are\nunlabeled;\nfor example, in Yarowsky’s (1995) influential work on word-sense disambigu"
            },
            {
              "para_id": "chap1_para173",
              "entity_text": "Banko",
              "entity_type": "PERSON",
              "start_char": 570,
              "end_char": 575,
              "context": "which sense was intended in a sentence. Moreover, Banko and Brill (2001) argued that the improvement in p"
            },
            {
              "para_id": "chap1_para173",
              "entity_text": "Brill",
              "entity_type": "ORG",
              "start_char": 580,
              "end_char": 585,
              "context": "e was intended in a sentence. Moreover, Banko and Brill (2001) argued that the improvement in performance"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para174",
          "content": "A similar phenomenon seems to occur in computer vision tasks such as filling in holes in photographs—holes caused either by damage or by the removal of ex-friends. Hays and Efros (2007) developed a clever method for doing this by blending in pixels from similar images; they found that the technique worked poorly with a database of only thousands of images but crossed a threshold of quality with millions of images. Soon after, the availability of tens of millions of images in the ImageNet database (Deng\net al\n., 2009) sparked a revolution in the field of computer vision.",
          "sentence_count": 3,
          "char_count": 481,
          "prev_para_id": "chap1_para173",
          "next_para_id": "chap1_para175",
          "style_metadata": {
            "para_id": "chap1_para174",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 108,
            "sentence_count": 3
          },
          "terminology": {
            "similar": 2,
            "phenomenon": 1,
            "seems": 1,
            "occur": 1,
            "computer": 2,
            "vision": 2,
            "task": 1,
            "filling": 1,
            "hole": 1,
            "photographs—holes": 1,
            "caused": 1,
            "damage": 1,
            "removal": 1,
            "ex-friends": 1,
            "hay": 1,
            "efros": 1,
            "developed": 1,
            "clever": 1,
            "method": 1,
            "blending": 1,
            "pixel": 1,
            "image": 4,
            "found": 1,
            "technique": 1,
            "worked": 1,
            "poorly": 1,
            "database": 2,
            "thousand": 1,
            "crossed": 1,
            "threshold": 1,
            "quality": 1,
            "million": 2,
            "availability": 1,
            "ten": 1,
            "imagenet": 1,
            "deng": 1,
            "sparked": 1,
            "revolution": 1,
            "field": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para174",
              "entity_text": "Efros",
              "entity_type": "PERSON",
              "start_char": 173,
              "end_char": 178,
              "context": " damage or by the removal of ex-friends. Hays and Efros (2007) developed a clever method for doing this b"
            },
            {
              "para_id": "chap1_para174",
              "entity_text": "ImageNet",
              "entity_type": "ORG",
              "start_char": 484,
              "end_char": 492,
              "context": "availability of tens of millions of images in the ImageNet database (Deng\net al\n., 2009) sparked a revolutio"
            },
            {
              "para_id": "chap1_para174",
              "entity_text": "Deng",
              "entity_type": "PERSON",
              "start_char": 503,
              "end_char": 507,
              "context": "s of millions of images in the ImageNet database (Deng\net al\n., 2009) sparked a revolution in the field "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para175",
          "content": "The availability of big data and the shift towards machine learning helped AI recover commercial attractiveness (Havenstein, 2005; Halevy\net al\n., 2009). Big data was a crucial factor in the 2011 victory of IBM’s Watson system over human champions in the Jeopardy! quiz game, an event that had a major impact on the public’s perception of AI.",
          "sentence_count": 3,
          "char_count": 287,
          "prev_para_id": "chap1_para174",
          "next_para_id": "chap1_para176",
          "style_metadata": {
            "para_id": "chap1_para175",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 71,
            "sentence_count": 3
          },
          "terminology": {
            "availability": 1,
            "big": 2,
            "data": 2,
            "shift": 1,
            "towards": 1,
            "machine": 1,
            "learning": 1,
            "helped": 1,
            "recover": 1,
            "commercial": 1,
            "attractiveness": 1,
            "havenstein": 1,
            "halevy": 1,
            "crucial": 1,
            "factor": 1,
            "victory": 1,
            "ibm": 1,
            "watson": 1,
            "system": 1,
            "human": 1,
            "champion": 1,
            "jeopardy": 1,
            "quiz": 1,
            "game": 1,
            "event": 1,
            "major": 1,
            "impact": 1,
            "public": 1,
            "perception": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para175",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 75,
              "end_char": 77,
              "context": "ata and the shift towards machine learning helped AI recover commercial attractiveness (Havenstein, 20"
            },
            {
              "para_id": "chap1_para175",
              "entity_text": "Havenstein",
              "entity_type": "PERSON",
              "start_char": 113,
              "end_char": 123,
              "context": "ning helped AI recover commercial attractiveness (Havenstein, 2005; Halevy\net al\n., 2009). Big data was a cruc"
            },
            {
              "para_id": "chap1_para175",
              "entity_text": "IBM",
              "entity_type": "ORG",
              "start_char": 207,
              "end_char": 210,
              "context": " data was a crucial factor in the 2011 victory of IBM’s Watson system over human champions in the Jeopa"
            },
            {
              "para_id": "chap1_para175",
              "entity_text": "Jeopardy",
              "entity_type": "PRODUCT",
              "start_char": 255,
              "end_char": 263,
              "context": "f IBM’s Watson system over human champions in the Jeopardy! quiz game, an event that had a major impact on t"
            },
            {
              "para_id": "chap1_para175",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 339,
              "end_char": 341,
              "context": " had a major impact on the public’s perception of AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para176",
          "content": "1.3.8\nDeep learning (2011–present)\nThe term\ndeep learning\nrefers to machine learning using multiple layers of simple, adjustable computing elements. Experiments were carried out with such networks as far back as the 1970s, and in the form of\nconvolutional neural networks\nthey found some success in hand-written digit recognition in the 1990s (LeCun\net al.,\n1995). It was not until 2011, however, that deep learning methods really took off. This occurred first in speech recognition and then in visual object recognition.",
          "sentence_count": 4,
          "char_count": 449,
          "prev_para_id": "chap1_para175",
          "next_para_id": "chap1_para177",
          "style_metadata": {
            "para_id": "chap1_para176",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 94,
            "sentence_count": 4
          },
          "terminology": {
            "deep": 3,
            "learning": 4,
            "2011–present": 1,
            "term": 1,
            "refers": 1,
            "machine": 1,
            "using": 1,
            "multiple": 1,
            "layer": 1,
            "simple": 1,
            "adjustable": 1,
            "computing": 1,
            "element": 1,
            "experiment": 1,
            "carried": 1,
            "network": 2,
            "form": 1,
            "convolutional": 1,
            "neural": 1,
            "found": 1,
            "success": 1,
            "hand-written": 1,
            "digit": 1,
            "recognition": 3,
            "lecun": 1,
            "al.": 1,
            "method": 1,
            "took": 1,
            "occurred": 1,
            "first": 1,
            "speech": 1,
            "visual": 1,
            "object": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para176",
              "entity_text": "LeCun",
              "entity_type": "PERSON",
              "start_char": 344,
              "end_char": 349,
              "context": "s in hand-written digit recognition in the 1990s (LeCun\net al.,\n1995). It was not until 2011, however, th"
            },
            {
              "para_id": "chap1_para176",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 353,
              "end_char": 356,
              "context": "-written digit recognition in the 1990s (LeCun\net al.,\n1995). It was not until 2011, however, that deep"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para177",
          "content": "In the 2012 ImageNet competition, which required classifying images into one of a thousand categories (armadillo, bookshelf, corkscrew, etc.), a deep learning system created in Geoffrey Hinton’s group at the University of Toronto (Krizhevsky\net al.,\n2013) demonstrated a dramatic improvement over previous systems, which were based largely on handcrafted features. Since then, deep learning systems have exceeded human performance on some vision tasks (and lag behind in some other tasks). Similar gains have been reported in speech\nrecognition, machine translation, medical diagnosis, and game playing. The use of a deep network to represent the evaluation function contributed to A\nLPHA\nG\nO’S\nvictories over the leading human Go players (Silver\net al.,\n2016, 2017, 2018).",
          "sentence_count": 5,
          "char_count": 667,
          "prev_para_id": "chap1_para176",
          "next_para_id": "chap1_para178",
          "style_metadata": {
            "para_id": "chap1_para177",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.4,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 147,
            "sentence_count": 5
          },
          "terminology": {
            "imagenet": 1,
            "competition": 1,
            "required": 1,
            "classifying": 1,
            "image": 1,
            "thousand": 1,
            "category": 1,
            "armadillo": 1,
            "corkscrew": 1,
            "deep": 3,
            "learning": 2,
            "system": 3,
            "created": 1,
            "geoffrey": 1,
            "hinton": 1,
            "group": 1,
            "university": 1,
            "krizhevsky": 1,
            "al.": 2,
            "demonstrated": 1,
            "dramatic": 1,
            "improvement": 1,
            "previous": 1,
            "based": 1,
            "handcrafted": 1,
            "feature": 1,
            "exceeded": 1,
            "human": 2,
            "performance": 1,
            "vision": 1,
            "task": 2,
            "lag": 1,
            "similar": 1,
            "gain": 1,
            "reported": 1,
            "speech": 1,
            "recognition": 1,
            "machine": 1,
            "translation": 1,
            "medical": 1,
            "diagnosis": 1,
            "game": 1,
            "playing": 1,
            "use": 1,
            "network": 1,
            "represent": 1,
            "evaluation": 1,
            "function": 1,
            "contributed": 1,
            "lpha": 1,
            "victory": 1,
            "leading": 1,
            "player": 1,
            "silver": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para177",
              "entity_text": "ImageNet",
              "entity_type": "ORG",
              "start_char": 12,
              "end_char": 20,
              "context": "In the 2012 ImageNet competition, which required classifying images in"
            },
            {
              "para_id": "chap1_para177",
              "entity_text": "Geoffrey Hinton’s",
              "entity_type": "ORG",
              "start_char": 177,
              "end_char": 194,
              "context": "rkscrew, etc.), a deep learning system created in Geoffrey Hinton’s group at the University of Toronto (Krizhevsky\net"
            },
            {
              "para_id": "chap1_para177",
              "entity_text": "the University of Toronto",
              "entity_type": "ORG",
              "start_char": 204,
              "end_char": 229,
              "context": "ning system created in Geoffrey Hinton’s group at the University of Toronto (Krizhevsky\net al.,\n2013) demonstrated a dramatic"
            },
            {
              "para_id": "chap1_para177",
              "entity_text": "Krizhevsky",
              "entity_type": "PERSON",
              "start_char": 231,
              "end_char": 241,
              "context": "frey Hinton’s group at the University of Toronto (Krizhevsky\net al.,\n2013) demonstrated a dramatic improvement"
            },
            {
              "para_id": "chap1_para177",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 245,
              "end_char": 248,
              "context": "group at the University of Toronto (Krizhevsky\net al.,\n2013) demonstrated a dramatic improvement over p"
            },
            {
              "para_id": "chap1_para177",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 750,
              "end_char": 753,
              "context": "ries over the leading human Go players (Silver\net al.,\n2016, 2017, 2018)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para178",
          "content": "These remarkable successes have led to a resurgence of interest in AI among students, companies, investors, governments, the media, and the general public. It seems that every week there is news of a new AI application approaching or exceeding human performance, often accompanied by speculation of either accelerated success or a new AI winter.",
          "sentence_count": 2,
          "char_count": 292,
          "prev_para_id": "chap1_para177",
          "next_para_id": "chap1_para179",
          "style_metadata": {
            "para_id": "chap1_para178",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 2
          },
          "terminology": {
            "remarkable": 1,
            "success": 2,
            "led": 1,
            "resurgence": 1,
            "interest": 1,
            "student": 1,
            "company": 1,
            "investor": 1,
            "government": 1,
            "medium": 1,
            "general": 1,
            "public": 1,
            "seems": 1,
            "week": 1,
            "news": 1,
            "new": 2,
            "application": 1,
            "approaching": 1,
            "exceeding": 1,
            "human": 1,
            "performance": 1,
            "accompanied": 1,
            "speculation": 1,
            "accelerated": 1,
            "winter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para178",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 67,
              "end_char": 69,
              "context": "successes have led to a resurgence of interest in AI among students, companies, investors, governments"
            },
            {
              "para_id": "chap1_para178",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 204,
              "end_char": 206,
              "context": ". It seems that every week there is news of a new AI application approaching or exceeding human perfor"
            },
            {
              "para_id": "chap1_para178",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 335,
              "end_char": 337,
              "context": "peculation of either accelerated success or a new AI winter."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para179",
          "content": "Deep learning relies heavily on powerful hardware. Whereas a standard computer CPU can do 10\n9\nor 10\n10\noperations per second. a deep learning algorithm running on specialized hardware (e.g., GPU, TPU, or FPGA) might consume between 10\n14\nand 10\n17\noperations per second, mostly in the form of highly parallelized matrix and vector operations. Of course, deep learning also depends on the availability of large amounts of training data, and on a few algorithmic tricks (see\nChapter 22\n).",
          "sentence_count": 4,
          "char_count": 416,
          "prev_para_id": "chap1_para178",
          "next_para_id": "chap1_para180",
          "style_metadata": {
            "para_id": "chap1_para179",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 4
          },
          "terminology": {
            "deep": 3,
            "learning": 3,
            "relies": 1,
            "powerful": 1,
            "hardware": 2,
            "whereas": 1,
            "standard": 1,
            "computer": 1,
            "cpu": 1,
            "operation": 3,
            "second": 2,
            "algorithm": 1,
            "running": 1,
            "specialized": 1,
            "e.g.": 1,
            "gpu": 1,
            "tpu": 1,
            "fpga": 1,
            "consume": 1,
            "form": 1,
            "parallelized": 1,
            "matrix": 1,
            "vector": 1,
            "course": 1,
            "depends": 1,
            "availability": 1,
            "large": 1,
            "amount": 1,
            "training": 1,
            "data": 1,
            "algorithmic": 1,
            "trick": 1,
            "see": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para179",
              "entity_text": "CPU",
              "entity_type": "ORG",
              "start_char": 79,
              "end_char": 82,
              "context": "on powerful hardware. Whereas a standard computer CPU can do 10\n9\nor 10\n10\noperations per second. a dee"
            },
            {
              "para_id": "chap1_para179",
              "entity_text": "GPU",
              "entity_type": "ORG",
              "start_char": 192,
              "end_char": 195,
              "context": " algorithm running on specialized hardware (e.g., GPU, TPU, or FPGA) might consume between 10\n14\nand 10"
            },
            {
              "para_id": "chap1_para179",
              "entity_text": "TPU",
              "entity_type": "ORG",
              "start_char": 197,
              "end_char": 200,
              "context": "rithm running on specialized hardware (e.g., GPU, TPU, or FPGA) might consume between 10\n14\nand 10\n17\no"
            },
            {
              "para_id": "chap1_para179",
              "entity_text": "FPGA",
              "entity_type": "ORG",
              "start_char": 205,
              "end_char": 209,
              "context": "nning on specialized hardware (e.g., GPU, TPU, or FPGA) might consume between 10\n14\nand 10\n17\noperations"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para180",
          "content": "1.4 The State of the Art\n1.4 The State of the Art\nStanford University’s One Hundred Year Study on AI (also known as AI100) convenes panels of experts to provide reports on the state of the art in AI. Their 2016 report (Stone\net al.,\n2016; Grosz and Stone, 2018) concludes that “Substantial increases in the future uses of AI applications, including more self-driving cars, healthcare diagnostics and targeted treatment, and physical assistance for elder care can be expected” and that “Society is now at a crucial juncture in determining how to deploy AI-based technologies in ways that promote rather than hinder democratic values such as freedom, equality, and transparency.” AI100 also produces an\nAI Index\nat\naiindex.org\nto help track progress. Some highlights from the 2018 and 2019 reports (comparing to a year 2000 baseline unless otherwise stated):\n•\nPublications: AI papers increased 20-fold between 2010 and 2019 to about 20,000 a year. The most popular category was machine learning. (Machine learning papers in arXiv.org doubled every year from 2009 to 2017.) Computer vision and natural language processing were the next most popular.",
          "sentence_count": 6,
          "char_count": 974,
          "prev_para_id": "chap1_para179",
          "next_para_id": "chap1_para181",
          "style_metadata": {
            "para_id": "chap1_para180",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 214,
            "sentence_count": 6
          },
          "terminology": {
            "state": 3,
            "art": 3,
            "stanford": 1,
            "university": 1,
            "year": 4,
            "study": 1,
            "known": 1,
            "ai100": 2,
            "convenes": 1,
            "panel": 1,
            "expert": 1,
            "provide": 1,
            "report": 3,
            "stone": 2,
            "al.": 1,
            "grosz": 1,
            "concludes": 1,
            "substantial": 1,
            "increase": 1,
            "future": 1,
            "us": 1,
            "application": 1,
            "including": 1,
            "self-driving": 1,
            "car": 1,
            "healthcare": 1,
            "diagnostics": 1,
            "targeted": 1,
            "treatment": 1,
            "physical": 1,
            "assistance": 1,
            "elder": 1,
            "care": 1,
            "expected": 1,
            "society": 1,
            "crucial": 1,
            "juncture": 1,
            "determining": 1,
            "deploy": 1,
            "ai-based": 1,
            "technology": 1,
            "way": 1,
            "promote": 1,
            "democratic": 1,
            "value": 1,
            "freedom": 1,
            "equality": 1,
            "transparency.": 1,
            "produce": 1,
            "index": 1,
            "aiindex.org": 1,
            "help": 1,
            "track": 1,
            "progress": 1,
            "highlight": 1,
            "comparing": 1,
            "baseline": 1,
            "stated": 1,
            "publication": 1,
            "paper": 2,
            "increased": 1,
            "20-fold": 1,
            "popular": 2,
            "category": 1,
            "machine": 2,
            "learning": 2,
            "doubled": 1,
            "computer": 1,
            "vision": 1,
            "natural": 1,
            "language": 1,
            "processing": 1,
            "next": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para180",
              "entity_text": "The State of the Art\n1.4",
              "entity_type": "ORG",
              "start_char": 4,
              "end_char": 28,
              "context": "1.4 The State of the Art\n1.4 The State of the Art\nStanford University’s One Hu"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "AI100",
              "entity_type": "PRODUCT",
              "start_char": 116,
              "end_char": 121,
              "context": "ity’s One Hundred Year Study on AI (also known as AI100) convenes panels of experts to provide reports on"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 196,
              "end_char": 198,
              "context": "rts to provide reports on the state of the art in AI. Their 2016 report (Stone\net al.,\n2016; Grosz and"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 228,
              "end_char": 231,
              "context": "ate of the art in AI. Their 2016 report (Stone\net al.,\n2016; Grosz and Stone, 2018) concludes that “Sub"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "Grosz and Stone",
              "entity_type": "WORK_OF_ART",
              "start_char": 239,
              "end_char": 254,
              "context": "art in AI. Their 2016 report (Stone\net al.,\n2016; Grosz and Stone, 2018) concludes that “Substantial increases in t"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 322,
              "end_char": 324,
              "context": "that “Substantial increases in the future uses of AI applications, including more self-driving cars, h"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 552,
              "end_char": 554,
              "context": "t a crucial juncture in determining how to deploy AI-based technologies in ways that promote rather th"
            },
            {
              "para_id": "chap1_para180",
              "entity_text": "AI100",
              "entity_type": "PRODUCT",
              "start_char": 678,
              "end_char": 683,
              "context": "ues such as freedom, equality, and transparency.” AI100 also produces an\nAI Index\nat\naiindex.org\nto help "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para181",
          "content": "•\nSentiment: About 70% of news articles on AI are neutral, but articles with positive tone increased from 12% in 2016 to 30% in 2018. The most common issues are ethical: data privacy and algorithm bias.",
          "sentence_count": 2,
          "char_count": 168,
          "prev_para_id": "chap1_para180",
          "next_para_id": "chap1_para182",
          "style_metadata": {
            "para_id": "chap1_para181",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 43,
            "sentence_count": 2
          },
          "terminology": {
            "sentiment": 1,
            "news": 1,
            "article": 2,
            "neutral": 1,
            "positive": 1,
            "tone": 1,
            "increased": 1,
            "common": 1,
            "issue": 1,
            "ethical": 1,
            "data": 1,
            "privacy": 1,
            "algorithm": 1,
            "bias": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para181",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 43,
              "end_char": 45,
              "context": "•\nSentiment: About 70% of news articles on AI are neutral, but articles with positive tone incr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para182",
          "content": "•\nStudents: Course enrollment increased 5-fold in the U.S. and 16-fold internationally from a 2010 baseline. AI is the most popular specialization in Computer Science.",
          "sentence_count": 2,
          "char_count": 144,
          "prev_para_id": "chap1_para181",
          "next_para_id": "chap1_para183",
          "style_metadata": {
            "para_id": "chap1_para182",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "student": 1,
            "course": 1,
            "enrollment": 1,
            "increased": 1,
            "5-fold": 1,
            "u.s.": 1,
            "16-fold": 1,
            "baseline": 1,
            "popular": 1,
            "specialization": 1,
            "computer": 1,
            "science": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para182",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 54,
              "end_char": 58,
              "context": "udents: Course enrollment increased 5-fold in the U.S. and 16-fold internationally from a 2010 baseline."
            },
            {
              "para_id": "chap1_para182",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 109,
              "end_char": 111,
              "context": "and 16-fold internationally from a 2010 baseline. AI is the most popular specialization in Computer Sc"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para183",
          "content": "•\nDiversity: AI Professors worldwide are about 80% male, 20% female. Similar numbers hold for Ph.D. students and industry hires.",
          "sentence_count": 2,
          "char_count": 110,
          "prev_para_id": "chap1_para182",
          "next_para_id": "chap1_para184",
          "style_metadata": {
            "para_id": "chap1_para183",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 2
          },
          "terminology": {
            "diversity": 1,
            "professor": 1,
            "worldwide": 1,
            "male": 1,
            "female": 1,
            "similar": 1,
            "number": 1,
            "hold": 1,
            "ph.d.": 1,
            "student": 1,
            "industry": 1,
            "hire": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para183",
              "entity_text": "Ph.D.",
              "entity_type": "WORK_OF_ART",
              "start_char": 94,
              "end_char": 99,
              "context": "ut 80% male, 20% female. Similar numbers hold for Ph.D. students and industry hires."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para184",
          "content": "•\nConferences: Attendance at NeurIPS increased 800% since 2012 to 13,500 attendees. Other conferences are seeing annual growth of about 30%.",
          "sentence_count": 2,
          "char_count": 121,
          "prev_para_id": "chap1_para183",
          "next_para_id": "chap1_para185",
          "style_metadata": {
            "para_id": "chap1_para184",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 2
          },
          "terminology": {
            "conference": 2,
            "neurips": 1,
            "increased": 1,
            "attendee": 1,
            "seeing": 1,
            "annual": 1,
            "growth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para185",
          "content": "•\nIndustry: AI startups in the U.S. increased 20-fold to over 800.",
          "sentence_count": 1,
          "char_count": 56,
          "prev_para_id": "chap1_para184",
          "next_para_id": "chap1_para186",
          "style_metadata": {
            "para_id": "chap1_para185",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "industry": 1,
            "startup": 1,
            "u.s.": 1,
            "increased": 1,
            "20-fold": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para185",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 31,
              "end_char": 35,
              "context": "•\nIndustry: AI startups in the U.S. increased 20-fold to over 800."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para186",
          "content": "•\nInternationalization: China publishes more papers per year than the U.S. and about as many as all of Europe. However, in citation-weighted impact, U.S. authors are 50% ahead of Chinese authors. Singapore, Brazil, Australia, Canada, and India are the fastest growing countries in terms of the number of AI hires.",
          "sentence_count": 3,
          "char_count": 265,
          "prev_para_id": "chap1_para185",
          "next_para_id": "chap1_para187",
          "style_metadata": {
            "para_id": "chap1_para186",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 20.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 61,
            "sentence_count": 3
          },
          "terminology": {
            "internationalization": 1,
            "china": 1,
            "publishes": 1,
            "paper": 1,
            "year": 1,
            "many": 1,
            "europe": 1,
            "citation-weighted": 1,
            "impact": 1,
            "u.s.": 1,
            "author": 2,
            "chinese": 1,
            "singapore": 1,
            "brazil": 1,
            "canada": 1,
            "india": 1,
            "fastest": 1,
            "growing": 1,
            "country": 1,
            "term": 1,
            "number": 1,
            "hire": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para186",
              "entity_text": "China",
              "entity_type": "GPE",
              "start_char": 24,
              "end_char": 29,
              "context": "•\nInternationalization: China publishes more papers per year than the U.S. and "
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 70,
              "end_char": 74,
              "context": "on: China publishes more papers per year than the U.S. and about as many as all of Europe. However, in c"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 149,
              "end_char": 153,
              "context": " of Europe. However, in citation-weighted impact, U.S. authors are 50% ahead of Chinese authors. Singapo"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "Singapore",
              "entity_type": "GPE",
              "start_char": 196,
              "end_char": 205,
              "context": "t, U.S. authors are 50% ahead of Chinese authors. Singapore, Brazil, Australia, Canada, and India are the fas"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "Brazil",
              "entity_type": "GPE",
              "start_char": 207,
              "end_char": 213,
              "context": "hors are 50% ahead of Chinese authors. Singapore, Brazil, Australia, Canada, and India are the fastest gro"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 215,
              "end_char": 224,
              "context": " 50% ahead of Chinese authors. Singapore, Brazil, Australia, Canada, and India are the fastest growing countr"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "Canada",
              "entity_type": "GPE",
              "start_char": 226,
              "end_char": 232,
              "context": "of Chinese authors. Singapore, Brazil, Australia, Canada, and India are the fastest growing countries in t"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "India",
              "entity_type": "GPE",
              "start_char": 238,
              "end_char": 243,
              "context": "uthors. Singapore, Brazil, Australia, Canada, and India are the fastest growing countries in terms of the"
            },
            {
              "para_id": "chap1_para186",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 304,
              "end_char": 306,
              "context": "stest growing countries in terms of the number of AI hires."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para187",
          "content": "•\nVision: Error rates for object detection (as achieved in LSVRC, the Large-Scale Visual Recognition Challenge) improved from 28% in 2010 to 2% in 2017, exceeding human performance. Accuracy on open-ended visual question answering (VQA) improved from 55% to 68% since 2015, but lags behind human performance at 83%.",
          "sentence_count": 2,
          "char_count": 268,
          "prev_para_id": "chap1_para186",
          "next_para_id": "chap1_para188",
          "style_metadata": {
            "para_id": "chap1_para187",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 2
          },
          "terminology": {
            "vision": 1,
            "error": 1,
            "rate": 1,
            "object": 1,
            "detection": 1,
            "achieved": 1,
            "lsvrc": 1,
            "large-scale": 1,
            "visual": 2,
            "recognition": 1,
            "challenge": 1,
            "improved": 2,
            "exceeding": 1,
            "human": 2,
            "performance": 2,
            "accuracy": 1,
            "open-ended": 1,
            "question": 1,
            "answering": 1,
            "vqa": 1,
            "lag": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para187",
              "entity_text": "LSVRC",
              "entity_type": "GPE",
              "start_char": 59,
              "end_char": 64,
              "context": " Error rates for object detection (as achieved in LSVRC, the Large-Scale Visual Recognition Challenge) im"
            },
            {
              "para_id": "chap1_para187",
              "entity_text": "the Large-Scale Visual Recognition Challenge",
              "entity_type": "ORG",
              "start_char": 66,
              "end_char": 110,
              "context": "rates for object detection (as achieved in LSVRC, the Large-Scale Visual Recognition Challenge) improved from 28% in 2010 to 2% in 2017, exceedi"
            },
            {
              "para_id": "chap1_para187",
              "entity_text": "VQA",
              "entity_type": "ORG",
              "start_char": 232,
              "end_char": 235,
              "context": "Accuracy on open-ended visual question answering (VQA) improved from 55% to 68% since 2015, but lags be"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para188",
          "content": "•\nSpeed: Training time for the image recognition task dropped by a factor of 100 in just the past two years. The amount of computing power used in top AI applications is doubling every 3.4 months.",
          "sentence_count": 2,
          "char_count": 162,
          "prev_para_id": "chap1_para187",
          "next_para_id": "chap1_para189",
          "style_metadata": {
            "para_id": "chap1_para188",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 2
          },
          "terminology": {
            "speed": 1,
            "training": 1,
            "time": 1,
            "image": 1,
            "recognition": 1,
            "task": 1,
            "dropped": 1,
            "factor": 1,
            "year": 1,
            "computing": 1,
            "power": 1,
            "used": 1,
            "top": 1,
            "application": 1,
            "doubling": 1,
            "month": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para188",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 151,
              "end_char": 153,
              "context": " years. The amount of computing power used in top AI applications is doubling every 3.4 months."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para189",
          "content": "•\nLanguage: Accuracy on question answering, as measured by F1 score on the Stanford Question Answering Dataset (SQ\nU\nAD), increased from 60 to 95 from 2015 to 2019; on the SQ\nU\nAD 2 variant, progress was faster, going from 62 to 90 in just one year. Both scores exceed human-level performance.",
          "sentence_count": 2,
          "char_count": 246,
          "prev_para_id": "chap1_para188",
          "next_para_id": "chap1_para190",
          "style_metadata": {
            "para_id": "chap1_para189",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "language": 1,
            "accuracy": 1,
            "question": 2,
            "answering": 2,
            "measured": 1,
            "score": 2,
            "stanford": 1,
            "dataset": 1,
            "increased": 1,
            "variant": 1,
            "progress": 1,
            "going": 1,
            "year": 1,
            "exceed": 1,
            "human-level": 1,
            "performance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para189",
              "entity_text": "F1",
              "entity_type": "GPE",
              "start_char": 59,
              "end_char": 61,
              "context": "e: Accuracy on question answering, as measured by F1 score on the Stanford Question Answering Dataset "
            },
            {
              "para_id": "chap1_para189",
              "entity_text": "the Stanford Question Answering Dataset",
              "entity_type": "ORG",
              "start_char": 71,
              "end_char": 110,
              "context": "on question answering, as measured by F1 score on the Stanford Question Answering Dataset (SQ\nU\nAD), increased from 60 to 95 from 2015 to 2"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para190",
          "content": "•\nHuman benchmarks: By 2019, AI systems had reportedly met or exceeded human-level performance in chess, Go, poker, Pac-Man, Jeopardy!, ImageNet object detection, speech recognition in a limited domain, Chinese-to-English translation in a restricted domain, Quake III, Dota 2, StarCraft II, various Atari games, skin cancer detection, prostate cancer detection, protein folding, and diabetic retinopathy diagnosis.",
          "sentence_count": 1,
          "char_count": 360,
          "prev_para_id": "chap1_para189",
          "next_para_id": "chap1_para191",
          "style_metadata": {
            "para_id": "chap1_para190",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 75.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 1
          },
          "terminology": {
            "human": 1,
            "benchmark": 1,
            "system": 1,
            "met": 1,
            "exceeded": 1,
            "human-level": 1,
            "performance": 1,
            "chess": 1,
            "poker": 1,
            "pac-man": 1,
            "jeopardy": 1,
            "imagenet": 1,
            "object": 1,
            "detection": 3,
            "speech": 1,
            "recognition": 1,
            "limited": 1,
            "domain": 2,
            "chinese-to-english": 1,
            "translation": 1,
            "restricted": 1,
            "quake": 1,
            "iii": 1,
            "dota": 1,
            "starcraft": 1,
            "various": 1,
            "atari": 1,
            "game": 1,
            "skin": 1,
            "cancer": 2,
            "prostate": 1,
            "folding": 1,
            "diabetic": 1,
            "retinopathy": 1,
            "diagnosis": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para190",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 29,
              "end_char": 31,
              "context": "•\nHuman benchmarks: By 2019, AI systems had reportedly met or exceeded human-leve"
            },
            {
              "para_id": "chap1_para190",
              "entity_text": "Pac-Man",
              "entity_type": "ORG",
              "start_char": 116,
              "end_char": 123,
              "context": "eded human-level performance in chess, Go, poker, Pac-Man, Jeopardy!, ImageNet object detection, speech rec"
            },
            {
              "para_id": "chap1_para190",
              "entity_text": "ImageNet",
              "entity_type": "ORG",
              "start_char": 136,
              "end_char": 144,
              "context": "formance in chess, Go, poker, Pac-Man, Jeopardy!, ImageNet object detection, speech recognition in a limited"
            },
            {
              "para_id": "chap1_para190",
              "entity_text": "StarCraft II",
              "entity_type": "EVENT",
              "start_char": 277,
              "end_char": 289,
              "context": "lation in a restricted domain, Quake III, Dota 2, StarCraft II, various Atari games, skin cancer detection, pros"
            },
            {
              "para_id": "chap1_para190",
              "entity_text": "Atari",
              "entity_type": "ORG",
              "start_char": 299,
              "end_char": 304,
              "context": " domain, Quake III, Dota 2, StarCraft II, various Atari games, skin cancer detection, prostate cancer det"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para191",
          "content": "When (if ever) will AI systems achieve human-level performance across a broad variety of tasks? Ford (2018) interviews AI experts and finds a wide range of target years, from 2029 to 2200, with a mean of 2099. In a similar survey (Grace\net al.,\n2017) 50% of respondents thought this could happen by 2066, although 10% thought it could happen as early as 2025, and a few said “never.” The experts were also split on whether we need fundamental new breakthroughs or just refinements on current approaches. But don’t take their predictions too seriously; as Philip Tetlock (2017) demonstrates in the area of predicting world events, experts are no better than amateurs.",
          "sentence_count": 4,
          "char_count": 557,
          "prev_para_id": "chap1_para190",
          "next_para_id": "chap1_para192",
          "style_metadata": {
            "para_id": "chap1_para191",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 4
          },
          "terminology": {
            "system": 1,
            "achieve": 1,
            "human-level": 1,
            "performance": 1,
            "broad": 1,
            "variety": 1,
            "task": 1,
            "ford": 1,
            "interview": 1,
            "expert": 3,
            "find": 1,
            "wide": 1,
            "range": 1,
            "target": 1,
            "year": 1,
            "mean": 1,
            "similar": 1,
            "survey": 1,
            "grace": 1,
            "al.": 1,
            "respondent": 1,
            "thought": 2,
            "happen": 2,
            "said": 1,
            "never.": 1,
            "split": 1,
            "need": 1,
            "fundamental": 1,
            "new": 1,
            "breakthrough": 1,
            "refinement": 1,
            "current": 1,
            "approach": 1,
            "take": 1,
            "prediction": 1,
            "philip": 1,
            "tetlock": 1,
            "demonstrates": 1,
            "area": 1,
            "predicting": 1,
            "world": 1,
            "event": 1,
            "amateur": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para191",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 20,
              "end_char": 22,
              "context": "When (if ever) will AI systems achieve human-level performance across a "
            },
            {
              "para_id": "chap1_para191",
              "entity_text": "Ford",
              "entity_type": "ORG",
              "start_char": 96,
              "end_char": 100,
              "context": "evel performance across a broad variety of tasks? Ford (2018) interviews AI experts and finds a wide ran"
            },
            {
              "para_id": "chap1_para191",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 119,
              "end_char": 121,
              "context": " a broad variety of tasks? Ford (2018) interviews AI experts and finds a wide range of target years, f"
            },
            {
              "para_id": "chap1_para191",
              "entity_text": "Grace",
              "entity_type": "PERSON",
              "start_char": 231,
              "end_char": 236,
              "context": "o 2200, with a mean of 2099. In a similar survey (Grace\net al.,\n2017) 50% of respondents thought this cou"
            },
            {
              "para_id": "chap1_para191",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 240,
              "end_char": 243,
              "context": "ith a mean of 2099. In a similar survey (Grace\net al.,\n2017) 50% of respondents thought this could happ"
            },
            {
              "para_id": "chap1_para191",
              "entity_text": "Philip Tetlock",
              "entity_type": "ORG",
              "start_char": 555,
              "end_char": 569,
              "context": "ut don’t take their predictions too seriously; as Philip Tetlock (2017) demonstrates in the area of predicting wor"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para192",
          "content": "How will future AI systems operate? We can’t yet say. As detailed in this section, the field has adopted several stories about itself—first the bold idea that intelligence by a machine was even possible, then that it could be achieved by encoding expert knowledge into logic, then that probabilistic models of the world would be the main tool, and most recently that machine learning would induce models that might not be based on any well-understood theory at all. The future will reveal what model comes next.",
          "sentence_count": 4,
          "char_count": 426,
          "prev_para_id": "chap1_para191",
          "next_para_id": "chap1_para193",
          "style_metadata": {
            "para_id": "chap1_para192",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 4
          },
          "terminology": {
            "future": 2,
            "system": 1,
            "operate": 1,
            "say": 1,
            "detailed": 1,
            "section": 1,
            "field": 1,
            "adopted": 1,
            "several": 1,
            "story": 1,
            "itself—first": 1,
            "bold": 1,
            "idea": 1,
            "intelligence": 1,
            "machine": 2,
            "possible": 1,
            "achieved": 1,
            "encoding": 1,
            "expert": 1,
            "knowledge": 1,
            "probabilistic": 1,
            "model": 3,
            "world": 1,
            "main": 1,
            "tool": 1,
            "learning": 1,
            "induce": 1,
            "based": 1,
            "well-understood": 1,
            "theory": 1,
            "reveal": 1,
            "come": 1,
            "next": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para192",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 16,
              "end_char": 18,
              "context": "How will future AI systems operate? We can’t yet say. As detailed in"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para193",
          "content": "What can AI do today? Perhaps not as much as some of the more optimistic media articles might lead one to believe, but still a great deal. Here are some examples:\nRobotic vehicles\n: The history of robotic vehicles stretches back to radio-controlled cars of the 1920s, but the first demonstrations of autonomous road driving without special guides occurred in the 1980s (Kanade\net al.,\n1986; Dickmanns and Zapp, 1987). After successful demonstrations of driving on dirt roads in the 132-mile DARPA Grand Challenge in 2005 (Thrun, 2006) and on streets with traffic in the 2007 Urban Challenge, the race to develop self-driving cars began in earnest. In 2018, Waymo test vehicles passed the landmark of 10 million miles driven on public roads without a serious accident, with the human driver stepping in to take over control only once every 6,000 miles. Soon after, the company began offering a commercial robotic taxi service.",
          "sentence_count": 6,
          "char_count": 777,
          "prev_para_id": "chap1_para192",
          "next_para_id": "chap1_para194",
          "style_metadata": {
            "para_id": "chap1_para193",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 174,
            "sentence_count": 6
          },
          "terminology": {
            "today": 1,
            "optimistic": 1,
            "medium": 1,
            "article": 1,
            "lead": 1,
            "believe": 1,
            "great": 1,
            "deal": 1,
            "example": 1,
            "robotic": 3,
            "vehicle": 3,
            "history": 1,
            "stretch": 1,
            "radio-controlled": 1,
            "car": 2,
            "first": 1,
            "demonstration": 2,
            "autonomous": 1,
            "road": 3,
            "driving": 2,
            "special": 1,
            "guide": 1,
            "occurred": 1,
            "kanade": 1,
            "al.": 1,
            "dickmanns": 1,
            "zapp": 1,
            "successful": 1,
            "dirt": 1,
            "132-mile": 1,
            "darpa": 1,
            "grand": 1,
            "challenge": 2,
            "thrun": 1,
            "street": 1,
            "traffic": 1,
            "urban": 1,
            "race": 1,
            "develop": 1,
            "self-driving": 1,
            "began": 2,
            "earnest": 1,
            "waymo": 1,
            "test": 1,
            "passed": 1,
            "landmark": 1,
            "mile": 2,
            "public": 1,
            "serious": 1,
            "accident": 1,
            "human": 1,
            "driver": 1,
            "stepping": 1,
            "take": 1,
            "control": 1,
            "company": 1,
            "offering": 1,
            "commercial": 1,
            "taxi": 1,
            "service": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para193",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 380,
              "end_char": 383,
              "context": "t special guides occurred in the 1980s (Kanade\net al.,\n1986; Dickmanns and Zapp, 1987). After successfu"
            },
            {
              "para_id": "chap1_para193",
              "entity_text": "Zapp",
              "entity_type": "ORG",
              "start_char": 405,
              "end_char": 409,
              "context": " in the 1980s (Kanade\net al.,\n1986; Dickmanns and Zapp, 1987). After successful demonstrations of drivin"
            },
            {
              "para_id": "chap1_para193",
              "entity_text": "DARPA Grand Challenge",
              "entity_type": "ORG",
              "start_char": 491,
              "end_char": 512,
              "context": "trations of driving on dirt roads in the 132-mile DARPA Grand Challenge in 2005 (Thrun, 2006) and on streets with traffic"
            },
            {
              "para_id": "chap1_para193",
              "entity_text": "Thrun",
              "entity_type": "GPE",
              "start_char": 522,
              "end_char": 527,
              "context": "ds in the 132-mile DARPA Grand Challenge in 2005 (Thrun, 2006) and on streets with traffic in the 2007 Ur"
            },
            {
              "para_id": "chap1_para193",
              "entity_text": "Urban Challenge",
              "entity_type": "ORG",
              "start_char": 575,
              "end_char": 590,
              "context": "un, 2006) and on streets with traffic in the 2007 Urban Challenge, the race to develop self-driving cars began in e"
            },
            {
              "para_id": "chap1_para193",
              "entity_text": "Waymo",
              "entity_type": "WORK_OF_ART",
              "start_char": 657,
              "end_char": 662,
              "context": "elop self-driving cars began in earnest. In 2018, Waymo test vehicles passed the landmark of 10 million m"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para194",
          "content": "In the air, autonomous fixed-wing drones have been providing cross-country blood deliveries in Rwanda since 2016. Quadcopters perform remarkable aerobatic maneuvers, explore buildings while constructing 3-D maps, and self-assemble into autonomous formations.",
          "sentence_count": 2,
          "char_count": 227,
          "prev_para_id": "chap1_para193",
          "next_para_id": "chap1_para195",
          "style_metadata": {
            "para_id": "chap1_para194",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 2
          },
          "terminology": {
            "air": 1,
            "autonomous": 2,
            "fixed-wing": 1,
            "drone": 1,
            "providing": 1,
            "cross-country": 1,
            "blood": 1,
            "delivery": 1,
            "rwanda": 1,
            "quadcopters": 1,
            "perform": 1,
            "remarkable": 1,
            "aerobatic": 1,
            "maneuver": 1,
            "explore": 1,
            "building": 1,
            "constructing": 1,
            "3-d": 1,
            "map": 1,
            "self-assemble": 1,
            "formation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para194",
              "entity_text": "Rwanda",
              "entity_type": "GPE",
              "start_char": 95,
              "end_char": 101,
              "context": " been providing cross-country blood deliveries in Rwanda since 2016. Quadcopters perform remarkable aeroba"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para195",
          "content": "Legged locomotion\n: BigDog, a quadruped robot by Raibert\net al.",
          "sentence_count": 1,
          "char_count": 55,
          "prev_para_id": "chap1_para194",
          "next_para_id": "chap1_para196",
          "style_metadata": {
            "para_id": "chap1_para195",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "legged": 1,
            "locomotion": 1,
            "bigdog": 1,
            "quadruped": 1,
            "robot": 1,
            "raibert": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para195",
              "entity_text": "BigDog",
              "entity_type": "PRODUCT",
              "start_char": 20,
              "end_char": 26,
              "context": "Legged locomotion\n: BigDog, a quadruped robot by Raibert\net al."
            },
            {
              "para_id": "chap1_para195",
              "entity_text": "Raibert",
              "entity_type": "PERSON",
              "start_char": 49,
              "end_char": 56,
              "context": "Legged locomotion\n: BigDog, a quadruped robot by Raibert\net al."
            },
            {
              "para_id": "chap1_para195",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 60,
              "end_char": 62,
              "context": "omotion\n: BigDog, a quadruped robot by Raibert\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para196",
          "content": "(2008), upended our notions of how robots move—no longer the slow, stiff-legged, side-to-side gait of Hollywood movie robots, but something closely resembling an animal and able to recover when shoved or when slipping on an icy puddle. Atlas, a humanoid robot, not only walks on uneven terrain but jumps onto boxes and does backflips (Ackerman and Guizzo, 2016).",
          "sentence_count": 2,
          "char_count": 305,
          "prev_para_id": "chap1_para195",
          "next_para_id": "chap1_para197",
          "style_metadata": {
            "para_id": "chap1_para196",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 71,
            "sentence_count": 2
          },
          "terminology": {
            "upended": 1,
            "notion": 1,
            "robot": 3,
            "slow": 1,
            "stiff-legged": 1,
            "side-to-side": 1,
            "gait": 1,
            "hollywood": 1,
            "movie": 1,
            "something": 1,
            "resembling": 1,
            "animal": 1,
            "able": 1,
            "recover": 1,
            "shoved": 1,
            "slipping": 1,
            "icy": 1,
            "puddle": 1,
            "atlas": 1,
            "humanoid": 1,
            "walk": 1,
            "terrain": 1,
            "jump": 1,
            "box": 1,
            "backflips": 1,
            "ackerman": 1,
            "guizzo": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para196",
              "entity_text": "Hollywood",
              "entity_type": "GPE",
              "start_char": 102,
              "end_char": 111,
              "context": "nger the slow, stiff-legged, side-to-side gait of Hollywood movie robots, but something closely resembling an"
            },
            {
              "para_id": "chap1_para196",
              "entity_text": "Atlas",
              "entity_type": "PERSON",
              "start_char": 236,
              "end_char": 241,
              "context": "er when shoved or when slipping on an icy puddle. Atlas, a humanoid robot, not only walks on uneven terra"
            },
            {
              "para_id": "chap1_para196",
              "entity_text": "Ackerman",
              "entity_type": "PERSON",
              "start_char": 335,
              "end_char": 343,
              "context": " terrain but jumps onto boxes and does backflips (Ackerman and Guizzo, 2016)."
            },
            {
              "para_id": "chap1_para196",
              "entity_text": "Guizzo",
              "entity_type": "PERSON",
              "start_char": 348,
              "end_char": 354,
              "context": "jumps onto boxes and does backflips (Ackerman and Guizzo, 2016)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para197",
          "content": "Autonomous planning and scheduling\n: A hundred million miles from Earth, NASA’s Remote Agent program became the first on-board autonomous planning program to control the scheduling of operations for a spacecraft (Jonsson\net al.,\n2000). Remote Agent generated plans from high-level goals specified from the ground and monitored the execution of those plans—detecting, diagnosing, and recovering from problems as they occurred. Today, the E\nUROPA\nplanning toolkit (Barreiro\net al.,\n2012) is used for daily operations of NASA’s Mars rovers and the S\nEXTANT\nsystem (Winternitz, 2017) allows autonomous navigation in deep space, beyond the global GPS system.",
          "sentence_count": 3,
          "char_count": 565,
          "prev_para_id": "chap1_para196",
          "next_para_id": "chap1_para198",
          "style_metadata": {
            "para_id": "chap1_para197",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.67,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 119,
            "sentence_count": 3
          },
          "terminology": {
            "autonomous": 3,
            "planning": 3,
            "scheduling": 2,
            "mile": 1,
            "nasa": 2,
            "remote": 2,
            "agent": 2,
            "program": 2,
            "became": 1,
            "first": 1,
            "control": 1,
            "operation": 2,
            "spacecraft": 1,
            "jonsson": 1,
            "al.": 2,
            "generated": 1,
            "plan": 1,
            "high-level": 1,
            "goal": 1,
            "specified": 1,
            "ground": 1,
            "monitored": 1,
            "execution": 1,
            "plans—detecting": 1,
            "diagnosing": 1,
            "recovering": 1,
            "problem": 1,
            "occurred": 1,
            "today": 1,
            "toolkit": 1,
            "barreiro": 1,
            "used": 1,
            "daily": 1,
            "mar": 1,
            "rover": 1,
            "extant": 1,
            "system": 2,
            "winternitz": 1,
            "allows": 1,
            "navigation": 1,
            "deep": 1,
            "space": 1,
            "global": 1,
            "gps": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para197",
              "entity_text": "NASA",
              "entity_type": "ORG",
              "start_char": 73,
              "end_char": 77,
              "context": " scheduling\n: A hundred million miles from Earth, NASA’s Remote Agent program became the first on-board "
            },
            {
              "para_id": "chap1_para197",
              "entity_text": "Jonsson",
              "entity_type": "PERSON",
              "start_char": 213,
              "end_char": 220,
              "context": "ol the scheduling of operations for a spacecraft (Jonsson\net al.,\n2000). Remote Agent generated plans from "
            },
            {
              "para_id": "chap1_para197",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 224,
              "end_char": 227,
              "context": "duling of operations for a spacecraft (Jonsson\net al.,\n2000). Remote Agent generated plans from high-le"
            },
            {
              "para_id": "chap1_para197",
              "entity_text": "Barreiro",
              "entity_type": "PERSON",
              "start_char": 463,
              "end_char": 471,
              "context": "ey occurred. Today, the E\nUROPA\nplanning toolkit (Barreiro\net al.,\n2012) is used for daily operations of NAS"
            },
            {
              "para_id": "chap1_para197",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 475,
              "end_char": 478,
              "context": " Today, the E\nUROPA\nplanning toolkit (Barreiro\net al.,\n2012) is used for daily operations of NASA’s Mar"
            },
            {
              "para_id": "chap1_para197",
              "entity_text": "NASA",
              "entity_type": "ORG",
              "start_char": 518,
              "end_char": 522,
              "context": "iro\net al.,\n2012) is used for daily operations of NASA’s Mars rovers and the S\nEXTANT\nsystem (Winternitz"
            },
            {
              "para_id": "chap1_para197",
              "entity_text": "Winternitz",
              "entity_type": "ORG",
              "start_char": 562,
              "end_char": 572,
              "context": "ns of NASA’s Mars rovers and the S\nEXTANT\nsystem (Winternitz, 2017) allows autonomous navigation in deep space"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para198",
          "content": "During the Persian Gulf crisis of 1991, U.S. forces deployed a Dynamic Analysis and Replanning Tool, D\nART\n(Cross and Walker, 1994), to do automated logistics planning and scheduling for transportation. This involved up to 50,000 vehicles, cargo, and people at a time, and had to account for starting points, destinations, routes, transport capacities, port and airfield capacities, and conflict resolution among all parameters. The Defense Advanced Research Project Agency (DARPA) stated that this single application more than paid back DARPA’s 30-year investment in AI.",
          "sentence_count": 3,
          "char_count": 489,
          "prev_para_id": "chap1_para197",
          "next_para_id": "chap1_para199",
          "style_metadata": {
            "para_id": "chap1_para198",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 3
          },
          "terminology": {
            "persian": 1,
            "gulf": 1,
            "crisis": 1,
            "u.s.": 1,
            "force": 1,
            "deployed": 1,
            "dynamic": 1,
            "analysis": 1,
            "replanning": 1,
            "tool": 1,
            "art": 1,
            "cross": 1,
            "walker": 1,
            "automated": 1,
            "logistics": 1,
            "planning": 1,
            "scheduling": 1,
            "transportation": 1,
            "involved": 1,
            "vehicle": 1,
            "cargo": 1,
            "people": 1,
            "time": 1,
            "account": 1,
            "starting": 1,
            "point": 1,
            "destination": 1,
            "route": 1,
            "transport": 1,
            "capacity": 2,
            "port": 1,
            "airfield": 1,
            "conflict": 1,
            "resolution": 1,
            "parameter": 1,
            "defense": 1,
            "advanced": 1,
            "research": 1,
            "project": 1,
            "agency": 1,
            "stated": 1,
            "single": 1,
            "application": 1,
            "paid": 1,
            "darpa": 1,
            "30-year": 1,
            "investment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para198",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 40,
              "end_char": 44,
              "context": "During the Persian Gulf crisis of 1991, U.S. forces deployed a Dynamic Analysis and Replanning"
            },
            {
              "para_id": "chap1_para198",
              "entity_text": "Walker",
              "entity_type": "ORG",
              "start_char": 118,
              "end_char": 124,
              "context": "ic Analysis and Replanning Tool, D\nART\n(Cross and Walker, 1994), to do automated logistics planning and sc"
            },
            {
              "para_id": "chap1_para198",
              "entity_text": "The Defense Advanced Research Project Agency",
              "entity_type": "ORG",
              "start_char": 429,
              "end_char": 473,
              "context": "es, and conflict resolution among all parameters. The Defense Advanced Research Project Agency (DARPA) stated that this single application more "
            },
            {
              "para_id": "chap1_para198",
              "entity_text": "DARPA",
              "entity_type": "ORG",
              "start_char": 475,
              "end_char": 480,
              "context": "rs. The Defense Advanced Research Project Agency (DARPA) stated that this single application more than pa"
            },
            {
              "para_id": "chap1_para198",
              "entity_text": "DARPA",
              "entity_type": "ORG",
              "start_char": 538,
              "end_char": 543,
              "context": " that this single application more than paid back DARPA’s 30-year investment in AI."
            },
            {
              "para_id": "chap1_para198",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 568,
              "end_char": 570,
              "context": "more than paid back DARPA’s 30-year investment in AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para199",
          "content": "Every day, ride hailing companies such as Uber and mapping services such as Google Maps provide driving directions for hundreds of millions of users, quickly plotting an optimal route taking into account current and predicted future traffic conditions.",
          "sentence_count": 1,
          "char_count": 215,
          "prev_para_id": "chap1_para198",
          "next_para_id": "chap1_para200",
          "style_metadata": {
            "para_id": "chap1_para199",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 1
          },
          "terminology": {
            "day": 1,
            "ride": 1,
            "hailing": 1,
            "company": 1,
            "uber": 1,
            "mapping": 1,
            "service": 1,
            "google": 1,
            "map": 1,
            "provide": 1,
            "driving": 1,
            "direction": 1,
            "hundred": 1,
            "million": 1,
            "user": 1,
            "plotting": 1,
            "optimal": 1,
            "route": 1,
            "taking": 1,
            "account": 1,
            "current": 1,
            "predicted": 1,
            "future": 1,
            "traffic": 1,
            "condition": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para199",
              "entity_text": "Google Maps",
              "entity_type": "ORG",
              "start_char": 76,
              "end_char": 87,
              "context": "mpanies such as Uber and mapping services such as Google Maps provide driving directions for hundreds of millio"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para200",
          "content": "Machine translation\n: Online machine translation systems now enable the reading of documents in over 100 languages, including the native languages of over 99% of humans, and render hundreds of billions of words per day for hundreds of millions of users. While not perfect, they are generally adequate for understanding. For closely related languages with a great deal of training data (such as French and English) translations within a narrow domain are close to the level of a human (Wu\net al.",
          "sentence_count": 3,
          "char_count": 415,
          "prev_para_id": "chap1_para199",
          "next_para_id": "chap1_para201",
          "style_metadata": {
            "para_id": "chap1_para200",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 92,
            "sentence_count": 3
          },
          "terminology": {
            "machine": 2,
            "translation": 3,
            "online": 1,
            "system": 1,
            "enable": 1,
            "reading": 1,
            "document": 1,
            "language": 3,
            "including": 1,
            "native": 1,
            "human": 2,
            "render": 1,
            "hundred": 2,
            "billion": 1,
            "word": 1,
            "day": 1,
            "million": 1,
            "user": 1,
            "perfect": 1,
            "adequate": 1,
            "understanding": 1,
            "related": 1,
            "great": 1,
            "deal": 1,
            "training": 1,
            "data": 1,
            "french": 1,
            "english": 1,
            "narrow": 1,
            "domain": 1,
            "close": 1,
            "level": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para200",
              "entity_text": "Wu",
              "entity_type": "PERSON",
              "start_char": 485,
              "end_char": 487,
              "context": " narrow domain are close to the level of a human (Wu\net al."
            },
            {
              "para_id": "chap1_para200",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 491,
              "end_char": 493,
              "context": "w domain are close to the level of a human (Wu\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para201",
          "content": ", 2016b).",
          "sentence_count": 1,
          "char_count": 8,
          "prev_para_id": "chap1_para200",
          "next_para_id": "chap1_para202",
          "style_metadata": {
            "para_id": "chap1_para201",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para202",
          "content": "Speech recognition\n: In 2017, Microsoft showed that its Conversational Speech Recognition System had reached a word error rate of 5.1%, matching human performance on the Switchboard task, which involves transcribing telephone conversations (Xiong\net al.,\n2017). About a third of computer interaction worldwide is now done by voice rather than keyboard; Skype provides real-time speech-to-speech translation in ten languages. Alexa, Siri, Cortana, and Google offer assistants that can answer questions and carry out tasks for the user; for example the Google Duplex service uses speech recognition and speech synthesis to make restaurant reservations for users, carrying out a fluent conversation on their behalf.",
          "sentence_count": 3,
          "char_count": 612,
          "prev_para_id": "chap1_para201",
          "next_para_id": "chap1_para203",
          "style_metadata": {
            "para_id": "chap1_para202",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 120,
            "sentence_count": 3
          },
          "terminology": {
            "speech": 4,
            "recognition": 3,
            "microsoft": 1,
            "showed": 1,
            "conversational": 1,
            "system": 1,
            "reached": 1,
            "word": 1,
            "error": 1,
            "rate": 1,
            "matching": 1,
            "human": 1,
            "performance": 1,
            "switchboard": 1,
            "task": 2,
            "involves": 1,
            "transcribing": 1,
            "telephone": 1,
            "conversation": 2,
            "xiong": 1,
            "al.": 1,
            "third": 1,
            "computer": 1,
            "interaction": 1,
            "done": 1,
            "voice": 1,
            "keyboard": 1,
            "skype": 1,
            "provides": 1,
            "real-time": 1,
            "speech-to-speech": 1,
            "translation": 1,
            "ten": 1,
            "language": 1,
            "siri": 1,
            "cortana": 1,
            "google": 2,
            "offer": 1,
            "assistant": 1,
            "answer": 1,
            "question": 1,
            "carry": 1,
            "user": 2,
            "example": 1,
            "duplex": 1,
            "service": 1,
            "us": 1,
            "synthesis": 1,
            "make": 1,
            "restaurant": 1,
            "reservation": 1,
            "carrying": 1,
            "fluent": 1,
            "behalf": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para202",
              "entity_text": "Microsoft",
              "entity_type": "ORG",
              "start_char": 30,
              "end_char": 39,
              "context": "Speech recognition\n: In 2017, Microsoft showed that its Conversational Speech Recognition"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Conversational Speech Recognition System",
              "entity_type": "ORG",
              "start_char": 56,
              "end_char": 96,
              "context": " recognition\n: In 2017, Microsoft showed that its Conversational Speech Recognition System had reached a word error rate of 5.1%, matching h"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Switchboard",
              "entity_type": "PRODUCT",
              "start_char": 170,
              "end_char": 181,
              "context": "r rate of 5.1%, matching human performance on the Switchboard task, which involves transcribing telephone conve"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Xiong",
              "entity_type": "GPE",
              "start_char": 241,
              "end_char": 246,
              "context": "ch involves transcribing telephone conversations (Xiong\net al.,\n2017). About a third of computer interact"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 250,
              "end_char": 253,
              "context": "es transcribing telephone conversations (Xiong\net al.,\n2017). About a third of computer interaction wor"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Skype",
              "entity_type": "ORG",
              "start_char": 353,
              "end_char": 358,
              "context": "ldwide is now done by voice rather than keyboard; Skype provides real-time speech-to-speech translation i"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Alexa",
              "entity_type": "ORG",
              "start_char": 425,
              "end_char": 430,
              "context": "me speech-to-speech translation in ten languages. Alexa, Siri, Cortana, and Google offer assistants that "
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Siri",
              "entity_type": "GPE",
              "start_char": 432,
              "end_char": 436,
              "context": "ch-to-speech translation in ten languages. Alexa, Siri, Cortana, and Google offer assistants that can an"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Cortana",
              "entity_type": "ORG",
              "start_char": 438,
              "end_char": 445,
              "context": "speech translation in ten languages. Alexa, Siri, Cortana, and Google offer assistants that can answer ques"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Google",
              "entity_type": "ORG",
              "start_char": 451,
              "end_char": 457,
              "context": "ation in ten languages. Alexa, Siri, Cortana, and Google offer assistants that can answer questions and ca"
            },
            {
              "para_id": "chap1_para202",
              "entity_text": "Google Duplex",
              "entity_type": "ORG",
              "start_char": 551,
              "end_char": 564,
              "context": "and carry out tasks for the user; for example the Google Duplex service uses speech recognition and speech synthe"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para203",
          "content": "Recommendations\n: Companies such as Amazon, Facebook, Netflix, Spotify, YouTube, Walmart, and others use machine learning to recommend what you might like based on your past experiences and those of others like you. The field of recommender systems has a long history (Resnick and Varian, 1997) but is changing rapidly due to new deep learning methods that analyze content (text, music, video) as well as history and metadata (van den Oord\net al.",
          "sentence_count": 2,
          "char_count": 376,
          "prev_para_id": "chap1_para202",
          "next_para_id": "chap1_para204",
          "style_metadata": {
            "para_id": "chap1_para203",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 2
          },
          "terminology": {
            "recommendation": 1,
            "company": 1,
            "amazon": 1,
            "facebook": 1,
            "netflix": 1,
            "spotify": 1,
            "youtube": 1,
            "walmart": 1,
            "others": 2,
            "use": 1,
            "machine": 1,
            "learning": 2,
            "recommend": 1,
            "like": 1,
            "based": 1,
            "past": 1,
            "experience": 1,
            "field": 1,
            "recommender": 1,
            "system": 1,
            "long": 1,
            "history": 2,
            "resnick": 1,
            "varian": 1,
            "changing": 1,
            "due": 1,
            "new": 1,
            "deep": 1,
            "method": 1,
            "analyze": 1,
            "content": 1,
            "text": 1,
            "music": 1,
            "video": 1,
            "metadata": 1,
            "van": 1,
            "den": 1,
            "oord": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para203",
              "entity_text": "Amazon",
              "entity_type": "ORG",
              "start_char": 36,
              "end_char": 42,
              "context": "Recommendations\n: Companies such as Amazon, Facebook, Netflix, Spotify, YouTube, Walmart, an"
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "Netflix",
              "entity_type": "GPE",
              "start_char": 54,
              "end_char": 61,
              "context": "mmendations\n: Companies such as Amazon, Facebook, Netflix, Spotify, YouTube, Walmart, and others use machin"
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "Spotify",
              "entity_type": "GPE",
              "start_char": 63,
              "end_char": 70,
              "context": "ns\n: Companies such as Amazon, Facebook, Netflix, Spotify, YouTube, Walmart, and others use machine learnin"
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "YouTube",
              "entity_type": "ORG",
              "start_char": 72,
              "end_char": 79,
              "context": "anies such as Amazon, Facebook, Netflix, Spotify, YouTube, Walmart, and others use machine learning to reco"
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "Walmart",
              "entity_type": "ORG",
              "start_char": 81,
              "end_char": 88,
              "context": "h as Amazon, Facebook, Netflix, Spotify, YouTube, Walmart, and others use machine learning to recommend wha"
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "Resnick",
              "entity_type": "GPE",
              "start_char": 269,
              "end_char": 276,
              "context": " field of recommender systems has a long history (Resnick and Varian, 1997) but is changing rapidly due to "
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "metadata",
              "entity_type": "PERSON",
              "start_char": 417,
              "end_char": 425,
              "context": "ntent (text, music, video) as well as history and metadata (van den Oord\net al."
            },
            {
              "para_id": "chap1_para203",
              "entity_text": "van den Oord",
              "entity_type": "PERSON",
              "start_char": 427,
              "end_char": 439,
              "context": "t, music, video) as well as history and metadata (van den Oord\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para204",
          "content": ", 2014; Zhang\net al.,\n2017). Spam filtering can also be considered a form of recommendation (or dis-recommendation); current AI techniques filter out over 99.9% of spam, and email services can also recommend potential recipients, as well as possible response text.",
          "sentence_count": 2,
          "char_count": 226,
          "prev_para_id": "chap1_para203",
          "next_para_id": "chap1_para205",
          "style_metadata": {
            "para_id": "chap1_para204",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 2
          },
          "terminology": {
            "zhang": 1,
            "al.": 1,
            "spam": 2,
            "filtering": 1,
            "considered": 1,
            "form": 1,
            "recommendation": 1,
            "dis-recommendation": 1,
            "current": 1,
            "technique": 1,
            "filter": 1,
            "email": 1,
            "service": 1,
            "recommend": 1,
            "potential": 1,
            "recipient": 1,
            "possible": 1,
            "response": 1,
            "text": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para204",
              "entity_text": "Zhang\net",
              "entity_type": "PERSON",
              "start_char": 8,
              "end_char": 16,
              "context": ", 2014; Zhang\net al.,\n2017). Spam filtering can also be considered"
            },
            {
              "para_id": "chap1_para204",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 17,
              "end_char": 20,
              "context": ", 2014; Zhang\net al.,\n2017). Spam filtering can also be considered a f"
            },
            {
              "para_id": "chap1_para204",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 125,
              "end_char": 127,
              "context": "f recommendation (or dis-recommendation); current AI techniques filter out over 99.9% of spam, and ema"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para205",
          "content": "Game playing\n: When Deep Blue defeated world chess champion Garry Kasparov in 1997, defenders of human supremacy placed their hopes on Go. Piet Hut, an astrophysicist and Go enthusiast, predicted that it would take “a hundred years before a computer beats humans at Go—maybe even longer.” But just 20 years later, A\nLPHA\nG\nO\nsurpassed all human players (Silver\net al.,\n2017). Ke Jie, the world champion, said, “Last year, it was still quite human-like when it played. But this year, it became like a god of Go.” A\nLPHA\nG\nO\nbenefited from studying hundreds of thousands of past games by human Go players, and from the distilled knowledge of expert Go players that worked on the team.",
          "sentence_count": 4,
          "char_count": 573,
          "prev_para_id": "chap1_para204",
          "next_para_id": "chap1_para206",
          "style_metadata": {
            "para_id": "chap1_para205",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 142,
            "sentence_count": 4
          },
          "terminology": {
            "game": 2,
            "playing": 1,
            "deep": 1,
            "blue": 1,
            "defeated": 1,
            "world": 2,
            "chess": 1,
            "champion": 2,
            "garry": 1,
            "kasparov": 1,
            "defender": 1,
            "human": 4,
            "supremacy": 1,
            "placed": 1,
            "hope": 1,
            "piet": 1,
            "hut": 1,
            "astrophysicist": 1,
            "enthusiast": 1,
            "predicted": 1,
            "take": 1,
            "year": 4,
            "computer": 1,
            "beat": 1,
            "lpha": 2,
            "surpassed": 1,
            "player": 3,
            "silver": 1,
            "jie": 1,
            "said": 1,
            "last": 1,
            "human-like": 1,
            "played": 1,
            "became": 1,
            "god": 1,
            "go.": 1,
            "benefited": 1,
            "studying": 1,
            "hundred": 1,
            "thousand": 1,
            "past": 1,
            "distilled": 1,
            "knowledge": 1,
            "expert": 1,
            "worked": 1,
            "team": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para205",
              "entity_text": "Deep Blue",
              "entity_type": "PERSON",
              "start_char": 20,
              "end_char": 29,
              "context": "Game playing\n: When Deep Blue defeated world chess champion Garry Kasparov in 1"
            },
            {
              "para_id": "chap1_para205",
              "entity_text": "Garry Kasparov",
              "entity_type": "PERSON",
              "start_char": 60,
              "end_char": 74,
              "context": "ng\n: When Deep Blue defeated world chess champion Garry Kasparov in 1997, defenders of human supremacy placed thei"
            },
            {
              "para_id": "chap1_para205",
              "entity_text": "Piet Hut",
              "entity_type": "PERSON",
              "start_char": 139,
              "end_char": 147,
              "context": "ders of human supremacy placed their hopes on Go. Piet Hut, an astrophysicist and Go enthusiast, predicted t"
            },
            {
              "para_id": "chap1_para205",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 364,
              "end_char": 367,
              "context": "A\nLPHA\nG\nO\nsurpassed all human players (Silver\net al.,\n2017). Ke Jie, the world champion, said, “Last y"
            },
            {
              "para_id": "chap1_para205",
              "entity_text": "Ke Jie",
              "entity_type": "PERSON",
              "start_char": 376,
              "end_char": 382,
              "context": "urpassed all human players (Silver\net al.,\n2017). Ke Jie, the world champion, said, “Last year, it was sti"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para206",
          "content": "A followup program, A\nLPHA\nZ\nERO\n, used no input from humans (except for the rules of the game), and was able to learn through self-play alone to defeat all opponents, human and machine, at Go, chess, and shogi (Silver\net al.,\n2018). Meanwhile, human champions have been beaten by AI systems at games as diverse as Jeopardy! (Ferrucci\net al.,\n2010), poker (Bowling\net al.,\n2015; Moravčík\net al.,\n2017; Brown and Sandholm, 2019), and the video games Dota 2 (Fernandez and Mahlmann, 2018), StarCraft II (Vinyals\net al.,\n2019), and Quake III (Jaderberg\net al.,\n2019).",
          "sentence_count": 3,
          "char_count": 482,
          "prev_para_id": "chap1_para205",
          "next_para_id": "chap1_para207",
          "style_metadata": {
            "para_id": "chap1_para206",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 137,
            "sentence_count": 3
          },
          "terminology": {
            "followup": 1,
            "program": 1,
            "lpha": 1,
            "ero": 1,
            "used": 1,
            "input": 1,
            "human": 3,
            "rule": 1,
            "game": 3,
            "able": 1,
            "learn": 1,
            "self-play": 1,
            "defeat": 1,
            "opponent": 1,
            "machine": 1,
            "chess": 1,
            "shogi": 1,
            "silver": 1,
            "al.": 6,
            "champion": 1,
            "beaten": 1,
            "system": 1,
            "diverse": 1,
            "jeopardy": 1,
            "ferrucci": 1,
            "poker": 1,
            "bowling": 1,
            "moravčík": 1,
            "brown": 1,
            "sandholm": 1,
            "video": 1,
            "dota": 1,
            "fernandez": 1,
            "mahlmann": 1,
            "starcraft": 1,
            "vinyals": 1,
            "quake": 1,
            "iii": 1,
            "jaderberg": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para206",
              "entity_text": "ERO",
              "entity_type": "ORG",
              "start_char": 29,
              "end_char": 32,
              "context": "A followup program, A\nLPHA\nZ\nERO\n, used no input from humans (except for the rules"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 222,
              "end_char": 225,
              "context": "n and machine, at Go, chess, and shogi (Silver\net al.,\n2018). Meanwhile, human champions have been beat"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 281,
              "end_char": 283,
              "context": "). Meanwhile, human champions have been beaten by AI systems at games as diverse as Jeopardy! (Ferrucc"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Jeopardy",
              "entity_type": "ORG",
              "start_char": 315,
              "end_char": 323,
              "context": " been beaten by AI systems at games as diverse as Jeopardy! (Ferrucci\net al.,\n2010), poker (Bowling\net al.,\n"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Ferrucci",
              "entity_type": "PERSON",
              "start_char": 326,
              "end_char": 334,
              "context": "n by AI systems at games as diverse as Jeopardy! (Ferrucci\net al.,\n2010), poker (Bowling\net al.,\n2015; Morav"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 338,
              "end_char": 341,
              "context": "ems at games as diverse as Jeopardy! (Ferrucci\net al.,\n2010), poker (Bowling\net al.,\n2015; Moravčík\net "
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Moravčík",
              "entity_type": "GPE",
              "start_char": 379,
              "end_char": 387,
              "context": "rucci\net al.,\n2010), poker (Bowling\net al.,\n2015; Moravčík\net al.,\n2017; Brown and Sandholm, 2019), and the "
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 391,
              "end_char": 394,
              "context": ",\n2010), poker (Bowling\net al.,\n2015; Moravčík\net al.,\n2017; Brown and Sandholm, 2019), and the video g"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Brown",
              "entity_type": "PERSON",
              "start_char": 402,
              "end_char": 407,
              "context": "ker (Bowling\net al.,\n2015; Moravčík\net al.,\n2017; Brown and Sandholm, 2019), and the video games Dota 2 ("
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Sandholm",
              "entity_type": "GPE",
              "start_char": 412,
              "end_char": 420,
              "context": "ng\net al.,\n2015; Moravčík\net al.,\n2017; Brown and Sandholm, 2019), and the video games Dota 2 (Fernandez and"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Dota 2",
              "entity_type": "ORG",
              "start_char": 449,
              "end_char": 455,
              "context": "7; Brown and Sandholm, 2019), and the video games Dota 2 (Fernandez and Mahlmann, 2018), StarCraft II (Vin"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Fernandez",
              "entity_type": "ORG",
              "start_char": 457,
              "end_char": 466,
              "context": " and Sandholm, 2019), and the video games Dota 2 (Fernandez and Mahlmann, 2018), StarCraft II (Vinyals\net al."
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Mahlmann",
              "entity_type": "ORG",
              "start_char": 471,
              "end_char": 479,
              "context": " 2019), and the video games Dota 2 (Fernandez and Mahlmann, 2018), StarCraft II (Vinyals\net al.,\n2019), and "
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "StarCraft II",
              "entity_type": "ORG",
              "start_char": 488,
              "end_char": 500,
              "context": "ideo games Dota 2 (Fernandez and Mahlmann, 2018), StarCraft II (Vinyals\net al.,\n2019), and Quake III (Jaderberg\n"
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 513,
              "end_char": 516,
              "context": "dez and Mahlmann, 2018), StarCraft II (Vinyals\net al.,\n2019), and Quake III (Jaderberg\net al.,\n2019)."
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "Jaderberg",
              "entity_type": "PERSON",
              "start_char": 540,
              "end_char": 549,
              "context": "arCraft II (Vinyals\net al.,\n2019), and Quake III (Jaderberg\net al.,\n2019)."
            },
            {
              "para_id": "chap1_para206",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 553,
              "end_char": 556,
              "context": "inyals\net al.,\n2019), and Quake III (Jaderberg\net al.,\n2019)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para207",
          "content": "Image understanding\n: Not content with exceeding human accuracy on the challenging ImageNet object recognition task, computer vision researchers have taken on the more difficult problem of image captioning. Some impressive examples include “A person riding a motorcycle on a dirt road,” “Two pizzas sitting on top of a stove top oven,” and “A group of young people playing a game of frisbee” (Vinyals\net al.,\n2017b). Current systems are far from perfect, however: a “refrigerator filled with lots of food and drinks” turns out to be a no-parking sign partially obscured by lots of small stickers.",
          "sentence_count": 3,
          "char_count": 503,
          "prev_para_id": "chap1_para206",
          "next_para_id": "chap1_para208",
          "style_metadata": {
            "para_id": "chap1_para207",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 38.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 116,
            "sentence_count": 3
          },
          "terminology": {
            "image": 2,
            "understanding": 1,
            "content": 1,
            "exceeding": 1,
            "human": 1,
            "accuracy": 1,
            "challenging": 1,
            "imagenet": 1,
            "object": 1,
            "recognition": 1,
            "task": 1,
            "computer": 1,
            "vision": 1,
            "researcher": 1,
            "taken": 1,
            "difficult": 1,
            "problem": 1,
            "captioning": 1,
            "impressive": 1,
            "example": 1,
            "include": 1,
            "person": 1,
            "riding": 1,
            "motorcycle": 1,
            "dirt": 1,
            "road": 1,
            "pizza": 1,
            "sitting": 1,
            "top": 2,
            "stove": 1,
            "oven": 1,
            "group": 1,
            "young": 1,
            "people": 1,
            "playing": 1,
            "game": 1,
            "frisbee": 1,
            "vinyals": 1,
            "al.": 1,
            "current": 1,
            "system": 1,
            "perfect": 1,
            "refrigerator": 1,
            "filled": 1,
            "lot": 2,
            "food": 1,
            "drink": 1,
            "turn": 1,
            "no-parking": 1,
            "sign": 1,
            "obscured": 1,
            "small": 1,
            "sticker": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para207",
              "entity_text": "ImageNet",
              "entity_type": "ORG",
              "start_char": 83,
              "end_char": 91,
              "context": " with exceeding human accuracy on the challenging ImageNet object recognition task, computer vision research"
            },
            {
              "para_id": "chap1_para207",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 404,
              "end_char": 407,
              "context": "ung people playing a game of frisbee” (Vinyals\net al.,\n2017b). Current systems are far from perfect, ho"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para208",
          "content": "Medicine\n: AI algorithms now equal or exceed expert doctors at diagnosing many conditions, particularly when the diagnosis is based on images. Examples include Alzheimer’s disease (Ding\net al.,\n2018), metastatic cancer (Liu\net al.,\n2017; Esteva\net al.,\n2017), ophthalmic disease (Gulshan\net al.,\n2016), and skin diseases (Liu\net al.,\n2019c). A systematic review and meta-analysis (Liu\net al.,\n2019a) found that the performance of AI programs, on average, was equivalent to health care professionals. One current emphasis in medical AI is in facilitating human–machine partnerships. For example, the L\nYNA\nsystem achieves 99.6% overall accuracy in diagnosing metastatic breast cancer—better than an unaided human expert—but the combination does better still (Liu\net al.",
          "sentence_count": 5,
          "char_count": 669,
          "prev_para_id": "chap1_para207",
          "next_para_id": "chap1_para209",
          "style_metadata": {
            "para_id": "chap1_para208",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.8,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 149,
            "sentence_count": 5
          },
          "terminology": {
            "medicine": 1,
            "algorithm": 1,
            "equal": 1,
            "exceed": 1,
            "expert": 1,
            "doctor": 1,
            "diagnosing": 2,
            "many": 1,
            "condition": 1,
            "diagnosis": 1,
            "based": 1,
            "image": 1,
            "example": 2,
            "include": 1,
            "alzheimer": 1,
            "disease": 3,
            "ding": 1,
            "al.": 5,
            "metastatic": 2,
            "cancer": 1,
            "liu": 4,
            "esteva": 1,
            "ophthalmic": 1,
            "gulshan": 1,
            "skin": 1,
            "systematic": 1,
            "review": 1,
            "meta-analysis": 1,
            "found": 1,
            "performance": 1,
            "program": 1,
            "average": 1,
            "equivalent": 1,
            "health": 1,
            "care": 1,
            "professional": 1,
            "current": 1,
            "emphasis": 1,
            "medical": 1,
            "facilitating": 1,
            "human–machine": 1,
            "partnership": 1,
            "yna": 1,
            "system": 1,
            "achieves": 1,
            "overall": 1,
            "accuracy": 1,
            "breast": 1,
            "cancer—better": 1,
            "unaided": 1,
            "human": 1,
            "expert—but": 1,
            "combination": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para208",
              "entity_text": "Ding",
              "entity_type": "PERSON",
              "start_char": 181,
              "end_char": 185,
              "context": " on images. Examples include Alzheimer’s disease (Ding\net al.,\n2018), metastatic cancer (Liu\net al.,\n201"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 189,
              "end_char": 192,
              "context": "es. Examples include Alzheimer’s disease (Ding\net al.,\n2018), metastatic cancer (Liu\net al.,\n2017; Este"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "Liu",
              "entity_type": "PERSON",
              "start_char": 220,
              "end_char": 223,
              "context": "s disease (Ding\net al.,\n2018), metastatic cancer (Liu\net al.,\n2017; Esteva\net al.,\n2017), ophthalmic di"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 227,
              "end_char": 230,
              "context": "se (Ding\net al.,\n2018), metastatic cancer (Liu\net al.,\n2017; Esteva\net al.,\n2017), ophthalmic disease ("
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "Esteva",
              "entity_type": "PERSON",
              "start_char": 238,
              "end_char": 244,
              "context": " al.,\n2018), metastatic cancer (Liu\net al.,\n2017; Esteva\net al.,\n2017), ophthalmic disease (Gulshan\net al."
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 248,
              "end_char": 251,
              "context": "), metastatic cancer (Liu\net al.,\n2017; Esteva\net al.,\n2017), ophthalmic disease (Gulshan\net al.,\n2016)"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "Gulshan",
              "entity_type": "GPE",
              "start_char": 280,
              "end_char": 287,
              "context": ",\n2017; Esteva\net al.,\n2017), ophthalmic disease (Gulshan\net al.,\n2016), and skin diseases (Liu\net al.,\n201"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 291,
              "end_char": 294,
              "context": "eva\net al.,\n2017), ophthalmic disease (Gulshan\net al.,\n2016), and skin diseases (Liu\net al.,\n2019c). A "
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "Liu",
              "entity_type": "PERSON",
              "start_char": 322,
              "end_char": 325,
              "context": "isease (Gulshan\net al.,\n2016), and skin diseases (Liu\net al.,\n2019c). A systematic review and meta-anal"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 329,
              "end_char": 332,
              "context": "(Gulshan\net al.,\n2016), and skin diseases (Liu\net al.,\n2019c). A systematic review and meta-analysis (L"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "Liu",
              "entity_type": "PERSON",
              "start_char": 381,
              "end_char": 384,
              "context": ".,\n2019c). A systematic review and meta-analysis (Liu\net al.,\n2019a) found that the performance of AI p"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 388,
              "end_char": 391,
              "context": "c). A systematic review and meta-analysis (Liu\net al.,\n2019a) found that the performance of AI programs"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 430,
              "end_char": 432,
              "context": "(Liu\net al.,\n2019a) found that the performance of AI programs, on average, was equivalent to health ca"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 532,
              "end_char": 534,
              "context": "re professionals. One current emphasis in medical AI is in facilitating human–machine partnerships. Fo"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "the L\nYNA",
              "entity_type": "ORG",
              "start_char": 595,
              "end_char": 604,
              "context": "litating human–machine partnerships. For example, the L\nYNA\nsystem achieves 99.6% overall accuracy in diagnos"
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "Liu",
              "entity_type": "PERSON",
              "start_char": 758,
              "end_char": 761,
              "context": "man expert—but the combination does better still (Liu\net al."
            },
            {
              "para_id": "chap1_para208",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 765,
              "end_char": 767,
              "context": "ert—but the combination does better still (Liu\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para209",
          "content": ", 2018; Steiner\net al.,\n2018).",
          "sentence_count": 1,
          "char_count": 27,
          "prev_para_id": "chap1_para208",
          "next_para_id": "chap1_para210",
          "style_metadata": {
            "para_id": "chap1_para209",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "steiner": 1,
            "al.": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para209",
              "entity_text": "Steiner",
              "entity_type": "PERSON",
              "start_char": 8,
              "end_char": 15,
              "context": ", 2018; Steiner\net al.,\n2018)."
            },
            {
              "para_id": "chap1_para209",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 19,
              "end_char": 22,
              "context": ", 2018; Steiner\net al.,\n2018)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para210",
          "content": "The widespread adoption of these techniques is now limited not by diagnostic accuracy but by the need to demonstrate improvement in clinical outcomes and to ensure transparency, lack of bias, and data privacy (Topol, 2019). In 2017, only two medical AI applications were approved by the FDA, but that increased to 12 in 2018, and continues to rise.",
          "sentence_count": 2,
          "char_count": 291,
          "prev_para_id": "chap1_para209",
          "next_para_id": "chap1_para211",
          "style_metadata": {
            "para_id": "chap1_para210",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 2
          },
          "terminology": {
            "widespread": 1,
            "adoption": 1,
            "technique": 1,
            "limited": 1,
            "diagnostic": 1,
            "accuracy": 1,
            "need": 1,
            "demonstrate": 1,
            "improvement": 1,
            "clinical": 1,
            "outcome": 1,
            "ensure": 1,
            "transparency": 1,
            "lack": 1,
            "bias": 1,
            "data": 1,
            "privacy": 1,
            "topol": 1,
            "medical": 1,
            "application": 1,
            "approved": 1,
            "fda": 1,
            "increased": 1,
            "continues": 1,
            "rise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para210",
              "entity_text": "Topol",
              "entity_type": "ORG",
              "start_char": 210,
              "end_char": 215,
              "context": "ure transparency, lack of bias, and data privacy (Topol, 2019). In 2017, only two medical AI applications"
            },
            {
              "para_id": "chap1_para210",
              "entity_text": "FDA",
              "entity_type": "ORG",
              "start_char": 287,
              "end_char": 290,
              "context": " two medical AI applications were approved by the FDA, but that increased to 12 in 2018, and continues "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para211",
          "content": "Climate science\n: A team of scientists won the 2018 Gordon Bell Prize for a deep learning model that discovers detailed information about extreme weather events that were previously buried in climate data. They used a supercomputer with specialized GPU hardware to exceed the exaop level (10\n18\noperations per second), the first machine learning program to do so (Kurth\net al.",
          "sentence_count": 2,
          "char_count": 319,
          "prev_para_id": "chap1_para210",
          "next_para_id": "chap1_para212",
          "style_metadata": {
            "para_id": "chap1_para211",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 2
          },
          "terminology": {
            "climate": 2,
            "science": 1,
            "team": 1,
            "scientist": 1,
            "gordon": 1,
            "prize": 1,
            "deep": 1,
            "learning": 2,
            "model": 1,
            "discovers": 1,
            "detailed": 1,
            "information": 1,
            "extreme": 1,
            "weather": 1,
            "event": 1,
            "buried": 1,
            "data": 1,
            "used": 1,
            "supercomputer": 1,
            "specialized": 1,
            "gpu": 1,
            "hardware": 1,
            "exceed": 1,
            "exaop": 1,
            "level": 1,
            "operation": 1,
            "second": 1,
            "first": 1,
            "machine": 1,
            "program": 1,
            "kurth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para211",
              "entity_text": "Gordon Bell Prize",
              "entity_type": "PERSON",
              "start_char": 52,
              "end_char": 69,
              "context": "imate science\n: A team of scientists won the 2018 Gordon Bell Prize for a deep learning model that discovers detailed"
            },
            {
              "para_id": "chap1_para211",
              "entity_text": "GPU",
              "entity_type": "ORG",
              "start_char": 249,
              "end_char": 252,
              "context": " data. They used a supercomputer with specialized GPU hardware to exceed the exaop level (10\n18\noperati"
            },
            {
              "para_id": "chap1_para211",
              "entity_text": "Kurth",
              "entity_type": "PERSON",
              "start_char": 364,
              "end_char": 369,
              "context": "nd), the first machine learning program to do so (Kurth\net al."
            },
            {
              "para_id": "chap1_para211",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 373,
              "end_char": 375,
              "context": "first machine learning program to do so (Kurth\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para212",
          "content": ", 2018). Rolnick\net al.",
          "sentence_count": 2,
          "char_count": 20,
          "prev_para_id": "chap1_para211",
          "next_para_id": "chap1_para213",
          "style_metadata": {
            "para_id": "chap1_para212",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 8,
            "sentence_count": 2
          },
          "terminology": {
            "rolnick": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para212",
              "entity_text": "Rolnick\net",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 19,
              "context": ", 2018). Rolnick\net al."
            },
            {
              "para_id": "chap1_para212",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 20,
              "end_char": 22,
              "context": ", 2018). Rolnick\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para213",
          "content": "(2019) present a 60-page catalog of ways in which machine learning can be used to tackle climate change.",
          "sentence_count": 1,
          "char_count": 87,
          "prev_para_id": "chap1_para212",
          "next_para_id": "chap1_para214",
          "style_metadata": {
            "para_id": "chap1_para213",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "present": 1,
            "60-page": 1,
            "catalog": 1,
            "way": 1,
            "machine": 1,
            "learning": 1,
            "used": 1,
            "tackle": 1,
            "climate": 1,
            "change": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para214",
          "content": "These are just a few examples of artificial intelligence systems that exist today. Not magic or science fiction—but rather science, engineering, and mathematics, to which this book provides an introduction.",
          "sentence_count": 2,
          "char_count": 177,
          "prev_para_id": "chap1_para213",
          "next_para_id": "chap1_para215",
          "style_metadata": {
            "para_id": "chap1_para214",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "example": 1,
            "artificial": 1,
            "intelligence": 1,
            "system": 1,
            "exist": 1,
            "today": 1,
            "magic": 1,
            "science": 2,
            "fiction—but": 1,
            "engineering": 1,
            "mathematics": 1,
            "book": 1,
            "provides": 1,
            "introduction": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para215",
          "content": "1.5 Risks and Benefits of AI\n1.5 Risks and Benefits of AI\nFrancis Bacon, a philosopher credited with creating the scientific method, noted in\nThe Wisdom of the Ancients\n(1609) that the “mechanical arts are of ambiguous use, serving as well for hurt as for remedy.” As AI plays an increasingly important role in the economic, social, scientific, medical, financial, and military spheres, we would do well to consider the hurts and remedies—in modern parlance, the risks and benefits—that it can bring. The topics summarized here are covered in greater depth in\nChapters 28\nand\n29\n.",
          "sentence_count": 2,
          "char_count": 492,
          "prev_para_id": "chap1_para214",
          "next_para_id": "chap1_para216",
          "style_metadata": {
            "para_id": "chap1_para215",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 56.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 2
          },
          "terminology": {
            "risk": 3,
            "benefit": 2,
            "francis": 1,
            "bacon": 1,
            "philosopher": 1,
            "credited": 1,
            "creating": 1,
            "scientific": 2,
            "method": 1,
            "noted": 1,
            "wisdom": 1,
            "ancient": 1,
            "mechanical": 1,
            "art": 1,
            "ambiguous": 1,
            "use": 1,
            "serving": 1,
            "hurt": 2,
            "remedy.": 1,
            "play": 1,
            "important": 1,
            "role": 1,
            "economic": 1,
            "social": 1,
            "medical": 1,
            "financial": 1,
            "military": 1,
            "sphere": 1,
            "consider": 1,
            "remedies—in": 1,
            "modern": 1,
            "parlance": 1,
            "bring": 1,
            "topic": 1,
            "summarized": 1,
            "covered": 1,
            "greater": 1,
            "depth": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para215",
              "entity_text": "Risks and Benefits of AI",
              "entity_type": "ORG",
              "start_char": 4,
              "end_char": 28,
              "context": "1.5 Risks and Benefits of AI\n1.5 Risks and Benefits of AI\nFrancis Bacon, a phi"
            },
            {
              "para_id": "chap1_para215",
              "entity_text": "Francis Bacon",
              "entity_type": "PERSON",
              "start_char": 58,
              "end_char": 71,
              "context": "s and Benefits of AI\n1.5 Risks and Benefits of AI\nFrancis Bacon, a philosopher credited with creating the scienti"
            },
            {
              "para_id": "chap1_para215",
              "entity_text": "The Wisdom of the Ancients",
              "entity_type": "WORK_OF_ART",
              "start_char": 142,
              "end_char": 168,
              "context": "ted with creating the scientific method, noted in\nThe Wisdom of the Ancients\n(1609) that the “mechanical arts are of ambiguous"
            },
            {
              "para_id": "chap1_para215",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 268,
              "end_char": 270,
              "context": " use, serving as well for hurt as for remedy.” As AI plays an increasingly important role in the econo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para216",
          "content": "To begin with the benefits: put simply, our entire civilization is the product of our human intelligence. If we have access to substantially greater machine intelligence, the ceiling on our ambitions is raised substantially. The potential for AI and robotics to free humanity from menial repetitive work and to dramatically increase the production of goods and services could presage an era of peace and plenty. The capacity to accelerate scientific research could result in cures for disease and solutions for climate change and resource shortages. As Demis Hassabis, CEO of Google DeepMind, has suggested: “First solve AI, then use AI to solve everything else.”\nLong before we have an opportunity to “solve AI,” however, we will incur risks from the misuse of AI, inadvertent or otherwise. Some of these are already apparent, while others seem likely based on current trends:\n•\nLethal autonomous weapons:\nThese are defined by the United Nations as weapons that can locate, select, and eliminate human targets without human intervention. A primary concern with such weapons is their\nscalability:\nthe absence of a requirement for human supervision means that a small group can deploy an arbitrarily large number of weapons against human targets defined by any feasible recognition criterion. The technologies needed for autonomous weapons are similar to those needed for self-driving cars. Informal expert discussions on the potential risks of lethal autonomous weapons began at the UN in 2014, moving to the formal pre-treaty stage of a Group of Governmental Experts in 2017.",
          "sentence_count": 9,
          "char_count": 1335,
          "prev_para_id": "chap1_para215",
          "next_para_id": "chap1_para217",
          "style_metadata": {
            "para_id": "chap1_para216",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 30.89,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 278,
            "sentence_count": 9
          },
          "terminology": {
            "begin": 1,
            "benefit": 1,
            "put": 1,
            "entire": 1,
            "civilization": 1,
            "product": 1,
            "human": 5,
            "intelligence": 2,
            "access": 1,
            "greater": 1,
            "machine": 1,
            "ceiling": 1,
            "ambition": 1,
            "raised": 1,
            "potential": 2,
            "robotics": 1,
            "free": 1,
            "humanity": 1,
            "menial": 1,
            "repetitive": 1,
            "work": 1,
            "increase": 1,
            "production": 1,
            "good": 1,
            "service": 1,
            "presage": 1,
            "era": 1,
            "peace": 1,
            "plenty": 1,
            "capacity": 1,
            "accelerate": 1,
            "scientific": 1,
            "research": 1,
            "result": 1,
            "cure": 1,
            "disease": 1,
            "solution": 1,
            "climate": 1,
            "change": 1,
            "resource": 1,
            "shortage": 1,
            "demis": 1,
            "hassabis": 1,
            "ceo": 1,
            "google": 1,
            "deepmind": 1,
            "suggested": 1,
            "solve": 3,
            "use": 1,
            "everything": 1,
            "else.": 1,
            "long": 1,
            "opportunity": 1,
            "incur": 1,
            "risk": 2,
            "misuse": 1,
            "inadvertent": 1,
            "apparent": 1,
            "others": 1,
            "seem": 1,
            "based": 1,
            "current": 1,
            "trend": 1,
            "lethal": 2,
            "autonomous": 3,
            "weapon": 6,
            "defined": 2,
            "united": 1,
            "nation": 1,
            "locate": 1,
            "select": 1,
            "eliminate": 1,
            "target": 2,
            "intervention": 1,
            "primary": 1,
            "concern": 1,
            "scalability": 1,
            "absence": 1,
            "requirement": 1,
            "supervision": 1,
            "mean": 1,
            "small": 1,
            "group": 2,
            "deploy": 1,
            "large": 1,
            "number": 1,
            "feasible": 1,
            "recognition": 1,
            "criterion": 1,
            "technology": 1,
            "needed": 2,
            "similar": 1,
            "self-driving": 1,
            "car": 1,
            "informal": 1,
            "expert": 2,
            "discussion": 1,
            "began": 1,
            "moving": 1,
            "formal": 1,
            "pre-treaty": 1,
            "stage": 1,
            "governmental": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para216",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 243,
              "end_char": 245,
              "context": "itions is raised substantially. The potential for AI and robotics to free humanity from menial repetit"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "Demis Hassabis",
              "entity_type": "PERSON",
              "start_char": 553,
              "end_char": 567,
              "context": "ons for climate change and resource shortages. As Demis Hassabis, CEO of Google DeepMind, has suggested: “First so"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "Google DeepMind",
              "entity_type": "ORG",
              "start_char": 576,
              "end_char": 591,
              "context": "and resource shortages. As Demis Hassabis, CEO of Google DeepMind, has suggested: “First solve AI, then use AI to s"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 621,
              "end_char": 623,
              "context": "O of Google DeepMind, has suggested: “First solve AI, then use AI to solve everything else.”\nLong befo"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 634,
              "end_char": 636,
              "context": "eepMind, has suggested: “First solve AI, then use AI to solve everything else.”\nLong before we have an"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 709,
              "end_char": 711,
              "context": "se.”\nLong before we have an opportunity to “solve AI,” however, we will incur risks from the misuse of"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 762,
              "end_char": 764,
              "context": "” however, we will incur risks from the misuse of AI, inadvertent or otherwise. Some of these are alre"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "the United Nations",
              "entity_type": "ORG",
              "start_char": 928,
              "end_char": 946,
              "context": "•\nLethal autonomous weapons:\nThese are defined by the United Nations as weapons that can locate, select, and eliminate"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "UN",
              "entity_type": "ORG",
              "start_char": 1483,
              "end_char": 1485,
              "context": "l risks of lethal autonomous weapons began at the UN in 2014, moving to the formal pre-treaty stage of"
            },
            {
              "para_id": "chap1_para216",
              "entity_text": "Group of Governmental Experts",
              "entity_type": "ORG",
              "start_char": 1538,
              "end_char": 1567,
              "context": " 2014, moving to the formal pre-treaty stage of a Group of Governmental Experts in 2017."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para217",
          "content": "•\nSurveillance and persuasion:\nWhile it is expensive, tedious, and sometimes legally questionable for security personnel to monitor phone lines, video camera feeds, emails, and other messaging channels, AI (speech recognition, computer vision, and natural language understanding) can be used in a scalable fashion to perform mass surveillance of individuals and detect activities of interest. By tailoring information flows to individuals through social media, based on machine learning techniques, political behavior can be modified and controlled to some extent—a concern that became apparent in elections beginning in 2016.",
          "sentence_count": 2,
          "char_count": 541,
          "prev_para_id": "chap1_para216",
          "next_para_id": "chap1_para218",
          "style_metadata": {
            "para_id": "chap1_para217",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 51.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 2
          },
          "terminology": {
            "surveillance": 2,
            "persuasion": 1,
            "expensive": 1,
            "tedious": 1,
            "questionable": 1,
            "security": 1,
            "personnel": 1,
            "monitor": 1,
            "phone": 1,
            "line": 1,
            "video": 1,
            "camera": 1,
            "feed": 1,
            "email": 1,
            "messaging": 1,
            "channel": 1,
            "speech": 1,
            "recognition": 1,
            "computer": 1,
            "vision": 1,
            "natural": 1,
            "language": 1,
            "understanding": 1,
            "used": 1,
            "scalable": 1,
            "fashion": 1,
            "perform": 1,
            "mass": 1,
            "individual": 2,
            "detect": 1,
            "activity": 1,
            "interest": 1,
            "tailoring": 1,
            "information": 1,
            "flow": 1,
            "social": 1,
            "medium": 1,
            "based": 1,
            "machine": 1,
            "learning": 1,
            "technique": 1,
            "political": 1,
            "behavior": 1,
            "modified": 1,
            "controlled": 1,
            "extent—a": 1,
            "concern": 1,
            "became": 1,
            "apparent": 1,
            "election": 1,
            "beginning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para217",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 203,
              "end_char": 205,
              "context": "mera feeds, emails, and other messaging channels, AI (speech recognition, computer vision, and natural"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para218",
          "content": "•\nBiased decision making:\nCareless or deliberate misuse of machine learning algorithms for tasks such as evaluating parole and loan applications can result in decisions that are biased by race, gender, or other protected categories. Often, the data themselves reflect pervasive bias in society.",
          "sentence_count": 2,
          "char_count": 253,
          "prev_para_id": "chap1_para217",
          "next_para_id": "chap1_para219",
          "style_metadata": {
            "para_id": "chap1_para218",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 2
          },
          "terminology": {
            "biased": 2,
            "decision": 2,
            "making": 1,
            "careless": 1,
            "deliberate": 1,
            "misuse": 1,
            "machine": 1,
            "learning": 1,
            "algorithm": 1,
            "task": 1,
            "evaluating": 1,
            "parole": 1,
            "loan": 1,
            "application": 1,
            "result": 1,
            "race": 1,
            "gender": 1,
            "protected": 1,
            "category": 1,
            "data": 1,
            "reflect": 1,
            "pervasive": 1,
            "bias": 1,
            "society": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para219",
          "content": "•\nImpact on employment:\nConcerns about machines eliminating jobs are centuries old. The story is never simple: machines do some of the tasks that humans might otherwise do, but they also make humans more productive and therefore more employable, and make companies more profitable and therefore able to pay higher wages. They may render some activities economically viable that would otherwise be impractical. Their\nuse generally results in increasing wealth but tends to have the effect of shifting wealth from labor to capital, further exacerbating increases in inequality. Previous advances in technology—such as the invention of mechanical looms—have resulted in serious disruptions to employment, but eventually people find new kinds of work to do. On the other hand, it is possible that AI will be doing those new kinds of work too. This topic is rapidly becoming a major focus for economists and governments around the world.",
          "sentence_count": 7,
          "char_count": 789,
          "prev_para_id": "chap1_para218",
          "next_para_id": "chap1_para220",
          "style_metadata": {
            "para_id": "chap1_para219",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 161,
            "sentence_count": 7
          },
          "terminology": {
            "impact": 1,
            "employment": 2,
            "concern": 1,
            "machine": 2,
            "eliminating": 1,
            "job": 1,
            "century": 1,
            "old": 1,
            "story": 1,
            "simple": 1,
            "task": 1,
            "human": 2,
            "make": 2,
            "productive": 1,
            "employable": 1,
            "company": 1,
            "profitable": 1,
            "able": 1,
            "pay": 1,
            "higher": 1,
            "wage": 1,
            "render": 1,
            "activity": 1,
            "viable": 1,
            "impractical": 1,
            "use": 1,
            "result": 1,
            "increasing": 1,
            "wealth": 2,
            "tends": 1,
            "effect": 1,
            "shifting": 1,
            "labor": 1,
            "capital": 1,
            "exacerbating": 1,
            "increase": 1,
            "inequality": 1,
            "previous": 1,
            "advance": 1,
            "technology—such": 1,
            "invention": 1,
            "mechanical": 1,
            "looms—have": 1,
            "resulted": 1,
            "serious": 1,
            "disruption": 1,
            "people": 1,
            "find": 1,
            "new": 2,
            "kind": 2,
            "work": 2,
            "hand": 1,
            "possible": 1,
            "becoming": 1,
            "major": 1,
            "focus": 1,
            "economist": 1,
            "government": 1,
            "world": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para219",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 793,
              "end_char": 795,
              "context": "ork to do. On the other hand, it is possible that AI will be doing those new kinds of work too. This t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para220",
          "content": "•\nSafety-critical applications\n: As AI techniques advance, they are increasingly used in high-stakes, safety-critical applications such as driving cars and managing the water supplies of cities. Fatal accidents have already occurred and highlight the difficulty of formal verification and statistical risk analysis for systems developed using machine learning techniques. The field of AI will need to develop technical and ethical standards at least comparable to those prevalent in other engineering and healthcare disciplines where people’s lives are at stake.",
          "sentence_count": 3,
          "char_count": 485,
          "prev_para_id": "chap1_para219",
          "next_para_id": "chap1_para221",
          "style_metadata": {
            "para_id": "chap1_para220",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 87,
            "sentence_count": 3
          },
          "terminology": {
            "safety-critical": 2,
            "application": 2,
            "technique": 2,
            "advance": 1,
            "used": 1,
            "high-stakes": 1,
            "driving": 1,
            "car": 1,
            "managing": 1,
            "water": 1,
            "supply": 1,
            "city": 1,
            "fatal": 1,
            "accident": 1,
            "occurred": 1,
            "highlight": 1,
            "difficulty": 1,
            "formal": 1,
            "verification": 1,
            "statistical": 1,
            "risk": 1,
            "analysis": 1,
            "system": 1,
            "developed": 1,
            "using": 1,
            "machine": 1,
            "learning": 1,
            "field": 1,
            "need": 1,
            "develop": 1,
            "technical": 1,
            "ethical": 1,
            "standard": 1,
            "least": 1,
            "comparable": 1,
            "prevalent": 1,
            "engineering": 1,
            "healthcare": 1,
            "discipline": 1,
            "people": 1,
            "life": 1,
            "stake": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para220",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 385,
              "end_char": 387,
              "context": "d using machine learning techniques. The field of AI will need to develop technical and ethical standa"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para221",
          "content": "•\nCybersecurity:\nAI techniques are useful in defending against cyberattack, for example by detecting unusual patterns of behavior, but they will also contribute to the potency, survivability, and proliferation capability of malware. For example, reinforcement learning methods have been used to create highly effective tools for automated, personalized blackmail and phishing attacks.",
          "sentence_count": 2,
          "char_count": 335,
          "prev_para_id": "chap1_para220",
          "next_para_id": "chap1_para222",
          "style_metadata": {
            "para_id": "chap1_para221",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 2
          },
          "terminology": {
            "cybersecurity": 1,
            "technique": 1,
            "useful": 1,
            "defending": 1,
            "cyberattack": 1,
            "example": 2,
            "detecting": 1,
            "unusual": 1,
            "pattern": 1,
            "behavior": 1,
            "contribute": 1,
            "potency": 1,
            "survivability": 1,
            "proliferation": 1,
            "capability": 1,
            "malware": 1,
            "reinforcement": 1,
            "learning": 1,
            "method": 1,
            "used": 1,
            "create": 1,
            "effective": 1,
            "tool": 1,
            "automated": 1,
            "personalized": 1,
            "blackmail": 1,
            "phishing": 1,
            "attack": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para222",
          "content": "We will revisit these topics in more depth in\nSection 28.3\n. As AI systems become more capable, they will take on more of the societal roles previously played by humans. Just as humans have used these roles in the past to perpetrate mischief, we can expect that humans may misuse AI systems in these roles to perpetrate even more mischief. All of the examples given above point to the importance of governance and, eventually, regulation. At present, the research community and the major corporations involved in AI research have developed voluntary self-governance principles for AI-related activities (see\nSection 28.3\n). Governments and international organizations are setting up advisory bodies to devise appropriate regulations for each specific use case, to prepare for the economic and social impacts, and to take advantage of AI capabilities to address major societal problems.",
          "sentence_count": 6,
          "char_count": 751,
          "prev_para_id": "chap1_para221",
          "next_para_id": "chap1_para223",
          "style_metadata": {
            "para_id": "chap1_para222",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 152,
            "sentence_count": 6
          },
          "terminology": {
            "revisit": 1,
            "topic": 1,
            "depth": 1,
            "section": 2,
            "system": 2,
            "become": 1,
            "capable": 1,
            "take": 2,
            "societal": 2,
            "role": 3,
            "played": 1,
            "human": 3,
            "used": 1,
            "past": 1,
            "perpetrate": 2,
            "mischief": 2,
            "expect": 1,
            "misuse": 1,
            "example": 1,
            "given": 1,
            "point": 1,
            "importance": 1,
            "governance": 1,
            "regulation": 2,
            "present": 1,
            "research": 2,
            "community": 1,
            "major": 2,
            "corporation": 1,
            "involved": 1,
            "developed": 1,
            "voluntary": 1,
            "self-governance": 1,
            "principle": 1,
            "ai-related": 1,
            "activity": 1,
            "see": 1,
            "government": 1,
            "international": 1,
            "organization": 1,
            "setting": 1,
            "advisory": 1,
            "body": 1,
            "devise": 1,
            "appropriate": 1,
            "specific": 1,
            "use": 1,
            "case": 1,
            "prepare": 1,
            "economic": 1,
            "social": 1,
            "impact": 1,
            "advantage": 1,
            "capability": 1,
            "address": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para222",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 64,
              "end_char": 66,
              "context": "t these topics in more depth in\nSection 28.3\n. As AI systems become more capable, they will take on mo"
            },
            {
              "para_id": "chap1_para222",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 280,
              "end_char": 282,
              "context": "te mischief, we can expect that humans may misuse AI systems in these roles to perpetrate even more mi"
            },
            {
              "para_id": "chap1_para222",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 513,
              "end_char": 515,
              "context": " community and the major corporations involved in AI research have developed voluntary self-governance"
            },
            {
              "para_id": "chap1_para222",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 581,
              "end_char": 583,
              "context": "eveloped voluntary self-governance principles for AI-related activities (see\nSection 28.3\n). Governmen"
            },
            {
              "para_id": "chap1_para222",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 834,
              "end_char": 836,
              "context": "omic and social impacts, and to take advantage of AI capabilities to address major societal problems."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para223",
          "content": "What of the longer term? Will we achieve the long-standing goal: the creation of intelligence comparable to or more capable than human intelligence? And, if we do, what then?",
          "sentence_count": 3,
          "char_count": 146,
          "prev_para_id": "chap1_para222",
          "next_para_id": "chap1_para224",
          "style_metadata": {
            "para_id": "chap1_para223",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 3
          },
          "terminology": {
            "longer": 1,
            "term": 1,
            "achieve": 1,
            "long-standing": 1,
            "goal": 1,
            "creation": 1,
            "intelligence": 2,
            "comparable": 1,
            "capable": 1,
            "human": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para224",
          "content": "For much of AI’s history, these questions have been overshadowed by the daily grind of getting AI systems to do anything even remotely intelligent. As with any broad discipline, the great majority of AI researchers have specialized in a specific subfield such as game-playing, knowledge representation, vision, or natural language understanding—often on the assumption that progress in these subfields would contribute to the broader goals of AI. Nils Nilsson (1995), one of the original leaders of the Shakey project at SRI, reminded the field of those broader goals and warned that the subfields were in danger of becoming ends in themselves. Later, some influential founders of AI, including John McCarthy (2007), Marvin Minsky (2007), and Patrick Winston (Beal and Winston, 2009), concurred with Nilsson’s warnings, suggesting that instead of focusing on measurable performance in specific applications, AI should return to its roots of striving for, in Herb Simon’s words, “machines that think, that learn and that create.” They called the effort\nhuman-level AI\nor HLAI—a machine should be able to learn to do anything a human can do. Their first symposium was in 2004 (Minsky\net al.,\n2004). Another effort with similar goals, the\nartificial general intelligence (AGI)\nmovement (Goertzel and Pennachin, 2007), held its first conference and organized the\nJournal of Artificial General Intelligence\nin 2008.",
          "sentence_count": 6,
          "char_count": 1202,
          "prev_para_id": "chap1_para223",
          "next_para_id": "chap1_para225",
          "style_metadata": {
            "para_id": "chap1_para224",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 267,
            "sentence_count": 6
          },
          "terminology": {
            "much": 1,
            "history": 1,
            "question": 1,
            "overshadowed": 1,
            "daily": 1,
            "grind": 1,
            "getting": 1,
            "system": 1,
            "anything": 2,
            "intelligent": 1,
            "broad": 1,
            "discipline": 1,
            "great": 1,
            "majority": 1,
            "researcher": 1,
            "specialized": 1,
            "specific": 2,
            "subfield": 1,
            "game-playing": 1,
            "knowledge": 1,
            "representation": 1,
            "vision": 1,
            "natural": 1,
            "language": 1,
            "understanding—often": 1,
            "assumption": 1,
            "progress": 1,
            "subfields": 2,
            "contribute": 1,
            "broader": 2,
            "goal": 3,
            "nil": 1,
            "nilsson": 2,
            "original": 1,
            "leader": 1,
            "shakey": 1,
            "project": 1,
            "sri": 1,
            "reminded": 1,
            "field": 1,
            "warned": 1,
            "becoming": 1,
            "end": 1,
            "influential": 1,
            "founder": 1,
            "including": 1,
            "john": 1,
            "mccarthy": 1,
            "marvin": 1,
            "minsky": 2,
            "patrick": 1,
            "winston": 2,
            "beal": 1,
            "concurred": 1,
            "warning": 1,
            "suggesting": 1,
            "focusing": 1,
            "measurable": 1,
            "performance": 1,
            "application": 1,
            "return": 1,
            "root": 1,
            "striving": 1,
            "herb": 1,
            "simon": 1,
            "word": 1,
            "machine": 2,
            "think": 1,
            "learn": 2,
            "create.": 1,
            "called": 1,
            "effort": 2,
            "human-level": 1,
            "hlai—a": 1,
            "able": 1,
            "human": 1,
            "first": 2,
            "symposium": 1,
            "similar": 1,
            "artificial": 2,
            "general": 2,
            "intelligence": 2,
            "agi": 1,
            "movement": 1,
            "goertzel": 1,
            "held": 1,
            "conference": 1,
            "organized": 1,
            "journal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para224",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 12,
              "end_char": 14,
              "context": "For much of AI’s history, these questions have been overshadowed"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 95,
              "end_char": 97,
              "context": "e been overshadowed by the daily grind of getting AI systems to do anything even remotely intelligent."
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 200,
              "end_char": 202,
              "context": " with any broad discipline, the great majority of AI researchers have specialized in a specific subfie"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 443,
              "end_char": 445,
              "context": "ubfields would contribute to the broader goals of AI. Nils Nilsson (1995), one of the original leaders"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Nils Nilsson",
              "entity_type": "PERSON",
              "start_char": 447,
              "end_char": 459,
              "context": "elds would contribute to the broader goals of AI. Nils Nilsson (1995), one of the original leaders of the Shakey"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Shakey",
              "entity_type": "ORG",
              "start_char": 503,
              "end_char": 509,
              "context": "ilsson (1995), one of the original leaders of the Shakey project at SRI, reminded the field of those broad"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 681,
              "end_char": 683,
              "context": "n themselves. Later, some influential founders of AI, including John McCarthy (2007), Marvin Minsky (2"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "John McCarthy",
              "entity_type": "PERSON",
              "start_char": 695,
              "end_char": 708,
              "context": "Later, some influential founders of AI, including John McCarthy (2007), Marvin Minsky (2007), and Patrick Winston"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Marvin Minsky",
              "entity_type": "PERSON",
              "start_char": 717,
              "end_char": 730,
              "context": "l founders of AI, including John McCarthy (2007), Marvin Minsky (2007), and Patrick Winston (Beal and Winston, 20"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Patrick Winston",
              "entity_type": "PERSON",
              "start_char": 743,
              "end_char": 758,
              "context": "g John McCarthy (2007), Marvin Minsky (2007), and Patrick Winston (Beal and Winston, 2009), concurred with Nilsson’"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Winston",
              "entity_type": "GPE",
              "start_char": 769,
              "end_char": 776,
              "context": "rvin Minsky (2007), and Patrick Winston (Beal and Winston, 2009), concurred with Nilsson’s warnings, sugges"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Nilsson’s",
              "entity_type": "ORG",
              "start_char": 800,
              "end_char": 809,
              "context": " Winston (Beal and Winston, 2009), concurred with Nilsson’s warnings, suggesting that instead of focusing on "
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 908,
              "end_char": 910,
              "context": " measurable performance in specific applications, AI should return to its roots of striving for, in He"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Herb Simon’s",
              "entity_type": "PERSON",
              "start_char": 958,
              "end_char": 970,
              "context": "AI should return to its roots of striving for, in Herb Simon’s words, “machines that think, that learn and that "
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "HLAI",
              "entity_type": "ORG",
              "start_char": 1070,
              "end_char": 1074,
              "context": "create.” They called the effort\nhuman-level AI\nor HLAI—a machine should be able to learn to do anything "
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 1185,
              "end_char": 1188,
              "context": " do. Their first symposium was in 2004 (Minsky\net al.,\n2004). Another effort with similar goals, the\nar"
            },
            {
              "para_id": "chap1_para224",
              "entity_text": "Journal of Artificial General Intelligence",
              "entity_type": "ORG",
              "start_char": 1359,
              "end_char": 1401,
              "context": "007), held its first conference and organized the\nJournal of Artificial General Intelligence\nin 2008."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para225",
          "content": "At around the same time, concerns were raised that creating\nartificial superintelligence\nor\nASI\n—intelligence that far surpasses human ability—might be a bad idea (Yudkowsky, 2008; Omohundro, 2008). Turing (1996) himself made the same point in a lecture given in Manchester in 1951, drawing on earlier ideas from Samuel Butler (1863):\n15\nIt seems probable that once the machine thinking method had started, it would not take long to outstrip our feeble powers. ... At some stage therefore we should have to expect the machines to take control, in the way that is mentioned in Samuel Butler’s\nErewhon.",
          "sentence_count": 3,
          "char_count": 510,
          "prev_para_id": "chap1_para224",
          "next_para_id": "chap1_para226",
          "style_metadata": {
            "para_id": "chap1_para225",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 117,
            "sentence_count": 3
          },
          "terminology": {
            "time": 1,
            "concern": 1,
            "raised": 1,
            "creating": 1,
            "artificial": 1,
            "superintelligence": 1,
            "asi": 1,
            "—intelligence": 1,
            "surpasses": 1,
            "human": 1,
            "ability—might": 1,
            "bad": 1,
            "idea": 2,
            "yudkowsky": 1,
            "turing": 1,
            "made": 1,
            "point": 1,
            "lecture": 1,
            "given": 1,
            "drawing": 1,
            "samuel": 2,
            "butler": 2,
            "seems": 1,
            "probable": 1,
            "machine": 2,
            "thinking": 1,
            "method": 1,
            "started": 1,
            "take": 2,
            "long": 1,
            "outstrip": 1,
            "feeble": 1,
            "power": 1,
            "stage": 1,
            "expect": 1,
            "control": 1,
            "way": 1,
            "mentioned": 1,
            "erewhon": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para225",
              "entity_text": "Yudkowsky",
              "entity_type": "PERSON",
              "start_char": 164,
              "end_char": 173,
              "context": " far surpasses human ability—might be a bad idea (Yudkowsky, 2008; Omohundro, 2008). Turing (1996) himself ma"
            },
            {
              "para_id": "chap1_para225",
              "entity_text": "Omohundro",
              "entity_type": "GPE",
              "start_char": 181,
              "end_char": 190,
              "context": "man ability—might be a bad idea (Yudkowsky, 2008; Omohundro, 2008). Turing (1996) himself made the same point"
            },
            {
              "para_id": "chap1_para225",
              "entity_text": "Manchester",
              "entity_type": "GPE",
              "start_char": 263,
              "end_char": 273,
              "context": "himself made the same point in a lecture given in Manchester in 1951, drawing on earlier ideas from Samuel But"
            },
            {
              "para_id": "chap1_para225",
              "entity_text": "Samuel Butler",
              "entity_type": "PERSON",
              "start_char": 313,
              "end_char": 326,
              "context": "Manchester in 1951, drawing on earlier ideas from Samuel Butler (1863):\n15\nIt seems probable that once the machin"
            },
            {
              "para_id": "chap1_para225",
              "entity_text": "Samuel Butler’s\nErewhon",
              "entity_type": "PERSON",
              "start_char": 576,
              "end_char": 599,
              "context": " to take control, in the way that is mentioned in Samuel Butler’s\nErewhon."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para226",
          "content": "These concerns have only become more widespread with recent advances in deep learning, the publication of books such as\nSuperintelligence\nby Nick Bostrom (2014), and public pronouncements from Stephen Hawking, Bill Gates, Martin Rees, and Elon Musk.",
          "sentence_count": 1,
          "char_count": 215,
          "prev_para_id": "chap1_para225",
          "next_para_id": "chap1_para227",
          "style_metadata": {
            "para_id": "chap1_para226",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 1
          },
          "terminology": {
            "concern": 1,
            "become": 1,
            "widespread": 1,
            "recent": 1,
            "advance": 1,
            "deep": 1,
            "learning": 1,
            "publication": 1,
            "book": 1,
            "superintelligence": 1,
            "public": 1,
            "pronouncement": 1,
            "stephen": 1,
            "hawking": 1,
            "bill": 1,
            "gate": 1,
            "martin": 1,
            "rees": 1,
            "elon": 1,
            "musk": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para226",
              "entity_text": "Nick Bostrom",
              "entity_type": "PERSON",
              "start_char": 141,
              "end_char": 153,
              "context": "publication of books such as\nSuperintelligence\nby Nick Bostrom (2014), and public pronouncements from Stephen Ha"
            },
            {
              "para_id": "chap1_para226",
              "entity_text": "Stephen Hawking",
              "entity_type": "PERSON",
              "start_char": 193,
              "end_char": 208,
              "context": "ck Bostrom (2014), and public pronouncements from Stephen Hawking, Bill Gates, Martin Rees, and Elon Musk."
            },
            {
              "para_id": "chap1_para226",
              "entity_text": "Bill Gates",
              "entity_type": "PERSON",
              "start_char": 210,
              "end_char": 220,
              "context": ", and public pronouncements from Stephen Hawking, Bill Gates, Martin Rees, and Elon Musk."
            },
            {
              "para_id": "chap1_para226",
              "entity_text": "Martin Rees",
              "entity_type": "PERSON",
              "start_char": 222,
              "end_char": 233,
              "context": " pronouncements from Stephen Hawking, Bill Gates, Martin Rees, and Elon Musk."
            },
            {
              "para_id": "chap1_para226",
              "entity_text": "Elon Musk",
              "entity_type": "PERSON",
              "start_char": 239,
              "end_char": 248,
              "context": "rom Stephen Hawking, Bill Gates, Martin Rees, and Elon Musk."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para227",
          "content": "Experiencing a general sense of unease with the idea of creating superintelligent machines is only natural. We might call this the\ngorilla problem\n: about seven million years ago, a now-extinct primate evolved, with one branch leading to gorillas and one to humans. Today, the gorillas are not too happy about the human branch; they have essentially no control over their future. If this is the result of success in creating superhuman AI—that humans cede control over their future—then perhaps we should stop work on AI, and, as a corollary, give up the benefits it might bring. This is the essence of Turing’s warning: it is not obvious that we can control machines that are more intelligent than us.",
          "sentence_count": 5,
          "char_count": 586,
          "prev_para_id": "chap1_para226",
          "next_para_id": "chap1_para228",
          "style_metadata": {
            "para_id": "chap1_para227",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 5
          },
          "terminology": {
            "experiencing": 1,
            "general": 1,
            "sense": 1,
            "unease": 1,
            "idea": 1,
            "creating": 2,
            "superintelligent": 1,
            "machine": 2,
            "natural": 1,
            "call": 1,
            "gorilla": 3,
            "problem": 1,
            "year": 1,
            "now-extinct": 1,
            "primate": 1,
            "evolved": 1,
            "branch": 2,
            "leading": 1,
            "human": 3,
            "today": 1,
            "happy": 1,
            "control": 3,
            "future": 1,
            "result": 1,
            "success": 1,
            "superhuman": 1,
            "cede": 1,
            "future—then": 1,
            "stop": 1,
            "work": 1,
            "corollary": 1,
            "give": 1,
            "benefit": 1,
            "bring": 1,
            "essence": 1,
            "turing": 1,
            "warning": 1,
            "obvious": 1,
            "intelligent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para227",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 436,
              "end_char": 438,
              "context": "s is the result of success in creating superhuman AI—that humans cede control over their future—then p"
            },
            {
              "para_id": "chap1_para227",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 518,
              "end_char": 520,
              "context": " their future—then perhaps we should stop work on AI, and, as a corollary, give up the benefits it mig"
            },
            {
              "para_id": "chap1_para227",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 603,
              "end_char": 609,
              "context": "e benefits it might bring. This is the essence of Turing’s warning: it is not obvious that we can control "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para228",
          "content": "If superhuman AI were a black box that arrived from outer space, then indeed it would be wise to exercise caution in opening the box. But it is not:\nwe\ndesign the AI systems, so if they do end up “taking control,” as Turing suggests, it would be the result of a design failure.",
          "sentence_count": 2,
          "char_count": 226,
          "prev_para_id": "chap1_para227",
          "next_para_id": "chap1_para229",
          "style_metadata": {
            "para_id": "chap1_para228",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "superhuman": 1,
            "black": 1,
            "box": 2,
            "arrived": 1,
            "outer": 1,
            "space": 1,
            "wise": 1,
            "exercise": 1,
            "caution": 1,
            "opening": 1,
            "design": 2,
            "system": 1,
            "end": 1,
            "taking": 1,
            "control": 1,
            "turing": 1,
            "suggests": 1,
            "result": 1,
            "failure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para228",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 14,
              "end_char": 16,
              "context": "If superhuman AI were a black box that arrived from outer space, t"
            },
            {
              "para_id": "chap1_para228",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 163,
              "end_char": 165,
              "context": " in opening the box. But it is not:\nwe\ndesign the AI systems, so if they do end up “taking control,” a"
            },
            {
              "para_id": "chap1_para228",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 217,
              "end_char": 223,
              "context": "ystems, so if they do end up “taking control,” as Turing suggests, it would be the result of a design fail"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para229",
          "content": "To avoid such an outcome, we need to understand the source of potential failure. Norbert Wiener (1960), who was motivated to consider the long-term future of AI after seeing Arthur Samuel’s checker-playing program learn to beat its creator, had this to say:\nIf we use, to achieve our purposes, a mechanical agency with whose operation we cannot interfere effectively ... we had better be quite sure that the purpose put into the machine is the purpose which we really desire.",
          "sentence_count": 2,
          "char_count": 397,
          "prev_para_id": "chap1_para228",
          "next_para_id": "chap1_para230",
          "style_metadata": {
            "para_id": "chap1_para229",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 46.5,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 93,
            "sentence_count": 2
          },
          "terminology": {
            "avoid": 1,
            "outcome": 1,
            "need": 1,
            "understand": 1,
            "source": 1,
            "potential": 1,
            "failure": 1,
            "norbert": 1,
            "wiener": 1,
            "motivated": 1,
            "consider": 1,
            "long-term": 1,
            "future": 1,
            "seeing": 1,
            "arthur": 1,
            "samuel": 1,
            "checker-playing": 1,
            "program": 1,
            "learn": 1,
            "beat": 1,
            "creator": 1,
            "say": 1,
            "achieve": 1,
            "purpose": 3,
            "mechanical": 1,
            "agency": 1,
            "operation": 1,
            "sure": 1,
            "put": 1,
            "machine": 1,
            "desire": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para229",
              "entity_text": "Norbert Wiener",
              "entity_type": "PERSON",
              "start_char": 81,
              "end_char": 95,
              "context": "ed to understand the source of potential failure. Norbert Wiener (1960), who was motivated to consider the long-te"
            },
            {
              "para_id": "chap1_para229",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 158,
              "end_char": 160,
              "context": "was motivated to consider the long-term future of AI after seeing Arthur Samuel’s checker-playing prog"
            },
            {
              "para_id": "chap1_para229",
              "entity_text": "Arthur Samuel’s",
              "entity_type": "PERSON",
              "start_char": 174,
              "end_char": 189,
              "context": " consider the long-term future of AI after seeing Arthur Samuel’s checker-playing program learn to beat its creator"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para230",
          "content": "Many cultures have myths of humans who ask gods, genies, magicians, or devils for something. Invariably, in these stories, they get what they literally ask for, and then regret it. The third wish, if there is one, is to undo the first two. We will call this the\nKing Midas problem\n: Midas, a legendary King in Greek mythology, asked that everything he touched should turn to gold, but then regretted it after touching his food, drink, and family members.",
          "sentence_count": 4,
          "char_count": 377,
          "prev_para_id": "chap1_para229",
          "next_para_id": "chap1_para231",
          "style_metadata": {
            "para_id": "chap1_para230",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 97,
            "sentence_count": 4
          },
          "terminology": {
            "many": 1,
            "culture": 1,
            "myth": 1,
            "human": 1,
            "ask": 2,
            "god": 1,
            "genie": 1,
            "magician": 1,
            "devil": 1,
            "something": 1,
            "story": 1,
            "get": 1,
            "regret": 1,
            "third": 1,
            "wish": 1,
            "undo": 1,
            "call": 1,
            "king": 2,
            "midas": 2,
            "problem": 1,
            "legendary": 1,
            "greek": 1,
            "mythology": 1,
            "asked": 1,
            "everything": 1,
            "touched": 1,
            "turn": 1,
            "gold": 1,
            "regretted": 1,
            "touching": 1,
            "food": 1,
            "drink": 1,
            "family": 1,
            "member": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para230",
              "entity_text": "King Midas",
              "entity_type": "GPE",
              "start_char": 262,
              "end_char": 272,
              "context": ", is to undo the first two. We will call this the\nKing Midas problem\n: Midas, a legendary King in Greek mythol"
            },
            {
              "para_id": "chap1_para230",
              "entity_text": "Midas",
              "entity_type": "PERSON",
              "start_char": 283,
              "end_char": 288,
              "context": "t two. We will call this the\nKing Midas problem\n: Midas, a legendary King in Greek mythology, asked that "
            },
            {
              "para_id": "chap1_para230",
              "entity_text": "King",
              "entity_type": "PERSON",
              "start_char": 302,
              "end_char": 306,
              "context": " this the\nKing Midas problem\n: Midas, a legendary King in Greek mythology, asked that everything he touc"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para231",
          "content": "16\nWe touched on this issue in\nSection 1.1.5\n, where we pointed out the need for a significant modification to the standard model of putting fixed objectives into the machine. The solution to Wiener’s predicament is not to have a definite “purpose put into the machine” at all. Instead, we want machines that strive to achieve human objectives but know that they don’t know for certain exactly what those objectives are.",
          "sentence_count": 3,
          "char_count": 352,
          "prev_para_id": "chap1_para230",
          "next_para_id": "chap1_para232",
          "style_metadata": {
            "para_id": "chap1_para231",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 3
          },
          "terminology": {
            "touched": 1,
            "issue": 1,
            "section": 1,
            "pointed": 1,
            "need": 1,
            "significant": 1,
            "modification": 1,
            "standard": 1,
            "model": 1,
            "putting": 1,
            "fixed": 1,
            "objective": 3,
            "machine": 3,
            "solution": 1,
            "wiener": 1,
            "predicament": 1,
            "definite": 1,
            "purpose": 1,
            "put": 1,
            "want": 1,
            "strive": 1,
            "achieve": 1,
            "human": 1,
            "know": 2,
            "certain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para231",
              "entity_text": "Wiener",
              "entity_type": "ORG",
              "start_char": 192,
              "end_char": 198,
              "context": "ixed objectives into the machine. The solution to Wiener’s predicament is not to have a definite “purpose "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para232",
          "content": "It is perhaps unfortunate that almost all AI research to date has been carried out within the standard model, which means that almost all of the technical material in this edition reflects that intellectual framework. There are, however, some early results within the new framework. In\nChapter 15\n, we show that a machine has a positive incentive to allow itself to be switched off if and only if it is uncertain about the human objective. In\nChapter 17\n, we formulate and study\nassistance games\n, which describe mathematically the situation in which a human has an objective and a machine tries to achieve it, but is initially uncertain about what it is. In\nChapter 23\n, we explain the methods of\ninverse reinforcement learning\nthat allow machines to learn more about human preferences from observations of the choices that humans make. In\nChapter 28\n, we explore two of the principal difficulties: first, that our choices depend on our preferences through a very complex cognitive architecture that is hard to invert; and, second, that we humans may not have consistent preferences in the first place—either individually or as a group—so it may not be clear what AI systems\nshould\nbe doing for us.",
          "sentence_count": 6,
          "char_count": 1009,
          "prev_para_id": "chap1_para231",
          "next_para_id": "chap1_para233",
          "style_metadata": {
            "para_id": "chap1_para232",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 36.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 220,
            "sentence_count": 6
          },
          "terminology": {
            "unfortunate": 1,
            "research": 1,
            "date": 1,
            "carried": 1,
            "standard": 1,
            "model": 1,
            "mean": 1,
            "technical": 1,
            "material": 1,
            "edition": 1,
            "reflects": 1,
            "intellectual": 1,
            "framework": 2,
            "early": 1,
            "result": 1,
            "new": 1,
            "chapter": 4,
            "show": 1,
            "machine": 3,
            "positive": 1,
            "incentive": 1,
            "allow": 2,
            "switched": 1,
            "uncertain": 2,
            "human": 5,
            "objective": 2,
            "formulate": 1,
            "study": 1,
            "assistance": 1,
            "game": 1,
            "describe": 1,
            "situation": 1,
            "try": 1,
            "achieve": 1,
            "explain": 1,
            "method": 1,
            "inverse": 1,
            "reinforcement": 1,
            "learning": 1,
            "learn": 1,
            "preference": 3,
            "observation": 1,
            "choice": 2,
            "make": 1,
            "explore": 1,
            "principal": 1,
            "difficulty": 1,
            "first": 1,
            "depend": 1,
            "complex": 1,
            "cognitive": 1,
            "architecture": 1,
            "hard": 1,
            "invert": 1,
            "second": 1,
            "consistent": 1,
            "group—so": 1,
            "clear": 1,
            "system": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para232",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 42,
              "end_char": 44,
              "context": "It is perhaps unfortunate that almost all AI research to date has been carried out within the "
            },
            {
              "para_id": "chap1_para232",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 1165,
              "end_char": 1167,
              "context": "idually or as a group—so it may not be clear what AI systems\nshould\nbe doing for us."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para233",
          "content": "Summary\nSummary\nThis chapter defines AI and establishes the cultural background against which it has developed. Some of the important points are as follows:\n•\nDifferent people approach AI with different goals in mind. Two important questions to ask are: Are you concerned with thinking, or behavior? Do you want to model humans, or try to achieve the optimal results?",
          "sentence_count": 4,
          "char_count": 312,
          "prev_para_id": "chap1_para232",
          "next_para_id": "chap1_para234",
          "style_metadata": {
            "para_id": "chap1_para233",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 4
          },
          "terminology": {
            "summary": 2,
            "chapter": 1,
            "defines": 1,
            "establishes": 1,
            "cultural": 1,
            "background": 1,
            "developed": 1,
            "important": 2,
            "point": 1,
            "follows": 1,
            "different": 2,
            "people": 1,
            "approach": 1,
            "goal": 1,
            "mind": 1,
            "question": 1,
            "ask": 1,
            "concerned": 1,
            "thinking": 1,
            "behavior": 1,
            "want": 1,
            "model": 1,
            "human": 1,
            "try": 1,
            "achieve": 1,
            "optimal": 1,
            "result": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para233",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 37,
              "end_char": 39,
              "context": "Summary\nSummary\nThis chapter defines AI and establishes the cultural background against w"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para234",
          "content": "•\nAccording to what we have called the standard model, AI is concerned mainly with\nrational action\n. An ideal\nintelligent agent\ntakes the best possible action in a situation. We study the problem of building agents that are intelligent in this sense.",
          "sentence_count": 3,
          "char_count": 213,
          "prev_para_id": "chap1_para233",
          "next_para_id": "chap1_para235",
          "style_metadata": {
            "para_id": "chap1_para234",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.33,
            "passive_voice_ratio": 0.022,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 3
          },
          "terminology": {
            "according": 1,
            "called": 1,
            "standard": 1,
            "model": 1,
            "concerned": 1,
            "rational": 1,
            "action": 2,
            "ideal": 1,
            "intelligent": 2,
            "agent": 2,
            "take": 1,
            "possible": 1,
            "situation": 1,
            "study": 1,
            "problem": 1,
            "building": 1,
            "sense": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para234",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 55,
              "end_char": 57,
              "context": "ording to what we have called the standard model, AI is concerned mainly with\nrational action\n. An ide"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para235",
          "content": "•\nTwo refinements to this simple idea are needed: first, the ability of any agent, human or otherwise, to choose rational actions is limited by the computational intractability of doing so; second, the concept of a machine that pursues a definite objective needs to be replaced with that of a machine pursuing objectives to benefit humans, but uncertain as to what those objectives are.",
          "sentence_count": 1,
          "char_count": 324,
          "prev_para_id": "chap1_para234",
          "next_para_id": "chap1_para236",
          "style_metadata": {
            "para_id": "chap1_para235",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 72.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 1
          },
          "terminology": {
            "refinement": 1,
            "simple": 1,
            "idea": 1,
            "needed": 1,
            "first": 1,
            "ability": 1,
            "agent": 1,
            "human": 2,
            "choose": 1,
            "rational": 1,
            "action": 1,
            "limited": 1,
            "computational": 1,
            "intractability": 1,
            "second": 1,
            "concept": 1,
            "machine": 2,
            "pursues": 1,
            "definite": 1,
            "objective": 3,
            "need": 1,
            "replaced": 1,
            "pursuing": 1,
            "benefit": 1,
            "uncertain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para236",
          "content": "•\nPhilosophers (going back to 400\nBCE\n) made AI conceivable by suggesting that the mind is in some ways like a machine, that it operates on knowledge encoded in some internal language, and that thought can be used to choose what actions to take.",
          "sentence_count": 1,
          "char_count": 204,
          "prev_para_id": "chap1_para235",
          "next_para_id": "chap1_para237",
          "style_metadata": {
            "para_id": "chap1_para236",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 1
          },
          "terminology": {
            "philosopher": 1,
            "going": 1,
            "bce": 1,
            "made": 1,
            "conceivable": 1,
            "suggesting": 1,
            "mind": 1,
            "way": 1,
            "machine": 1,
            "operates": 1,
            "knowledge": 1,
            "encoded": 1,
            "internal": 1,
            "language": 1,
            "thought": 1,
            "used": 1,
            "choose": 1,
            "action": 1,
            "take": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para236",
              "entity_text": "•\nPhilosophers",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 14,
              "context": "•\nPhilosophers (going back to 400\nBCE\n) made AI conceivable by s"
            },
            {
              "para_id": "chap1_para236",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 45,
              "end_char": 47,
              "context": "•\nPhilosophers (going back to 400\nBCE\n) made AI conceivable by suggesting that the mind is in som"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para237",
          "content": "•\nMathematicians provided the tools to manipulate statements of logical certainty as well as uncertain, probabilistic statements. They also set the groundwork for understanding computation and reasoning about algorithms.",
          "sentence_count": 2,
          "char_count": 193,
          "prev_para_id": "chap1_para236",
          "next_para_id": "chap1_para238",
          "style_metadata": {
            "para_id": "chap1_para237",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 2
          },
          "terminology": {
            "mathematician": 1,
            "provided": 1,
            "tool": 1,
            "manipulate": 1,
            "statement": 2,
            "logical": 1,
            "certainty": 1,
            "uncertain": 1,
            "probabilistic": 1,
            "set": 1,
            "groundwork": 1,
            "understanding": 1,
            "computation": 1,
            "reasoning": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para238",
          "content": "•\nEconomists formalized the problem of making decisions that maximize the expected utility to the decision maker.",
          "sentence_count": 1,
          "char_count": 98,
          "prev_para_id": "chap1_para237",
          "next_para_id": "chap1_para239",
          "style_metadata": {
            "para_id": "chap1_para238",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "economist": 1,
            "formalized": 1,
            "problem": 1,
            "making": 1,
            "decision": 2,
            "maximize": 1,
            "expected": 1,
            "utility": 1,
            "maker": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para239",
          "content": "•\nNeuroscientists discovered some facts about how the brain works and the ways in which it is similar to and different from computers.",
          "sentence_count": 1,
          "char_count": 113,
          "prev_para_id": "chap1_para238",
          "next_para_id": "chap1_para240",
          "style_metadata": {
            "para_id": "chap1_para239",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "neuroscientist": 1,
            "discovered": 1,
            "fact": 1,
            "brain": 1,
            "work": 1,
            "way": 1,
            "similar": 1,
            "different": 1,
            "computer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para240",
          "content": "•\nPsychologists adopted the idea that humans and animals can be considered information-processing machines. Linguists showed that language use fits into this model.",
          "sentence_count": 2,
          "char_count": 143,
          "prev_para_id": "chap1_para239",
          "next_para_id": "chap1_para241",
          "style_metadata": {
            "para_id": "chap1_para240",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 2
          },
          "terminology": {
            "psychologist": 1,
            "adopted": 1,
            "idea": 1,
            "human": 1,
            "animal": 1,
            "considered": 1,
            "information-processing": 1,
            "machine": 1,
            "linguist": 1,
            "showed": 1,
            "language": 1,
            "use": 1,
            "fit": 1,
            "model": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para241",
          "content": "•\nComputer engineers provided the ever-more-powerful machines that make AI applications possible, and software engineers made them more usable.",
          "sentence_count": 1,
          "char_count": 126,
          "prev_para_id": "chap1_para240",
          "next_para_id": "chap1_para242",
          "style_metadata": {
            "para_id": "chap1_para241",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "computer": 1,
            "engineer": 2,
            "provided": 1,
            "ever-more-powerful": 1,
            "machine": 1,
            "make": 1,
            "application": 1,
            "possible": 1,
            "software": 1,
            "made": 1,
            "usable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para242",
          "content": "•\nControl theory deals with designing devices that act optimally on the basis of feedback from the environment. Initially, the mathematical tools of control theory were quite different from those used in AI, but the fields are coming closer together.",
          "sentence_count": 2,
          "char_count": 212,
          "prev_para_id": "chap1_para241",
          "next_para_id": "chap1_para243",
          "style_metadata": {
            "para_id": "chap1_para242",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "control": 2,
            "theory": 2,
            "deal": 1,
            "designing": 1,
            "device": 1,
            "act": 1,
            "basis": 1,
            "feedback": 1,
            "environment": 1,
            "mathematical": 1,
            "tool": 1,
            "different": 1,
            "used": 1,
            "field": 1,
            "coming": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para242",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 204,
              "end_char": 206,
              "context": "ol theory were quite different from those used in AI, but the fields are coming closer together."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para243",
          "content": "•\nThe history of AI has had cycles of success, misplaced optimism, and resulting cutbacks in enthusiasm and funding. There have also been cycles of introducing new, creative approaches and systematically refining the best ones.",
          "sentence_count": 2,
          "char_count": 194,
          "prev_para_id": "chap1_para242",
          "next_para_id": "chap1_para244",
          "style_metadata": {
            "para_id": "chap1_para243",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 2
          },
          "terminology": {
            "history": 1,
            "cycle": 2,
            "success": 1,
            "misplaced": 1,
            "optimism": 1,
            "resulting": 1,
            "cutback": 1,
            "enthusiasm": 1,
            "funding": 1,
            "introducing": 1,
            "new": 1,
            "creative": 1,
            "approach": 1,
            "refining": 1,
            "best": 1,
            "one": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para243",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 17,
              "end_char": 19,
              "context": "•\nThe history of AI has had cycles of success, misplaced optimism, an"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para244",
          "content": "•\nAI has matured considerably compared to its early decades, both theoretically and methodologically. As the problems that AI deals with became more complex, the field moved from Boolean logic to probabilistic reasoning, and from hand-crafted knowledge to machine learning from data. This has led to improvements in the capabilities of real systems and greater integration with other disciplines.",
          "sentence_count": 3,
          "char_count": 339,
          "prev_para_id": "chap1_para243",
          "next_para_id": "chap1_para245",
          "style_metadata": {
            "para_id": "chap1_para244",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 3
          },
          "terminology": {
            "matured": 1,
            "compared": 1,
            "early": 1,
            "decade": 1,
            "problem": 1,
            "deal": 1,
            "became": 1,
            "complex": 1,
            "field": 1,
            "moved": 1,
            "boolean": 1,
            "logic": 1,
            "probabilistic": 1,
            "reasoning": 1,
            "hand-crafted": 1,
            "knowledge": 1,
            "machine": 1,
            "learning": 1,
            "data": 1,
            "led": 1,
            "improvement": 1,
            "capability": 1,
            "real": 1,
            "system": 1,
            "greater": 1,
            "integration": 1,
            "discipline": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para244",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 123,
              "end_char": 125,
              "context": "ically and methodologically. As the problems that AI deals with became more complex, the field moved f"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para245",
          "content": "•\nAs AI systems find application in the real world, it has become necessary to consider a wide range of risks and ethical consequences.",
          "sentence_count": 1,
          "char_count": 113,
          "prev_para_id": "chap1_para244",
          "next_para_id": "chap1_para246",
          "style_metadata": {
            "para_id": "chap1_para245",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "system": 1,
            "find": 1,
            "application": 1,
            "real": 1,
            "world": 1,
            "become": 1,
            "necessary": 1,
            "consider": 1,
            "wide": 1,
            "range": 1,
            "risk": 1,
            "ethical": 1,
            "consequence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para245",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 5,
              "end_char": 7,
              "context": "•\nAs AI systems find application in the real world, it ha"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para246",
          "content": "•\nIn the longer term, we face the difficult problem of controlling superintelligent AI systems that may evolve in unpredictable ways. Solving this problem seems to necessitate a change in our conception of AI.",
          "sentence_count": 2,
          "char_count": 177,
          "prev_para_id": "chap1_para245",
          "next_para_id": "chap1_para247",
          "style_metadata": {
            "para_id": "chap1_para246",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "longer": 1,
            "term": 1,
            "face": 1,
            "difficult": 1,
            "problem": 2,
            "controlling": 1,
            "superintelligent": 1,
            "system": 1,
            "evolve": 1,
            "unpredictable": 1,
            "way": 1,
            "solving": 1,
            "seems": 1,
            "necessitate": 1,
            "change": 1,
            "conception": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para246",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 84,
              "end_char": 86,
              "context": "difficult problem of controlling superintelligent AI systems that may evolve in unpredictable ways. So"
            },
            {
              "para_id": "chap1_para246",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 206,
              "end_char": 208,
              "context": "eems to necessitate a change in our conception of AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para247",
          "content": "Bibliographical and Historical Notes\nBibliographical and Historical Notes\nA comprehensive history of AI is given by Nils Nilsson (2009), one of the early pioneers of the field. Pedro Domingos (2015) and Melanie Mitchell (2019) give overviews of machine learning for a general audience, and Kai-Fu Lee (2018) describes the race for international leadership in AI. Martin Ford (2018) interviews 23 leading AI researchers.",
          "sentence_count": 3,
          "char_count": 359,
          "prev_para_id": "chap1_para246",
          "next_para_id": "chap1_para248",
          "style_metadata": {
            "para_id": "chap1_para247",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "bibliographical": 2,
            "historical": 2,
            "note": 2,
            "comprehensive": 1,
            "history": 1,
            "given": 1,
            "nil": 1,
            "early": 1,
            "pioneer": 1,
            "field": 1,
            "pedro": 1,
            "domingo": 1,
            "give": 1,
            "overview": 1,
            "machine": 1,
            "learning": 1,
            "general": 1,
            "audience": 1,
            "kai-fu": 1,
            "lee": 1,
            "describes": 1,
            "race": 1,
            "international": 1,
            "leadership": 1,
            "martin": 1,
            "ford": 1,
            "interview": 1,
            "leading": 1,
            "researcher": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para247",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 101,
              "end_char": 103,
              "context": "l and Historical Notes\nA comprehensive history of AI is given by Nils Nilsson (2009), one of the early"
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "Nils Nilsson",
              "entity_type": "PERSON",
              "start_char": 116,
              "end_char": 128,
              "context": "l Notes\nA comprehensive history of AI is given by Nils Nilsson (2009), one of the early pioneers of the field. P"
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "Pedro Domingos",
              "entity_type": "PERSON",
              "start_char": 177,
              "end_char": 191,
              "context": "n (2009), one of the early pioneers of the field. Pedro Domingos (2015) and Melanie Mitchell (2019) give overviews"
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "Melanie Mitchell",
              "entity_type": "PERSON",
              "start_char": 203,
              "end_char": 219,
              "context": " pioneers of the field. Pedro Domingos (2015) and Melanie Mitchell (2019) give overviews of machine learning for a g"
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "Kai-Fu Lee",
              "entity_type": "PERSON",
              "start_char": 290,
              "end_char": 300,
              "context": "s of machine learning for a general audience, and Kai-Fu Lee (2018) describes the race for international leade"
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 359,
              "end_char": 361,
              "context": "escribes the race for international leadership in AI. Martin Ford (2018) interviews 23 leading AI rese"
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "Martin Ford",
              "entity_type": "PERSON",
              "start_char": 363,
              "end_char": 374,
              "context": "ibes the race for international leadership in AI. Martin Ford (2018) interviews 23 leading AI researchers."
            },
            {
              "para_id": "chap1_para247",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 404,
              "end_char": 406,
              "context": "p in AI. Martin Ford (2018) interviews 23 leading AI researchers."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para248",
          "content": "The main professional societies for AI are the Association for the Advancement of Artificial Intelligence (AAAI), the ACM Special Interest Group in Artificial Intelligence (SIGAI, formerly SIGART), the European Association for AI, and the Society for Artificial Intelligence and Simulation of Behaviour (AISB). The Partnership on AI brings together many commercial and nonprofit organizations concerned with the ethical and social impacts of AI. AAAI’s\nAI Magazine\ncontains many topical and tutorial articles, and its Web site,\naaai.org\n, contains news, tutorials, and background information.",
          "sentence_count": 3,
          "char_count": 513,
          "prev_para_id": "chap1_para247",
          "next_para_id": "chap1_para249",
          "style_metadata": {
            "para_id": "chap1_para248",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 3
          },
          "terminology": {
            "main": 1,
            "professional": 1,
            "society": 2,
            "association": 2,
            "advancement": 1,
            "artificial": 3,
            "intelligence": 3,
            "aaai": 2,
            "acm": 1,
            "special": 1,
            "interest": 1,
            "group": 1,
            "sigai": 1,
            "sigart": 1,
            "european": 1,
            "simulation": 1,
            "behaviour": 1,
            "aisb": 1,
            "partnership": 1,
            "brings": 1,
            "many": 2,
            "commercial": 1,
            "nonprofit": 1,
            "organization": 1,
            "concerned": 1,
            "ethical": 1,
            "social": 1,
            "impact": 1,
            "magazine": 1,
            "contains": 2,
            "topical": 1,
            "tutorial": 2,
            "article": 1,
            "web": 1,
            "site": 1,
            "aaai.org": 1,
            "news": 1,
            "background": 1,
            "information": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para248",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 36,
              "end_char": 38,
              "context": "The main professional societies for AI are the Association for the Advancement of Artifi"
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "the ACM Special Interest Group",
              "entity_type": "ORG",
              "start_char": 114,
              "end_char": 144,
              "context": "he Advancement of Artificial Intelligence (AAAI), the ACM Special Interest Group in Artificial Intelligence (SIGAI, formerly SIGAR"
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "Artificial Intelligence",
              "entity_type": "GPE",
              "start_char": 148,
              "end_char": 171,
              "context": "ligence (AAAI), the ACM Special Interest Group in Artificial Intelligence (SIGAI, formerly SIGART), the European Associatio"
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "the European Association for AI",
              "entity_type": "ORG",
              "start_char": 198,
              "end_char": 229,
              "context": "Artificial Intelligence (SIGAI, formerly SIGART), the European Association for AI, and the Society for Artificial Intelligence and "
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "the Society for Artificial Intelligence and Simulation of Behaviour",
              "entity_type": "ORG",
              "start_char": 235,
              "end_char": 302,
              "context": "rly SIGART), the European Association for AI, and the Society for Artificial Intelligence and Simulation of Behaviour (AISB). The Partnership on AI brings together man"
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "The Partnership on AI",
              "entity_type": "ORG",
              "start_char": 311,
              "end_char": 332,
              "context": " Intelligence and Simulation of Behaviour (AISB). The Partnership on AI brings together many commercial and nonprofit org"
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 442,
              "end_char": 444,
              "context": " concerned with the ethical and social impacts of AI. AAAI’s\nAI Magazine\ncontains many topical and tut"
            },
            {
              "para_id": "chap1_para248",
              "entity_text": "AAAI",
              "entity_type": "ORG",
              "start_char": 446,
              "end_char": 450,
              "context": "cerned with the ethical and social impacts of AI. AAAI’s\nAI Magazine\ncontains many topical and tutorial "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para249",
          "content": "The most recent work appears in the proceedings of the major AI conferences: the International Joint Conference on AI (IJCAI), the annual European Conference on AI (ECAI), and the AAAI Conference. Machine learning is covered by the International Conference on Machine Learning and the Neural Information Processing Systems (NeurIPS) meeting. The major journals for general AI are\nArtificial Intelligence, Computational Intelligence,\nthe\nIEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Intelligent Systems,\nand the\nJournal of Artificial Intelligence Research\n. There are also many conferences and journals devoted to specific areas, which we cover in the appropriate chapters.",
          "sentence_count": 4,
          "char_count": 604,
          "prev_para_id": "chap1_para248",
          "next_para_id": "chap1_para250",
          "style_metadata": {
            "para_id": "chap1_para249",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 116,
            "sentence_count": 4
          },
          "terminology": {
            "recent": 1,
            "work": 1,
            "appears": 1,
            "proceeding": 1,
            "major": 2,
            "conference": 6,
            "international": 2,
            "joint": 1,
            "ijcai": 1,
            "annual": 1,
            "european": 1,
            "ecai": 1,
            "aaai": 1,
            "machine": 3,
            "learning": 2,
            "covered": 1,
            "neural": 1,
            "information": 1,
            "processing": 1,
            "system": 2,
            "meeting": 1,
            "journal": 3,
            "general": 1,
            "artificial": 2,
            "intelligence": 4,
            "computational": 1,
            "ieee": 2,
            "transaction": 1,
            "pattern": 1,
            "analysis": 1,
            "intelligent": 1,
            "research": 1,
            "many": 1,
            "devoted": 1,
            "specific": 1,
            "area": 1,
            "cover": 1,
            "appropriate": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para249",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 61,
              "end_char": 63,
              "context": "cent work appears in the proceedings of the major AI conferences: the International Joint Conference o"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "the International Joint Conference on AI (IJCAI",
              "entity_type": "ORG",
              "start_char": 77,
              "end_char": 124,
              "context": "s in the proceedings of the major AI conferences: the International Joint Conference on AI (IJCAI), the annual European Conference on AI (ECAI), an"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "European Conference on AI",
              "entity_type": "ORG",
              "start_char": 138,
              "end_char": 163,
              "context": "tional Joint Conference on AI (IJCAI), the annual European Conference on AI (ECAI), and the AAAI Conference. Machine learning"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "the AAAI Conference",
              "entity_type": "ORG",
              "start_char": 176,
              "end_char": 195,
              "context": " the annual European Conference on AI (ECAI), and the AAAI Conference. Machine learning is covered by the International"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "the International Conference on Machine Learning",
              "entity_type": "ORG",
              "start_char": 228,
              "end_char": 276,
              "context": "e AAAI Conference. Machine learning is covered by the International Conference on Machine Learning and the Neural Information Processing Systems (Ne"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "the Neural Information Processing Systems",
              "entity_type": "ORG",
              "start_char": 281,
              "end_char": 322,
              "context": " International Conference on Machine Learning and the Neural Information Processing Systems (NeurIPS) meeting. The major journals for general"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "Artificial Intelligence",
              "entity_type": "ORG",
              "start_char": 380,
              "end_char": 403,
              "context": "S) meeting. The major journals for general AI are\nArtificial Intelligence, Computational Intelligence,\nthe\nIEEE Transaction"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "Pattern Analysis",
              "entity_type": "ORG",
              "start_char": 458,
              "end_char": 474,
              "context": "putational Intelligence,\nthe\nIEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Intelligent System"
            },
            {
              "para_id": "chap1_para249",
              "entity_text": "the\nJournal of Artificial Intelligence Research",
              "entity_type": "ORG",
              "start_char": 531,
              "end_char": 578,
              "context": "chine Intelligence, IEEE Intelligent Systems,\nand the\nJournal of Artificial Intelligence Research\n. There are also many conferences and journals de"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para250",
          "content": "1\nIn the public eye, there is sometimes confusion between the terms “artificial intelligence” and “machine learning.” Machine learning is a subfield of AI that studies the ability to improve performance based on experience. Some AI systems use machine learning methods to achieve competence, but some do not.",
          "sentence_count": 2,
          "char_count": 262,
          "prev_para_id": "chap1_para249",
          "next_para_id": "chap1_para251",
          "style_metadata": {
            "para_id": "chap1_para250",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 56,
            "sentence_count": 2
          },
          "terminology": {
            "public": 1,
            "eye": 1,
            "confusion": 1,
            "term": 1,
            "artificial": 1,
            "intelligence": 1,
            "machine": 3,
            "learning.": 1,
            "learning": 2,
            "subfield": 1,
            "study": 1,
            "ability": 1,
            "improve": 1,
            "performance": 1,
            "based": 1,
            "experience": 1,
            "system": 1,
            "use": 1,
            "method": 1,
            "achieve": 1,
            "competence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para250",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 152,
              "end_char": 154,
              "context": "hine learning.” Machine learning is a subfield of AI that studies the ability to improve performance b"
            },
            {
              "para_id": "chap1_para250",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 229,
              "end_char": 231,
              "context": " to improve performance based on experience. Some AI systems use machine learning methods to achieve c"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para251",
          "content": "2\nWe are not suggesting that humans are “irrational” in the dictionary sense of “deprived of normal mental clarity.” We are merely conceding that human decisions are not always mathematically perfect.",
          "sentence_count": 1,
          "char_count": 171,
          "prev_para_id": "chap1_para250",
          "next_para_id": "chap1_para252",
          "style_metadata": {
            "para_id": "chap1_para251",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 1
          },
          "terminology": {
            "suggesting": 1,
            "human": 2,
            "irrational": 1,
            "dictionary": 1,
            "sense": 1,
            "deprived": 1,
            "normal": 1,
            "mental": 1,
            "clarity.": 1,
            "conceding": 1,
            "decision": 1,
            "perfect": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para252",
          "content": "3\nIn one of the first books on chess, Ruy Lopez (1561) wrote, “Always place the board so the sun is in your opponent’s eyes.”\n4\nThe\nNovum Organum\nis an update of Aristotle’s\nOrganon\n, or instrument of thought.",
          "sentence_count": 1,
          "char_count": 177,
          "prev_para_id": "chap1_para251",
          "next_para_id": "chap1_para253",
          "style_metadata": {
            "para_id": "chap1_para252",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 51.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 1
          },
          "terminology": {
            "first": 1,
            "book": 1,
            "chess": 1,
            "ruy": 1,
            "lopez": 1,
            "wrote": 1,
            "place": 1,
            "board": 1,
            "sun": 1,
            "opponent": 1,
            "eyes.": 1,
            "novum": 1,
            "organum": 1,
            "update": 1,
            "aristotle": 1,
            "organon": 1,
            "instrument": 1,
            "thought": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para252",
              "entity_text": "Ruy Lopez",
              "entity_type": "ORG",
              "start_char": 38,
              "end_char": 47,
              "context": "3\nIn one of the first books on chess, Ruy Lopez (1561) wrote, “Always place the board so the sun "
            },
            {
              "para_id": "chap1_para252",
              "entity_text": "Aristotle’s\nOrganon",
              "entity_type": "ORG",
              "start_char": 162,
              "end_char": 181,
              "context": "nent’s eyes.”\n4\nThe\nNovum Organum\nis an update of Aristotle’s\nOrganon\n, or instrument of thought."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para253",
          "content": "5\nFrege’s proposed notation for first-order logic—an arcane combination of textual and geometric features—never became popular.",
          "sentence_count": 1,
          "char_count": 113,
          "prev_para_id": "chap1_para252",
          "next_para_id": "chap1_para254",
          "style_metadata": {
            "para_id": "chap1_para253",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "frege": 1,
            "proposed": 1,
            "notation": 1,
            "first-order": 1,
            "logic—an": 1,
            "arcane": 1,
            "combination": 1,
            "textual": 1,
            "geometric": 1,
            "features—never": 1,
            "became": 1,
            "popular": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para253",
              "entity_text": "Frege’s",
              "entity_type": "ORG",
              "start_char": 2,
              "end_char": 9,
              "context": "5\nFrege’s proposed notation for first-order logic—an arcane"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para254",
          "content": "6\nIt has since been discovered that the tree shrew and some bird species exceed the human brain/body ratio.",
          "sentence_count": 1,
          "char_count": 90,
          "prev_para_id": "chap1_para253",
          "next_para_id": "chap1_para255",
          "style_metadata": {
            "para_id": "chap1_para254",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "discovered": 1,
            "tree": 1,
            "shrew": 1,
            "bird": 1,
            "specie": 1,
            "exceed": 1,
            "human": 1,
            "brain/body": 1,
            "ratio": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para255",
          "content": "7\nMany cite Alexander Hood (1824) as a possible prior source.",
          "sentence_count": 1,
          "char_count": 52,
          "prev_para_id": "chap1_para254",
          "next_para_id": "chap1_para256",
          "style_metadata": {
            "para_id": "chap1_para255",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "many": 1,
            "cite": 1,
            "alexander": 1,
            "hood": 1,
            "possible": 1,
            "prior": 1,
            "source": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para255",
              "entity_text": "Alexander Hood",
              "entity_type": "PERSON",
              "start_char": 12,
              "end_char": 26,
              "context": "7\nMany cite Alexander Hood (1824) as a possible prior source."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para256",
          "content": "8\nGolgi persisted in his belief that the brain’s functions were carried out primarily in a continuous medium in which neurons were embedded, whereas Cajal propounded the “neuronal doctrine.” The two shared the Nobel Prize in 1906 but gave mutually antagonistic acceptance speeches.",
          "sentence_count": 1,
          "char_count": 240,
          "prev_para_id": "chap1_para255",
          "next_para_id": "chap1_para257",
          "style_metadata": {
            "para_id": "chap1_para256",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.0,
            "passive_voice_ratio": 0.041,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 1
          },
          "terminology": {
            "golgi": 1,
            "persisted": 1,
            "belief": 1,
            "brain": 1,
            "function": 1,
            "carried": 1,
            "continuous": 1,
            "medium": 1,
            "neuron": 1,
            "embedded": 1,
            "whereas": 1,
            "cajal": 1,
            "propounded": 1,
            "neuronal": 1,
            "doctrine.": 1,
            "shared": 1,
            "nobel": 1,
            "prize": 1,
            "gave": 1,
            "antagonistic": 1,
            "acceptance": 1,
            "speech": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para256",
              "entity_text": "Cajal",
              "entity_type": "PERSON",
              "start_char": 149,
              "end_char": 154,
              "context": "us medium in which neurons were embedded, whereas Cajal propounded the “neuronal doctrine.” The two share"
            },
            {
              "para_id": "chap1_para256",
              "entity_text": "the Nobel Prize",
              "entity_type": "WORK_OF_ART",
              "start_char": 206,
              "end_char": 221,
              "context": "ropounded the “neuronal doctrine.” The two shared the Nobel Prize in 1906 but gave mutually antagonistic acceptance"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para257",
          "content": "9\nA complex machine named after a British cartoonist who depicted whimsical and absurdly complicated contraptions for everyday tasks such as buttering toast.",
          "sentence_count": 1,
          "char_count": 136,
          "prev_para_id": "chap1_para256",
          "next_para_id": "chap1_para258",
          "style_metadata": {
            "para_id": "chap1_para257",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "complex": 1,
            "machine": 1,
            "named": 1,
            "british": 1,
            "cartoonist": 1,
            "depicted": 1,
            "whimsical": 1,
            "complicated": 1,
            "contraption": 1,
            "everyday": 1,
            "task": 1,
            "buttering": 1,
            "toast": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para258",
          "content": "10\nIn the postwar period, Turing wanted to use these computers for AI research—for example, he created an outline of the first chess program (Turing\net al.,\n1953)—but the British government blocked this research.",
          "sentence_count": 1,
          "char_count": 182,
          "prev_para_id": "chap1_para257",
          "next_para_id": "chap1_para259",
          "style_metadata": {
            "para_id": "chap1_para258",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 1
          },
          "terminology": {
            "postwar": 1,
            "period": 1,
            "turing": 2,
            "wanted": 1,
            "use": 1,
            "computer": 1,
            "research—for": 1,
            "example": 1,
            "created": 1,
            "outline": 1,
            "first": 1,
            "chess": 1,
            "program": 1,
            "al.": 1,
            "—but": 1,
            "british": 1,
            "government": 1,
            "blocked": 1,
            "research": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para258",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 32,
              "context": "10\nIn the postwar period, Turing wanted to use these computers for AI research—for"
            },
            {
              "para_id": "chap1_para258",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 67,
              "end_char": 69,
              "context": " period, Turing wanted to use these computers for AI research—for example, he created an outline of th"
            },
            {
              "para_id": "chap1_para258",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 152,
              "end_char": 155,
              "context": " an outline of the first chess program (Turing\net al.,\n1953)—but the British government blocked this re"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para259",
          "content": "11\nNow Carnegie Mellon University (CMU).",
          "sentence_count": 1,
          "char_count": 36,
          "prev_para_id": "chap1_para258",
          "next_para_id": "chap1_para260",
          "style_metadata": {
            "para_id": "chap1_para259",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "carnegie": 1,
            "mellon": 1,
            "university": 1,
            "cmu": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para259",
              "entity_text": "Carnegie Mellon University",
              "entity_type": "ORG",
              "start_char": 7,
              "end_char": 33,
              "context": "11\nNow Carnegie Mellon University (CMU)."
            },
            {
              "para_id": "chap1_para259",
              "entity_text": "CMU",
              "entity_type": "ORG",
              "start_char": 35,
              "end_char": 38,
              "context": "11\nNow Carnegie Mellon University (CMU)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para260",
          "content": "12\nThis was the first official usage of McCarthy’s term\nartificial intelligence.",
          "sentence_count": 1,
          "char_count": 71,
          "prev_para_id": "chap1_para259",
          "next_para_id": "chap1_para261",
          "style_metadata": {
            "para_id": "chap1_para260",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "official": 1,
            "usage": 1,
            "mccarthy": 1,
            "term": 1,
            "artificial": 1,
            "intelligence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para260",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 40,
              "end_char": 48,
              "context": "12\nThis was the first official usage of McCarthy’s term\nartificial intelligence."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para261",
          "content": "Perhaps “computational rationality” would have been more precise and less threatening, but “AI” has stuck. At the 50th anniversary of the Dartmouth conference, McCarthy stated that he resisted the terms “computer” or “computational” in deference to Norbert Wiener, who was promoting analog cybernetic devices rather than digital computers.",
          "sentence_count": 2,
          "char_count": 292,
          "prev_para_id": "chap1_para260",
          "next_para_id": "chap1_para262",
          "style_metadata": {
            "para_id": "chap1_para261",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 2
          },
          "terminology": {
            "computational": 2,
            "rationality": 1,
            "precise": 1,
            "threatening": 1,
            "stuck": 1,
            "50th": 1,
            "anniversary": 1,
            "dartmouth": 1,
            "conference": 1,
            "mccarthy": 1,
            "stated": 1,
            "resisted": 1,
            "term": 1,
            "computer": 2,
            "deference": 1,
            "norbert": 1,
            "wiener": 1,
            "promoting": 1,
            "analog": 1,
            "cybernetic": 1,
            "device": 1,
            "digital": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para261",
              "entity_text": "Dartmouth",
              "entity_type": "ORG",
              "start_char": 138,
              "end_char": 147,
              "context": "ut “AI” has stuck. At the 50th anniversary of the Dartmouth conference, McCarthy stated that he resisted the "
            },
            {
              "para_id": "chap1_para261",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 160,
              "end_char": 168,
              "context": "the 50th anniversary of the Dartmouth conference, McCarthy stated that he resisted the terms “computer” or “"
            },
            {
              "para_id": "chap1_para261",
              "entity_text": "Norbert Wiener",
              "entity_type": "PERSON",
              "start_char": 249,
              "end_char": 263,
              "context": "rms “computer” or “computational” in deference to Norbert Wiener, who was promoting analog cybernetic devices rath"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para262",
          "content": "13\nNewell and Simon also invented a list-processing language, IPL, to write LT. They had no compiler and translated it into machine code by hand. To avoid errors, they worked in parallel, calling out binary numbers to each other as they wrote each instruction to make sure they agreed.",
          "sentence_count": 3,
          "char_count": 238,
          "prev_para_id": "chap1_para261",
          "next_para_id": "chap1_para263",
          "style_metadata": {
            "para_id": "chap1_para262",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 3
          },
          "terminology": {
            "simon": 1,
            "invented": 1,
            "list-processing": 1,
            "language": 1,
            "ipl": 1,
            "write": 1,
            "lt.": 1,
            "compiler": 1,
            "translated": 1,
            "machine": 1,
            "code": 1,
            "hand": 1,
            "avoid": 1,
            "error": 1,
            "worked": 1,
            "parallel": 1,
            "calling": 1,
            "binary": 1,
            "number": 1,
            "wrote": 1,
            "instruction": 1,
            "make": 1,
            "sure": 1,
            "agreed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para262",
              "entity_text": "Newell",
              "entity_type": "PERSON",
              "start_char": 3,
              "end_char": 9,
              "context": "13\nNewell and Simon also invented a list-processing languag"
            },
            {
              "para_id": "chap1_para262",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 14,
              "end_char": 19,
              "context": "13\nNewell and Simon also invented a list-processing language, IPL, to"
            },
            {
              "para_id": "chap1_para262",
              "entity_text": "IPL",
              "entity_type": "PERSON",
              "start_char": 62,
              "end_char": 65,
              "context": "d Simon also invented a list-processing language, IPL, to write LT. They had no compiler and translated"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para263",
          "content": "14\nSome have characterized this change as a victory of the\nneats\n—those who think that AI theories should be grounded in mathematical rigor—over the\nscruffies\n—those who would rather try out lots of ideas, write some programs, and then assess what seems to be working. Both approaches are important. A shift toward neatness implies that the held has reached a level of stability and maturity. The present emphasis on deep learning may represent a resurgence of the scruffies.",
          "sentence_count": 4,
          "char_count": 402,
          "prev_para_id": "chap1_para262",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap1_para263",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 4
          },
          "terminology": {
            "characterized": 1,
            "change": 1,
            "victory": 1,
            "neats": 1,
            "—those": 2,
            "think": 1,
            "theory": 1,
            "grounded": 1,
            "mathematical": 1,
            "rigor—over": 1,
            "scruffies": 2,
            "try": 1,
            "lot": 1,
            "idea": 1,
            "write": 1,
            "program": 1,
            "seems": 1,
            "working": 1,
            "approach": 1,
            "important": 1,
            "shift": 1,
            "neatness": 1,
            "implies": 1,
            "held": 1,
            "reached": 1,
            "level": 1,
            "stability": 1,
            "maturity": 1,
            "present": 1,
            "emphasis": 1,
            "deep": 1,
            "learning": 1,
            "represent": 1,
            "resurgence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para263",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 87,
              "end_char": 89,
              "context": "e as a victory of the\nneats\n—those who think that AI theories should be grounded in mathematical rigor"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap1_para264",
          "content": "15\nEven earlier, in 1847, Richard Thornton, editor of the\nPrimitive Expounder,\nrailed against mechanical calculators: “Mind ... outruns itself and does away with the necessity of its own existence by inventing machines to do its own thinking. ... But who knows that such machines when brought to greater perfection, may not think of a plan to remedy all their own defects and then grind out ideas beyond the ken of mortal mind!”\n16\nMidas would have done better if he had followed basic principles of safety and included an “undo” button and a “pause” button in his wish.",
          "sentence_count": 3,
          "char_count": 477,
          "prev_para_id": "chap1_para263",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap1_para264",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 3
          },
          "terminology": {
            "richard": 1,
            "thornton": 1,
            "editor": 1,
            "primitive": 1,
            "expounder": 1,
            "railed": 1,
            "mechanical": 1,
            "calculator": 1,
            "mind": 2,
            "outruns": 1,
            "necessity": 1,
            "existence": 1,
            "inventing": 1,
            "machine": 2,
            "thinking": 1,
            "know": 1,
            "brought": 1,
            "greater": 1,
            "perfection": 1,
            "think": 1,
            "plan": 1,
            "remedy": 1,
            "defect": 1,
            "grind": 1,
            "idea": 1,
            "ken": 1,
            "mortal": 1,
            "midas": 1,
            "done": 1,
            "followed": 1,
            "basic": 1,
            "principle": 1,
            "safety": 1,
            "included": 1,
            "undo": 1,
            "button": 2,
            "wish": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap1_para264",
              "entity_text": "Richard Thornton",
              "entity_type": "PERSON",
              "start_char": 26,
              "end_char": 42,
              "context": "15\nEven earlier, in 1847, Richard Thornton, editor of the\nPrimitive Expounder,\nrailed agains"
            },
            {
              "para_id": "chap1_para264",
              "entity_text": "the\nPrimitive Expounder",
              "entity_type": "ORG",
              "start_char": 54,
              "end_char": 77,
              "context": "ven earlier, in 1847, Richard Thornton, editor of the\nPrimitive Expounder,\nrailed against mechanical calculators: “Mind ..."
            },
            {
              "para_id": "chap1_para264",
              "entity_text": "Midas",
              "entity_type": "PERSON",
              "start_char": 432,
              "end_char": 437,
              "context": "rind out ideas beyond the ken of mortal mind!”\n16\nMidas would have done better if he had followed basic p"
            }
          ],
          "cultural_words": []
        }
      ],
      "para_count": 264,
      "char_count": 105690
    },
    {
      "chapter_num": 2,
      "title": "Chapter 2: CHAPTER",
      "paragraphs": [
        {
          "para_id": "chap2_para1",
          "content": "2\nINTELLIGENT AGENTS\nIn which we discuss the nature of agents, perfect or otherwise, the diversity of environments, and the resulting menagerie of agent types.",
          "sentence_count": 1,
          "char_count": 137,
          "prev_para_id": "None",
          "next_para_id": "chap2_para2",
          "style_metadata": {
            "para_id": "chap2_para1",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "intelligent": 1,
            "agent": 3,
            "discus": 1,
            "nature": 1,
            "perfect": 1,
            "diversity": 1,
            "environment": 1,
            "resulting": 1,
            "menagerie": 1,
            "type": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para2",
          "content": "Chapter 1\nidentified the concept of\nrational agents\nas central to our approach to artificial intelligence. In this chapter, we make this notion more concrete. We will see that the concept of rationality can be applied to a wide variety of agents operating in any imaginable environment. Our plan in this book is to use this concept to develop a small set of design principles for building successful agents—systems that can reasonably be called\nintelligent\n.",
          "sentence_count": 4,
          "char_count": 388,
          "prev_para_id": "chap2_para1",
          "next_para_id": "chap2_para3",
          "style_metadata": {
            "para_id": "chap2_para2",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 4
          },
          "terminology": {
            "chapter": 2,
            "identified": 1,
            "concept": 3,
            "rational": 1,
            "agent": 2,
            "central": 1,
            "approach": 1,
            "artificial": 1,
            "intelligence": 1,
            "make": 1,
            "notion": 1,
            "concrete": 1,
            "see": 1,
            "rationality": 1,
            "applied": 1,
            "wide": 1,
            "variety": 1,
            "operating": 1,
            "imaginable": 1,
            "environment": 1,
            "plan": 1,
            "book": 1,
            "use": 1,
            "develop": 1,
            "small": 1,
            "set": 1,
            "design": 1,
            "principle": 1,
            "building": 1,
            "successful": 1,
            "agents—systems": 1,
            "called": 1,
            "intelligent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para3",
          "content": "We begin by examining agents, environments, and the coupling between them. The observation that some agents behave better than others leads naturally to the idea of a rational agent—one that behaves as well as possible. How well an agent can behave depends on the nature of the environment; some environments are more difficult than others. We give a crude categorization of environments and show how properties of an environment influence the design of suitable agents for that environment. We describe a number of basic “skeleton” agent designs, which we flesh out in the rest of the book.",
          "sentence_count": 5,
          "char_count": 495,
          "prev_para_id": "chap2_para2",
          "next_para_id": "chap2_para4",
          "style_metadata": {
            "para_id": "chap2_para3",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 108,
            "sentence_count": 5
          },
          "terminology": {
            "begin": 1,
            "examining": 1,
            "agent": 5,
            "environment": 6,
            "coupling": 1,
            "observation": 1,
            "behave": 2,
            "better": 1,
            "others": 2,
            "lead": 1,
            "idea": 1,
            "rational": 1,
            "agent—one": 1,
            "behaves": 1,
            "possible": 1,
            "depends": 1,
            "nature": 1,
            "difficult": 1,
            "give": 1,
            "crude": 1,
            "categorization": 1,
            "show": 1,
            "property": 1,
            "influence": 1,
            "design": 2,
            "suitable": 1,
            "describe": 1,
            "number": 1,
            "basic": 1,
            "skeleton": 1,
            "flesh": 1,
            "rest": 1,
            "book": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para4",
          "content": "2.1Agents and Environments\n2.1\nAgents and Environments\nAn\nagent\nis anything that can be viewed as perceiving its\nenvironment\nthrough\nsensors\nand acting upon that environment through\nactuators\n. This simple idea is illustrated in\nFigure 2.1\n. A human agent has eyes, ears, and other organs for sensors and hands, legs, vocal tract, and so on for actuators. A robotic agent might have cameras and infrared range finders for sensors and various motors for actuators. A software agent receives file contents, network packets, and human input (keyboard/mouse/touchscreen/voice) as sensory inputs and acts on the environment by writing files, sending network packets, and displaying information or generating sounds. The environment could be everything—the entire universe! In practice it is just that part of the universe whose state we care about when designing this agent—the part that affects what the agent perceives and that is affected by the agent’s actions.",
          "sentence_count": 7,
          "char_count": 825,
          "prev_para_id": "chap2_para3",
          "next_para_id": "chap2_para5",
          "style_metadata": {
            "para_id": "chap2_para4",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.86,
            "passive_voice_ratio": 0.012,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 167,
            "sentence_count": 7
          },
          "terminology": {
            "environment": 6,
            "agent": 7,
            "anything": 1,
            "viewed": 1,
            "perceiving": 1,
            "sensor": 3,
            "acting": 1,
            "actuator": 3,
            "simple": 1,
            "idea": 1,
            "illustrated": 1,
            "figure": 1,
            "human": 2,
            "eye": 1,
            "ear": 1,
            "organ": 1,
            "hand": 1,
            "leg": 1,
            "vocal": 1,
            "tract": 1,
            "robotic": 1,
            "camera": 1,
            "infrared": 1,
            "range": 1,
            "finder": 1,
            "various": 1,
            "motor": 1,
            "software": 1,
            "receives": 1,
            "file": 2,
            "content": 1,
            "network": 2,
            "packet": 2,
            "input": 2,
            "keyboard/mouse/touchscreen/voice": 1,
            "sensory": 1,
            "act": 1,
            "writing": 1,
            "sending": 1,
            "displaying": 1,
            "information": 1,
            "generating": 1,
            "sound": 1,
            "everything—the": 1,
            "entire": 1,
            "universe": 2,
            "practice": 1,
            "part": 2,
            "state": 1,
            "care": 1,
            "designing": 1,
            "agent—the": 1,
            "affect": 1,
            "perceives": 1,
            "affected": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para4",
              "entity_text": "keyboard/mouse",
              "entity_type": "ORG",
              "start_char": 539,
              "end_char": 553,
              "context": " file contents, network packets, and human input (keyboard/mouse/touchscreen/voice) as sensory inputs and acts on "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para5",
          "content": "Description\nThe block diagram starts with a block labeled Agent. An unknown block marked with a question mark is shown inside the agent block. An arrow from the sensors points to the unknown block. An arrow from the unknown block points to the actuators. An arrow from the actuators points to a block labeled Environment, which is outside the agent block. An arrow from the environment block points back to sensors in the agent block.",
          "sentence_count": 6,
          "char_count": 361,
          "prev_para_id": "chap2_para4",
          "next_para_id": "chap2_para6",
          "style_metadata": {
            "para_id": "chap2_para5",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 6
          },
          "terminology": {
            "description": 1,
            "block": 9,
            "diagram": 1,
            "start": 1,
            "labeled": 2,
            "agent": 4,
            "unknown": 3,
            "marked": 1,
            "question": 1,
            "mark": 1,
            "shown": 1,
            "inside": 1,
            "arrow": 4,
            "sensor": 2,
            "point": 4,
            "actuator": 2,
            "environment": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para6",
          "content": "×\nFigure 2.1\nAgents interact with environments through sensors and actuators.",
          "sentence_count": 1,
          "char_count": 69,
          "prev_para_id": "chap2_para5",
          "next_para_id": "chap2_para7",
          "style_metadata": {
            "para_id": "chap2_para6",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "agent": 1,
            "interact": 1,
            "environment": 1,
            "sensor": 1,
            "actuator": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para7",
          "content": "We use the term\npercept\nto refer to the content an agent’s sensors are perceiving. An agent’s\npercept sequence\nis the complete history of everything the agent has ever perceived. In general,\nan agent’s choice of action at any given instant can depend on its built-in knowledge and on the entire percept sequence observed to date, but not on anything it hasn’t perceived.",
          "sentence_count": 3,
          "char_count": 313,
          "prev_para_id": "chap2_para6",
          "next_para_id": "chap2_para8",
          "style_metadata": {
            "para_id": "chap2_para7",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "use": 1,
            "term": 1,
            "percept": 3,
            "refer": 1,
            "content": 1,
            "agent": 4,
            "sensor": 1,
            "perceiving": 1,
            "sequence": 2,
            "complete": 1,
            "history": 1,
            "everything": 1,
            "perceived": 2,
            "general": 1,
            "choice": 1,
            "action": 1,
            "given": 1,
            "instant": 1,
            "depend": 1,
            "built-in": 1,
            "knowledge": 1,
            "entire": 1,
            "observed": 1,
            "date": 1,
            "anything": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para8",
          "content": "By specifying the agent’s choice of action for every possible percept sequence, we have said more or less everything there is to say about the agent. Mathematically speaking, we say that an agent’s behavior is described by the\nagent function\nthat maps any given percept sequence to an action.",
          "sentence_count": 2,
          "char_count": 246,
          "prev_para_id": "chap2_para7",
          "next_para_id": "chap2_para9",
          "style_metadata": {
            "para_id": "chap2_para8",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 2
          },
          "terminology": {
            "specifying": 1,
            "agent": 4,
            "choice": 1,
            "action": 2,
            "possible": 1,
            "percept": 2,
            "sequence": 2,
            "said": 1,
            "everything": 1,
            "say": 2,
            "speaking": 1,
            "described": 1,
            "function": 1,
            "map": 1,
            "given": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para9",
          "content": "We can imagine\ntabulating\nthe agent function that describes any given agent; for most agents, this would be a very large table—infinite, in fact, unless we place a bound on the length of percept sequences we want to consider. Given an agent to experiment with, we can, in principle, construct this table by trying out all possible percept sequences and recording which actions the agent does in response.",
          "sentence_count": 2,
          "char_count": 339,
          "prev_para_id": "chap2_para8",
          "next_para_id": "chap2_para10",
          "style_metadata": {
            "para_id": "chap2_para9",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 2
          },
          "terminology": {
            "imagine": 1,
            "tabulating": 1,
            "agent": 5,
            "function": 1,
            "describes": 1,
            "given": 2,
            "large": 1,
            "table—infinite": 1,
            "fact": 1,
            "place": 1,
            "bound": 1,
            "length": 1,
            "percept": 2,
            "sequence": 2,
            "want": 1,
            "consider": 1,
            "experiment": 1,
            "principle": 1,
            "construct": 1,
            "table": 1,
            "trying": 1,
            "possible": 1,
            "recording": 1,
            "action": 1,
            "response": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para10",
          "content": "1\nThe table is, of course, an\nexternal\ncharacterization of the agent.",
          "sentence_count": 1,
          "char_count": 61,
          "prev_para_id": "chap2_para9",
          "next_para_id": "chap2_para11",
          "style_metadata": {
            "para_id": "chap2_para10",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "table": 1,
            "course": 1,
            "external": 1,
            "characterization": 1,
            "agent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para11",
          "content": "Internally\n, the agent function for an artificial agent will be implemented by an\nagent program\n. It is important to keep these two ideas distinct. The agent function is an abstract mathematical description; the agent program is a concrete implementation, running within some physical system.",
          "sentence_count": 3,
          "char_count": 250,
          "prev_para_id": "chap2_para10",
          "next_para_id": "chap2_para12",
          "style_metadata": {
            "para_id": "chap2_para11",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 3
          },
          "terminology": {
            "agent": 5,
            "function": 2,
            "artificial": 1,
            "implemented": 1,
            "program": 2,
            "important": 1,
            "keep": 1,
            "idea": 1,
            "distinct": 1,
            "abstract": 1,
            "mathematical": 1,
            "description": 1,
            "concrete": 1,
            "implementation": 1,
            "running": 1,
            "physical": 1,
            "system": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para12",
          "content": "To illustrate these ideas, we use a simple example—the vacuum-cleaner world, which consists of a robotic vacuum-cleaning agent in a world consisting of squares that can be either dirty or clean.",
          "sentence_count": 1,
          "char_count": 164,
          "prev_para_id": "chap2_para11",
          "next_para_id": "chap2_para13",
          "style_metadata": {
            "para_id": "chap2_para12",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "illustrate": 1,
            "idea": 1,
            "use": 1,
            "simple": 1,
            "vacuum-cleaner": 1,
            "world": 2,
            "consists": 1,
            "robotic": 1,
            "vacuum-cleaning": 1,
            "agent": 1,
            "consisting": 1,
            "square": 1,
            "dirty": 1,
            "clean": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para13",
          "content": "Figure 2.2\nshows a configuration with just two squares,\nA\nand\nB\n. The vacuum agent perceives which square it is in and whether there is dirt in the square. The agent starts in square\nA\n. The available actions are to move to the right, move to the left, suck up the dirt, or do nothing.",
          "sentence_count": 4,
          "char_count": 236,
          "prev_para_id": "chap2_para12",
          "next_para_id": "chap2_para14",
          "style_metadata": {
            "para_id": "chap2_para13",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "configuration": 1,
            "square": 4,
            "vacuum": 1,
            "agent": 2,
            "perceives": 1,
            "dirt": 2,
            "start": 1,
            "available": 1,
            "action": 1,
            "move": 2,
            "left": 1,
            "suck": 1,
            "nothing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para14",
          "content": "2\nOne very simple agent function is the following: if the current square is dirty, then suck; otherwise, move to the other square. A partial tabulation of this agent function is shown in\nFigure 2.3\nand an agent program that implements it appears in\nFigure 2.8\non\npage 67\n.",
          "sentence_count": 2,
          "char_count": 230,
          "prev_para_id": "chap2_para13",
          "next_para_id": "chap2_para15",
          "style_metadata": {
            "para_id": "chap2_para14",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 2
          },
          "terminology": {
            "simple": 1,
            "agent": 3,
            "function": 2,
            "following": 1,
            "current": 1,
            "square": 2,
            "dirty": 1,
            "suck": 1,
            "move": 1,
            "partial": 1,
            "tabulation": 1,
            "shown": 1,
            "figure": 2,
            "program": 1,
            "implement": 1,
            "appears": 1,
            "page": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para15",
          "content": "Description\nA robotic vacuum-cleaning agent and dirt are shown in block \"A\". Dirt is shown in block B.",
          "sentence_count": 2,
          "char_count": 86,
          "prev_para_id": "chap2_para14",
          "next_para_id": "chap2_para16",
          "style_metadata": {
            "para_id": "chap2_para15",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "robotic": 1,
            "vacuum-cleaning": 1,
            "agent": 1,
            "dirt": 2,
            "shown": 2,
            "block": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para15",
              "entity_text": "Dirt",
              "entity_type": "PERSON",
              "start_char": 77,
              "end_char": 81,
              "context": "m-cleaning agent and dirt are shown in block \"A\". Dirt is shown in block B."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para16",
          "content": "×\nFigure 2.2\nA vacuum-cleaner world with just two locations. Each location can be clean or dirty, and the agent can move left or right and can clean the square that it occupies. Different versions of the vacuum world allow for different rules about what the agent can perceive, whether its actions always succeed, and so on.",
          "sentence_count": 3,
          "char_count": 270,
          "prev_para_id": "chap2_para15",
          "next_para_id": "chap2_para17",
          "style_metadata": {
            "para_id": "chap2_para16",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "vacuum-cleaner": 1,
            "world": 2,
            "location": 2,
            "clean": 2,
            "dirty": 1,
            "agent": 2,
            "move": 1,
            "left": 1,
            "right": 1,
            "square": 1,
            "occupies": 1,
            "different": 2,
            "version": 1,
            "vacuum": 1,
            "allow": 1,
            "rule": 1,
            "perceive": 1,
            "action": 1,
            "succeed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para17",
          "content": "Looking at\nFigure 2.3\n, we see that various vacuum-world agents can be defined simply by filling in the right-hand column in various ways. The obvious question, then, is this:\nWhat is the right way to fill out the table?",
          "sentence_count": 2,
          "char_count": 184,
          "prev_para_id": "chap2_para16",
          "next_para_id": "chap2_para18",
          "style_metadata": {
            "para_id": "chap2_para17",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "looking": 1,
            "figure": 1,
            "see": 1,
            "various": 2,
            "vacuum-world": 1,
            "agent": 1,
            "defined": 1,
            "filling": 1,
            "right-hand": 1,
            "column": 1,
            "way": 2,
            "obvious": 1,
            "question": 1,
            "right": 1,
            "table": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para18",
          "content": "In other words, what makes an agent good or bad, intelligent or stupid? We answer these questions in the next section.",
          "sentence_count": 2,
          "char_count": 98,
          "prev_para_id": "chap2_para17",
          "next_para_id": "chap2_para19",
          "style_metadata": {
            "para_id": "chap2_para18",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 2
          },
          "terminology": {
            "word": 1,
            "make": 1,
            "agent": 1,
            "good": 1,
            "bad": 1,
            "intelligent": 1,
            "stupid": 1,
            "answer": 1,
            "question": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para19",
          "content": "Description\nThe block diagram starts with a block labeled Agent. Three blocks are shown inside the Agent block. The first block inside the agent block is labeled, What the world is like now. An arrow from the first block points to the second block labeled, What action I should do now. The third block is labeled Condition action rules and an arrow from the third block points to the second block. An arrow from the second block points to the Actuators. An arrow from the actuators points to a block labeled Environment, which is outside the agent block. An arrow from the environment block points to the sensors in the Agent block. An arrow from the sensors points back to the first block.",
          "sentence_count": 9,
          "char_count": 569,
          "prev_para_id": "chap2_para18",
          "next_para_id": "chap2_para20",
          "style_metadata": {
            "para_id": "chap2_para19",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 135,
            "sentence_count": 9
          },
          "terminology": {
            "description": 1,
            "block": 16,
            "diagram": 1,
            "start": 1,
            "labeled": 5,
            "agent": 5,
            "shown": 1,
            "inside": 1,
            "world": 1,
            "arrow": 6,
            "point": 6,
            "second": 3,
            "action": 2,
            "third": 2,
            "condition": 1,
            "rule": 1,
            "actuator": 2,
            "environment": 2,
            "sensor": 2,
            "first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para19",
              "entity_text": "Actuators",
              "entity_type": "ORG",
              "start_char": 443,
              "end_char": 452,
              "context": "ock. An arrow from the second block points to the Actuators. An arrow from the actuators points to a block la"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para20",
          "content": "×\nFigure 2.3\nPartial tabulation of a simple agent function for the vacuum-cleaner world shown in\nFigure 2.2\n. The agent cleans the current square if it is dirty, otherwise it moves to the other square. Note that the table is of unbounded size unless there is a restriction on the length of possible percept sequences.",
          "sentence_count": 3,
          "char_count": 266,
          "prev_para_id": "chap2_para19",
          "next_para_id": "chap2_para21",
          "style_metadata": {
            "para_id": "chap2_para20",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 2,
            "partial": 1,
            "tabulation": 1,
            "simple": 1,
            "agent": 2,
            "function": 1,
            "vacuum-cleaner": 1,
            "world": 1,
            "shown": 1,
            "clean": 1,
            "current": 1,
            "square": 2,
            "dirty": 1,
            "otherwise": 1,
            "move": 1,
            "note": 1,
            "table": 1,
            "unbounded": 1,
            "size": 1,
            "restriction": 1,
            "length": 1,
            "possible": 1,
            "percept": 1,
            "sequence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para21",
          "content": "Before closing this section, we should emphasize that the notion of an agent is meant to be a tool for analyzing systems, not an absolute characterization that divides the world into agents and non-agents. One could view a hand-held calculator as an agent that chooses the action of displaying “4” when given the percept sequence “2 + 2 =,” but such an analysis would hardly aid our understanding of the calculator. In a sense, all areas of engineering can be seen as designing artifacts that interact with the world; AI operates at (what the authors consider to be) the most interesting end of the spectrum, where the artifacts have significant computational resources and the task environment requires nontrivial decision making.",
          "sentence_count": 3,
          "char_count": 612,
          "prev_para_id": "chap2_para20",
          "next_para_id": "chap2_para22",
          "style_metadata": {
            "para_id": "chap2_para21",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 135,
            "sentence_count": 3
          },
          "terminology": {
            "closing": 1,
            "section": 1,
            "emphasize": 1,
            "notion": 1,
            "agent": 3,
            "meant": 1,
            "tool": 1,
            "analyzing": 1,
            "system": 1,
            "absolute": 1,
            "characterization": 1,
            "divide": 1,
            "world": 2,
            "non-agents": 1,
            "view": 1,
            "hand-held": 1,
            "calculator": 2,
            "chooses": 1,
            "action": 1,
            "displaying": 1,
            "given": 1,
            "percept": 1,
            "sequence": 1,
            "analysis": 1,
            "aid": 1,
            "understanding": 1,
            "sense": 1,
            "area": 1,
            "engineering": 1,
            "seen": 1,
            "designing": 1,
            "artifact": 2,
            "interact": 1,
            "operates": 1,
            "author": 1,
            "consider": 1,
            "interesting": 1,
            "end": 1,
            "spectrum": 1,
            "significant": 1,
            "computational": 1,
            "resource": 1,
            "task": 1,
            "environment": 1,
            "requires": 1,
            "nontrivial": 1,
            "decision": 1,
            "making": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para21",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 518,
              "end_char": 520,
              "context": "designing artifacts that interact with the world; AI operates at (what the authors consider to be) the"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para22",
          "content": "2.2Good Behavior: The Concept of Rationality\n2.2\nGood Behavior: The Concept of Rationality\nA\nrational agent\nis one that does the right thing. Obviously, doing the right thing is better than doing the wrong thing, but what does it mean to do the right thing?",
          "sentence_count": 2,
          "char_count": 218,
          "prev_para_id": "chap2_para21",
          "next_para_id": "chap2_para23",
          "style_metadata": {
            "para_id": "chap2_para22",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 2
          },
          "terminology": {
            "behavior": 2,
            "concept": 2,
            "rationality": 2,
            "good": 1,
            "rational": 1,
            "agent": 1,
            "right": 3,
            "thing": 4,
            "wrong": 1,
            "mean": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para23",
          "content": "2.2.1\nPerformance measures\nMoral philosophy has developed several different notions of the “right thing,” but AI has generally stuck to one notion called\nconsequentialism\n: we evaluate an agent’s behavior by its consequences. When an agent is plunked down in an environment, it generates a sequence of actions according to the percepts it receives. This sequence of actions causes the environment to go through a sequence of states. If the sequence is desirable, then the agent has performed well. This notion of desirability is captured by a\nperformance measure\nthat evaluates any given sequence of environment states.",
          "sentence_count": 5,
          "char_count": 529,
          "prev_para_id": "chap2_para22",
          "next_para_id": "chap2_para24",
          "style_metadata": {
            "para_id": "chap2_para23",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.8,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 109,
            "sentence_count": 5
          },
          "terminology": {
            "performance": 2,
            "measure": 2,
            "moral": 1,
            "philosophy": 1,
            "developed": 1,
            "several": 1,
            "different": 1,
            "notion": 3,
            "right": 1,
            "thing": 1,
            "stuck": 1,
            "called": 1,
            "consequentialism": 1,
            "evaluate": 1,
            "agent": 3,
            "behavior": 1,
            "consequence": 1,
            "plunked": 1,
            "environment": 3,
            "generates": 1,
            "sequence": 5,
            "action": 2,
            "according": 1,
            "percept": 1,
            "receives": 1,
            "cause": 1,
            "state": 2,
            "desirable": 1,
            "performed": 1,
            "desirability": 1,
            "captured": 1,
            "evaluates": 1,
            "given": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para23",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 110,
              "end_char": 112,
              "context": "veral different notions of the “right thing,” but AI has generally stuck to one notion called\nconseque"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para24",
          "content": "Humans have desires and preferences of their own, so the notion of rationality as applied to humans has to do with their success in choosing actions that produce sequences of environment states that are desirable\nfrom their point of view.",
          "sentence_count": 1,
          "char_count": 200,
          "prev_para_id": "chap2_para23",
          "next_para_id": "chap2_para25",
          "style_metadata": {
            "para_id": "chap2_para24",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 1
          },
          "terminology": {
            "human": 2,
            "desire": 1,
            "preference": 1,
            "notion": 1,
            "rationality": 1,
            "applied": 1,
            "success": 1,
            "choosing": 1,
            "action": 1,
            "produce": 1,
            "sequence": 1,
            "environment": 1,
            "state": 1,
            "desirable": 1,
            "point": 1,
            "view": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para25",
          "content": "Machines, on the other hand, do\nnot\nhave desires and preferences of their own; the performance measure is, initially at least, in the mind of the designer of the machine, or in the mind of the users the machine is designed for. We will see that some agent designs have an explicit representation of (a version of) the performance measure, while in other designs the performance measure is entirely implicit—the agent may do the right thing, but it doesn’t know why.",
          "sentence_count": 2,
          "char_count": 387,
          "prev_para_id": "chap2_para24",
          "next_para_id": "chap2_para26",
          "style_metadata": {
            "para_id": "chap2_para25",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 47.5,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 2
          },
          "terminology": {
            "machine": 3,
            "hand": 1,
            "desire": 1,
            "preference": 1,
            "performance": 3,
            "measure": 3,
            "least": 1,
            "mind": 2,
            "designer": 1,
            "user": 1,
            "designed": 1,
            "see": 1,
            "agent": 2,
            "design": 2,
            "explicit": 1,
            "representation": 1,
            "version": 1,
            "implicit—the": 1,
            "right": 1,
            "thing": 1,
            "know": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para26",
          "content": "Recalling Norbert Wiener’s warning to ensure that “the purpose put into the machine is the purpose which we really desire” (\npage 51\n), notice that it can be quite hard to formulate a performance measure correctly. Consider, for example, the vacuum-cleaner agent from the preceding section. We might propose to measure performance by the amount of dirt cleaned up in a single eight-hour shift. With a rational agent, of course, what you ask for is what you get. A rational agent can maximize this performance measure by cleaning up the dirt, then dumping it all on the floor, then cleaning it up again, and so on. A more suitable performance measure would reward the agent for having a clean floor. For example, one point could be awarded for each clean square at each time step (perhaps with a penalty for electricity consumed and noise generated).",
          "sentence_count": 7,
          "char_count": 706,
          "prev_para_id": "chap2_para25",
          "next_para_id": "chap2_para27",
          "style_metadata": {
            "para_id": "chap2_para26",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 168,
            "sentence_count": 7
          },
          "terminology": {
            "recalling": 1,
            "norbert": 1,
            "wiener": 1,
            "warning": 1,
            "ensure": 1,
            "purpose": 2,
            "machine": 1,
            "desire": 1,
            "page": 1,
            "hard": 1,
            "formulate": 1,
            "performance": 4,
            "measure": 4,
            "consider": 1,
            "example": 2,
            "vacuum-cleaner": 1,
            "agent": 4,
            "preceding": 1,
            "section": 1,
            "propose": 1,
            "amount": 1,
            "dirt": 2,
            "cleaned": 1,
            "single": 1,
            "eight-hour": 1,
            "shift": 1,
            "rational": 2,
            "course": 1,
            "ask": 1,
            "get": 1,
            "maximize": 1,
            "cleaning": 2,
            "dumping": 1,
            "floor": 2,
            "suitable": 1,
            "reward": 1,
            "clean": 2,
            "point": 1,
            "awarded": 1,
            "square": 1,
            "time": 1,
            "step": 1,
            "penalty": 1,
            "electricity": 1,
            "consumed": 1,
            "generated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para26",
              "entity_text": "Norbert Wiener",
              "entity_type": "PERSON",
              "start_char": 10,
              "end_char": 24,
              "context": "Recalling Norbert Wiener’s warning to ensure that “the purpose put into th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para27",
          "content": "As a general rule, it is better to design performance measures according to what one actually wants to be achieved in the environment, rather than according to how one thinks the agent should behave.",
          "sentence_count": 1,
          "char_count": 166,
          "prev_para_id": "chap2_para26",
          "next_para_id": "chap2_para28",
          "style_metadata": {
            "para_id": "chap2_para27",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 1
          },
          "terminology": {
            "general": 1,
            "rule": 1,
            "design": 1,
            "performance": 1,
            "measure": 1,
            "according": 2,
            "want": 1,
            "achieved": 1,
            "environment": 1,
            "think": 1,
            "agent": 1,
            "behave": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para28",
          "content": "Even when the obvious pitfalls are avoided, some knotty problems remain. For example, the notion of “clean floor” in the preceding paragraph is based on average cleanliness over time. Yet the same average cleanliness can be achieved by two different agents, one of which does a mediocre job all the time while the other cleans energetically but takes long breaks. Which is preferable might seem to be a fine point of janitorial science, but in fact it is a deep philosophical question with far-reaching implications. Which is better—a reckless life of highs and lows, or a safe but humdrum existence? Which is better—an economy where everyone lives in moderate poverty, or one in which some live in plenty while others are very poor? We leave these questions as an exercise for the diligent reader.",
          "sentence_count": 7,
          "char_count": 665,
          "prev_para_id": "chap2_para27",
          "next_para_id": "chap2_para29",
          "style_metadata": {
            "para_id": "chap2_para28",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.29,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 149,
            "sentence_count": 7
          },
          "terminology": {
            "obvious": 1,
            "pitfall": 1,
            "avoided": 1,
            "knotty": 1,
            "problem": 1,
            "remain": 1,
            "example": 1,
            "notion": 1,
            "clean": 2,
            "floor": 1,
            "preceding": 1,
            "paragraph": 1,
            "based": 1,
            "average": 2,
            "cleanliness": 2,
            "time": 2,
            "achieved": 1,
            "different": 1,
            "agent": 1,
            "mediocre": 1,
            "job": 1,
            "take": 1,
            "long": 1,
            "break": 1,
            "preferable": 1,
            "seem": 1,
            "fine": 1,
            "point": 1,
            "janitorial": 1,
            "science": 1,
            "fact": 1,
            "deep": 1,
            "philosophical": 1,
            "question": 2,
            "far-reaching": 1,
            "implication": 1,
            "better—a": 1,
            "reckless": 1,
            "life": 2,
            "high": 1,
            "low": 1,
            "safe": 1,
            "humdrum": 1,
            "existence": 1,
            "better—an": 1,
            "economy": 1,
            "everyone": 1,
            "moderate": 1,
            "poverty": 1,
            "live": 1,
            "plenty": 1,
            "others": 1,
            "poor": 1,
            "leave": 1,
            "exercise": 1,
            "diligent": 1,
            "reader": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para29",
          "content": "For most of the book, we will assume that the performance measure can be specified correctly. For the reasons given above, however, we must accept the possibility that we might put the wrong purpose into the machine—precisely the King Midas problem described on\npage 51\n. Moreover, when designing one piece of software, copies of which will belong to different users, we cannot anticipate the exact preferences of each individual user. Thus, we may need to build agents that reflect initial uncertainty about the true performance measure and learn more about it as time goes by; such agents are described in\nChapters 15\n,\n17\n, and\n23\n.",
          "sentence_count": 4,
          "char_count": 535,
          "prev_para_id": "chap2_para28",
          "next_para_id": "chap2_para30",
          "style_metadata": {
            "para_id": "chap2_para29",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 9.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover",
              "however"
            ],
            "word_count": 120,
            "sentence_count": 4
          },
          "terminology": {
            "book": 1,
            "assume": 1,
            "performance": 2,
            "measure": 2,
            "specified": 1,
            "reason": 1,
            "given": 1,
            "accept": 1,
            "possibility": 1,
            "put": 1,
            "wrong": 1,
            "purpose": 1,
            "king": 1,
            "midas": 1,
            "problem": 1,
            "described": 2,
            "page": 1,
            "designing": 1,
            "piece": 1,
            "software": 1,
            "copy": 1,
            "belong": 1,
            "different": 1,
            "user": 1,
            "anticipate": 1,
            "exact": 1,
            "preference": 1,
            "individual": 1,
            "need": 1,
            "build": 1,
            "agent": 2,
            "reflect": 1,
            "initial": 1,
            "uncertainty": 1,
            "true": 1,
            "learn": 1,
            "time": 1,
            "go": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para29",
              "entity_text": "King Midas",
              "entity_type": "GPE",
              "start_char": 230,
              "end_char": 240,
              "context": " the wrong purpose into the machine—precisely the King Midas problem described on\npage 51\n. Moreover, when des"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para30",
          "content": "2.2.2\nRationality\nWhat is rational at any given time depends on four things:\n•\nThe performance measure that defines the criterion of success.",
          "sentence_count": 1,
          "char_count": 123,
          "prev_para_id": "chap2_para29",
          "next_para_id": "chap2_para31",
          "style_metadata": {
            "para_id": "chap2_para30",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "rationality": 1,
            "rational": 1,
            "given": 1,
            "time": 1,
            "depends": 1,
            "thing": 1,
            "performance": 1,
            "measure": 1,
            "defines": 1,
            "criterion": 1,
            "success": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para31",
          "content": "•\nThe agent’s prior knowledge of the environment.",
          "sentence_count": 1,
          "char_count": 43,
          "prev_para_id": "chap2_para30",
          "next_para_id": "chap2_para32",
          "style_metadata": {
            "para_id": "chap2_para31",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "agent": 1,
            "knowledge": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para32",
          "content": "•\nThe actions that the agent can perform.",
          "sentence_count": 1,
          "char_count": 35,
          "prev_para_id": "chap2_para31",
          "next_para_id": "chap2_para33",
          "style_metadata": {
            "para_id": "chap2_para32",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "action": 1,
            "agent": 1,
            "perform": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para33",
          "content": "•\nThe agent’s percept sequence to date.",
          "sentence_count": 1,
          "char_count": 34,
          "prev_para_id": "chap2_para32",
          "next_para_id": "chap2_para34",
          "style_metadata": {
            "para_id": "chap2_para33",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "agent": 1,
            "percept": 1,
            "sequence": 1,
            "date": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para34",
          "content": "This leads to a\ndefinition of a rational agent\n:\nFor each possible percept sequence, a rational agent should select an action that is expected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has.",
          "sentence_count": 1,
          "char_count": 237,
          "prev_para_id": "chap2_para33",
          "next_para_id": "chap2_para35",
          "style_metadata": {
            "para_id": "chap2_para34",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 48.0,
            "passive_voice_ratio": 0.021,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 1
          },
          "terminology": {
            "lead": 1,
            "definition": 1,
            "rational": 2,
            "agent": 3,
            "possible": 1,
            "percept": 2,
            "sequence": 2,
            "select": 1,
            "action": 1,
            "expected": 1,
            "maximize": 1,
            "performance": 1,
            "measure": 1,
            "given": 1,
            "evidence": 1,
            "provided": 1,
            "built-in": 1,
            "knowledge": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para35",
          "content": "Consider the simple vacuum-cleaner agent that cleans a square if it is dirty and moves to the other square if not; this is the agent function tabulated in\nFigure 2.3\n. Is this a rational agent? That depends! First, we need to say what the performance measure is, what is known about the environment, and what sensors and actuators the agent has. Let us assume the following:\n•\nThe performance measure awards one point for each clean square at each time step, over a “lifetime” of 1000 time steps.",
          "sentence_count": 5,
          "char_count": 412,
          "prev_para_id": "chap2_para34",
          "next_para_id": "chap2_para36",
          "style_metadata": {
            "para_id": "chap2_para35",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 101,
            "sentence_count": 5
          },
          "terminology": {
            "consider": 1,
            "simple": 1,
            "vacuum-cleaner": 1,
            "agent": 4,
            "clean": 2,
            "square": 3,
            "dirty": 1,
            "move": 1,
            "function": 1,
            "tabulated": 1,
            "figure": 1,
            "rational": 1,
            "depends": 1,
            "first": 1,
            "need": 1,
            "say": 1,
            "performance": 2,
            "measure": 2,
            "known": 1,
            "environment": 1,
            "sensor": 1,
            "actuator": 1,
            "let": 1,
            "assume": 1,
            "following": 1,
            "award": 1,
            "point": 1,
            "time": 2,
            "step": 2,
            "lifetime": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para36",
          "content": "•\nThe “geography” of the environment is known\na priori\n(\nFigure 2.2\n) but the dirt distribution and the initial location of the agent are not. Clean squares stay clean and sucking cleans the current square. The\nRight\nand\nLeft\nactions move the agent one square except when this would take the agent outside the environment, in which case the agent remains where it is.",
          "sentence_count": 3,
          "char_count": 311,
          "prev_para_id": "chap2_para35",
          "next_para_id": "chap2_para37",
          "style_metadata": {
            "para_id": "chap2_para36",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 3
          },
          "terminology": {
            "geography": 1,
            "environment": 2,
            "known": 1,
            "priori": 1,
            "figure": 1,
            "dirt": 1,
            "distribution": 1,
            "initial": 1,
            "location": 1,
            "agent": 4,
            "clean": 3,
            "square": 3,
            "stay": 1,
            "sucking": 1,
            "current": 1,
            "right": 1,
            "left": 1,
            "action": 1,
            "move": 1,
            "take": 1,
            "case": 1,
            "remains": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para37",
          "content": "•\nThe only available actions are\nRight, Left,\nand\nSuck.",
          "sentence_count": 1,
          "char_count": 50,
          "prev_para_id": "chap2_para36",
          "next_para_id": "chap2_para38",
          "style_metadata": {
            "para_id": "chap2_para37",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "available": 1,
            "action": 1,
            "left": 1,
            "suck": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para38",
          "content": "•\nThe agent correctly perceives its location and whether that location contains dirt.",
          "sentence_count": 1,
          "char_count": 74,
          "prev_para_id": "chap2_para37",
          "next_para_id": "chap2_para39",
          "style_metadata": {
            "para_id": "chap2_para38",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "agent": 1,
            "perceives": 1,
            "location": 2,
            "contains": 1,
            "dirt": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para39",
          "content": "Under these circumstances the agent is indeed rational; its expected performance is at least as good as any other agent’s.",
          "sentence_count": 1,
          "char_count": 103,
          "prev_para_id": "chap2_para38",
          "next_para_id": "chap2_para40",
          "style_metadata": {
            "para_id": "chap2_para39",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.042,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "circumstance": 1,
            "agent": 2,
            "rational": 1,
            "expected": 1,
            "performance": 1,
            "least": 1,
            "good": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para40",
          "content": "One can see easily that the same agent would be irrational under different circumstances. For example, once all the dirt is cleaned up, the agent will oscillate needlessly back and forth; if the performance measure includes a penalty of one point for each movement, the agent will fare poorly. A better agent for this case would do nothing once it is sure that all the squares are clean. If clean squares can become dirty again, the agent should occasionally check and re-clean them if needed. If the geography of the environment is unknown, the agent will need to\nexplore\nit. Exercise\n2.",
          "sentence_count": 6,
          "char_count": 490,
          "prev_para_id": "chap2_para39",
          "next_para_id": "chap2_para41",
          "style_metadata": {
            "para_id": "chap2_para40",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 6
          },
          "terminology": {
            "see": 1,
            "agent": 6,
            "irrational": 1,
            "different": 1,
            "circumstance": 1,
            "example": 1,
            "dirt": 1,
            "cleaned": 1,
            "oscillate": 1,
            "forth": 1,
            "performance": 1,
            "measure": 1,
            "includes": 1,
            "penalty": 1,
            "point": 1,
            "movement": 1,
            "fare": 1,
            "case": 1,
            "nothing": 1,
            "sure": 1,
            "square": 2,
            "clean": 2,
            "become": 1,
            "dirty": 1,
            "check": 1,
            "re-clean": 1,
            "needed": 1,
            "geography": 1,
            "environment": 1,
            "unknown": 1,
            "explore": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para41",
          "content": "VACR\nasks you to design agents for these cases.",
          "sentence_count": 1,
          "char_count": 40,
          "prev_para_id": "chap2_para40",
          "next_para_id": "chap2_para42",
          "style_metadata": {
            "para_id": "chap2_para41",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "vacr": 1,
            "asks": 1,
            "design": 1,
            "agent": 1,
            "case": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para42",
          "content": "2.2.3\nOmniscience, learning, and autonomy\nWe need to be careful to distinguish between rationality and\nomniscience\n. An omniscient agent knows the\nactual\noutcome of its actions and can act accordingly; but omniscience is impossible in reality. Consider the following example: I am walking along the Champs Elysées one day and I see an old friend across the street. There is no traffic nearby and I’m\nnot otherwise engaged, so, being rational, I start to cross the street. Meanwhile, at 33,000 feet, a cargo door falls off a passing airliner,\n3\nand before I make it to the other side of the street I am flattened. Was I irrational to cross the street? It is unlikely that my obituary would read “Idiot attempts to cross street.”\nThis example shows that rationality is not the same as perfection. Rationality maximizes\nexpected\nperformance, while perfection maximizes\nactual\nperformance. Retreating from a requirement of perfection is not just a question of being fair to agents. The point is that if we expect an agent to do what turns out after the fact to be the best action, it will be impossible to design an agent to fulfill this specification—unless we improve the performance of crystal balls or time machines.",
          "sentence_count": 10,
          "char_count": 1025,
          "prev_para_id": "chap2_para41",
          "next_para_id": "chap2_para43",
          "style_metadata": {
            "para_id": "chap2_para42",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.1,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 231,
            "sentence_count": 10
          },
          "terminology": {
            "omniscience": 2,
            "learning": 1,
            "autonomy": 1,
            "need": 1,
            "careful": 1,
            "distinguish": 1,
            "rationality": 3,
            "omniscient": 1,
            "agent": 4,
            "know": 1,
            "actual": 2,
            "outcome": 1,
            "action": 2,
            "act": 1,
            "impossible": 2,
            "reality": 1,
            "consider": 1,
            "following": 1,
            "example": 2,
            "walking": 1,
            "champ": 1,
            "elysées": 1,
            "day": 1,
            "see": 1,
            "old": 1,
            "friend": 1,
            "street": 4,
            "traffic": 1,
            "nearby": 1,
            "engaged": 1,
            "rational": 1,
            "start": 1,
            "cross": 3,
            "foot": 1,
            "cargo": 1,
            "door": 1,
            "fall": 1,
            "passing": 1,
            "airliner": 1,
            "make": 1,
            "side": 1,
            "flattened": 1,
            "irrational": 1,
            "unlikely": 1,
            "obituary": 1,
            "read": 1,
            "idiot": 1,
            "attempt": 1,
            "street.": 1,
            "show": 1,
            "perfection": 3,
            "maximizes": 2,
            "expected": 1,
            "performance": 3,
            "retreating": 1,
            "requirement": 1,
            "question": 1,
            "fair": 1,
            "point": 1,
            "expect": 1,
            "turn": 1,
            "fact": 1,
            "best": 1,
            "design": 1,
            "fulfill": 1,
            "specification—unless": 1,
            "improve": 1,
            "crystal": 1,
            "ball": 1,
            "time": 1,
            "machine": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para42",
              "entity_text": "Champs Elysées",
              "entity_type": "ORG",
              "start_char": 299,
              "end_char": 313,
              "context": "der the following example: I am walking along the Champs Elysées one day and I see an old friend across the street"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para43",
          "content": "Our definition of rationality does not require omniscience, then, because the rational choice depends only on the percept sequence\nto date.",
          "sentence_count": 1,
          "char_count": 120,
          "prev_para_id": "chap2_para42",
          "next_para_id": "chap2_para44",
          "style_metadata": {
            "para_id": "chap2_para43",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "definition": 1,
            "rationality": 1,
            "require": 1,
            "omniscience": 1,
            "rational": 1,
            "choice": 1,
            "depends": 1,
            "percept": 1,
            "sequence": 1,
            "date": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para44",
          "content": "We must also ensure that we haven’t inadvertently allowed the agent to engage in decidedly underintelligent activities. For example, if an agent does not look both ways before crossing a busy road, then its percept sequence will not tell it that there is a large truck approaching at high speed. Does our definition of rationality say that it’s now OK to cross the road? Far from it!",
          "sentence_count": 4,
          "char_count": 317,
          "prev_para_id": "chap2_para43",
          "next_para_id": "chap2_para45",
          "style_metadata": {
            "para_id": "chap2_para44",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 4
          },
          "terminology": {
            "ensure": 1,
            "allowed": 1,
            "agent": 2,
            "engage": 1,
            "underintelligent": 1,
            "activity": 1,
            "example": 1,
            "look": 1,
            "way": 1,
            "crossing": 1,
            "busy": 1,
            "road": 2,
            "percept": 1,
            "sequence": 1,
            "tell": 1,
            "large": 1,
            "truck": 1,
            "approaching": 1,
            "high": 1,
            "speed": 1,
            "definition": 1,
            "rationality": 1,
            "say": 1,
            "cross": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para45",
          "content": "First, it would not be rational to cross the road given this uninformative percept sequence: the risk of accident from crossing without looking is too great. Second, a rational agent should choose the “looking” action before stepping into the street, because looking helps maximize the expected performance. Doing actions\nin order to modify future percepts\n—sometimes called\ninformation gathering\n—is an important part of rationality and is covered in depth in\nChapter 15\n. A second example of information gathering is provided by the\nexploration\nthat must be undertaken by a vacuum-cleaning agent in an initially unknown environment.",
          "sentence_count": 4,
          "char_count": 545,
          "prev_para_id": "chap2_para44",
          "next_para_id": "chap2_para46",
          "style_metadata": {
            "para_id": "chap2_para45",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.75,
            "passive_voice_ratio": 0.019,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 107,
            "sentence_count": 4
          },
          "terminology": {
            "rational": 2,
            "cross": 1,
            "road": 1,
            "given": 1,
            "uninformative": 1,
            "percept": 2,
            "sequence": 1,
            "risk": 1,
            "accident": 1,
            "crossing": 1,
            "looking": 3,
            "great": 1,
            "second": 2,
            "agent": 2,
            "choose": 1,
            "action": 2,
            "stepping": 1,
            "street": 1,
            "help": 1,
            "maximize": 1,
            "expected": 1,
            "performance": 1,
            "order": 1,
            "modify": 1,
            "future": 1,
            "called": 1,
            "information": 2,
            "gathering": 2,
            "—is": 1,
            "important": 1,
            "part": 1,
            "rationality": 1,
            "covered": 1,
            "depth": 1,
            "chapter": 1,
            "example": 1,
            "provided": 1,
            "exploration": 1,
            "undertaken": 1,
            "vacuum-cleaning": 1,
            "unknown": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para46",
          "content": "Our definition requires a rational agent not only to gather information but also to\nlearn\nas much as possible from what it perceives. The agent’s initial configuration could reflect some prior knowledge of the environment, but as the agent gains experience this may be modified and augmented. There are extreme cases in which the environment is completely known\na priori\nand completely predictable. In such cases, the agent need not perceive or learn; it simply acts correctly.",
          "sentence_count": 4,
          "char_count": 405,
          "prev_para_id": "chap2_para45",
          "next_para_id": "chap2_para47",
          "style_metadata": {
            "para_id": "chap2_para46",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 86,
            "sentence_count": 4
          },
          "terminology": {
            "definition": 1,
            "requires": 1,
            "rational": 1,
            "agent": 4,
            "gather": 1,
            "information": 1,
            "much": 1,
            "possible": 1,
            "perceives": 1,
            "initial": 1,
            "configuration": 1,
            "reflect": 1,
            "prior": 1,
            "knowledge": 1,
            "environment": 2,
            "gain": 1,
            "experience": 1,
            "modified": 1,
            "augmented": 1,
            "extreme": 1,
            "case": 2,
            "known": 1,
            "priori": 1,
            "predictable": 1,
            "need": 1,
            "perceive": 1,
            "learn": 1,
            "act": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para47",
          "content": "Of course, such agents are fragile. Consider the lowly dung beetle. After digging its nest and laying its eggs, it fetches a ball of dung from a nearby heap to plug the entrance. If the ball of dung is removed from its grasp\nen route\n, the beetle continues its task and pantomimes plugging the nest with the nonexistent dung ball, never noticing that it is missing. Evolution has built an assumption into the beetle’s behavior, and when it is violated, unsuccessful behavior results.",
          "sentence_count": 5,
          "char_count": 402,
          "prev_para_id": "chap2_para46",
          "next_para_id": "chap2_para48",
          "style_metadata": {
            "para_id": "chap2_para47",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.2,
            "passive_voice_ratio": 0.021,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 5
          },
          "terminology": {
            "course": 1,
            "agent": 1,
            "fragile": 1,
            "consider": 1,
            "dung": 4,
            "beetle": 3,
            "digging": 1,
            "nest": 2,
            "laying": 1,
            "egg": 1,
            "fetch": 1,
            "ball": 3,
            "heap": 1,
            "plug": 1,
            "entrance": 1,
            "removed": 1,
            "grasp": 1,
            "route": 1,
            "continues": 1,
            "task": 1,
            "pantomime": 1,
            "plugging": 1,
            "nonexistent": 1,
            "noticing": 1,
            "missing": 1,
            "evolution": 1,
            "built": 1,
            "assumption": 1,
            "behavior": 2,
            "violated": 1,
            "unsuccessful": 1,
            "result": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para48",
          "content": "Slightly more intelligent is the sphex wasp. The female sphex will dig a burrow, go out and sting a caterpillar and drag it to the burrow, enter the burrow again to check all is well, drag the caterpillar inside, and lay its eggs. The caterpillar serves as a food source when the eggs hatch. So far so good, but if an entomologist moves the caterpillar a few inches away while the sphex is doing the check, it will revert to the “drag the caterpillar” step of its plan and will continue the plan without modification, re-checking the burrow, even after dozens of caterpillar-moving interventions. The sphex is unable to learn that its innate plan is failing, and thus will not change it.",
          "sentence_count": 5,
          "char_count": 566,
          "prev_para_id": "chap2_para47",
          "next_para_id": "chap2_para49",
          "style_metadata": {
            "para_id": "chap2_para48",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 138,
            "sentence_count": 5
          },
          "terminology": {
            "intelligent": 1,
            "sphex": 4,
            "female": 1,
            "dig": 1,
            "burrow": 4,
            "sting": 1,
            "caterpillar": 5,
            "drag": 2,
            "enter": 1,
            "check": 2,
            "lay": 1,
            "egg": 2,
            "serf": 1,
            "food": 1,
            "source": 1,
            "hatch": 1,
            "good": 1,
            "entomologist": 1,
            "move": 1,
            "inch": 1,
            "revert": 1,
            "step": 1,
            "plan": 3,
            "continue": 1,
            "modification": 1,
            "re-checking": 1,
            "dozen": 1,
            "caterpillar-moving": 1,
            "intervention": 1,
            "unable": 1,
            "learn": 1,
            "innate": 1,
            "failing": 1,
            "change": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para48",
              "entity_text": "caterpillar",
              "entity_type": "ORG",
              "start_char": 193,
              "end_char": 204,
              "context": "r the burrow again to check all is well, drag the caterpillar inside, and lay its eggs. The caterpillar serves "
            },
            {
              "para_id": "chap2_para48",
              "entity_text": "caterpillar",
              "entity_type": "ORG",
              "start_char": 235,
              "end_char": 246,
              "context": "rag the caterpillar inside, and lay its eggs. The caterpillar serves as a food source when the eggs hatch. So f"
            },
            {
              "para_id": "chap2_para48",
              "entity_text": "caterpillar",
              "entity_type": "ORG",
              "start_char": 439,
              "end_char": 450,
              "context": " doing the check, it will revert to the “drag the caterpillar” step of its plan and will continue the plan with"
            },
            {
              "para_id": "chap2_para48",
              "entity_text": "caterpillar",
              "entity_type": "ORG",
              "start_char": 563,
              "end_char": 574,
              "context": "ion, re-checking the burrow, even after dozens of caterpillar-moving interventions. The sphex is unable to lear"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para49",
          "content": "To the extent that an agent relies on the prior knowledge of its designer rather than on its own percepts and learning processes, we say that the agent lacks\nautonomy\n. A rational agent should be autonomous—it should learn what it can to compensate for partial or incorrect prior knowledge. For example, a vacuum-cleaning agent that learns to predict where and when additional dirt will appear will do better than one that does not.",
          "sentence_count": 3,
          "char_count": 361,
          "prev_para_id": "chap2_para48",
          "next_para_id": "chap2_para50",
          "style_metadata": {
            "para_id": "chap2_para49",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "extent": 1,
            "agent": 4,
            "relies": 1,
            "knowledge": 2,
            "designer": 1,
            "percept": 1,
            "learning": 1,
            "process": 1,
            "say": 1,
            "lack": 1,
            "autonomy": 1,
            "rational": 1,
            "autonomous—it": 1,
            "learn": 1,
            "compensate": 1,
            "partial": 1,
            "incorrect": 1,
            "prior": 1,
            "example": 1,
            "vacuum-cleaning": 1,
            "learns": 1,
            "predict": 1,
            "additional": 1,
            "dirt": 1,
            "appear": 1,
            "better": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para50",
          "content": "As a practical matter, one seldom requires complete autonomy from the start: when the agent has had little or no experience, it would have to act randomly unless the designer gave some assistance. Just as evolution provides animals with enough built-in reflexes to survive long enough to learn for themselves, it would be reasonable to provide an artificial intelligent agent with some initial knowledge as well as an ability to learn. After sufficient experience of its environment, the behavior of a rational agent can become effectively\nindependent\nof its prior knowledge. Hence, the incorporation of learning allows one to design a single rational agent that will succeed in a vast variety of environments.",
          "sentence_count": 4,
          "char_count": 600,
          "prev_para_id": "chap2_para49",
          "next_para_id": "chap2_para51",
          "style_metadata": {
            "para_id": "chap2_para50",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 123,
            "sentence_count": 4
          },
          "terminology": {
            "practical": 1,
            "matter": 1,
            "seldom": 1,
            "requires": 1,
            "complete": 1,
            "autonomy": 1,
            "start": 1,
            "agent": 4,
            "little": 1,
            "experience": 2,
            "act": 1,
            "designer": 1,
            "gave": 1,
            "assistance": 1,
            "evolution": 1,
            "provides": 1,
            "animal": 1,
            "built-in": 1,
            "reflex": 1,
            "survive": 1,
            "learn": 2,
            "reasonable": 1,
            "provide": 1,
            "artificial": 1,
            "intelligent": 1,
            "initial": 1,
            "knowledge": 2,
            "ability": 1,
            "sufficient": 1,
            "environment": 2,
            "behavior": 1,
            "rational": 2,
            "become": 1,
            "independent": 1,
            "hence": 1,
            "incorporation": 1,
            "learning": 1,
            "allows": 1,
            "design": 1,
            "single": 1,
            "succeed": 1,
            "vast": 1,
            "variety": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para51",
          "content": "2.3The Nature of Environments\n2.3\nThe Nature of Environments\nNow that we have a definition of rationality, we are almost ready to think about building rational agents. First, however, we must think about\ntask environments\n, which are essentially the “problems” to which rational agents are the “solutions.” We begin by showing how to specify a task environment, illustrating the process with a number of examples. We then show that task environments come in a variety of flavors. The nature of the task environment directly affects the appropriate design for the agent program.",
          "sentence_count": 4,
          "char_count": 490,
          "prev_para_id": "chap2_para50",
          "next_para_id": "chap2_para52",
          "style_metadata": {
            "para_id": "chap2_para51",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 26.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 105,
            "sentence_count": 4
          },
          "terminology": {
            "nature": 3,
            "environment": 6,
            "definition": 1,
            "rationality": 1,
            "ready": 1,
            "think": 2,
            "building": 1,
            "rational": 2,
            "agent": 3,
            "first": 1,
            "task": 4,
            "problem": 1,
            "solutions.": 1,
            "begin": 1,
            "showing": 1,
            "specify": 1,
            "illustrating": 1,
            "process": 1,
            "number": 1,
            "example": 1,
            "show": 1,
            "come": 1,
            "variety": 1,
            "flavor": 1,
            "affect": 1,
            "appropriate": 1,
            "design": 1,
            "program": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para51",
              "entity_text": "Nature of Environments",
              "entity_type": "WORK_OF_ART",
              "start_char": 7,
              "end_char": 29,
              "context": "2.3The Nature of Environments\n2.3\nThe Nature of Environments\nNow that we have a"
            },
            {
              "para_id": "chap2_para51",
              "entity_text": "The Nature of Environments\nNow",
              "entity_type": "WORK_OF_ART",
              "start_char": 34,
              "end_char": 64,
              "context": "2.3The Nature of Environments\n2.3\nThe Nature of Environments\nNow that we have a definition of rationality, we are "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para52",
          "content": "2.3.1\nSpecifying the task environment\nIn our discussion of the rationality of the simple vacuum-cleaner agent, we had to specify the performance measure, the environment, and the agent’s actuators and sensors. We group all these under the heading of the\ntask environment\n. For the acronymically minded, we call this the\nPEAS\n(\nP\nerformance,\nE\nnvironment,\nA\nctuators,\nS\nensors) description. In designing an agent, the first step must always be to specify the task environment as fully as possible.",
          "sentence_count": 4,
          "char_count": 430,
          "prev_para_id": "chap2_para51",
          "next_para_id": "chap2_para53",
          "style_metadata": {
            "para_id": "chap2_para52",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 4
          },
          "terminology": {
            "specifying": 1,
            "task": 3,
            "environment": 4,
            "discussion": 1,
            "rationality": 1,
            "simple": 1,
            "vacuum-cleaner": 1,
            "agent": 3,
            "specify": 2,
            "performance": 1,
            "measure": 1,
            "actuator": 1,
            "sensor": 1,
            "group": 1,
            "heading": 1,
            "minded": 1,
            "call": 1,
            "pea": 1,
            "erformance": 1,
            "nvironment": 1,
            "ctuators": 1,
            "ensors": 1,
            "description": 1,
            "designing": 1,
            "first": 1,
            "step": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para53",
          "content": "The vacuum world was a simple example; let us consider a more complex problem: an automated taxi driver.",
          "sentence_count": 1,
          "char_count": 87,
          "prev_para_id": "chap2_para52",
          "next_para_id": "chap2_para54",
          "style_metadata": {
            "para_id": "chap2_para53",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "vacuum": 1,
            "world": 1,
            "simple": 1,
            "example": 1,
            "let": 1,
            "consider": 1,
            "complex": 1,
            "problem": 1,
            "automated": 1,
            "taxi": 1,
            "driver": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para54",
          "content": "Figure 2.4\nsummarizes the PEAS description for the taxi’s task environment. We discuss each element in more detail in the following paragraphs.",
          "sentence_count": 2,
          "char_count": 123,
          "prev_para_id": "chap2_para53",
          "next_para_id": "chap2_para55",
          "style_metadata": {
            "para_id": "chap2_para54",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "summarizes": 1,
            "pea": 1,
            "description": 1,
            "taxi": 1,
            "task": 1,
            "environment": 1,
            "discus": 1,
            "element": 1,
            "detail": 1,
            "following": 1,
            "paragraph": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para55",
          "content": "Description\nThe block diagram starts with a block labeled Agent. There are six blocks inside the Agent block. The first block inside the agent block is labeled, What the world is like now. Arrows from the second, third, and fourth blocks labeled State, How the world evolves, and What my actions do, point to the first block. A dashed arrow from the first block points back to the state block. A solid arrow from the first block points to the fifth block labeled, What action I should do now. An arrow from the sixth block labeled, Condition action rules, points to the fifth block. An arrow from the fifth block points to the Actuators. An arrow from actuators points to the block labeled, Environment, which is outside the agent block. An arrow from the environment block to the sensors in the agent block. An arrow from the sensors points back to the first block.",
          "sentence_count": 11,
          "char_count": 714,
          "prev_para_id": "chap2_para54",
          "next_para_id": "chap2_para56",
          "style_metadata": {
            "para_id": "chap2_para55",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 176,
            "sentence_count": 11
          },
          "terminology": {
            "description": 1,
            "block": 19,
            "diagram": 1,
            "start": 1,
            "labeled": 6,
            "agent": 5,
            "world": 2,
            "arrow": 8,
            "second": 1,
            "third": 1,
            "fourth": 1,
            "state": 2,
            "evolves": 1,
            "action": 3,
            "point": 7,
            "dashed": 1,
            "solid": 1,
            "fifth": 3,
            "sixth": 1,
            "condition": 1,
            "rule": 1,
            "actuator": 2,
            "environment": 2,
            "sensor": 2,
            "first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para55",
              "entity_text": "State",
              "entity_type": "ORG",
              "start_char": 246,
              "end_char": 251,
              "context": "from the second, third, and fourth blocks labeled State, How the world evolves, and What my actions do, p"
            },
            {
              "para_id": "chap2_para55",
              "entity_text": "Actuators",
              "entity_type": "ORG",
              "start_char": 627,
              "end_char": 636,
              "context": "lock. An arrow from the fifth block points to the Actuators. An arrow from actuators points to the block labe"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para56",
          "content": "×\nFigure 2.4\nPEAS description of the task environment for an automated taxi driver.",
          "sentence_count": 1,
          "char_count": 72,
          "prev_para_id": "chap2_para55",
          "next_para_id": "chap2_para57",
          "style_metadata": {
            "para_id": "chap2_para56",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "pea": 1,
            "description": 1,
            "task": 1,
            "environment": 1,
            "automated": 1,
            "taxi": 1,
            "driver": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para57",
          "content": "First, what is the\nperformance measure\nto which we would like our automated driver to aspire? Desirable qualities include getting to the correct destination; minimizing fuel consumption and wear and tear; minimizing the trip time or cost; minimizing violations of traffic laws and disturbances to other drivers; maximizing safety and passenger comfort; maximizing profits. Obviously, some of these goals conflict, so tradeoffs will be required.",
          "sentence_count": 3,
          "char_count": 382,
          "prev_para_id": "chap2_para56",
          "next_para_id": "chap2_para58",
          "style_metadata": {
            "para_id": "chap2_para57",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "first": 1,
            "performance": 1,
            "measure": 1,
            "like": 1,
            "automated": 1,
            "aspire": 1,
            "desirable": 1,
            "quality": 1,
            "include": 1,
            "getting": 1,
            "correct": 1,
            "destination": 1,
            "minimizing": 3,
            "fuel": 1,
            "consumption": 1,
            "tear": 1,
            "trip": 1,
            "time": 1,
            "cost": 1,
            "violation": 1,
            "traffic": 1,
            "law": 1,
            "disturbance": 1,
            "driver": 1,
            "maximizing": 2,
            "safety": 1,
            "passenger": 1,
            "comfort": 1,
            "profit": 1,
            "goal": 1,
            "conflict": 1,
            "tradeoff": 1,
            "required": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para58",
          "content": "Next, what is the driving\nenvironment\nthat the taxi will face? Any taxi driver must deal with a variety of roads, ranging from rural lanes and urban alleys to 12-lane freeways. The roads contain other traffic, pedestrians, stray animals, road works, police cars, puddles, and potholes. The taxi must also interact with potential and actual passengers. There are also some optional choices. The taxi might need to operate in Southern California, where snow is seldom a problem, or in Alaska, where it seldom is not. It could always be driving on the right, or we might want it to be flexible enough to drive on the left when in Britain or Japan. Obviously, the more restricted the environment, the easier the design problem.",
          "sentence_count": 8,
          "char_count": 603,
          "prev_para_id": "chap2_para57",
          "next_para_id": "chap2_para59",
          "style_metadata": {
            "para_id": "chap2_para58",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.12,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 145,
            "sentence_count": 8
          },
          "terminology": {
            "next": 1,
            "driving": 2,
            "environment": 2,
            "taxi": 4,
            "face": 1,
            "driver": 1,
            "deal": 1,
            "variety": 1,
            "road": 3,
            "ranging": 1,
            "rural": 1,
            "lane": 1,
            "urban": 1,
            "alley": 1,
            "12-lane": 1,
            "freeway": 1,
            "contain": 1,
            "traffic": 1,
            "pedestrian": 1,
            "stray": 1,
            "animal": 1,
            "work": 1,
            "police": 1,
            "car": 1,
            "puddle": 1,
            "pothole": 1,
            "interact": 1,
            "potential": 1,
            "actual": 1,
            "passenger": 1,
            "optional": 1,
            "choice": 1,
            "need": 1,
            "operate": 1,
            "southern": 1,
            "california": 1,
            "snow": 1,
            "seldom": 2,
            "problem": 2,
            "alaska": 1,
            "right": 1,
            "want": 1,
            "flexible": 1,
            "drive": 1,
            "left": 1,
            "britain": 1,
            "japan": 1,
            "restricted": 1,
            "easier": 1,
            "design": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para58",
              "entity_text": "Alaska",
              "entity_type": "GPE",
              "start_char": 483,
              "end_char": 489,
              "context": "California, where snow is seldom a problem, or in Alaska, where it seldom is not. It could always be drivi"
            },
            {
              "para_id": "chap2_para58",
              "entity_text": "Britain",
              "entity_type": "GPE",
              "start_char": 627,
              "end_char": 634,
              "context": "o be flexible enough to drive on the left when in Britain or Japan. Obviously, the more restricted the envi"
            },
            {
              "para_id": "chap2_para58",
              "entity_text": "Japan",
              "entity_type": "GPE",
              "start_char": 638,
              "end_char": 643,
              "context": "le enough to drive on the left when in Britain or Japan. Obviously, the more restricted the environment, "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para59",
          "content": "The\nactuators\nfor an automated taxi include those available to a human driver: control over the engine through the accelerator and control over steering and braking. In addition, it will need output to a display screen or voice synthesizer to talk back to the passengers, and perhaps some way to communicate with other vehicles, politely or otherwise.",
          "sentence_count": 2,
          "char_count": 297,
          "prev_para_id": "chap2_para58",
          "next_para_id": "chap2_para60",
          "style_metadata": {
            "para_id": "chap2_para59",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "actuator": 1,
            "automated": 1,
            "taxi": 1,
            "include": 1,
            "available": 1,
            "human": 1,
            "driver": 1,
            "control": 2,
            "engine": 1,
            "accelerator": 1,
            "steering": 1,
            "braking": 1,
            "addition": 1,
            "need": 1,
            "output": 1,
            "display": 1,
            "screen": 1,
            "voice": 1,
            "synthesizer": 1,
            "talk": 1,
            "passenger": 1,
            "way": 1,
            "communicate": 1,
            "vehicle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para60",
          "content": "The basic\nsensors\nfor the taxi will include one or more video cameras so that it can see, as well as lidar and ultrasound sensors to detect distances to other cars and obstacles. To avoid speeding tickets, the taxi should have a speedometer, and to control the vehicle properly, especially on curves, it should have an accelerometer. To determine the mechanical state of the vehicle, it will need the usual array of engine, fuel, and electrical system sensors. Like many human drivers, it might want to access GPS signals so that it doesn’t get lost. Finally, it will need touchscreen or voice input for the passenger to request a destination.",
          "sentence_count": 5,
          "char_count": 536,
          "prev_para_id": "chap2_para59",
          "next_para_id": "chap2_para61",
          "style_metadata": {
            "para_id": "chap2_para60",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 127,
            "sentence_count": 5
          },
          "terminology": {
            "basic": 1,
            "sensor": 3,
            "taxi": 2,
            "include": 1,
            "video": 1,
            "camera": 1,
            "see": 1,
            "ultrasound": 1,
            "detect": 1,
            "distance": 1,
            "car": 1,
            "obstacle": 1,
            "avoid": 1,
            "speeding": 1,
            "ticket": 1,
            "speedometer": 1,
            "control": 1,
            "vehicle": 2,
            "curve": 1,
            "accelerometer": 1,
            "determine": 1,
            "mechanical": 1,
            "state": 1,
            "need": 2,
            "usual": 1,
            "array": 1,
            "engine": 1,
            "fuel": 1,
            "electrical": 1,
            "system": 1,
            "many": 1,
            "human": 1,
            "driver": 1,
            "want": 1,
            "access": 1,
            "gps": 1,
            "signal": 1,
            "get": 1,
            "lost": 1,
            "touchscreen": 1,
            "voice": 1,
            "input": 1,
            "passenger": 1,
            "request": 1,
            "destination": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para61",
          "content": "In\nFigure 2.5\n, we have sketched the basic PEAS elements for a number of additional agent types. Further examples appear in Exercise\n2.",
          "sentence_count": 2,
          "char_count": 115,
          "prev_para_id": "chap2_para60",
          "next_para_id": "chap2_para62",
          "style_metadata": {
            "para_id": "chap2_para61",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "sketched": 1,
            "basic": 1,
            "pea": 1,
            "element": 1,
            "number": 1,
            "additional": 1,
            "agent": 1,
            "type": 1,
            "example": 1,
            "appear": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para62",
          "content": "PEAS\n. The examples include physical as well as virtual environments. Note that virtual task environments can be just as complex as the “real” world: for example, a\nsoftware agent\n(or software robot or\nsoftbot\n) that trades on auction and reselling Web sites deals with millions of other users and billions of objects, many with real images.",
          "sentence_count": 3,
          "char_count": 289,
          "prev_para_id": "chap2_para61",
          "next_para_id": "chap2_para63",
          "style_metadata": {
            "para_id": "chap2_para62",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 3
          },
          "terminology": {
            "pea": 1,
            "example": 2,
            "include": 1,
            "physical": 1,
            "virtual": 2,
            "environment": 2,
            "note": 1,
            "task": 1,
            "complex": 1,
            "real": 2,
            "world": 1,
            "software": 2,
            "agent": 1,
            "robot": 1,
            "softbot": 1,
            "trade": 1,
            "auction": 1,
            "reselling": 1,
            "web": 1,
            "site": 1,
            "deal": 1,
            "million": 1,
            "user": 1,
            "billion": 1,
            "object": 1,
            "many": 1,
            "image": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para63",
          "content": "Description\nThe block diagram starts with a block labeled Agent. There are seven blocks inside the Agent block. The first block inside the agent block is labeled, What the word is like now. Arrows from the second, third, and fourth blocks labeled State, How the world evolves, and What my actions do, point to the first block. A dashed arow from the first block points back to the state block. A solid arrow from the first block points to the fifth block labeled, What it will be like if I do action \"A\". Arrows from third and fourth blocks labeled, How the world evolves and What my action do, point to fifth block. An arrow from the fifth block points to the sixth block labeled, What action I should do now. An arrow from the seventh block labeled Goals points to the sixth block. An arrow from the sixth block points to the Actuators. An arrow from the actuators points to the block labeled, Environment, which is outside the agent block. An arrow from the environment block points to the sensors in the agent block. An arrow from the sensors points back to the first block.",
          "sentence_count": 13,
          "char_count": 884,
          "prev_para_id": "chap2_para62",
          "next_para_id": "chap2_para64",
          "style_metadata": {
            "para_id": "chap2_para63",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.15,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 223,
            "sentence_count": 13
          },
          "terminology": {
            "description": 1,
            "block": 23,
            "diagram": 1,
            "start": 1,
            "labeled": 8,
            "agent": 5,
            "word": 1,
            "arrow": 9,
            "second": 1,
            "third": 2,
            "fourth": 2,
            "state": 2,
            "world": 2,
            "evolves": 2,
            "action": 4,
            "point": 10,
            "dashed": 1,
            "arow": 1,
            "solid": 1,
            "fifth": 3,
            "sixth": 3,
            "seventh": 1,
            "goal": 1,
            "actuator": 2,
            "environment": 2,
            "sensor": 2,
            "first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para63",
              "entity_text": "State",
              "entity_type": "ORG",
              "start_char": 247,
              "end_char": 252,
              "context": "from the second, third, and fourth blocks labeled State, How the world evolves, and What my actions do, p"
            },
            {
              "para_id": "chap2_para63",
              "entity_text": "Actuators",
              "entity_type": "ORG",
              "start_char": 828,
              "end_char": 837,
              "context": "lock. An arrow from the sixth block points to the Actuators. An arrow from the actuators points to the block "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para64",
          "content": "×\nFigure 2.5\nExamples of agent types and their PEAS descriptions.",
          "sentence_count": 1,
          "char_count": 57,
          "prev_para_id": "chap2_para63",
          "next_para_id": "chap2_para65",
          "style_metadata": {
            "para_id": "chap2_para64",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "example": 1,
            "agent": 1,
            "type": 1,
            "pea": 1,
            "description": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para65",
          "content": "2.3.2\nProperties of task environments\nThe range of task environments that might arise in AI is obviously vast. We can, however, identify a fairly small number of dimensions along which task environments can be categorized. These dimensions determine, to a large extent, the appropriate agent design and the applicability of each of the principal families of techniques for agent implementation. First we list the dimensions, then we analyze several task environments to illustrate the ideas. The definitions here are informal; later chapters provide more precise statements and examples of each kind of environment.",
          "sentence_count": 5,
          "char_count": 525,
          "prev_para_id": "chap2_para64",
          "next_para_id": "chap2_para66",
          "style_metadata": {
            "para_id": "chap2_para65",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 20.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 104,
            "sentence_count": 5
          },
          "terminology": {
            "property": 1,
            "task": 4,
            "environment": 5,
            "range": 1,
            "arise": 1,
            "vast": 1,
            "identify": 1,
            "small": 1,
            "number": 1,
            "dimension": 3,
            "categorized": 1,
            "determine": 1,
            "large": 1,
            "extent": 1,
            "appropriate": 1,
            "agent": 2,
            "design": 1,
            "applicability": 1,
            "principal": 1,
            "family": 1,
            "technique": 1,
            "implementation": 1,
            "list": 1,
            "analyze": 1,
            "several": 1,
            "illustrate": 1,
            "idea": 1,
            "definition": 1,
            "informal": 1,
            "chapter": 1,
            "provide": 1,
            "precise": 1,
            "statement": 1,
            "example": 1,
            "kind": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para65",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 89,
              "end_char": 91,
              "context": "he range of task environments that might arise in AI is obviously vast. We can, however, identify a fa"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para66",
          "content": "Fully observable\nvs.",
          "sentence_count": 1,
          "char_count": 19,
          "prev_para_id": "chap2_para65",
          "next_para_id": "chap2_para67",
          "style_metadata": {
            "para_id": "chap2_para66",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "observable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para67",
          "content": "partially observable\n: If an agent’s sensors give it access to the complete state of the environment at each point in time, then we say that the task environment is fully observable. A task environment is effectively fully observable if the sensors detect all aspects that are\nrelevant\nto the choice of action; relevance, in turn, depends on the\nperformance measure. Fully observable environments are convenient because the agent need not maintain any internal state to keep track of the world. An environment might be partially observable because of noisy and inaccurate sensors or because parts of the state are simply missing from the sensor data—for example, a vacuum agent with only a local dirt sensor cannot tell whether there is dirt in other squares, and an automated taxi cannot see what other drivers are thinking. If the agent has no sensors at all then the environment is\nunobservable\n. One might think that in such cases the agent’s plight is hopeless, but, as we discuss in\nChapter 4\n, the agent’s goals may still be achievable, sometimes with certainty.",
          "sentence_count": 6,
          "char_count": 898,
          "prev_para_id": "chap2_para66",
          "next_para_id": "chap2_para68",
          "style_metadata": {
            "para_id": "chap2_para67",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 202,
            "sentence_count": 6
          },
          "terminology": {
            "observable": 5,
            "agent": 6,
            "sensor": 6,
            "give": 1,
            "access": 1,
            "complete": 1,
            "state": 3,
            "environment": 6,
            "point": 1,
            "time": 1,
            "say": 1,
            "task": 2,
            "detect": 1,
            "aspect": 1,
            "relevant": 1,
            "choice": 1,
            "action": 1,
            "relevance": 1,
            "turn": 1,
            "depends": 1,
            "performance": 1,
            "measure": 1,
            "convenient": 1,
            "need": 1,
            "maintain": 1,
            "internal": 1,
            "keep": 1,
            "track": 1,
            "world": 1,
            "noisy": 1,
            "inaccurate": 1,
            "part": 1,
            "missing": 1,
            "data—for": 1,
            "example": 1,
            "vacuum": 1,
            "local": 1,
            "dirt": 2,
            "tell": 1,
            "square": 1,
            "automated": 1,
            "taxi": 1,
            "see": 1,
            "driver": 1,
            "thinking": 1,
            "unobservable": 1,
            "think": 1,
            "case": 1,
            "plight": 1,
            "hopeless": 1,
            "discus": 1,
            "chapter": 1,
            "goal": 1,
            "achievable": 1,
            "certainty": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para68",
          "content": "Single-agent\nvs.",
          "sentence_count": 1,
          "char_count": 16,
          "prev_para_id": "chap2_para67",
          "next_para_id": "chap2_para69",
          "style_metadata": {
            "para_id": "chap2_para68",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "single-agent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para69",
          "content": "multiagent\n: The distinction between single-agent and multiagent environments may seem simple enough. For example, an agent solving a crossword puzzle by itself is clearly in a single-agent environment, whereas an agent playing chess is in a two-agent environment. However, there are some subtle issues. First, we have described how an entity\nmay\nbe viewed as an agent, but we have not explained which entities\nmust\nbe viewed as agents. Does an agent\nA\n(the taxi driver for example) have to treat an object\nB\n(another vehicle) as an agent, or can it be treated merely as an object behaving according to the laws of physics, analogous to waves at the beach or leaves blowing in the wind? The key distinction is whether\nB\n’s behavior is best described as maximizing a performance measure whose value depends on agent\nA\n’s behavior.",
          "sentence_count": 6,
          "char_count": 701,
          "prev_para_id": "chap2_para68",
          "next_para_id": "chap2_para70",
          "style_metadata": {
            "para_id": "chap2_para69",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 26.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 161,
            "sentence_count": 6
          },
          "terminology": {
            "multiagent": 2,
            "distinction": 2,
            "single-agent": 2,
            "environment": 3,
            "seem": 1,
            "simple": 1,
            "example": 2,
            "agent": 7,
            "solving": 1,
            "crossword": 1,
            "puzzle": 1,
            "whereas": 1,
            "playing": 1,
            "chess": 1,
            "two-agent": 1,
            "subtle": 1,
            "issue": 1,
            "described": 2,
            "entity": 2,
            "viewed": 2,
            "explained": 1,
            "taxi": 1,
            "driver": 1,
            "treat": 1,
            "object": 2,
            "vehicle": 1,
            "treated": 1,
            "behaving": 1,
            "according": 1,
            "law": 1,
            "physic": 1,
            "analogous": 1,
            "wave": 1,
            "beach": 1,
            "leaf": 1,
            "blowing": 1,
            "key": 1,
            "behavior": 2,
            "best": 1,
            "maximizing": 1,
            "performance": 1,
            "measure": 1,
            "value": 1,
            "depends": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para70",
          "content": "For example, in chess, the opponent entity\nB\nis trying to maximize its performance measure, which, by the rules of chess, minimizes agent\nA\n’s performance measure. Thus, chess is a\ncompetitive\nmultiagent environment. On the other hand, in the taxi-driving environment, avoiding collisions maximizes the performance measure of all agents, so it is a partially\ncooperative\nmultiagent environment. It is also partially competitive because, for example, only one car can occupy a parking space.",
          "sentence_count": 4,
          "char_count": 424,
          "prev_para_id": "chap2_para69",
          "next_para_id": "chap2_para71",
          "style_metadata": {
            "para_id": "chap2_para70",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 4
          },
          "terminology": {
            "example": 2,
            "chess": 2,
            "opponent": 1,
            "entity": 1,
            "trying": 1,
            "maximize": 1,
            "performance": 3,
            "measure": 3,
            "rule": 1,
            "minimizes": 1,
            "agent": 2,
            "competitive": 2,
            "multiagent": 2,
            "environment": 3,
            "hand": 1,
            "taxi-driving": 1,
            "avoiding": 1,
            "collision": 1,
            "maximizes": 1,
            "cooperative": 1,
            "car": 1,
            "occupy": 1,
            "parking": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para71",
          "content": "The agent-design problems in multiagent environments are often quite different from those in single-agent environments; for example, communication often emerges as a rational behavior in multiagent environments; in some competitive environments, randomized behavior is rational because it avoids the pitfalls of predictability.",
          "sentence_count": 1,
          "char_count": 286,
          "prev_para_id": "chap2_para70",
          "next_para_id": "chap2_para72",
          "style_metadata": {
            "para_id": "chap2_para71",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 47.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 1
          },
          "terminology": {
            "agent-design": 1,
            "problem": 1,
            "multiagent": 2,
            "environment": 4,
            "different": 1,
            "single-agent": 1,
            "example": 1,
            "communication": 1,
            "emerges": 1,
            "rational": 2,
            "behavior": 2,
            "competitive": 1,
            "randomized": 1,
            "avoids": 1,
            "pitfall": 1,
            "predictability": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para72",
          "content": "Deterministic\nvs.",
          "sentence_count": 1,
          "char_count": 17,
          "prev_para_id": "chap2_para71",
          "next_para_id": "chap2_para73",
          "style_metadata": {
            "para_id": "chap2_para72",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "deterministic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para73",
          "content": "nondeterministic\n. If the next state of the environment is completely determined by the current state and the action executed by the agent(s), then we say the environment is deterministic; otherwise, it is nondeterministic. In principle, an agent need not worry about uncertainty in a fully observable, deterministic environment. If the environment is partially observable, however, then it could\nappear\nto be nondeterministic.",
          "sentence_count": 4,
          "char_count": 368,
          "prev_para_id": "chap2_para72",
          "next_para_id": "chap2_para74",
          "style_metadata": {
            "para_id": "chap2_para73",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 76,
            "sentence_count": 4
          },
          "terminology": {
            "nondeterministic": 3,
            "next": 1,
            "state": 2,
            "environment": 4,
            "determined": 1,
            "current": 1,
            "action": 1,
            "executed": 1,
            "agent": 2,
            "say": 1,
            "deterministic": 2,
            "principle": 1,
            "need": 1,
            "worry": 1,
            "uncertainty": 1,
            "observable": 2,
            "appear": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para74",
          "content": "Most real situations are so complex that it is impossible to keep track of all the unobserved aspects; for practical purposes, they must be treated as nondeterministic. Taxi driving is clearly nondeterministic in this sense, because one can never predict the behavior of traffic exactly; moreover, one’s tires may blow out unexpectedly and one’s engine may seize up without warning. The vacuum world as we described it is deterministic, but variations can include nondeterministic elements such as randomly appearing dirt and an unreliable suction mechanism (Exercise\n2.",
          "sentence_count": 3,
          "char_count": 485,
          "prev_para_id": "chap2_para73",
          "next_para_id": "chap2_para75",
          "style_metadata": {
            "para_id": "chap2_para74",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 33.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 101,
            "sentence_count": 3
          },
          "terminology": {
            "real": 1,
            "situation": 1,
            "complex": 1,
            "impossible": 1,
            "keep": 1,
            "track": 1,
            "unobserved": 1,
            "aspect": 1,
            "practical": 1,
            "purpose": 1,
            "treated": 1,
            "nondeterministic": 3,
            "taxi": 1,
            "driving": 1,
            "sense": 1,
            "predict": 1,
            "behavior": 1,
            "traffic": 1,
            "tire": 1,
            "blow": 1,
            "engine": 1,
            "seize": 1,
            "warning": 1,
            "vacuum": 1,
            "world": 1,
            "described": 1,
            "deterministic": 1,
            "variation": 1,
            "include": 1,
            "element": 1,
            "appearing": 1,
            "dirt": 1,
            "unreliable": 1,
            "suction": 1,
            "mechanism": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para75",
          "content": "VFIN\n)\n.",
          "sentence_count": 1,
          "char_count": 8,
          "prev_para_id": "chap2_para74",
          "next_para_id": "chap2_para76",
          "style_metadata": {
            "para_id": "chap2_para75",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "vfin": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para76",
          "content": "One final note: the word\nstochastic\nis used by some as a synonym for “nondeterministic,” but we make a distinction between the two terms; we say that a model of the environment is stochastic if it explicitly deals with probabilities (e.g., “there’s a 25% chance of rain tomorrow”) and “nondeterministic” if the possibilities are listed without being quantified (e.g., “there’s a chance of rain tomorrow”).",
          "sentence_count": 1,
          "char_count": 343,
          "prev_para_id": "chap2_para75",
          "next_para_id": "chap2_para77",
          "style_metadata": {
            "para_id": "chap2_para76",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 88.0,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 1
          },
          "terminology": {
            "final": 1,
            "note": 1,
            "word": 1,
            "stochastic": 2,
            "used": 1,
            "synonym": 1,
            "nondeterministic": 2,
            "make": 1,
            "distinction": 1,
            "term": 1,
            "say": 1,
            "model": 1,
            "environment": 1,
            "deal": 1,
            "probability": 1,
            "e.g.": 2,
            "chance": 2,
            "rain": 2,
            "tomorrow": 2,
            "possibility": 1,
            "listed": 1,
            "quantified": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para77",
          "content": "Episodic\nvs.",
          "sentence_count": 1,
          "char_count": 12,
          "prev_para_id": "chap2_para76",
          "next_para_id": "chap2_para78",
          "style_metadata": {
            "para_id": "chap2_para77",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "episodic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para78",
          "content": "sequential\n: In an episodic task environment, the agent’s experience is divided into atomic episodes. In each episode the agent receives a percept and then performs a single action. Crucially, the next episode does not depend on the actions taken in previous episodes. Many classification tasks are episodic. For example, an agent that has to spot defective parts on an assembly line bases each decision on the current part, regardless of previous decisions; moreover, the current decision doesn’t affect whether the next part is defective. In sequential environments, on the other hand, the current decision could affect all future decisions.",
          "sentence_count": 6,
          "char_count": 545,
          "prev_para_id": "chap2_para77",
          "next_para_id": "chap2_para79",
          "style_metadata": {
            "para_id": "chap2_para78",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 118,
            "sentence_count": 6
          },
          "terminology": {
            "sequential": 2,
            "episodic": 2,
            "task": 2,
            "environment": 2,
            "agent": 3,
            "experience": 1,
            "divided": 1,
            "atomic": 1,
            "episode": 4,
            "receives": 1,
            "performs": 1,
            "single": 1,
            "action": 2,
            "next": 2,
            "depend": 1,
            "taken": 1,
            "previous": 2,
            "many": 1,
            "classification": 1,
            "example": 1,
            "spot": 1,
            "defective": 2,
            "part": 3,
            "line": 1,
            "base": 1,
            "decision": 5,
            "current": 3,
            "affect": 2,
            "hand": 1,
            "future": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para79",
          "content": "4\nChess and taxi driving are sequential: in both cases, short-term actions can have long-term consequences. Episodic environments are much simpler than sequential environments because the agent does not need to think ahead.",
          "sentence_count": 2,
          "char_count": 192,
          "prev_para_id": "chap2_para78",
          "next_para_id": "chap2_para80",
          "style_metadata": {
            "para_id": "chap2_para79",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "chess": 1,
            "taxi": 1,
            "driving": 1,
            "sequential": 2,
            "case": 1,
            "short-term": 1,
            "action": 1,
            "long-term": 1,
            "consequence": 1,
            "episodic": 1,
            "environment": 2,
            "much": 1,
            "simpler": 1,
            "agent": 1,
            "think": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para80",
          "content": "Static\nvs.",
          "sentence_count": 1,
          "char_count": 10,
          "prev_para_id": "chap2_para79",
          "next_para_id": "chap2_para81",
          "style_metadata": {
            "para_id": "chap2_para80",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "static": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para81",
          "content": "dynamic\n: If the environment can change while an agent is deliberating, then we say the environment is dynamic for that agent; otherwise, it is static. Static environments are easy to deal with because the agent need not keep looking at the world while it is deciding on an action, nor need it worry about the passage of time. Dynamic environments, on the other hand, are continuously asking the agent what it wants to do; if it hasn’t decided yet,\nthat counts as deciding to do nothing. If the environment itself does not change with the passage of time but the agent’s performance score does, then we say the environment is\nsemidynamic\n. Taxi driving is clearly dynamic: the other cars and the taxi itself keep moving while the driving algorithm dithers about what to do next. Chess, when played with a clock, is semidynamic. Crossword puzzles are static.",
          "sentence_count": 7,
          "char_count": 713,
          "prev_para_id": "chap2_para80",
          "next_para_id": "chap2_para82",
          "style_metadata": {
            "para_id": "chap2_para81",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 171,
            "sentence_count": 7
          },
          "terminology": {
            "dynamic": 4,
            "environment": 6,
            "change": 2,
            "agent": 5,
            "deliberating": 1,
            "say": 2,
            "static": 3,
            "easy": 1,
            "deal": 1,
            "need": 2,
            "keep": 2,
            "looking": 1,
            "world": 1,
            "deciding": 2,
            "action": 1,
            "worry": 1,
            "passage": 2,
            "time": 2,
            "hand": 1,
            "asking": 1,
            "want": 1,
            "decided": 1,
            "count": 1,
            "nothing": 1,
            "performance": 1,
            "score": 1,
            "semidynamic": 2,
            "taxi": 2,
            "driving": 2,
            "car": 1,
            "moving": 1,
            "algorithm": 1,
            "dither": 1,
            "chess": 1,
            "played": 1,
            "clock": 1,
            "crossword": 1,
            "puzzle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para82",
          "content": "Discrete\nvs.",
          "sentence_count": 1,
          "char_count": 12,
          "prev_para_id": "chap2_para81",
          "next_para_id": "chap2_para83",
          "style_metadata": {
            "para_id": "chap2_para82",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "discrete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para83",
          "content": "continuous\n: The discrete/continuous distinction applies to the\nstate\nof the environment, to the way\ntime\nis handled, and to the\npercepts\nand\nactions\nof the agent. For example, the chess environment has a finite number of distinct states (excluding the clock). Chess also has a discrete set of percepts and actions. Taxi driving is a continuous-state and continuous-time problem: the speed and location of the taxi and of the other vehicles sweep through a range of continuous values and do so smoothly over time. Taxi-driving actions are also continuous (steering angles, etc.). Input from digital cameras is discrete, strictly speaking, but is typically treated as representing continuously varying intensities and locations.",
          "sentence_count": 6,
          "char_count": 625,
          "prev_para_id": "chap2_para82",
          "next_para_id": "chap2_para84",
          "style_metadata": {
            "para_id": "chap2_para83",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 129,
            "sentence_count": 6
          },
          "terminology": {
            "continuous": 3,
            "discrete/continuous": 1,
            "distinction": 1,
            "applies": 1,
            "state": 2,
            "environment": 2,
            "way": 1,
            "time": 2,
            "handled": 1,
            "percept": 2,
            "action": 3,
            "agent": 1,
            "example": 1,
            "chess": 2,
            "finite": 1,
            "number": 1,
            "distinct": 1,
            "excluding": 1,
            "clock": 1,
            "discrete": 2,
            "set": 1,
            "taxi": 2,
            "driving": 1,
            "continuous-state": 1,
            "continuous-time": 1,
            "problem": 1,
            "speed": 1,
            "location": 2,
            "vehicle": 1,
            "sweep": 1,
            "range": 1,
            "value": 1,
            "smoothly": 1,
            "taxi-driving": 1,
            "steering": 1,
            "angle": 1,
            "input": 1,
            "digital": 1,
            "camera": 1,
            "speaking": 1,
            "treated": 1,
            "representing": 1,
            "varying": 1,
            "intensity": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para83",
              "entity_text": "Chess",
              "entity_type": "ORG",
              "start_char": 261,
              "end_char": 266,
              "context": " number of distinct states (excluding the clock). Chess also has a discrete set of percepts and actions. "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para84",
          "content": "Known\nvs.",
          "sentence_count": 1,
          "char_count": 9,
          "prev_para_id": "chap2_para83",
          "next_para_id": "chap2_para85",
          "style_metadata": {
            "para_id": "chap2_para84",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 3,
            "sentence_count": 1
          },
          "terminology": {
            "known": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para85",
          "content": "unknown\n: Strictly speaking, this distinction refers not to the environment itself but to the agent’s (or designer’s) state of knowledge about the “laws of physics” of the environment. In a known environment, the outcomes (or outcome probabilities if the environment is nondeterministic) for all actions are given. Obviously, if the environment is unknown, the agent will have to learn how it works in order to make good decisions.",
          "sentence_count": 3,
          "char_count": 364,
          "prev_para_id": "chap2_para84",
          "next_para_id": "chap2_para86",
          "style_metadata": {
            "para_id": "chap2_para85",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 86,
            "sentence_count": 3
          },
          "terminology": {
            "unknown": 2,
            "speaking": 1,
            "distinction": 1,
            "refers": 1,
            "environment": 5,
            "agent": 2,
            "designer": 1,
            "state": 1,
            "knowledge": 1,
            "law": 1,
            "physic": 1,
            "known": 1,
            "outcome": 2,
            "probability": 1,
            "nondeterministic": 1,
            "action": 1,
            "given": 1,
            "learn": 1,
            "work": 1,
            "order": 1,
            "make": 1,
            "good": 1,
            "decision": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para86",
          "content": "The distinction between known and unknown environments is not the same as the one between fully and partially observable environments. It is quite possible for a\nknown\nenvironment to be\npartially\nobservable—for example, in solitaire card games, I know the rules but am still unable to see the cards that have not yet been turned over. Conversely, an\nunknown\nenvironment can be\nfully\nobservable—in a new video game, the screen may show the entire game state but I still don’t know what the buttons do until I try them.",
          "sentence_count": 3,
          "char_count": 437,
          "prev_para_id": "chap2_para85",
          "next_para_id": "chap2_para87",
          "style_metadata": {
            "para_id": "chap2_para86",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 98,
            "sentence_count": 3
          },
          "terminology": {
            "distinction": 1,
            "known": 2,
            "unknown": 2,
            "environment": 4,
            "observable": 1,
            "possible": 1,
            "observable—for": 1,
            "example": 1,
            "solitaire": 1,
            "card": 2,
            "game": 3,
            "know": 2,
            "rule": 1,
            "unable": 1,
            "see": 1,
            "turned": 1,
            "observable—in": 1,
            "new": 1,
            "video": 1,
            "screen": 1,
            "show": 1,
            "entire": 1,
            "state": 1,
            "button": 1,
            "try": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para87",
          "content": "As noted on\npage 57\n, the performance measure itself may be unknown, either because the designer is not sure how to write it down correctly or because the ultimate user—whose preferences matter—is not known. For example, a taxi driver usually won’t know whether a new passenger prefers a leisurely or speedy journey, a cautious or aggressive driving style. A virtual personal assistant starts out knowing nothing about the personal preferences of its new owner. In such cases, the agent may learn more about the performance measure based on further interactions with the designer or user. This, in turn, suggests that the task environment is necessarily viewed as a multiagent environment.",
          "sentence_count": 5,
          "char_count": 581,
          "prev_para_id": "chap2_para86",
          "next_para_id": "chap2_para88",
          "style_metadata": {
            "para_id": "chap2_para87",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 124,
            "sentence_count": 5
          },
          "terminology": {
            "noted": 1,
            "page": 1,
            "performance": 2,
            "measure": 2,
            "unknown": 1,
            "designer": 2,
            "sure": 1,
            "ultimate": 1,
            "user—whose": 1,
            "preference": 2,
            "matter—is": 1,
            "known": 1,
            "example": 1,
            "taxi": 1,
            "driver": 1,
            "know": 1,
            "new": 2,
            "passenger": 1,
            "prefers": 1,
            "speedy": 1,
            "journey": 1,
            "cautious": 1,
            "aggressive": 1,
            "driving": 1,
            "style": 1,
            "virtual": 1,
            "personal": 2,
            "assistant": 1,
            "start": 1,
            "knowing": 1,
            "nothing": 1,
            "owner": 1,
            "case": 1,
            "agent": 1,
            "learn": 1,
            "based": 1,
            "interaction": 1,
            "user": 1,
            "turn": 1,
            "suggests": 1,
            "task": 1,
            "environment": 2,
            "viewed": 1,
            "multiagent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para88",
          "content": "The hardest case is\npartially observable\n,\nmultiagent\n,\nnondeterministic\n,\nsequential\n,\ndynamic\n,\ncontinuous\n, and\nunknown\n. Taxi driving is hard in all these senses, except that the driver’s environment is mostly known. Driving a rented car in a new country with unfamiliar geography, different traffic laws, and nervous passengers is a lot more exciting.",
          "sentence_count": 3,
          "char_count": 313,
          "prev_para_id": "chap2_para87",
          "next_para_id": "chap2_para89",
          "style_metadata": {
            "para_id": "chap2_para88",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 3
          },
          "terminology": {
            "hardest": 1,
            "case": 1,
            "observable": 1,
            "multiagent": 1,
            "nondeterministic": 1,
            "sequential": 1,
            "dynamic": 1,
            "continuous": 1,
            "unknown": 1,
            "taxi": 1,
            "driving": 2,
            "hard": 1,
            "sens": 1,
            "driver": 1,
            "environment": 1,
            "known": 1,
            "rented": 1,
            "car": 1,
            "new": 1,
            "country": 1,
            "unfamiliar": 1,
            "geography": 1,
            "different": 1,
            "traffic": 1,
            "law": 1,
            "nervous": 1,
            "passenger": 1,
            "lot": 1,
            "exciting": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para89",
          "content": "Figure 2.6\nlists the properties of a number of familiar environments. Note that the properties are not always cut and dried. For example, we have listed the medical-diagnosis task as single-agent because the disease process in a patient is not profitably modeled as an agent; but a medical-diagnosis system might also have to deal with recalcitrant patients and skeptical staff, so the environment could have a multiagent aspect. Furthermore, medical diagnosis is episodic if one conceives of the task as selecting a diagnosis given a list of symptoms; the problem is sequential if the task can include proposing a series of tests, evaluating progress over the course of treatment, handling multiple patients, and so on.",
          "sentence_count": 4,
          "char_count": 607,
          "prev_para_id": "chap2_para88",
          "next_para_id": "chap2_para90",
          "style_metadata": {
            "para_id": "chap2_para89",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 31.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore"
            ],
            "word_count": 127,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "list": 2,
            "property": 2,
            "number": 1,
            "familiar": 1,
            "environment": 2,
            "note": 1,
            "cut": 1,
            "dried": 1,
            "example": 1,
            "listed": 1,
            "medical-diagnosis": 2,
            "task": 3,
            "single-agent": 1,
            "disease": 1,
            "process": 1,
            "patient": 3,
            "modeled": 1,
            "agent": 1,
            "system": 1,
            "deal": 1,
            "recalcitrant": 1,
            "skeptical": 1,
            "staff": 1,
            "multiagent": 1,
            "aspect": 1,
            "medical": 1,
            "diagnosis": 2,
            "episodic": 1,
            "conceives": 1,
            "selecting": 1,
            "given": 1,
            "symptom": 1,
            "problem": 1,
            "sequential": 1,
            "include": 1,
            "proposing": 1,
            "series": 1,
            "test": 1,
            "evaluating": 1,
            "progress": 1,
            "course": 1,
            "treatment": 1,
            "handling": 1,
            "multiple": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para90",
          "content": "Description\nThe block diagram starts with a block labeled Agent. There are eight blocks inside the Agent block. The first block inside the agent block is labeled, What the world is like now. Arrows from the second, third, and fourth blocks labeled State, How the world evolves, and What my actions do, point to the first block. A dashed arow from the first block points back to the state block. A solid arrow from the first block points to the fifth block labeled, What it will be like if I do action \"A\". Arrows from third and fourth blocks labeled, How the world evolves and What my action do, point to fifth block. An arrow from the fifth block points to the sixth block labeled, How happy I will be in such a state. An arrow from the seventh block labeled Utility also points to the sixth block. An arrow from the sixth block points to the eighth block labeled, What action I should do now. An arrow from the eighth block points to the Actuators. An arrow from the actuators points to the block labeled, Environment, which is outside the agent block. An arrow from the environment block points to the sensors in the agent block. An arrow from the sensors points back to the first block.",
          "sentence_count": 14,
          "char_count": 974,
          "prev_para_id": "chap2_para89",
          "next_para_id": "chap2_para91",
          "style_metadata": {
            "para_id": "chap2_para90",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.64,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 247,
            "sentence_count": 14
          },
          "terminology": {
            "description": 1,
            "block": 25,
            "diagram": 1,
            "start": 1,
            "labeled": 9,
            "agent": 5,
            "world": 3,
            "arrow": 10,
            "second": 1,
            "third": 2,
            "fourth": 2,
            "state": 3,
            "evolves": 2,
            "action": 4,
            "point": 11,
            "dashed": 1,
            "arow": 1,
            "solid": 1,
            "fifth": 3,
            "sixth": 3,
            "happy": 1,
            "seventh": 1,
            "utility": 1,
            "eighth": 2,
            "actuator": 2,
            "environment": 2,
            "sensor": 2,
            "first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para90",
              "entity_text": "State",
              "entity_type": "ORG",
              "start_char": 248,
              "end_char": 253,
              "context": "from the second, third, and fourth blocks labeled State, How the world evolves, and What my actions do, p"
            },
            {
              "para_id": "chap2_para90",
              "entity_text": "Actuators",
              "entity_type": "ORG",
              "start_char": 940,
              "end_char": 949,
              "context": "now. An arrow from the eighth block points to the Actuators. An arrow from the actuators points to the block "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para91",
          "content": "×\nFigure 2.6\nExamples of task environments and their characteristics.",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap2_para90",
          "next_para_id": "chap2_para92",
          "style_metadata": {
            "para_id": "chap2_para91",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "example": 1,
            "task": 1,
            "environment": 1,
            "characteristic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para92",
          "content": "We have not included a “known/unknown” column because, as explained earlier, this is not strictly a property of the environment. For some environments, such as chess and poker, it is quite easy to supply the agent with full knowledge of the rules, but it is nonetheless interesting to consider how an agent might learn to play these games without such knowledge.",
          "sentence_count": 2,
          "char_count": 302,
          "prev_para_id": "chap2_para91",
          "next_para_id": "chap2_para93",
          "style_metadata": {
            "para_id": "chap2_para92",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 2
          },
          "terminology": {
            "included": 1,
            "known/unknown": 1,
            "column": 1,
            "explained": 1,
            "property": 1,
            "environment": 2,
            "chess": 1,
            "poker": 1,
            "easy": 1,
            "supply": 1,
            "agent": 2,
            "full": 1,
            "knowledge": 2,
            "rule": 1,
            "interesting": 1,
            "consider": 1,
            "learn": 1,
            "play": 1,
            "game": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para93",
          "content": "The code repository associated with this book (\naima.cs.berkeley.edu\n) includes multiple environment implementations, together with a general-purpose environment simulator for evaluating an agent’s performance. Experiments are often carried out not for a single environment but for many environments drawn from an\nenvironment class\n. For example, to evaluate a taxi driver in simulated traffic, we would want to run many simulations with different traffic, lighting, and weather conditions. We are then interested in the agent’s average performance over the environment class.",
          "sentence_count": 4,
          "char_count": 499,
          "prev_para_id": "chap2_para92",
          "next_para_id": "chap2_para94",
          "style_metadata": {
            "para_id": "chap2_para93",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 94,
            "sentence_count": 4
          },
          "terminology": {
            "code": 1,
            "repository": 1,
            "associated": 1,
            "book": 1,
            "aima.cs.berkeley.edu": 1,
            "includes": 1,
            "multiple": 1,
            "environment": 6,
            "implementation": 1,
            "general-purpose": 1,
            "simulator": 1,
            "evaluating": 1,
            "agent": 2,
            "performance": 2,
            "experiment": 1,
            "carried": 1,
            "single": 1,
            "many": 2,
            "drawn": 1,
            "class": 2,
            "example": 1,
            "evaluate": 1,
            "taxi": 1,
            "driver": 1,
            "simulated": 1,
            "traffic": 2,
            "want": 1,
            "run": 1,
            "simulation": 1,
            "different": 1,
            "lighting": 1,
            "weather": 1,
            "condition": 1,
            "interested": 1,
            "average": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para94",
          "content": "2.4The Structure of Agents\n2.4\nThe Structure of Agents\nSo far we have talked about agents by describing\nbehavior\n—the action that is performed after any given sequence of percepts. Now we must bite the bullet and talk about how the insides work. The job of AI is to design an\nagent program\nthat implements the agent function—the mapping from percepts to actions. We assume this program will run on some sort of computing device with physical sensors and actuators—we call this the\nagent architecture\n:\nagent = architecture\n+\nprogram.",
          "sentence_count": 4,
          "char_count": 455,
          "prev_para_id": "chap2_para93",
          "next_para_id": "chap2_para95",
          "style_metadata": {
            "para_id": "chap2_para94",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.75,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 4
          },
          "terminology": {
            "structure": 2,
            "agent": 7,
            "talked": 1,
            "describing": 1,
            "behavior": 1,
            "action": 2,
            "performed": 1,
            "given": 1,
            "sequence": 1,
            "percept": 2,
            "bite": 1,
            "bullet": 1,
            "talk": 1,
            "work": 1,
            "job": 1,
            "design": 1,
            "program": 3,
            "implement": 1,
            "function—the": 1,
            "mapping": 1,
            "assume": 1,
            "run": 1,
            "computing": 1,
            "device": 1,
            "physical": 1,
            "sensor": 1,
            "actuators—we": 1,
            "call": 1,
            "architecture": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para94",
              "entity_text": "2.4The Structure of Agents",
              "entity_type": "WORK_OF_ART",
              "start_char": 0,
              "end_char": 26,
              "context": "2.4The Structure of Agents\n2.4\nThe Structure of Agents\nSo far we have talked"
            },
            {
              "para_id": "chap2_para94",
              "entity_text": "The Structure of Agents\nSo",
              "entity_type": "WORK_OF_ART",
              "start_char": 31,
              "end_char": 57,
              "context": "2.4The Structure of Agents\n2.4\nThe Structure of Agents\nSo far we have talked about agents by describing\nbeh"
            },
            {
              "para_id": "chap2_para94",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 257,
              "end_char": 259,
              "context": "t and talk about how the insides work. The job of AI is to design an\nagent program\nthat implements the"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para95",
          "content": "Obviously, the program we choose has to be one that is appropriate for the architecture. If the program is going to recommend actions like\nWalk,\nthe architecture had better have legs. The architecture might be just an ordinary PC, or it might be a robotic car with several onboard computers, cameras, and other sensors. In general, the architecture makes the percepts from the sensors available to the program, runs the program, and feeds the program’s action choices to the actuators as they are generated. Most of this book is about designing agent programs, although\nChapters 26\nand\n27\ndeal directly with the sensors and actuators.",
          "sentence_count": 5,
          "char_count": 536,
          "prev_para_id": "chap2_para94",
          "next_para_id": "chap2_para96",
          "style_metadata": {
            "para_id": "chap2_para95",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 5
          },
          "terminology": {
            "program": 6,
            "choose": 1,
            "appropriate": 1,
            "architecture": 4,
            "going": 1,
            "recommend": 1,
            "action": 2,
            "walk": 1,
            "leg": 1,
            "ordinary": 1,
            "robotic": 1,
            "car": 1,
            "several": 1,
            "computer": 1,
            "camera": 1,
            "sensor": 3,
            "general": 1,
            "make": 1,
            "percept": 1,
            "available": 1,
            "run": 1,
            "feed": 1,
            "choice": 1,
            "actuator": 2,
            "generated": 1,
            "book": 1,
            "designing": 1,
            "agent": 1,
            "chapter": 1,
            "deal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para96",
          "content": "2.4.1\nAgent programs\nThe agent programs that we design in this book all have the same skeleton: they take the current percept as input from the sensors and return an action to the actuators.",
          "sentence_count": 1,
          "char_count": 159,
          "prev_para_id": "chap2_para95",
          "next_para_id": "chap2_para97",
          "style_metadata": {
            "para_id": "chap2_para96",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 1
          },
          "terminology": {
            "agent": 2,
            "program": 2,
            "design": 1,
            "book": 1,
            "skeleton": 1,
            "take": 1,
            "current": 1,
            "percept": 1,
            "input": 1,
            "sensor": 1,
            "return": 1,
            "action": 1,
            "actuator": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para97",
          "content": "5\nNotice the difference between the agent program, which takes the current percept as input, and the agent function, which may depend on the entire percept history. The agent program has no choice but to take just the current percept as input because nothing more is available from the environment; if the agent’s actions need to depend on the entire percept sequence, the agent will have to remember the percepts.",
          "sentence_count": 2,
          "char_count": 346,
          "prev_para_id": "chap2_para96",
          "next_para_id": "chap2_para98",
          "style_metadata": {
            "para_id": "chap2_para97",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 79,
            "sentence_count": 2
          },
          "terminology": {
            "notice": 1,
            "difference": 1,
            "agent": 5,
            "program": 2,
            "take": 2,
            "current": 2,
            "input": 2,
            "function": 1,
            "depend": 2,
            "entire": 2,
            "history": 1,
            "choice": 1,
            "percept": 3,
            "nothing": 1,
            "available": 1,
            "environment": 1,
            "action": 1,
            "need": 1,
            "sequence": 1,
            "remember": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para98",
          "content": "We describe the agent programs in the simple pseudocode language that is defined in\nAppendix B\n. (The online code repository contains implementations in real programming languages.) For example,\nFigure 2.7\nshows a rather trivial agent program that keeps track of the percept sequence and then uses it to index into a table of actions to decide what to do. The table—an example of which is given for the vacuum world in\nFigure 2.3\n—represents explicitly the agent function that the agent program embodies. To build a rational agent in this way, we as designers must construct a table that contains the appropriate action for every possible percept sequence.",
          "sentence_count": 5,
          "char_count": 554,
          "prev_para_id": "chap2_para97",
          "next_para_id": "chap2_para99",
          "style_metadata": {
            "para_id": "chap2_para98",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.4,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 117,
            "sentence_count": 5
          },
          "terminology": {
            "describe": 1,
            "agent": 5,
            "program": 3,
            "simple": 1,
            "pseudocode": 1,
            "language": 2,
            "defined": 1,
            "appendix": 1,
            "online": 1,
            "code": 1,
            "repository": 1,
            "contains": 2,
            "implementation": 1,
            "real": 1,
            "programming": 1,
            "example": 2,
            "figure": 2,
            "show": 1,
            "trivial": 1,
            "keep": 1,
            "percept": 2,
            "sequence": 2,
            "us": 1,
            "index": 1,
            "table": 2,
            "action": 2,
            "decide": 1,
            "table—an": 1,
            "given": 1,
            "vacuum": 1,
            "world": 1,
            "—represents": 1,
            "function": 1,
            "embodies": 1,
            "build": 1,
            "rational": 1,
            "way": 1,
            "designer": 1,
            "construct": 1,
            "appropriate": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para99",
          "content": "Description\nThe block diagram starts with a block labeled Agent. There are four blocks inside the Agent block. An arrow labeled, Performance standard, points to a block labeled, Critic. An arrow labeled, feedback, from the Critic block points to a block labeled, Learning element. An arrow labeled, learning goals, from the Learning element block, points to a block labeled, Problem generator. An arrow from the problem generator block points to a block labeled, Performance element. An arrow labeled, changes, from the learning element block points to the performance element block. An arrow labeled, knowledge from the performance element block points back to the Learning element block. Another arrow from the performance element block points to the Actuators. An arrow from the actuators points to the block labeled, Environment, which is outside the agent block. An arrow from the environment block points to the sensors in the agent block. An arrow each from the sensors points to the Performance element and Critic block.",
          "sentence_count": 12,
          "char_count": 868,
          "prev_para_id": "chap2_para98",
          "next_para_id": "chap2_para100",
          "style_metadata": {
            "para_id": "chap2_para99",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 190,
            "sentence_count": 12
          },
          "terminology": {
            "description": 1,
            "block": 20,
            "diagram": 1,
            "start": 1,
            "labeled": 11,
            "agent": 4,
            "arrow": 10,
            "performance": 6,
            "standard": 1,
            "point": 10,
            "critic": 3,
            "learning": 5,
            "element": 9,
            "goal": 1,
            "problem": 2,
            "generator": 2,
            "change": 1,
            "knowledge": 1,
            "actuator": 2,
            "environment": 2,
            "sensor": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para99",
              "entity_text": "Critic",
              "entity_type": "ORG",
              "start_char": 178,
              "end_char": 184,
              "context": " Performance standard, points to a block labeled, Critic. An arrow labeled, feedback, from the Critic bloc"
            },
            {
              "para_id": "chap2_para99",
              "entity_text": "Learning",
              "entity_type": "PERSON",
              "start_char": 263,
              "end_char": 271,
              "context": " from the Critic block points to a block labeled, Learning element. An arrow labeled, learning goals, from t"
            },
            {
              "para_id": "chap2_para99",
              "entity_text": "Learning",
              "entity_type": "PERSON",
              "start_char": 324,
              "end_char": 332,
              "context": "ement. An arrow labeled, learning goals, from the Learning element block, points to a block labeled, Problem"
            },
            {
              "para_id": "chap2_para99",
              "entity_text": "Learning",
              "entity_type": "PERSON",
              "start_char": 666,
              "end_char": 674,
              "context": " the performance element block points back to the Learning element block. Another arrow from the performance"
            },
            {
              "para_id": "chap2_para99",
              "entity_text": "Actuators",
              "entity_type": "ORG",
              "start_char": 753,
              "end_char": 762,
              "context": " from the performance element block points to the Actuators. An arrow from the actuators points to the block "
            },
            {
              "para_id": "chap2_para99",
              "entity_text": "Performance",
              "entity_type": "ORG",
              "start_char": 991,
              "end_char": 1002,
              "context": "ock. An arrow each from the sensors points to the Performance element and Critic block."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para100",
          "content": "×\nFigure 2.7\nThe T\nABLE\n-D\nRIVEN\n-A\nGENT\nprogram is invoked for each new percept and returns an action each time. It retains the complete percept sequence in memory.",
          "sentence_count": 2,
          "char_count": 143,
          "prev_para_id": "chap2_para99",
          "next_para_id": "chap2_para101",
          "style_metadata": {
            "para_id": "chap2_para100",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.03,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "able": 1,
            "riven": 1,
            "gent": 1,
            "program": 1,
            "invoked": 1,
            "new": 1,
            "return": 1,
            "action": 1,
            "time": 1,
            "retains": 1,
            "complete": 1,
            "sequence": 1,
            "memory": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para101",
          "content": "It is instructive to consider why the table-driven approach to agent construction is doomed to failure. Let\nƤ\nbe the set of possible percepts and let\nT\nbe the lifetime of the agent (the total number of percepts it will receive). The lookup table will contain\n∑\nt\n=\n1\nT\n|\nƤ\n|\nt\nentries. Consider the automated taxi: the visual input from a single camera (eight cameras is typical) comes in at the rate of roughly 70 megabytes per second (30 frames per second, 1080 × 720 pixels with 24 bits of color information). This gives a lookup table with over 10\n600,000,000,000\nentries for an hour’s driving. Even the lookup table for chess—a tiny, well-behaved fragment of the real world—has (it turns out) at least 10\n150\nentries. In comparison, the number of atoms in the observable universe is less than 10\n80\n. The daunting size of these tables means that (a) no physical agent in this universe will have the space to store the table; (b) the designer would not have time to create the table; and (c) no agent could ever learn all the right table entries from its experience.",
          "sentence_count": 8,
          "char_count": 895,
          "prev_para_id": "chap2_para100",
          "next_para_id": "chap2_para102",
          "style_metadata": {
            "para_id": "chap2_para101",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.12,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 225,
            "sentence_count": 8
          },
          "terminology": {
            "instructive": 1,
            "consider": 2,
            "table-driven": 1,
            "approach": 1,
            "agent": 4,
            "construction": 1,
            "doomed": 1,
            "failure": 1,
            "let": 2,
            "set": 1,
            "possible": 1,
            "percept": 2,
            "lifetime": 1,
            "total": 1,
            "number": 2,
            "receive": 1,
            "lookup": 2,
            "table": 7,
            "contain": 1,
            "entry": 4,
            "automated": 1,
            "taxi": 1,
            "visual": 1,
            "input": 1,
            "single": 1,
            "camera": 2,
            "typical": 1,
            "come": 1,
            "rate": 1,
            "megabyte": 1,
            "second": 2,
            "frame": 1,
            "pixel": 1,
            "bit": 1,
            "color": 1,
            "information": 1,
            "give": 1,
            "hour": 1,
            "driving": 1,
            "chess—a": 1,
            "tiny": 1,
            "well-behaved": 1,
            "fragment": 1,
            "real": 1,
            "world—has": 1,
            "turn": 1,
            "least": 1,
            "comparison": 1,
            "atom": 1,
            "observable": 1,
            "universe": 2,
            "daunting": 1,
            "size": 1,
            "mean": 1,
            "physical": 1,
            "space": 1,
            "store": 1,
            "designer": 1,
            "time": 1,
            "create": 1,
            "learn": 1,
            "right": 1,
            "experience": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para102",
          "content": "Despite all this, T\nABLE\n-D\nRIVEN\n-A\nGENT\ndoes\ndo what we want, assuming the table is filled in correctly: it implements the desired agent function.",
          "sentence_count": 1,
          "char_count": 129,
          "prev_para_id": "chap2_para101",
          "next_para_id": "chap2_para103",
          "style_metadata": {
            "para_id": "chap2_para102",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.032,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "able": 1,
            "riven": 1,
            "gent": 1,
            "want": 1,
            "assuming": 1,
            "table": 1,
            "filled": 1,
            "implement": 1,
            "desired": 1,
            "agent": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para103",
          "content": "The key challenge for AI is to find out how to write programs that, to the extent possible, produce rational behavior from a smallish program rather than from a vast table.",
          "sentence_count": 1,
          "char_count": 142,
          "prev_para_id": "chap2_para102",
          "next_para_id": "chap2_para104",
          "style_metadata": {
            "para_id": "chap2_para103",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "key": 1,
            "challenge": 1,
            "find": 1,
            "write": 1,
            "program": 2,
            "extent": 1,
            "possible": 1,
            "produce": 1,
            "rational": 1,
            "behavior": 1,
            "smallish": 1,
            "vast": 1,
            "table": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para103",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 22,
              "end_char": 24,
              "context": "The key challenge for AI is to find out how to write programs that, to the"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para104",
          "content": "We have many examples showing that this can be done successfully in other areas: for example, the huge tables of square roots used by engineers and schoolchildren prior to the 1970s have now been replaced by a five-line program for Newton’s method running on electronic calculators. The question is, can AI do for general intelligent behavior what Newton did for square roots? We believe the answer is yes.",
          "sentence_count": 3,
          "char_count": 339,
          "prev_para_id": "chap2_para103",
          "next_para_id": "chap2_para105",
          "style_metadata": {
            "para_id": "chap2_para104",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "many": 1,
            "example": 2,
            "showing": 1,
            "done": 1,
            "area": 1,
            "huge": 1,
            "table": 1,
            "square": 2,
            "root": 2,
            "used": 1,
            "engineer": 1,
            "schoolchildren": 1,
            "replaced": 1,
            "five-line": 1,
            "program": 1,
            "newton": 1,
            "method": 1,
            "running": 1,
            "electronic": 1,
            "calculator": 1,
            "question": 1,
            "general": 1,
            "intelligent": 1,
            "believe": 1,
            "answer": 1,
            "yes": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para104",
              "entity_text": "Newton",
              "entity_type": "ORG",
              "start_char": 232,
              "end_char": 238,
              "context": "have now been replaced by a five-line program for Newton’s method running on electronic calculators. The q"
            },
            {
              "para_id": "chap2_para104",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 304,
              "end_char": 306,
              "context": "g on electronic calculators. The question is, can AI do for general intelligent behavior what Newton d"
            },
            {
              "para_id": "chap2_para104",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 348,
              "end_char": 354,
              "context": ", can AI do for general intelligent behavior what Newton did for square roots? We believe the answer is ye"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para105",
          "content": "In the remainder of this section, we outline four basic kinds of agent programs that embody the principles underlying almost all intelligent systems:\n•\nSimple reflex agents;\n•\nModel-based reflex agents;\n•\nGoal-based agents; and\n•\nUtility-based agents.",
          "sentence_count": 1,
          "char_count": 222,
          "prev_para_id": "chap2_para104",
          "next_para_id": "chap2_para106",
          "style_metadata": {
            "para_id": "chap2_para105",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 1
          },
          "terminology": {
            "remainder": 1,
            "section": 1,
            "basic": 1,
            "kind": 1,
            "agent": 5,
            "program": 1,
            "embody": 1,
            "principle": 1,
            "underlying": 1,
            "intelligent": 1,
            "system": 1,
            "simple": 1,
            "reflex": 2,
            "model-based": 1,
            "goal-based": 1,
            "utility-based": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para106",
          "content": "Each kind of agent program combines particular components in particular ways to generate actions.",
          "sentence_count": 1,
          "char_count": 84,
          "prev_para_id": "chap2_para105",
          "next_para_id": "chap2_para107",
          "style_metadata": {
            "para_id": "chap2_para106",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "kind": 1,
            "agent": 1,
            "program": 1,
            "combine": 1,
            "particular": 2,
            "component": 1,
            "way": 1,
            "generate": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para107",
          "content": "Section 2.4.6\nexplains in general terms how to convert all these agents into\nlearning agents\nthat can improve the performance of their components so as to generate better actions. Finally,\nSection 2.4.7\ndescribes the variety of ways in which the components themselves can be represented within the agent. This variety provides a major organizing principle for the field and for the book itself.",
          "sentence_count": 3,
          "char_count": 337,
          "prev_para_id": "chap2_para106",
          "next_para_id": "chap2_para108",
          "style_metadata": {
            "para_id": "chap2_para107",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 3
          },
          "terminology": {
            "section": 2,
            "explains": 1,
            "general": 1,
            "term": 1,
            "convert": 1,
            "agent": 3,
            "learning": 1,
            "improve": 1,
            "performance": 1,
            "component": 2,
            "generate": 1,
            "better": 1,
            "action": 1,
            "describes": 1,
            "variety": 2,
            "way": 1,
            "represented": 1,
            "provides": 1,
            "major": 1,
            "organizing": 1,
            "principle": 1,
            "field": 1,
            "book": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para108",
          "content": "2.4.2\nSimple reflex agents\nThe simplest kind of agent is the\nsimple reflex agent\n. These agents select actions on the basis of the\ncurrent\npercept, ignoring the rest of the percept history. For example, the vacuum agent whose agent function is tabulated in\nFigure 2.3\nis a simple reflex agent, because its decision is based only on the current location and on whether that location contains dirt. An agent program for this agent is shown in\nFigure 2.8\n.",
          "sentence_count": 4,
          "char_count": 384,
          "prev_para_id": "chap2_para107",
          "next_para_id": "chap2_para109",
          "style_metadata": {
            "para_id": "chap2_para108",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.25,
            "passive_voice_ratio": 0.024,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 4
          },
          "terminology": {
            "simple": 3,
            "reflex": 3,
            "agent": 9,
            "simplest": 1,
            "kind": 1,
            "select": 1,
            "action": 1,
            "basis": 1,
            "current": 2,
            "ignoring": 1,
            "rest": 1,
            "history": 1,
            "example": 1,
            "vacuum": 1,
            "function": 1,
            "tabulated": 1,
            "figure": 2,
            "decision": 1,
            "based": 1,
            "location": 2,
            "contains": 1,
            "dirt": 1,
            "program": 1,
            "shown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para109",
          "content": "Description\nPart (“a”), Atomic: An arrow from a block labeled B points to a block labeled C.",
          "sentence_count": 1,
          "char_count": 77,
          "prev_para_id": "chap2_para108",
          "next_para_id": "chap2_para110",
          "style_metadata": {
            "para_id": "chap2_para109",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "atomic": 1,
            "arrow": 1,
            "block": 2,
            "labeled": 2,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para109",
              "entity_text": "Atomic",
              "entity_type": "PERSON",
              "start_char": 24,
              "end_char": 30,
              "context": "Description\nPart (“a”), Atomic: An arrow from a block labeled B points to a bloc"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para110",
          "content": "Part (b), Factored: Two blocks labeled B and C are shown. In both blocks, four circles are shown one below the other and two progress bars are shown below the bottom circle. In block B, the circles have alternating black and blue shades from the top. In the first progress bar, black shade fills about 40 percent of the bar while the blue shade fills the rest. In the second progress bar, the black shade fills about 90 percent of the bar while the blue shade fills the rest. In block C, the first two circles from the top are shaded blue and the other two circles are shaded black. In the first progress bar, black shade fills about 40 percent of the bar while the blue shade fills the rest. In the second progress bar, the black shade fills about 60 percent of the bar while the blue shade fills the rest.",
          "sentence_count": 8,
          "char_count": 655,
          "prev_para_id": "chap2_para109",
          "next_para_id": "chap2_para111",
          "style_metadata": {
            "para_id": "chap2_para110",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 172,
            "sentence_count": 8
          },
          "terminology": {
            "part": 1,
            "factored": 1,
            "block": 4,
            "labeled": 1,
            "shown": 3,
            "circle": 5,
            "progress": 5,
            "bar": 9,
            "bottom": 1,
            "alternating": 1,
            "black": 6,
            "blue": 6,
            "shade": 9,
            "top": 1,
            "first": 2,
            "fill": 8,
            "percent": 4,
            "rest": 4,
            "second": 2,
            "shaded": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para111",
          "content": "Part (c), Structured: The figure shows two blocks connected by an arrow. There are four red blocks, three green blocks, and two white blocks in the first block. These are arranged in three columns and four rows. The following blocks are shown on each row. Row 1: Column 1, red. Column 2, green. Row 2: Column 2, red. Row 3: Column 1, red. Column 2, green. Column 3, white. Row 4: Column 1, white. Column 2, red. Column 3, green. These blocks are connected using arrows in different paths. There are four red blocks, three green blocks, and four white blocks in the second block. These are arranged in three columns and four rows. The following blocks are shown on each row. Row 1: Column 1, white. Column 2, green. Column 3, white. Row 2: Column 2, red. Column 3, red. Row 3: Column 1, red. Column 2, white. Column 3, white. Row 4: Column 1, green. Column 2, red. Column 3, green. These blocks are connected using arrows in different paths.",
          "sentence_count": 29,
          "char_count": 769,
          "prev_para_id": "chap2_para110",
          "next_para_id": "chap2_para112",
          "style_metadata": {
            "para_id": "chap2_para111",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 237,
            "sentence_count": 29
          },
          "terminology": {
            "part": 1,
            "structured": 1,
            "figure": 1,
            "show": 1,
            "block": 13,
            "connected": 3,
            "red": 10,
            "green": 8,
            "white": 8,
            "first": 1,
            "arranged": 2,
            "column": 22,
            "row": 12,
            "following": 2,
            "shown": 2,
            "using": 2,
            "arrow": 2,
            "different": 2,
            "path": 2,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para112",
          "content": "×\nFigure 2.8\nThe agent program for a simple reflex agent in the two-location vacuum environment. This program implements the agent function tabulated in\nFigure 2.3\n.",
          "sentence_count": 2,
          "char_count": 143,
          "prev_para_id": "chap2_para111",
          "next_para_id": "chap2_para113",
          "style_metadata": {
            "para_id": "chap2_para112",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 2,
            "agent": 3,
            "program": 2,
            "simple": 1,
            "reflex": 1,
            "two-location": 1,
            "vacuum": 1,
            "environment": 1,
            "implement": 1,
            "function": 1,
            "tabulated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para113",
          "content": "Notice that the vacuum agent program is very small indeed compared to the corresponding table. The most obvious reduction comes from ignoring the percept history, which cuts down the number of relevant percept sequences from 4\nT\nto just 4. A further, small reduction comes from the fact that when the current square is dirty, the action does not depend on the location. Although we have written the agent program using if-then-else statements, it is simple enough that it can also be implemented as a Boolean circuit.",
          "sentence_count": 4,
          "char_count": 433,
          "prev_para_id": "chap2_para112",
          "next_para_id": "chap2_para114",
          "style_metadata": {
            "para_id": "chap2_para113",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 94,
            "sentence_count": 4
          },
          "terminology": {
            "notice": 1,
            "vacuum": 1,
            "agent": 2,
            "program": 2,
            "small": 2,
            "compared": 1,
            "corresponding": 1,
            "table": 1,
            "obvious": 1,
            "reduction": 2,
            "come": 2,
            "ignoring": 1,
            "percept": 2,
            "history": 1,
            "cut": 1,
            "number": 1,
            "relevant": 1,
            "sequence": 1,
            "fact": 1,
            "current": 1,
            "square": 1,
            "dirty": 1,
            "action": 1,
            "depend": 1,
            "location": 1,
            "written": 1,
            "using": 1,
            "if-then-else": 1,
            "statement": 1,
            "simple": 1,
            "implemented": 1,
            "boolean": 1,
            "circuit": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para114",
          "content": "Simple reflex behaviors occur even in more complex environments. Imagine yourself as the driver of the automated taxi. If the car in front brakes and its brake lights come on, then you should notice this and initiate braking. In other words, some processing is done on the\nvisual input to establish the condition we call “The car in front is braking.” Then, this triggers some established connection in the agent program to the action “initiate braking.” We call such a connection a\ncondition–action rule\n,\n6\nwritten as\nif\ncar-in-front-is-braking\nthen\ninitiate-braking.",
          "sentence_count": 4,
          "char_count": 487,
          "prev_para_id": "chap2_para113",
          "next_para_id": "chap2_para115",
          "style_metadata": {
            "para_id": "chap2_para114",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 4
          },
          "terminology": {
            "simple": 1,
            "reflex": 1,
            "behavior": 1,
            "occur": 1,
            "complex": 1,
            "environment": 1,
            "imagine": 1,
            "automated": 1,
            "taxi": 1,
            "car": 2,
            "front": 2,
            "brake": 2,
            "light": 1,
            "come": 1,
            "initiate": 2,
            "braking": 1,
            "word": 1,
            "processing": 1,
            "done": 1,
            "visual": 1,
            "input": 1,
            "establish": 1,
            "condition": 1,
            "call": 2,
            "braking.": 2,
            "trigger": 1,
            "established": 1,
            "connection": 2,
            "agent": 1,
            "program": 1,
            "action": 1,
            "condition–action": 1,
            "rule": 1,
            "written": 1,
            "car-in-front-is-braking": 1,
            "initiate-braking": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para115",
          "content": "Humans also have many such connections, some of which are learned responses (as for driving) and some of which are innate reflexes (such as blinking when something approaches the eye). In the course of the book, we show several different ways in which such connections can be learned and implemented.",
          "sentence_count": 2,
          "char_count": 251,
          "prev_para_id": "chap2_para114",
          "next_para_id": "chap2_para116",
          "style_metadata": {
            "para_id": "chap2_para115",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "human": 1,
            "many": 1,
            "connection": 2,
            "learned": 2,
            "response": 1,
            "driving": 1,
            "innate": 1,
            "reflex": 1,
            "blinking": 1,
            "something": 1,
            "approach": 1,
            "eye": 1,
            "course": 1,
            "book": 1,
            "show": 1,
            "several": 1,
            "different": 1,
            "way": 1,
            "implemented": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para116",
          "content": "The program in\nFigure 2.8\nis specific to one particular vacuum environment. A more general and flexible approach is first to build a general-purpose interpreter for condition–action rules and then to create rule sets for specific task environments.",
          "sentence_count": 2,
          "char_count": 213,
          "prev_para_id": "chap2_para115",
          "next_para_id": "chap2_para117",
          "style_metadata": {
            "para_id": "chap2_para116",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 2
          },
          "terminology": {
            "program": 1,
            "figure": 1,
            "specific": 2,
            "particular": 1,
            "vacuum": 1,
            "environment": 2,
            "general": 1,
            "flexible": 1,
            "approach": 1,
            "build": 1,
            "general-purpose": 1,
            "interpreter": 1,
            "condition–action": 1,
            "rule": 2,
            "create": 1,
            "set": 1,
            "task": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para117",
          "content": "Figure 2.9\ngives the structure of this general program in schematic form, showing how the condition–action rules allow the agent to make the connection from percept to action. Do not worry if this seems trivial; it gets more interesting shortly.",
          "sentence_count": 2,
          "char_count": 207,
          "prev_para_id": "chap2_para116",
          "next_para_id": "chap2_para118",
          "style_metadata": {
            "para_id": "chap2_para117",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "give": 1,
            "structure": 1,
            "general": 1,
            "program": 1,
            "schematic": 1,
            "form": 1,
            "showing": 1,
            "condition–action": 1,
            "rule": 1,
            "allow": 1,
            "agent": 1,
            "make": 1,
            "connection": 1,
            "action": 1,
            "worry": 1,
            "seems": 1,
            "trivial": 1,
            "get": 1,
            "interesting": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para118",
          "content": "×\nFigure 2.9\nSchematic diagram of a simple reflex agent. We use rectangles to denote the current internal state of the agent’s decision process, and ovals to represent the background information used in the process.",
          "sentence_count": 2,
          "char_count": 183,
          "prev_para_id": "chap2_para117",
          "next_para_id": "chap2_para119",
          "style_metadata": {
            "para_id": "chap2_para118",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "schematic": 1,
            "diagram": 1,
            "simple": 1,
            "reflex": 1,
            "agent": 2,
            "use": 1,
            "rectangle": 1,
            "denote": 1,
            "current": 1,
            "internal": 1,
            "state": 1,
            "decision": 1,
            "process": 2,
            "oval": 1,
            "represent": 1,
            "background": 1,
            "information": 1,
            "used": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para118",
              "entity_text": "Schematic",
              "entity_type": "ORG",
              "start_char": 13,
              "end_char": 22,
              "context": "×\nFigure 2.9\nSchematic diagram of a simple reflex agent. We use rectangl"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para119",
          "content": "An agent program for\nFigure 2.9\nis shown in\nFigure 2.10\n. The I\nNTERPRET\n-I\nNPUT\nfunction generates an abstracted description of the current state from the percept, and the R\nULE\n-M\nATCH\nfunction returns the first rule in the set of rules that matches the given state description. Note that the description in terms of “rules” and “matching” is purely conceptual; as noted above, actual implementations can be as simple as a collection of logic gates implementing a Boolean circuit. Alternatively, a “neural” circuit can be used, where the logic gates are replaced by the nonlinear units of artificial neural networks (see\nChapter 22\n).",
          "sentence_count": 4,
          "char_count": 543,
          "prev_para_id": "chap2_para118",
          "next_para_id": "chap2_para120",
          "style_metadata": {
            "para_id": "chap2_para119",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 123,
            "sentence_count": 4
          },
          "terminology": {
            "agent": 1,
            "program": 1,
            "figure": 2,
            "shown": 1,
            "nterpret": 1,
            "nput": 1,
            "function": 2,
            "generates": 1,
            "abstracted": 1,
            "description": 3,
            "current": 1,
            "state": 2,
            "percept": 1,
            "ule": 1,
            "atch": 1,
            "return": 1,
            "rule": 3,
            "set": 1,
            "match": 1,
            "given": 1,
            "note": 1,
            "term": 1,
            "matching": 1,
            "conceptual": 1,
            "noted": 1,
            "actual": 1,
            "implementation": 1,
            "simple": 1,
            "collection": 1,
            "logic": 2,
            "gate": 2,
            "implementing": 1,
            "boolean": 1,
            "circuit": 2,
            "neural": 2,
            "used": 1,
            "replaced": 1,
            "nonlinear": 1,
            "unit": 1,
            "artificial": 1,
            "network": 1,
            "see": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para120",
          "content": "×\nFigure 2.10\nA simple reflex agent. It acts according to a rule whose condition matches the current state, as defined by the percept.",
          "sentence_count": 2,
          "char_count": 113,
          "prev_para_id": "chap2_para119",
          "next_para_id": "chap2_para121",
          "style_metadata": {
            "para_id": "chap2_para120",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "simple": 1,
            "reflex": 1,
            "agent": 1,
            "act": 1,
            "according": 1,
            "rule": 1,
            "condition": 1,
            "match": 1,
            "current": 1,
            "state": 1,
            "defined": 1,
            "percept": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para121",
          "content": "Simple reflex agents have the admirable property of being simple, but they are of limited intelligence. The agent in\nFigure 2.10\nwill work\nonly if the correct decision can be made on the basis of just the current percept—that is, only if the environment is fully observable.",
          "sentence_count": 2,
          "char_count": 231,
          "prev_para_id": "chap2_para120",
          "next_para_id": "chap2_para122",
          "style_metadata": {
            "para_id": "chap2_para121",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 2
          },
          "terminology": {
            "simple": 2,
            "reflex": 1,
            "agent": 2,
            "admirable": 1,
            "property": 1,
            "limited": 1,
            "intelligence": 1,
            "figure": 1,
            "work": 1,
            "correct": 1,
            "decision": 1,
            "made": 1,
            "basis": 1,
            "current": 1,
            "environment": 1,
            "observable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para122",
          "content": "Even a little bit of unobservability can cause serious trouble. For example, the braking rule given earlier assumes that the condition\ncar-in-front-is-braking\ncan be determined from the current percept—a single frame of video. This works if the car in front has a centrally mounted (and hence uniquely identifiable) brake light. Unfortunately, older models have different configurations of taillights, brake lights, and turn-signal lights, and it is not always possible to tell from a single image whether the car is braking or simply has its taillights on. A simple reflex agent driving behind such a car would either brake continuously and unnecessarily, or, worse, never brake at all.",
          "sentence_count": 5,
          "char_count": 583,
          "prev_para_id": "chap2_para121",
          "next_para_id": "chap2_para123",
          "style_metadata": {
            "para_id": "chap2_para122",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 122,
            "sentence_count": 5
          },
          "terminology": {
            "little": 1,
            "bit": 1,
            "unobservability": 1,
            "cause": 1,
            "serious": 1,
            "trouble": 1,
            "example": 1,
            "braking": 2,
            "rule": 1,
            "given": 1,
            "assumes": 1,
            "condition": 1,
            "car-in-front-is-braking": 1,
            "determined": 1,
            "current": 1,
            "percept—a": 1,
            "single": 2,
            "frame": 1,
            "video": 1,
            "work": 1,
            "car": 3,
            "front": 1,
            "mounted": 1,
            "hence": 1,
            "identifiable": 1,
            "brake": 4,
            "light": 3,
            "older": 1,
            "model": 1,
            "different": 1,
            "configuration": 1,
            "taillight": 2,
            "turn-signal": 1,
            "possible": 1,
            "tell": 1,
            "image": 1,
            "simple": 1,
            "reflex": 1,
            "agent": 1,
            "driving": 1,
            "unnecessarily": 1,
            "worse": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para123",
          "content": "We can see a similar problem arising in the vacuum world. Suppose that a simple reflex vacuum agent is deprived of its location sensor and has only a dirt sensor. Such an agent has just two possible percepts: [\nDirty\n] and [\nClean\n]\n.",
          "sentence_count": 3,
          "char_count": 194,
          "prev_para_id": "chap2_para122",
          "next_para_id": "chap2_para124",
          "style_metadata": {
            "para_id": "chap2_para123",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.33,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 3
          },
          "terminology": {
            "see": 1,
            "similar": 1,
            "problem": 1,
            "arising": 1,
            "vacuum": 2,
            "world": 1,
            "suppose": 1,
            "simple": 1,
            "reflex": 1,
            "agent": 2,
            "deprived": 1,
            "location": 1,
            "sensor": 2,
            "dirt": 1,
            "possible": 1,
            "percept": 1,
            "dirty": 1,
            "clean": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para124",
          "content": "It can\nSuck\nin response to [\nDirty\n]; what should it do in response to [\nClean\n]? Moving\nLeft\nfails (forever) if it happens to start in square\nA\n, and moving\nRight\nfails (forever) if it happens to start in square\nB\n. Infinite loops are often unavoidable for simple reflex agents operating in partially observable environments.",
          "sentence_count": 3,
          "char_count": 281,
          "prev_para_id": "chap2_para123",
          "next_para_id": "chap2_para125",
          "style_metadata": {
            "para_id": "chap2_para124",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 3
          },
          "terminology": {
            "suck": 1,
            "response": 2,
            "dirty": 1,
            "clean": 1,
            "moving": 2,
            "left": 1,
            "fails": 2,
            "happens": 2,
            "start": 2,
            "square": 2,
            "infinite": 1,
            "loop": 1,
            "unavoidable": 1,
            "simple": 1,
            "reflex": 1,
            "agent": 1,
            "operating": 1,
            "observable": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para125",
          "content": "Escape from infinite loops is possible if the agent can\nrandomize\nits actions. For example, if the vacuum agent perceives [\nClean\n], it might flip a coin to choose between\nRight\nand\nLeft.",
          "sentence_count": 2,
          "char_count": 161,
          "prev_para_id": "chap2_para124",
          "next_para_id": "chap2_para126",
          "style_metadata": {
            "para_id": "chap2_para125",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "escape": 1,
            "infinite": 1,
            "loop": 1,
            "possible": 1,
            "agent": 2,
            "randomize": 1,
            "action": 1,
            "example": 1,
            "vacuum": 1,
            "perceives": 1,
            "clean": 1,
            "flip": 1,
            "coin": 1,
            "choose": 1,
            "right": 1,
            "left": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para126",
          "content": "It is easy to show that the agent will reach the other square in an average of two steps. Then, if that square is dirty, the agent will clean it and the task will be complete. Hence, a randomized simple reflex agent might outperform a deterministic simple reflex agent.",
          "sentence_count": 3,
          "char_count": 221,
          "prev_para_id": "chap2_para125",
          "next_para_id": "chap2_para127",
          "style_metadata": {
            "para_id": "chap2_para126",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 3
          },
          "terminology": {
            "easy": 1,
            "show": 1,
            "agent": 4,
            "reach": 1,
            "square": 2,
            "average": 1,
            "step": 1,
            "dirty": 1,
            "clean": 1,
            "task": 1,
            "complete": 1,
            "randomized": 1,
            "simple": 2,
            "reflex": 2,
            "outperform": 1,
            "deterministic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para127",
          "content": "We mentioned in\nSection 2.3\nthat randomized behavior of the right kind can be rational in some multiagent environments. In single-agent environments, randomization is usually\nnot\nrational. It is a useful trick that helps a simple reflex agent in some situations, but in most cases we can do much better with more sophisticated deterministic agents.",
          "sentence_count": 3,
          "char_count": 298,
          "prev_para_id": "chap2_para126",
          "next_para_id": "chap2_para128",
          "style_metadata": {
            "para_id": "chap2_para127",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 60,
            "sentence_count": 3
          },
          "terminology": {
            "mentioned": 1,
            "section": 1,
            "randomized": 1,
            "right": 1,
            "kind": 1,
            "rational": 2,
            "multiagent": 1,
            "environment": 2,
            "single-agent": 1,
            "randomization": 1,
            "useful": 1,
            "trick": 1,
            "help": 1,
            "simple": 1,
            "reflex": 1,
            "agent": 2,
            "situation": 1,
            "case": 1,
            "sophisticated": 1,
            "deterministic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para128",
          "content": "2.4.3\nModel-based reflex agents\nThe most effective way to handle partial observability is for the agent to\nkeep track of the part of the world it can’t see now.",
          "sentence_count": 1,
          "char_count": 135,
          "prev_para_id": "chap2_para127",
          "next_para_id": "chap2_para129",
          "style_metadata": {
            "para_id": "chap2_para128",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 1
          },
          "terminology": {
            "model-based": 1,
            "reflex": 1,
            "agent": 2,
            "effective": 1,
            "way": 1,
            "handle": 1,
            "partial": 1,
            "observability": 1,
            "keep": 1,
            "track": 1,
            "part": 1,
            "world": 1,
            "see": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para129",
          "content": "That is, the agent should maintain some sort of\ninternal state\nthat depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. For the braking problem, the internal state is not too extensive—just the previous frame from the camera, allowing the agent to detect when two red lights at the edge of the vehicle go on or off simultaneously. For other driving tasks such as changing lanes, the agent needs to keep track of where the other cars are if it can’t see them all at once. And for any driving to be possible at all, the agent needs to keep track of where its keys are.",
          "sentence_count": 4,
          "char_count": 515,
          "prev_para_id": "chap2_para128",
          "next_para_id": "chap2_para130",
          "style_metadata": {
            "para_id": "chap2_para129",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 127,
            "sentence_count": 4
          },
          "terminology": {
            "agent": 4,
            "maintain": 1,
            "sort": 1,
            "internal": 2,
            "state": 3,
            "depends": 1,
            "percept": 1,
            "history": 1,
            "thereby": 1,
            "reflects": 1,
            "least": 1,
            "unobserved": 1,
            "aspect": 1,
            "current": 1,
            "braking": 1,
            "problem": 1,
            "extensive—just": 1,
            "previous": 1,
            "frame": 1,
            "camera": 1,
            "allowing": 1,
            "detect": 1,
            "red": 1,
            "light": 1,
            "edge": 1,
            "vehicle": 1,
            "driving": 2,
            "task": 1,
            "changing": 1,
            "lane": 1,
            "need": 2,
            "keep": 2,
            "track": 2,
            "car": 1,
            "see": 1,
            "possible": 1,
            "key": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para130",
          "content": "Updating this internal state information as time goes by requires two kinds of knowledge to be encoded in the agent program in some form. First, we need some information about how the world changes over time, which can be divided roughly into two parts: the effects of the agent’s actions and how the world evolves independently of the agent. For example, when the agent turns the steering wheel clockwise, the car turns to the right, and when it’s raining the car’s cameras can get wet. This knowledge about “how the world works”—whether implemented in simple Boolean circuits or in complete scientific theories—is called a\ntransition model\nof the world.",
          "sentence_count": 4,
          "char_count": 549,
          "prev_para_id": "chap2_para129",
          "next_para_id": "chap2_para131",
          "style_metadata": {
            "para_id": "chap2_para130",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 4
          },
          "terminology": {
            "updating": 1,
            "internal": 1,
            "state": 1,
            "information": 2,
            "time": 2,
            "go": 1,
            "requires": 1,
            "kind": 1,
            "knowledge": 2,
            "encoded": 1,
            "agent": 4,
            "program": 1,
            "form": 1,
            "need": 1,
            "world": 4,
            "change": 1,
            "divided": 1,
            "part": 1,
            "effect": 1,
            "action": 1,
            "evolves": 1,
            "example": 1,
            "turn": 2,
            "steering": 1,
            "wheel": 1,
            "clockwise": 1,
            "car": 2,
            "raining": 1,
            "camera": 1,
            "get": 1,
            "wet": 1,
            "work": 1,
            "implemented": 1,
            "simple": 1,
            "boolean": 1,
            "circuit": 1,
            "complete": 1,
            "scientific": 1,
            "theories—is": 1,
            "called": 1,
            "transition": 1,
            "model": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para131",
          "content": "Second, we need some information about how the state of the world is reflected in the agent’s percepts. For example, when the car in front initiates braking, one or more illuminated red regions appear in the forward-facing camera image, and, when the camera gets wet, droplet-shaped objects appear in the image partially obscuring the road. This kind of knowledge is called a\nsensor model\n.",
          "sentence_count": 3,
          "char_count": 328,
          "prev_para_id": "chap2_para130",
          "next_para_id": "chap2_para132",
          "style_metadata": {
            "para_id": "chap2_para131",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.027,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 3
          },
          "terminology": {
            "second": 1,
            "need": 1,
            "information": 1,
            "state": 1,
            "world": 1,
            "reflected": 1,
            "agent": 1,
            "percept": 1,
            "example": 1,
            "car": 1,
            "front": 1,
            "initiate": 1,
            "braking": 1,
            "illuminated": 1,
            "red": 1,
            "region": 1,
            "appear": 2,
            "forward-facing": 1,
            "camera": 2,
            "image": 2,
            "get": 1,
            "wet": 1,
            "droplet-shaped": 1,
            "object": 1,
            "obscuring": 1,
            "road": 1,
            "kind": 1,
            "knowledge": 1,
            "called": 1,
            "sensor": 1,
            "model": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para132",
          "content": "Together, the transition model and sensor model allow an agent to keep track of the state of the world—to the extent possible given the limitations of the agent’s sensors. An agent that uses such models is called a\nmodel-based agent\n.",
          "sentence_count": 2,
          "char_count": 196,
          "prev_para_id": "chap2_para131",
          "next_para_id": "chap2_para133",
          "style_metadata": {
            "para_id": "chap2_para132",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.022,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "transition": 1,
            "model": 3,
            "sensor": 2,
            "allow": 1,
            "agent": 4,
            "keep": 1,
            "track": 1,
            "state": 1,
            "world—to": 1,
            "extent": 1,
            "possible": 1,
            "given": 1,
            "limitation": 1,
            "us": 1,
            "called": 1,
            "model-based": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para133",
          "content": "Figure 2.11\ngives the structure of the model-based reflex agent with internal state, showing how the current percept is combined with the old internal state to generate the updated description of the current state, based on the agent’s model of how the world works. The agent program is shown in\nFigure 2.12\n. The interesting part is the function U\nPDATE\n-S\nTATE\n, which is responsible for creating the new internal state description. The details of how models and states are represented vary widely depending on the type of environment and the particular technology used in the agent design.",
          "sentence_count": 4,
          "char_count": 500,
          "prev_para_id": "chap2_para132",
          "next_para_id": "chap2_para134",
          "style_metadata": {
            "para_id": "chap2_para133",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.75,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 107,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 2,
            "give": 1,
            "structure": 1,
            "model-based": 1,
            "reflex": 1,
            "agent": 4,
            "internal": 3,
            "state": 5,
            "showing": 1,
            "current": 2,
            "percept": 1,
            "combined": 1,
            "old": 1,
            "generate": 1,
            "updated": 1,
            "description": 2,
            "based": 1,
            "model": 2,
            "world": 1,
            "work": 1,
            "program": 1,
            "shown": 1,
            "interesting": 1,
            "part": 1,
            "function": 1,
            "pdate": 1,
            "tate": 1,
            "responsible": 1,
            "creating": 1,
            "new": 1,
            "detail": 1,
            "represented": 1,
            "vary": 1,
            "depending": 1,
            "type": 1,
            "environment": 1,
            "particular": 1,
            "technology": 1,
            "used": 1,
            "design": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para134",
          "content": "×\nFigure 2.11\nA model-based reflex agent.",
          "sentence_count": 1,
          "char_count": 37,
          "prev_para_id": "chap2_para133",
          "next_para_id": "chap2_para135",
          "style_metadata": {
            "para_id": "chap2_para134",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 8,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "model-based": 1,
            "reflex": 1,
            "agent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para135",
          "content": "×\nFigure 2.12\nA model-based reflex agent. It keeps track of the current state of the world, using an internal model. It then chooses an action in the same way as the reflex agent.",
          "sentence_count": 3,
          "char_count": 148,
          "prev_para_id": "chap2_para134",
          "next_para_id": "chap2_para136",
          "style_metadata": {
            "para_id": "chap2_para135",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "model-based": 1,
            "reflex": 2,
            "agent": 2,
            "keep": 1,
            "current": 1,
            "state": 1,
            "world": 1,
            "using": 1,
            "internal": 1,
            "model": 1,
            "chooses": 1,
            "action": 1,
            "way": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para136",
          "content": "Regardless of the kind of representation used, it is seldom possible for the agent to determine the current state of a partially observable environment\nexactly.",
          "sentence_count": 1,
          "char_count": 137,
          "prev_para_id": "chap2_para135",
          "next_para_id": "chap2_para137",
          "style_metadata": {
            "para_id": "chap2_para136",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 1
          },
          "terminology": {
            "kind": 1,
            "representation": 1,
            "used": 1,
            "possible": 1,
            "agent": 1,
            "determine": 1,
            "current": 1,
            "state": 1,
            "observable": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para137",
          "content": "Instead, the box labeled “what the world is like now” (\nFigure 2.11\n) represents the agent’s “best guess” (or sometimes best guesses, if the agent entertains multiple possibilities). For example, an automated taxi\nmay not be able to see around the large truck that has stopped in front of it and can only guess about what may be causing the hold-up. Thus, uncertainty about the current state may be unavoidable, but the agent still has to make a decision.",
          "sentence_count": 3,
          "char_count": 379,
          "prev_para_id": "chap2_para136",
          "next_para_id": "chap2_para138",
          "style_metadata": {
            "para_id": "chap2_para137",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 3
          },
          "terminology": {
            "box": 1,
            "labeled": 1,
            "world": 1,
            "figure": 1,
            "represents": 1,
            "agent": 3,
            "best": 2,
            "guess": 3,
            "entertains": 1,
            "multiple": 1,
            "possibility": 1,
            "example": 1,
            "automated": 1,
            "taxi": 1,
            "able": 1,
            "see": 1,
            "large": 1,
            "truck": 1,
            "stopped": 1,
            "front": 1,
            "causing": 1,
            "hold-up": 1,
            "uncertainty": 1,
            "current": 1,
            "state": 1,
            "unavoidable": 1,
            "make": 1,
            "decision": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para138",
          "content": "2.4.4\nGoal-based agents\nKnowing something about the current state of the environment is not always enough to decide what to do. For example, at a road junction, the taxi can turn left, turn right, or go straight on. The correct decision depends on where the taxi is trying to get to. In other words, as well as a current state description, the agent needs some sort of\ngoal\ninformation that describes situations that are desirable—for example, being at a particular destination. The agent program can combine this with the model (the same information as was used in the model-based reflex agent) to choose actions that achieve the goal.",
          "sentence_count": 5,
          "char_count": 533,
          "prev_para_id": "chap2_para137",
          "next_para_id": "chap2_para139",
          "style_metadata": {
            "para_id": "chap2_para138",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.4,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 122,
            "sentence_count": 5
          },
          "terminology": {
            "goal-based": 1,
            "agent": 4,
            "knowing": 1,
            "something": 1,
            "current": 2,
            "state": 2,
            "environment": 1,
            "decide": 1,
            "example": 2,
            "road": 1,
            "junction": 1,
            "taxi": 1,
            "turn": 2,
            "left": 1,
            "right": 1,
            "straight": 1,
            "correct": 1,
            "decision": 1,
            "depends": 1,
            "trying": 1,
            "get": 1,
            "word": 1,
            "description": 1,
            "need": 1,
            "sort": 1,
            "goal": 2,
            "information": 2,
            "describes": 1,
            "situation": 1,
            "desirable—for": 1,
            "particular": 1,
            "destination": 1,
            "program": 1,
            "combine": 1,
            "model": 1,
            "used": 1,
            "model-based": 1,
            "reflex": 1,
            "choose": 1,
            "action": 1,
            "achieve": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para139",
          "content": "Figure 2.13\nshows the goal-based agent’s structure.",
          "sentence_count": 1,
          "char_count": 46,
          "prev_para_id": "chap2_para138",
          "next_para_id": "chap2_para140",
          "style_metadata": {
            "para_id": "chap2_para139",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "goal-based": 1,
            "agent": 1,
            "structure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para140",
          "content": "×\nFigure 2.13\nA model-based, goal-based agent. It keeps track of the world state as well as a set of goals it is trying to achieve, and chooses an action that will (eventually) lead to the achievement of its goals.",
          "sentence_count": 2,
          "char_count": 177,
          "prev_para_id": "chap2_para139",
          "next_para_id": "chap2_para141",
          "style_metadata": {
            "para_id": "chap2_para140",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "model-based": 1,
            "goal-based": 1,
            "agent": 1,
            "keep": 1,
            "track": 1,
            "world": 1,
            "state": 1,
            "set": 1,
            "goal": 2,
            "trying": 1,
            "achieve": 1,
            "chooses": 1,
            "action": 1,
            "lead": 1,
            "achievement": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para141",
          "content": "Sometimes goal-based action selection is straightforward—for example, when goal satisfaction results immediately from a single action. Sometimes it will be more tricky—for example, when the agent has to consider long sequences of twists and turns in order to find a way to achieve the goal.",
          "sentence_count": 2,
          "char_count": 246,
          "prev_para_id": "chap2_para140",
          "next_para_id": "chap2_para142",
          "style_metadata": {
            "para_id": "chap2_para141",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 2
          },
          "terminology": {
            "goal-based": 1,
            "action": 2,
            "selection": 1,
            "straightforward—for": 1,
            "example": 2,
            "goal": 2,
            "satisfaction": 1,
            "result": 1,
            "single": 1,
            "tricky—for": 1,
            "agent": 1,
            "consider": 1,
            "long": 1,
            "sequence": 1,
            "twist": 1,
            "turn": 1,
            "order": 1,
            "find": 1,
            "way": 1,
            "achieve": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para142",
          "content": "Search\n(\nChapters 3\n,\n4\n, and\n6\n) and\nplanning\n(\nChapter 11\n) are the subfields of AI devoted to finding action sequences that achieve the agent’s goals.",
          "sentence_count": 1,
          "char_count": 134,
          "prev_para_id": "chap2_para141",
          "next_para_id": "chap2_para143",
          "style_metadata": {
            "para_id": "chap2_para142",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "search": 1,
            "chapter": 2,
            "planning": 1,
            "subfields": 1,
            "devoted": 1,
            "finding": 1,
            "action": 1,
            "sequence": 1,
            "achieve": 1,
            "agent": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para142",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 83,
              "end_char": 85,
              "context": " and\nplanning\n(\nChapter 11\n) are the subfields of AI devoted to finding action sequences that achieve "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para143",
          "content": "Notice that decision making of this kind is fundamentally different from the condition–action rules described earlier, in that it involves consideration of the future—both “What will happen if I do such-and-such?” and “Will that make me happy?” In the reflex agent designs, this information is not explicitly represented, because the built-in rules map directly from percepts to actions. The reflex agent brakes when it sees brake lights, period. It has no idea why. A goal-based agent brakes when it sees brake lights because that’s the only action that it predicts will achieve its goal of not hitting other cars.",
          "sentence_count": 4,
          "char_count": 517,
          "prev_para_id": "chap2_para142",
          "next_para_id": "chap2_para144",
          "style_metadata": {
            "para_id": "chap2_para143",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 4
          },
          "terminology": {
            "notice": 1,
            "decision": 1,
            "making": 1,
            "kind": 1,
            "different": 1,
            "condition–action": 1,
            "rule": 2,
            "described": 1,
            "involves": 1,
            "consideration": 1,
            "happen": 1,
            "such-and-such": 1,
            "make": 1,
            "happy": 1,
            "reflex": 2,
            "agent": 3,
            "design": 1,
            "information": 1,
            "represented": 1,
            "built-in": 1,
            "map": 1,
            "percept": 1,
            "action": 2,
            "brake": 4,
            "see": 2,
            "light": 2,
            "period": 1,
            "idea": 1,
            "goal-based": 1,
            "predicts": 1,
            "achieve": 1,
            "goal": 1,
            "hitting": 1,
            "car": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para144",
          "content": "Although the goal-based agent appears less efficient, it is more flexible because the knowledge that supports its decisions is represented explicitly and can be modified. For example, a goal-based agent’s behavior can easily be changed to go to a different destination,\nsimply by specifying that destination as the goal. The reflex agent’s rules for when to turn and when to go straight will work only for a single destination; they must all be replaced to go somewhere new.",
          "sentence_count": 3,
          "char_count": 398,
          "prev_para_id": "chap2_para143",
          "next_para_id": "chap2_para145",
          "style_metadata": {
            "para_id": "chap2_para144",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.67,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 3
          },
          "terminology": {
            "goal-based": 2,
            "agent": 3,
            "appears": 1,
            "efficient": 1,
            "flexible": 1,
            "knowledge": 1,
            "support": 1,
            "decision": 1,
            "represented": 1,
            "modified": 1,
            "example": 1,
            "behavior": 1,
            "changed": 1,
            "different": 1,
            "destination": 3,
            "specifying": 1,
            "goal": 1,
            "reflex": 1,
            "rule": 1,
            "turn": 1,
            "straight": 1,
            "work": 1,
            "single": 1,
            "replaced": 1,
            "new": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para145",
          "content": "2.4.5\nUtility-based agents\nGoals alone are not enough to generate high-quality behavior in most environments. For example, many action sequences will get the taxi to its destination (thereby achieving the goal), but some are quicker, safer, more reliable, or cheaper than others. Goals just provide a crude binary distinction between “happy” and “unhappy” states. A more general performance measure should allow a comparison of different world states according to exactly how happy they would make the agent. Because “happy” does not sound very scientific, economists and computer scientists use the term\nutility\ninstead.",
          "sentence_count": 5,
          "char_count": 533,
          "prev_para_id": "chap2_para144",
          "next_para_id": "chap2_para146",
          "style_metadata": {
            "para_id": "chap2_para145",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 5
          },
          "terminology": {
            "utility-based": 1,
            "agent": 2,
            "goal": 3,
            "generate": 1,
            "high-quality": 1,
            "behavior": 1,
            "environment": 1,
            "example": 1,
            "many": 1,
            "action": 1,
            "sequence": 1,
            "get": 1,
            "taxi": 1,
            "destination": 1,
            "achieving": 1,
            "quicker": 1,
            "safer": 1,
            "reliable": 1,
            "cheaper": 1,
            "others": 1,
            "provide": 1,
            "crude": 1,
            "binary": 1,
            "distinction": 1,
            "happy": 3,
            "unhappy": 1,
            "state": 2,
            "general": 1,
            "performance": 1,
            "measure": 1,
            "allow": 1,
            "comparison": 1,
            "different": 1,
            "world": 1,
            "according": 1,
            "make": 1,
            "sound": 1,
            "scientific": 1,
            "economist": 1,
            "computer": 1,
            "scientist": 1,
            "use": 1,
            "term": 1,
            "utility": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para146",
          "content": "7\nWe have already seen that a performance measure assigns a score to any given sequence of environment states, so it can easily distinguish between more and less desirable ways of getting to the taxi’s destination. An agent’s\nutility function\nis essentially an internalization of the performance measure. Provided that the internal utility function and the external performance measure are in agreement, an agent that chooses actions to maximize its utility will be rational according to the external performance measure.",
          "sentence_count": 3,
          "char_count": 445,
          "prev_para_id": "chap2_para145",
          "next_para_id": "chap2_para147",
          "style_metadata": {
            "para_id": "chap2_para146",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 3
          },
          "terminology": {
            "seen": 1,
            "performance": 4,
            "measure": 4,
            "assigns": 1,
            "given": 1,
            "sequence": 1,
            "environment": 1,
            "state": 1,
            "distinguish": 1,
            "desirable": 1,
            "way": 1,
            "getting": 1,
            "taxi": 1,
            "destination": 1,
            "agent": 2,
            "utility": 3,
            "function": 2,
            "internalization": 1,
            "provided": 1,
            "internal": 1,
            "external": 2,
            "agreement": 1,
            "chooses": 1,
            "action": 1,
            "maximize": 1,
            "rational": 1,
            "according": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para147",
          "content": "Let us emphasize again that this is not the\nonly\nway to be rational—we have already seen a rational agent program for the vacuum world (\nFigure 2.8\n) that has no idea what its utility function is—but, like goal-based agents, a utility-based agent has many advantages in terms of flexibility and learning. Furthermore, in two kinds of cases, goals are inadequate but a utility-based agent can still make rational decisions. First, when there are conflicting goals, only some of which can be achieved (for example, speed and safety), the utility function specifies the appropriate tradeoff. Second, when there are several goals that the agent can\naim for, none of which can be achieved with certainty, utility provides a way in which the likelihood of success can be weighed against the importance of the goals.",
          "sentence_count": 4,
          "char_count": 680,
          "prev_para_id": "chap2_para146",
          "next_para_id": "chap2_para148",
          "style_metadata": {
            "para_id": "chap2_para147",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore"
            ],
            "word_count": 152,
            "sentence_count": 4
          },
          "terminology": {
            "let": 1,
            "emphasize": 1,
            "way": 2,
            "rational—we": 1,
            "seen": 1,
            "rational": 2,
            "agent": 5,
            "program": 1,
            "vacuum": 1,
            "world": 1,
            "figure": 1,
            "idea": 1,
            "utility": 3,
            "function": 2,
            "is—but": 1,
            "goal-based": 1,
            "utility-based": 2,
            "many": 1,
            "advantage": 1,
            "term": 1,
            "flexibility": 1,
            "learning": 1,
            "kind": 1,
            "case": 1,
            "goal": 4,
            "inadequate": 1,
            "make": 1,
            "decision": 1,
            "conflicting": 1,
            "achieved": 2,
            "example": 1,
            "speed": 1,
            "safety": 1,
            "specifies": 1,
            "appropriate": 1,
            "second": 1,
            "several": 1,
            "none": 1,
            "certainty": 1,
            "provides": 1,
            "likelihood": 1,
            "success": 1,
            "weighed": 1,
            "importance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para148",
          "content": "Partial observability and nondeterminism are ubiquitous in the real world, and so, therefore, is decision making under uncertainty. Technically speaking, a rational utility-based agent chooses the action that maximizes the\nexpected utility\nof the action outcomes—that is, the utility the agent expects to derive, on average, given the probabilities and utilities of each outcome. (\nAppendix A\ndefines expectation more precisely.) In\nChapter 15\n, we show that any rational agent must behave\nas if\nit possesses a utility function whose expected value it tries to maximize. An agent that possesses an\nexplicit\nutility function can make rational decisions with a general-purpose algorithm that does not depend on the specific utility function being maximized. In this way, the “global” definition of rationality—designating as rational those agent functions that have the highest performance—is turned into a “local” constraint on rational-agent designs that can be expressed in a simple program.",
          "sentence_count": 6,
          "char_count": 855,
          "prev_para_id": "chap2_para147",
          "next_para_id": "chap2_para149",
          "style_metadata": {
            "para_id": "chap2_para148",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 27.83,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 167,
            "sentence_count": 6
          },
          "terminology": {
            "partial": 1,
            "observability": 1,
            "nondeterminism": 1,
            "ubiquitous": 1,
            "real": 1,
            "world": 1,
            "therefore": 1,
            "decision": 2,
            "making": 1,
            "uncertainty": 1,
            "speaking": 1,
            "rational": 4,
            "utility-based": 1,
            "agent": 5,
            "chooses": 1,
            "action": 2,
            "maximizes": 1,
            "expected": 2,
            "utility": 6,
            "expects": 1,
            "derive": 1,
            "average": 1,
            "given": 1,
            "probability": 1,
            "outcome": 1,
            "appendix": 1,
            "defines": 1,
            "expectation": 1,
            "chapter": 1,
            "show": 1,
            "behave": 1,
            "possesses": 2,
            "function": 4,
            "value": 1,
            "try": 1,
            "maximize": 1,
            "explicit": 1,
            "make": 1,
            "general-purpose": 1,
            "algorithm": 1,
            "depend": 1,
            "specific": 1,
            "maximized": 1,
            "way": 1,
            "global": 1,
            "definition": 1,
            "rationality—designating": 1,
            "highest": 1,
            "performance—is": 1,
            "turned": 1,
            "local": 1,
            "constraint": 1,
            "rational-agent": 1,
            "design": 1,
            "expressed": 1,
            "simple": 1,
            "program": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para149",
          "content": "The utility-based agent structure appears in\nFigure 2.14\n. Utility-based agent programs appear in\nChapters 15\nand\n16\n, where we design decision-making agents that must handle the uncertainty inherent in nondeterministic or partially observable environments. Decision making in multiagent environments is also studied in the framework of utility theory, as explained in\nChapter 17\n.",
          "sentence_count": 3,
          "char_count": 334,
          "prev_para_id": "chap2_para148",
          "next_para_id": "chap2_para150",
          "style_metadata": {
            "para_id": "chap2_para149",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 3
          },
          "terminology": {
            "utility-based": 2,
            "agent": 3,
            "structure": 1,
            "appears": 1,
            "figure": 1,
            "program": 1,
            "appear": 1,
            "chapter": 2,
            "design": 1,
            "decision-making": 1,
            "handle": 1,
            "uncertainty": 1,
            "inherent": 1,
            "nondeterministic": 1,
            "observable": 1,
            "environment": 2,
            "decision": 1,
            "making": 1,
            "multiagent": 1,
            "studied": 1,
            "framework": 1,
            "utility": 1,
            "theory": 1,
            "explained": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para150",
          "content": "×\nFigure 2.14\nA model-based, utility-based agent. It uses a model of the world, along with a utility function that measures its preferences among states of the world. Then it chooses the action that leads to the best expected utility, where expected utility is computed by averaging over all possible outcome states, weighted by the probability of the outcome.",
          "sentence_count": 3,
          "char_count": 304,
          "prev_para_id": "chap2_para149",
          "next_para_id": "chap2_para151",
          "style_metadata": {
            "para_id": "chap2_para150",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "model-based": 1,
            "utility-based": 1,
            "agent": 1,
            "us": 1,
            "model": 1,
            "world": 2,
            "utility": 3,
            "function": 1,
            "measure": 1,
            "preference": 1,
            "state": 2,
            "chooses": 1,
            "action": 1,
            "lead": 1,
            "expected": 2,
            "computed": 1,
            "averaging": 1,
            "possible": 1,
            "outcome": 2,
            "weighted": 1,
            "probability": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para151",
          "content": "At this point, the reader may be wondering, “Is it that simple? We just build agents that maximize expected utility, and we’re done?” It’s true that such agents would be intelligent, but it’s not simple. A utility-based agent has to model and keep track of its environment, tasks that have involved a great deal of research on perception, representation, reasoning, and learning. The results of this research fill many of the chapters of this book. Choosing the utility-maximizing course of action is also a difficult task, requiring ingenious algorithms that fill several more chapters. Even with these algorithms, perfect rationality is usually\nunachievable in practice because of computational complexity, as we noted in\nChapter 1\n. We also note that not all utility-based agents are model-based; we will see in\nChapters 23\nand\n26\nthat a\nmodel-free agent\ncan learn what action is best in a particular situation without ever learning exactly how that action changes the environment.",
          "sentence_count": 7,
          "char_count": 836,
          "prev_para_id": "chap2_para150",
          "next_para_id": "chap2_para152",
          "style_metadata": {
            "para_id": "chap2_para151",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 185,
            "sentence_count": 7
          },
          "terminology": {
            "point": 1,
            "reader": 1,
            "wondering": 1,
            "simple": 2,
            "build": 1,
            "agent": 5,
            "maximize": 1,
            "expected": 1,
            "utility": 1,
            "done": 1,
            "true": 1,
            "intelligent": 1,
            "utility-based": 2,
            "model": 1,
            "keep": 1,
            "track": 1,
            "environment": 2,
            "task": 2,
            "involved": 1,
            "great": 1,
            "deal": 1,
            "research": 2,
            "perception": 1,
            "representation": 1,
            "reasoning": 1,
            "learning": 2,
            "result": 1,
            "fill": 2,
            "many": 1,
            "chapter": 4,
            "book": 1,
            "choosing": 1,
            "utility-maximizing": 1,
            "course": 1,
            "action": 3,
            "difficult": 1,
            "requiring": 1,
            "ingenious": 1,
            "algorithm": 2,
            "several": 1,
            "perfect": 1,
            "rationality": 1,
            "unachievable": 1,
            "practice": 1,
            "computational": 1,
            "complexity": 1,
            "noted": 1,
            "note": 1,
            "model-based": 1,
            "see": 1,
            "model-free": 1,
            "learn": 1,
            "best": 1,
            "particular": 1,
            "situation": 1,
            "change": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para152",
          "content": "Finally, all of this assumes that the designer can specify the utility function correctly;\nChapters 16\n,\n17\n, and\n23\nconsider the issue of unknown utility functions in more depth.",
          "sentence_count": 1,
          "char_count": 155,
          "prev_para_id": "chap2_para151",
          "next_para_id": "chap2_para153",
          "style_metadata": {
            "para_id": "chap2_para152",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "assumes": 1,
            "designer": 1,
            "specify": 1,
            "utility": 2,
            "function": 2,
            "chapter": 1,
            "consider": 1,
            "issue": 1,
            "unknown": 1,
            "depth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para152",
              "entity_text": "Chapters 16",
              "entity_type": "PERSON",
              "start_char": 91,
              "end_char": 102,
              "context": "igner can specify the utility function correctly;\nChapters 16\n,\n17\n, and\n23\nconsider the issue of unknown utili"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para153",
          "content": "2.4.6\nLearning agents\nWe have described agent programs with various methods for selecting actions. We have not, so far, explained how the agent programs\ncome into being.",
          "sentence_count": 2,
          "char_count": 146,
          "prev_para_id": "chap2_para152",
          "next_para_id": "chap2_para154",
          "style_metadata": {
            "para_id": "chap2_para153",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 2
          },
          "terminology": {
            "learning": 1,
            "agent": 3,
            "described": 1,
            "program": 2,
            "various": 1,
            "method": 1,
            "selecting": 1,
            "action": 1,
            "explained": 1,
            "come": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para154",
          "content": "In his famous early paper, Turing (1950) considers the idea of actually programming his intelligent machines by hand. He estimates how much work this might take and concludes, “Some more expeditious method seems desirable.” The method he proposes is to build learning machines and then to teach them. In many areas of AI, this is now the preferred method for creating state-of-the-art systems. Any type of agent (model-based, goal-based, utility-based, etc.) can be built as a learning agent (or not).",
          "sentence_count": 5,
          "char_count": 422,
          "prev_para_id": "chap2_para153",
          "next_para_id": "chap2_para155",
          "style_metadata": {
            "para_id": "chap2_para154",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 5
          },
          "terminology": {
            "famous": 1,
            "early": 1,
            "paper": 1,
            "turing": 1,
            "considers": 1,
            "idea": 1,
            "programming": 1,
            "intelligent": 1,
            "machine": 2,
            "hand": 1,
            "estimate": 1,
            "much": 1,
            "work": 1,
            "take": 1,
            "concludes": 1,
            "expeditious": 1,
            "method": 3,
            "seems": 1,
            "desirable.": 1,
            "proposes": 1,
            "build": 1,
            "learning": 2,
            "many": 1,
            "area": 1,
            "preferred": 1,
            "creating": 1,
            "state-of-the-art": 1,
            "system": 1,
            "type": 1,
            "agent": 2,
            "model-based": 1,
            "goal-based": 1,
            "utility-based": 1,
            "etc": 1,
            "built": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para154",
              "entity_text": "Turing",
              "entity_type": "ORG",
              "start_char": 27,
              "end_char": 33,
              "context": "In his famous early paper, Turing (1950) considers the idea of actually programming"
            },
            {
              "para_id": "chap2_para154",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 318,
              "end_char": 320,
              "context": "machines and then to teach them. In many areas of AI, this is now the preferred method for creating st"
            }
          ],
          "cultural_words": [
            {
              "para_id": "chap2_para154",
              "cultural_word": "state-of-the-art",
              "semantic_explanation": "AI领域指当前最高技术水平",
              "translation_strategy": "意译‘前沿技术’",
              "context": "AI, this is now the preferred method for creating state-of-the-art systems. Any type of agent (model-based, goal-bas"
            }
          ]
        },
        {
          "para_id": "chap2_para155",
          "content": "Learning has another advantage, as we noted earlier: it allows the agent to operate in initially unknown environments and to become more competent than its initial knowledge alone might allow. In this section, we briefly introduce the main ideas of learning agents. Throughout the book, we comment on opportunities and methods for learning in particular kinds of agents.",
          "sentence_count": 3,
          "char_count": 313,
          "prev_para_id": "chap2_para154",
          "next_para_id": "chap2_para156",
          "style_metadata": {
            "para_id": "chap2_para155",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 3
          },
          "terminology": {
            "learning": 3,
            "advantage": 1,
            "noted": 1,
            "allows": 1,
            "agent": 3,
            "operate": 1,
            "unknown": 1,
            "environment": 1,
            "become": 1,
            "competent": 1,
            "initial": 1,
            "knowledge": 1,
            "allow": 1,
            "section": 1,
            "briefly": 1,
            "introduce": 1,
            "main": 1,
            "idea": 1,
            "book": 1,
            "comment": 1,
            "opportunity": 1,
            "method": 1,
            "particular": 1,
            "kind": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para156",
          "content": "Chapters 19\n,\n21\n,\n22\n, and\n23\ngo into much more depth on the learning algorithms themselves.",
          "sentence_count": 1,
          "char_count": 82,
          "prev_para_id": "chap2_para155",
          "next_para_id": "chap2_para157",
          "style_metadata": {
            "para_id": "chap2_para156",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "chapter": 1,
            "much": 1,
            "depth": 1,
            "learning": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para157",
          "content": "A learning agent can be divided into four conceptual components, as shown in\nFigure 2.15\n. The most important distinction is between the\nlearning element\n, which is responsible for making improvements, and the\nperformance element\n, which is responsible for selecting external actions. The performance element is what we have previously considered\nto be the entire agent: it takes in percepts and decides on actions. The learning element uses feedback from the\ncritic\non how the agent is doing and determines how the performance element should be modified to do better in the future.",
          "sentence_count": 4,
          "char_count": 497,
          "prev_para_id": "chap2_para156",
          "next_para_id": "chap2_para158",
          "style_metadata": {
            "para_id": "chap2_para157",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 101,
            "sentence_count": 4
          },
          "terminology": {
            "learning": 3,
            "agent": 3,
            "divided": 1,
            "conceptual": 1,
            "component": 1,
            "shown": 1,
            "figure": 1,
            "important": 1,
            "distinction": 1,
            "element": 5,
            "responsible": 2,
            "making": 1,
            "improvement": 1,
            "performance": 3,
            "selecting": 1,
            "external": 1,
            "action": 2,
            "considered": 1,
            "entire": 1,
            "take": 1,
            "percept": 1,
            "decides": 1,
            "us": 1,
            "feedback": 1,
            "critic": 1,
            "determines": 1,
            "modified": 1,
            "better": 1,
            "future": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para158",
          "content": "×\nFigure 2.15\nA general learning agent. The “performance element” box represents what we have previously considered to be the whole agent program. Now, the “learning element” box gets to modify that program to improve its performance.",
          "sentence_count": 3,
          "char_count": 200,
          "prev_para_id": "chap2_para157",
          "next_para_id": "chap2_para159",
          "style_metadata": {
            "para_id": "chap2_para158",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "general": 1,
            "learning": 2,
            "agent": 2,
            "performance": 2,
            "element": 2,
            "box": 2,
            "represents": 1,
            "considered": 1,
            "whole": 1,
            "program": 2,
            "get": 1,
            "modify": 1,
            "improve": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para159",
          "content": "The design of the learning element depends very much on the design of the performance element. When trying to design an agent that learns a certain capability, the first question is not “How am I going to get it to learn this?” but “What kind of performance element will my agent use to do this once it has learned how?” Given a design for the performance element, learning mechanisms can be constructed to improve every part of the agent.",
          "sentence_count": 2,
          "char_count": 361,
          "prev_para_id": "chap2_para158",
          "next_para_id": "chap2_para160",
          "style_metadata": {
            "para_id": "chap2_para159",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 2
          },
          "terminology": {
            "design": 4,
            "learning": 2,
            "element": 4,
            "depends": 1,
            "much": 1,
            "performance": 3,
            "trying": 1,
            "agent": 3,
            "learns": 1,
            "certain": 1,
            "capability": 1,
            "first": 1,
            "question": 1,
            "going": 1,
            "get": 1,
            "learn": 1,
            "kind": 1,
            "use": 1,
            "learned": 1,
            "given": 1,
            "mechanism": 1,
            "constructed": 1,
            "improve": 1,
            "part": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para160",
          "content": "The critic tells the learning element how well the agent is doing with respect to a fixed performance standard. The critic is necessary because the percepts themselves provide no indication of the agent’s success. For example, a chess program could receive a percept indicating that it has checkmated its opponent, but it needs a performance standard to know that this is a good thing; the percept itself does not say so. It is important that the performance standard be fixed. Conceptually, one should think of it as being outside the agent altogether because the agent must not modify it to fit its own behavior.",
          "sentence_count": 5,
          "char_count": 511,
          "prev_para_id": "chap2_para159",
          "next_para_id": "chap2_para161",
          "style_metadata": {
            "para_id": "chap2_para160",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 5
          },
          "terminology": {
            "critic": 2,
            "tell": 1,
            "learning": 1,
            "element": 1,
            "agent": 4,
            "respect": 1,
            "fixed": 2,
            "performance": 3,
            "standard": 3,
            "necessary": 1,
            "percept": 2,
            "provide": 1,
            "indication": 1,
            "success": 1,
            "example": 1,
            "chess": 1,
            "program": 1,
            "receive": 1,
            "indicating": 1,
            "checkmated": 1,
            "opponent": 1,
            "need": 1,
            "know": 1,
            "good": 1,
            "thing": 1,
            "say": 1,
            "important": 1,
            "think": 1,
            "modify": 1,
            "fit": 1,
            "behavior": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para161",
          "content": "The last component of the learning agent is the\nproblem generator\n. It is responsible for suggesting actions that will lead to new and informative experiences. If the performance element had its way, it would keep doing the actions that are best, given what it knows, but if the agent is willing to explore a little and do some perhaps suboptimal actions in the short run, it might discover much better actions for the long run. The problem generator’s job is to suggest these exploratory actions. This is what scientists do when they carry out experiments. Galileo did not think that dropping rocks from the top of a tower in Pisa was valuable in itself. He was not trying to break the rocks or to modify the brains of unfortunate pedestrians. His aim was to modify his own brain by identifying a better theory of the motion of objects.",
          "sentence_count": 8,
          "char_count": 691,
          "prev_para_id": "chap2_para160",
          "next_para_id": "chap2_para162",
          "style_metadata": {
            "para_id": "chap2_para161",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 162,
            "sentence_count": 8
          },
          "terminology": {
            "last": 1,
            "component": 1,
            "learning": 1,
            "agent": 2,
            "problem": 2,
            "generator": 2,
            "responsible": 1,
            "suggesting": 1,
            "action": 5,
            "lead": 1,
            "new": 1,
            "informative": 1,
            "experience": 1,
            "performance": 1,
            "element": 1,
            "way": 1,
            "keep": 1,
            "best": 1,
            "given": 1,
            "know": 1,
            "willing": 1,
            "little": 1,
            "suboptimal": 1,
            "short": 1,
            "run": 2,
            "better": 2,
            "long": 1,
            "job": 1,
            "suggest": 1,
            "exploratory": 1,
            "scientist": 1,
            "carry": 1,
            "experiment": 1,
            "galileo": 1,
            "think": 1,
            "dropping": 1,
            "rock": 2,
            "top": 1,
            "tower": 1,
            "pisa": 1,
            "valuable": 1,
            "trying": 1,
            "break": 1,
            "modify": 2,
            "brain": 2,
            "unfortunate": 1,
            "pedestrian": 1,
            "aim": 1,
            "identifying": 1,
            "theory": 1,
            "motion": 1,
            "object": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para161",
              "entity_text": "Galileo",
              "entity_type": "PRODUCT",
              "start_char": 558,
              "end_char": 565,
              "context": "at scientists do when they carry out experiments. Galileo did not think that dropping rocks from the top of"
            },
            {
              "para_id": "chap2_para161",
              "entity_text": "Pisa",
              "entity_type": "PERSON",
              "start_char": 627,
              "end_char": 631,
              "context": "nk that dropping rocks from the top of a tower in Pisa was valuable in itself. He was not trying to brea"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para162",
          "content": "The learning element can make changes to any of the “knowledge” components shown in the agent diagrams (\nFigures 2.9\n,\n2.11\n,\n2.13\n, and\n2.14\n). The simplest cases involve learning directly from the percept sequence. Observation of pairs of successive states of the environment can allow the agent to learn “What my actions do” and “How the world evolves” in response to its actions. For example, if the automated taxi exerts a certain braking pressure when driving on a wet road, then it will soon find out how much deceleration is actually achieved, and whether it skids off the road. The problem generator might identify certain parts of the model that are in need of improvement and suggest experiments, such as trying out the brakes on different road surfaces under different conditions.",
          "sentence_count": 5,
          "char_count": 666,
          "prev_para_id": "chap2_para161",
          "next_para_id": "chap2_para163",
          "style_metadata": {
            "para_id": "chap2_para162",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 5
          },
          "terminology": {
            "learning": 2,
            "element": 1,
            "make": 1,
            "change": 1,
            "knowledge": 1,
            "component": 1,
            "shown": 1,
            "agent": 2,
            "diagram": 1,
            "figure": 1,
            "simplest": 1,
            "case": 1,
            "involve": 1,
            "percept": 1,
            "sequence": 1,
            "observation": 1,
            "pair": 1,
            "successive": 1,
            "state": 1,
            "environment": 1,
            "allow": 1,
            "learn": 1,
            "action": 2,
            "world": 1,
            "evolves": 1,
            "response": 1,
            "example": 1,
            "automated": 1,
            "taxi": 1,
            "exerts": 1,
            "certain": 2,
            "braking": 1,
            "pressure": 1,
            "driving": 1,
            "wet": 1,
            "road": 3,
            "much": 1,
            "deceleration": 1,
            "achieved": 1,
            "skid": 1,
            "problem": 1,
            "generator": 1,
            "identify": 1,
            "part": 1,
            "model": 1,
            "improvement": 1,
            "suggest": 1,
            "experiment": 1,
            "trying": 1,
            "brake": 1,
            "different": 2,
            "surface": 1,
            "condition": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para163",
          "content": "Improving the model components of a model-based agent so that they conform better with reality is almost always a good idea, regardless of the external performance standard. (In some cases, it is better from a computational point of view to have a simple but slightly inaccurate model rather than a perfect but fiendishly complex model.) Information from the external standard is needed when trying to learn a reflex component or a utility function.",
          "sentence_count": 3,
          "char_count": 377,
          "prev_para_id": "chap2_para162",
          "next_para_id": "chap2_para164",
          "style_metadata": {
            "para_id": "chap2_para163",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.67,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 3
          },
          "terminology": {
            "improving": 1,
            "model": 3,
            "component": 2,
            "model-based": 1,
            "agent": 1,
            "conform": 1,
            "reality": 1,
            "good": 1,
            "idea": 1,
            "external": 2,
            "performance": 1,
            "standard": 2,
            "case": 1,
            "computational": 1,
            "point": 1,
            "view": 1,
            "simple": 1,
            "inaccurate": 1,
            "perfect": 1,
            "complex": 1,
            "information": 1,
            "needed": 1,
            "trying": 1,
            "learn": 1,
            "reflex": 1,
            "utility": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para164",
          "content": "For example, suppose the taxi-driving agent receives no tips from passengers who have been thoroughly shaken up during the trip. The external performance standard must inform the agent that the loss of tips is a negative contribution to its overall performance; then the agent might be able to learn that violent maneuvers do not contribute to its own utility. In a sense, the performance standard distinguishes part of the incoming percept as a\nreward\n(or\npenalty\n) that provides direct feedback on the quality of the agent’s behavior. Hard-wired performance standards such as pain and hunger in animals can be understood in this way.",
          "sentence_count": 4,
          "char_count": 536,
          "prev_para_id": "chap2_para163",
          "next_para_id": "chap2_para165",
          "style_metadata": {
            "para_id": "chap2_para164",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "example": 1,
            "suppose": 1,
            "taxi-driving": 1,
            "agent": 4,
            "receives": 1,
            "tip": 2,
            "passenger": 1,
            "shaken": 1,
            "trip": 1,
            "external": 1,
            "performance": 4,
            "standard": 3,
            "inform": 1,
            "loss": 1,
            "negative": 1,
            "contribution": 1,
            "overall": 1,
            "able": 1,
            "learn": 1,
            "violent": 1,
            "maneuver": 1,
            "contribute": 1,
            "utility": 1,
            "sense": 1,
            "distinguishes": 1,
            "part": 1,
            "incoming": 1,
            "percept": 1,
            "reward": 1,
            "penalty": 1,
            "provides": 1,
            "direct": 1,
            "feedback": 1,
            "quality": 1,
            "behavior": 1,
            "hard-wired": 1,
            "pain": 1,
            "hunger": 1,
            "animal": 1,
            "understood": 1,
            "way": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para165",
          "content": "More generally,\nhuman choices\ncan provide information about human preferences. For example, suppose the taxi does not know that people generally don’t like loud noises, and settles on the idea of blowing its horn continuously as a way of ensuring that pedestrians know it’s coming. The consequent human behavior—covering ears, using bad language, and possibly cutting the wires to the horn—would provide evidence to the agent with which to update its utility function. This issue is discussed further in\nChapter 23\n.",
          "sentence_count": 4,
          "char_count": 439,
          "prev_para_id": "chap2_para164",
          "next_para_id": "chap2_para166",
          "style_metadata": {
            "para_id": "chap2_para165",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 94,
            "sentence_count": 4
          },
          "terminology": {
            "human": 3,
            "choice": 1,
            "provide": 2,
            "information": 1,
            "preference": 1,
            "example": 1,
            "suppose": 1,
            "taxi": 1,
            "know": 2,
            "people": 1,
            "loud": 1,
            "noise": 1,
            "settle": 1,
            "idea": 1,
            "blowing": 1,
            "horn": 1,
            "way": 1,
            "ensuring": 1,
            "pedestrian": 1,
            "coming": 1,
            "consequent": 1,
            "behavior—covering": 1,
            "ear": 1,
            "using": 1,
            "bad": 1,
            "language": 1,
            "cutting": 1,
            "wire": 1,
            "horn—would": 1,
            "evidence": 1,
            "agent": 1,
            "update": 1,
            "utility": 1,
            "function": 1,
            "issue": 1,
            "discussed": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para166",
          "content": "In summary, agents have a variety of components, and those components can be represented in many ways within the agent program, so there appears to be great variety among learning methods. There is, however, a single unifying theme. Learning in intelligent agents can be summarized as a process of modification of each component of the agent to bring the components into closer agreement with the available feedback information, thereby improving the overall performance of the agent.",
          "sentence_count": 3,
          "char_count": 409,
          "prev_para_id": "chap2_para165",
          "next_para_id": "chap2_para167",
          "style_metadata": {
            "para_id": "chap2_para166",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 28.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 85,
            "sentence_count": 3
          },
          "terminology": {
            "summary": 1,
            "agent": 5,
            "variety": 2,
            "component": 4,
            "represented": 1,
            "many": 1,
            "way": 1,
            "program": 1,
            "appears": 1,
            "great": 1,
            "learning": 2,
            "method": 1,
            "single": 1,
            "unifying": 1,
            "theme": 1,
            "intelligent": 1,
            "summarized": 1,
            "process": 1,
            "modification": 1,
            "bring": 1,
            "agreement": 1,
            "available": 1,
            "feedback": 1,
            "information": 1,
            "improving": 1,
            "overall": 1,
            "performance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para167",
          "content": "2.4.7\nHow the components of agent programs work\nWe have described agent programs (in very high-level terms) as consisting of various components, whose function it is to answer questions such as: “What is the world like now?” “What action should I do now?” “What do my actions do?” The next question for a student of AI is, “How on Earth do these components work?” It takes about a thousand pages to begin to answer that question properly, but here we want to draw the reader’s attention to some basic distinctions among the various ways that the components can represent the environment that the agent inhabits.",
          "sentence_count": 1,
          "char_count": 509,
          "prev_para_id": "chap2_para166",
          "next_para_id": "chap2_para168",
          "style_metadata": {
            "para_id": "chap2_para167",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 126.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 126,
            "sentence_count": 1
          },
          "terminology": {
            "component": 4,
            "agent": 3,
            "program": 2,
            "work": 2,
            "described": 1,
            "high-level": 1,
            "term": 1,
            "consisting": 1,
            "various": 2,
            "function": 1,
            "question": 3,
            "world": 1,
            "action": 2,
            "student": 1,
            "earth": 1,
            "take": 1,
            "page": 1,
            "begin": 1,
            "answer": 1,
            "want": 1,
            "draw": 1,
            "reader": 1,
            "attention": 1,
            "basic": 1,
            "distinction": 1,
            "way": 1,
            "represent": 1,
            "environment": 1,
            "inhabits": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para167",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 316,
              "end_char": 318,
              "context": "y actions do?” The next question for a student of AI is, “How on Earth do these components work?” It t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para168",
          "content": "Roughly speaking, we can place the representations along an axis of increasing complexity and expressive power—atomic, factored, and structured. To illustrate these ideas, it helps to consider a particular agent component, such as the one that deals with “What my actions do.” This component describes the changes that might occur in the environment as the result of taking an action, and\nFigure 2.16\nprovides schematic depictions of how those transitions might be represented.",
          "sentence_count": 2,
          "char_count": 407,
          "prev_para_id": "chap2_para167",
          "next_para_id": "chap2_para169",
          "style_metadata": {
            "para_id": "chap2_para168",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 2
          },
          "terminology": {
            "speaking": 1,
            "place": 1,
            "representation": 1,
            "axis": 1,
            "increasing": 1,
            "complexity": 1,
            "expressive": 1,
            "power—atomic": 1,
            "factored": 1,
            "structured": 1,
            "illustrate": 1,
            "idea": 1,
            "help": 1,
            "consider": 1,
            "particular": 1,
            "agent": 1,
            "component": 2,
            "deal": 1,
            "action": 2,
            "do.": 1,
            "describes": 1,
            "change": 1,
            "occur": 1,
            "environment": 1,
            "result": 1,
            "taking": 1,
            "figure": 1,
            "provides": 1,
            "schematic": 1,
            "depiction": 1,
            "transition": 1,
            "represented": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para169",
          "content": "Description\nPart (“a”), Atomic: An arrow from a block labeled B points to a block labeled C.",
          "sentence_count": 1,
          "char_count": 77,
          "prev_para_id": "chap2_para168",
          "next_para_id": "chap2_para170",
          "style_metadata": {
            "para_id": "chap2_para169",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "atomic": 1,
            "arrow": 1,
            "block": 2,
            "labeled": 2,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para169",
              "entity_text": "Atomic",
              "entity_type": "PERSON",
              "start_char": 24,
              "end_char": 30,
              "context": "Description\nPart (“a”), Atomic: An arrow from a block labeled B points to a bloc"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para170",
          "content": "Part (b), Factored: Two blocks labeled B and C are shown. In both blocks, four circles are shown one below the other and two progress bars are shown below the bottom circle. In block B, the circles have alternating black and blue shades from the top. In the first progress bar, black shade fills about 40 percent of the bar while the blue shade fills the rest. In the second progress bar, the black shade fills about 90 percent of the bar while the blue shade fills the rest. In block C, the first two circles from the top are shaded blue and the other two circles are shaded black. In the first progress bar, black shade fills about 40 percent of the bar while the blue shade fills the rest. In the second progress bar, the black shade fills about 60 percent of the bar while the blue shade fills the rest.",
          "sentence_count": 8,
          "char_count": 655,
          "prev_para_id": "chap2_para169",
          "next_para_id": "chap2_para171",
          "style_metadata": {
            "para_id": "chap2_para170",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 172,
            "sentence_count": 8
          },
          "terminology": {
            "part": 1,
            "factored": 1,
            "block": 4,
            "labeled": 1,
            "shown": 3,
            "circle": 5,
            "progress": 5,
            "bar": 9,
            "bottom": 1,
            "alternating": 1,
            "black": 6,
            "blue": 6,
            "shade": 9,
            "top": 1,
            "first": 2,
            "fill": 8,
            "percent": 4,
            "rest": 4,
            "second": 2,
            "shaded": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para171",
          "content": "Part (c), Structured: The figure shows two blocks connected by an arrow. There are four red blocks, three green blocks, and two white blocks in the first block. These are arranged in three columns and four rows. The following blocks are shown on each row. Row 1: Column 1, red. Column 2, green. Row 2: Column 2, red. Row 3: Column 1, red. Column 2, green. Column 3, white. Row 4: Column 1, white. Column 2, red. Column 3, green. These blocks are connected using arrows in different paths. There are four red blocks, three green blocks, and four white blocks in the second block. These are arranged in three columns and four rows. The following blocks are shown on each row. Row 1: Column 1, white. Column 2, green. Column 3, white. Row 2: Column 2, red. Column 3, red. Row 3: Column 1, red. Column 2, white. Column 3, white. Row 4: Column 1, green. Column 2, red. Column 3, green. These blocks are connected using arrows in different paths.",
          "sentence_count": 29,
          "char_count": 769,
          "prev_para_id": "chap2_para170",
          "next_para_id": "chap2_para172",
          "style_metadata": {
            "para_id": "chap2_para171",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 237,
            "sentence_count": 29
          },
          "terminology": {
            "part": 1,
            "structured": 1,
            "figure": 1,
            "show": 1,
            "block": 13,
            "connected": 3,
            "red": 10,
            "green": 8,
            "white": 8,
            "first": 1,
            "arranged": 2,
            "column": 22,
            "row": 12,
            "following": 2,
            "shown": 2,
            "using": 2,
            "arrow": 2,
            "different": 2,
            "path": 2,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para172",
          "content": "×\nFigure 2.16\nThree ways to represent states and the transitions between them. (a) Atomic representation: a state (such as B or C) is a black box with no internal structure; (b) Factored representation: a state consists of a vector of attribute values; values can be Boolean, real-valued, or one of a fixed set of symbols. (c) Structured representation: a state includes objects, each of which may have attributes of its own as well as relationships to other objects.",
          "sentence_count": 3,
          "char_count": 391,
          "prev_para_id": "chap2_para171",
          "next_para_id": "chap2_para173",
          "style_metadata": {
            "para_id": "chap2_para172",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 98,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "way": 1,
            "represent": 1,
            "state": 4,
            "transition": 1,
            "atomic": 1,
            "representation": 3,
            "black": 1,
            "box": 1,
            "internal": 1,
            "structure": 1,
            "factored": 1,
            "consists": 1,
            "vector": 1,
            "attribute": 2,
            "value": 2,
            "boolean": 1,
            "real-valued": 1,
            "fixed": 1,
            "set": 1,
            "symbol": 1,
            "structured": 1,
            "includes": 1,
            "object": 2,
            "relationship": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para173",
          "content": "In an\natomic representation\neach state of the world is indivisible—it has no internal structure. Consider the task of finding a driving route from one end of a country to the other via some sequence of cities (we address this problem in\nFigure 3.1\non\npage 82\n). For the purposes of solving this problem, it may suffice to reduce the state of the world to just the name of the city we are in—a single atom of knowledge, a “black box” whose only discernible property is that of being identical to or different from another black box. The standard algorithms underlying search and game-playing (\nChapters 3\n,\n4\n, and\n6\n), hidden Markov models (\nChapter 14\n), and Markov decision processes (\nChapter 16\n) all work with atomic representations.",
          "sentence_count": 4,
          "char_count": 621,
          "prev_para_id": "chap2_para172",
          "next_para_id": "chap2_para174",
          "style_metadata": {
            "para_id": "chap2_para173",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 145,
            "sentence_count": 4
          },
          "terminology": {
            "atomic": 2,
            "representation": 2,
            "state": 2,
            "world": 2,
            "indivisible—it": 1,
            "internal": 1,
            "structure": 1,
            "consider": 1,
            "task": 1,
            "finding": 1,
            "driving": 1,
            "route": 1,
            "end": 1,
            "country": 1,
            "sequence": 1,
            "city": 2,
            "address": 1,
            "problem": 2,
            "figure": 1,
            "page": 1,
            "purpose": 1,
            "solving": 1,
            "suffice": 1,
            "reduce": 1,
            "name": 1,
            "in—a": 1,
            "single": 1,
            "atom": 1,
            "knowledge": 1,
            "black": 2,
            "box": 2,
            "discernible": 1,
            "property": 1,
            "identical": 1,
            "different": 1,
            "standard": 1,
            "underlying": 1,
            "search": 1,
            "game-playing": 1,
            "chapter": 3,
            "hidden": 1,
            "markov": 2,
            "model": 1,
            "decision": 1,
            "process": 1,
            "work": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para173",
              "entity_text": "Markov",
              "entity_type": "PERSON",
              "start_char": 626,
              "end_char": 632,
              "context": "d game-playing (\nChapters 3\n,\n4\n, and\n6\n), hidden Markov models (\nChapter 14\n), and Markov decision proces"
            },
            {
              "para_id": "chap2_para173",
              "entity_text": "Markov",
              "entity_type": "PERSON",
              "start_char": 660,
              "end_char": 666,
              "context": "and\n6\n), hidden Markov models (\nChapter 14\n), and Markov decision processes (\nChapter 16\n) all work with a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para174",
          "content": "A\nfactored representation\nsplits up each state into a fixed set of\nvariables\nor\nattributes\n, each of which can have a\nvalue\n. Consider a higher-fidelity description for the same driving problem, where we need to be concerned with more than just atomic location in one city or another; we might need to pay attention to how much gas is in the tank, our current GPS coordinates, whether or not the oil warning light is working, how much money we have for tolls, what station is on the radio, and so on. While two different atomic states have nothing in common—they are just different black boxes—two different factored states can share some attributes (such as being at some particular GPS location) and not others (such as having lots of gas or having no gas); this makes it much easier to work out how to turn one state into another. Many important areas of AI are based on factored representations, including constraint satisfaction algorithms (\nChapter 5\n), propositional logic (\nChapter 7\n), planning (\nChapter 11\n), Bayesian networks (\nChapters 12\n,\n13\n,\n14\n,\n15\n, and\n18\n), and various machine learning algorithms.",
          "sentence_count": 4,
          "char_count": 945,
          "prev_para_id": "chap2_para173",
          "next_para_id": "chap2_para175",
          "style_metadata": {
            "para_id": "chap2_para174",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 54.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 219,
            "sentence_count": 4
          },
          "terminology": {
            "factored": 3,
            "representation": 2,
            "split": 1,
            "state": 4,
            "fixed": 1,
            "set": 1,
            "variable": 1,
            "attribute": 2,
            "value": 1,
            "consider": 1,
            "higher-fidelity": 1,
            "description": 1,
            "driving": 1,
            "problem": 1,
            "need": 2,
            "concerned": 1,
            "atomic": 2,
            "location": 2,
            "city": 1,
            "pay": 1,
            "attention": 1,
            "gas": 3,
            "tank": 1,
            "current": 1,
            "gps": 2,
            "coordinate": 1,
            "oil": 1,
            "warning": 1,
            "light": 1,
            "working": 1,
            "much": 1,
            "money": 1,
            "toll": 1,
            "station": 1,
            "radio": 1,
            "different": 3,
            "nothing": 1,
            "common—they": 1,
            "black": 1,
            "boxes—two": 1,
            "share": 1,
            "particular": 1,
            "others": 1,
            "lot": 1,
            "make": 1,
            "easier": 1,
            "work": 1,
            "turn": 1,
            "many": 1,
            "important": 1,
            "area": 1,
            "based": 1,
            "including": 1,
            "constraint": 1,
            "satisfaction": 1,
            "chapter": 4,
            "propositional": 1,
            "logic": 1,
            "planning": 1,
            "bayesian": 1,
            "network": 1,
            "various": 1,
            "machine": 1,
            "learning": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para174",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 858,
              "end_char": 860,
              "context": "n one state into another. Many important areas of AI are based on factored representations, including "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para175",
          "content": "For many purposes, we need to understand the world as having\nthings\nin it that are\nrelated\nto each other, not just variables with values. For example, we might notice that a large truck ahead of us is reversing into the driveway of a dairy farm, but a loose cow is blocking the truck’s path. A factored representation is unlikely to be pre-equipped with the attribute\nTruckAheadBackinglntoDairyFarmDrivewayBlockedByLooseCow\nwith value\ntrue\nor\nfalse.",
          "sentence_count": 3,
          "char_count": 387,
          "prev_para_id": "chap2_para174",
          "next_para_id": "chap2_para176",
          "style_metadata": {
            "para_id": "chap2_para175",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 3
          },
          "terminology": {
            "many": 1,
            "purpose": 1,
            "need": 1,
            "understand": 1,
            "world": 1,
            "thing": 1,
            "related": 1,
            "variable": 1,
            "value": 2,
            "example": 1,
            "notice": 1,
            "large": 1,
            "truck": 2,
            "reversing": 1,
            "dairy": 1,
            "farm": 1,
            "loose": 1,
            "cow": 1,
            "blocking": 1,
            "path": 1,
            "factored": 1,
            "representation": 1,
            "unlikely": 1,
            "pre-equipped": 1,
            "attribute": 1,
            "truckaheadbackinglntodairyfarmdrivewayblockedbyloosecow": 1,
            "true": 1,
            "false": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para176",
          "content": "Instead, we would need a\nstructured representation\n, in which objects such as cows and trucks and their various and varying relationships can be described explicitly (see\nFigure 2.16(c)\n). Structured representations underlie relational databases and first-order logic (\nChapters 8\n,\n9\n, and\n10\n), first-order probability models (\nChapter 18\n), and much of natural language understanding (\nChapters 24\nand\n25\n). In fact, much of what humans express in natural language concerns objects and their relationships.",
          "sentence_count": 3,
          "char_count": 445,
          "prev_para_id": "chap2_para175",
          "next_para_id": "chap2_para177",
          "style_metadata": {
            "para_id": "chap2_para176",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 92,
            "sentence_count": 3
          },
          "terminology": {
            "need": 1,
            "structured": 2,
            "representation": 2,
            "object": 2,
            "cow": 1,
            "truck": 1,
            "various": 1,
            "varying": 1,
            "relationship": 2,
            "described": 1,
            "see": 1,
            "figure": 1,
            "underlie": 1,
            "relational": 1,
            "database": 1,
            "first-order": 2,
            "logic": 1,
            "chapter": 3,
            "probability": 1,
            "model": 1,
            "much": 2,
            "natural": 2,
            "language": 2,
            "understanding": 1,
            "fact": 1,
            "human": 1,
            "express": 1,
            "concern": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para176",
              "entity_text": "Chapters 24",
              "entity_type": "PRODUCT",
              "start_char": 389,
              "end_char": 400,
              "context": "8\n), and much of natural language understanding (\nChapters 24\nand\n25\n). In fact, much of what humans express in"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para177",
          "content": "As we mentioned earlier, the axis along which atomic, factored, and structured representations lie is the axis of increasing\nexpressiveness\n. Roughly speaking, a more expressive representation can capture, at least as concisely, everything a less expressive one can capture, plus some more. Often, the more expressive language is\nmuch\nmore concise; for example, the rules of chess can be written in a page or two of a structured-representation language such as first-order logic but require thousands of pages when written in a factored-representation language such as propositional logic and around 10\n38\npages when written in an atomic language such as that of finite-state automata. On the other hand, reasoning and learning become more complex as the expressive power of the representation increases. To gain the benefits of expressive representations while avoiding their drawbacks, intelligent systems for the real world may need to operate at all points along the axis simultaneously.",
          "sentence_count": 5,
          "char_count": 846,
          "prev_para_id": "chap2_para176",
          "next_para_id": "chap2_para178",
          "style_metadata": {
            "para_id": "chap2_para177",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 168,
            "sentence_count": 5
          },
          "terminology": {
            "mentioned": 1,
            "atomic": 2,
            "factored": 1,
            "structured": 1,
            "representation": 4,
            "lie": 1,
            "axis": 1,
            "increasing": 1,
            "expressiveness": 1,
            "speaking": 1,
            "expressive": 5,
            "capture": 2,
            "least": 1,
            "everything": 1,
            "language": 4,
            "much": 1,
            "concise": 1,
            "example": 1,
            "rule": 1,
            "chess": 1,
            "written": 3,
            "page": 3,
            "structured-representation": 1,
            "first-order": 1,
            "logic": 2,
            "require": 1,
            "thousand": 1,
            "factored-representation": 1,
            "propositional": 1,
            "finite-state": 1,
            "automaton": 1,
            "hand": 1,
            "reasoning": 1,
            "learning": 1,
            "become": 1,
            "complex": 1,
            "power": 1,
            "increase": 1,
            "gain": 1,
            "benefit": 1,
            "avoiding": 1,
            "drawback": 1,
            "intelligent": 1,
            "system": 1,
            "real": 1,
            "world": 1,
            "need": 1,
            "operate": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para178",
          "content": "Another axis for representation involves the mapping of concepts to locations in physical memory, whether in a computer or in a brain. If there is a one-to-one mapping between concepts and memory locations, we call that a\nlocalist representation\n. On the other hand,\nif the representation of a concept is spread over many memory locations, and each memory location is employed as part of the representation of multiple different concepts, we call that a\ndistributed representation\n. Distributed representations are more robust against noise and information loss. With a localist representation, the mapping from concept to memory location is arbitrary, and if a transmission error garbles a few bits, we might confuse\nTruck\nwith the unrelated concept\nTruce.",
          "sentence_count": 5,
          "char_count": 647,
          "prev_para_id": "chap2_para177",
          "next_para_id": "chap2_para179",
          "style_metadata": {
            "para_id": "chap2_para178",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 130,
            "sentence_count": 5
          },
          "terminology": {
            "axis": 1,
            "representation": 7,
            "involves": 1,
            "mapping": 3,
            "concept": 6,
            "location": 5,
            "physical": 1,
            "memory": 5,
            "computer": 1,
            "brain": 1,
            "one-to-one": 1,
            "call": 2,
            "localist": 2,
            "hand": 1,
            "spread": 1,
            "many": 1,
            "employed": 1,
            "part": 1,
            "multiple": 1,
            "different": 1,
            "distributed": 2,
            "robust": 1,
            "noise": 1,
            "information": 1,
            "loss": 1,
            "arbitrary": 1,
            "transmission": 1,
            "error": 1,
            "garbles": 1,
            "bit": 1,
            "confuse": 1,
            "truck": 1,
            "unrelated": 1,
            "truce": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para178",
              "entity_text": "Truce",
              "entity_type": "PRODUCT",
              "start_char": 751,
              "end_char": 756,
              "context": "we might confuse\nTruck\nwith the unrelated concept\nTruce."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para179",
          "content": "But with a distributed representation, you can think of each concept representing a point in multidimensional space, and if you garble a few bits you move to a nearby point in that space, which will have similar meaning.",
          "sentence_count": 1,
          "char_count": 183,
          "prev_para_id": "chap2_para178",
          "next_para_id": "chap2_para180",
          "style_metadata": {
            "para_id": "chap2_para179",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 1
          },
          "terminology": {
            "distributed": 1,
            "representation": 1,
            "think": 1,
            "concept": 1,
            "representing": 1,
            "point": 2,
            "multidimensional": 1,
            "space": 2,
            "garble": 1,
            "bit": 1,
            "move": 1,
            "similar": 1,
            "meaning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para180",
          "content": "Summary\nSummary\nThis chapter has been something of a whirlwind tour of AI, which we have conceived of as the science of agent design. The major points to recall are as follows:\n•\nAn\nagent\nis something that perceives and acts in an environment. The\nagent function\nfor an agent specifies the action taken by the agent in response to any percept sequence.",
          "sentence_count": 3,
          "char_count": 298,
          "prev_para_id": "chap2_para179",
          "next_para_id": "chap2_para181",
          "style_metadata": {
            "para_id": "chap2_para180",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 3
          },
          "terminology": {
            "summary": 2,
            "chapter": 1,
            "something": 2,
            "tour": 1,
            "conceived": 1,
            "science": 1,
            "agent": 5,
            "design": 1,
            "major": 1,
            "point": 1,
            "recall": 1,
            "follows": 1,
            "perceives": 1,
            "act": 1,
            "environment": 1,
            "function": 1,
            "specifies": 1,
            "action": 1,
            "taken": 1,
            "response": 1,
            "percept": 1,
            "sequence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para180",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 71,
              "end_char": 73,
              "context": "chapter has been something of a whirlwind tour of AI, which we have conceived of as the science of age"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para181",
          "content": "•\nThe\nperformance measure\nevaluates the behavior of the agent in an environment. A\nrational agent\nacts so as to maximize the expected value of the performance measure, given the percept sequence it has seen so far.",
          "sentence_count": 2,
          "char_count": 183,
          "prev_para_id": "chap2_para180",
          "next_para_id": "chap2_para182",
          "style_metadata": {
            "para_id": "chap2_para181",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 2
          },
          "terminology": {
            "performance": 2,
            "measure": 2,
            "evaluates": 1,
            "behavior": 1,
            "agent": 2,
            "environment": 1,
            "rational": 1,
            "act": 1,
            "maximize": 1,
            "expected": 1,
            "value": 1,
            "given": 1,
            "percept": 1,
            "sequence": 1,
            "seen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para182",
          "content": "•\nA\ntask environment\nspecification includes the performance measure, the external environment, the actuators, and the sensors. In designing an agent, the first step must always be to specify the task environment as fully as possible.",
          "sentence_count": 2,
          "char_count": 201,
          "prev_para_id": "chap2_para181",
          "next_para_id": "chap2_para183",
          "style_metadata": {
            "para_id": "chap2_para182",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 2
          },
          "terminology": {
            "task": 2,
            "environment": 3,
            "specification": 1,
            "includes": 1,
            "performance": 1,
            "measure": 1,
            "external": 1,
            "actuator": 1,
            "sensor": 1,
            "designing": 1,
            "agent": 1,
            "first": 1,
            "step": 1,
            "specify": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para183",
          "content": "•\nTask environments vary along several significant dimensions. They can be fully or partially observable, single-agent or multiagent, deterministic or nondeterministic, episodic or sequential, static or dynamic, discrete or continuous, and known or unknown.",
          "sentence_count": 2,
          "char_count": 225,
          "prev_para_id": "chap2_para182",
          "next_para_id": "chap2_para184",
          "style_metadata": {
            "para_id": "chap2_para183",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 2
          },
          "terminology": {
            "task": 1,
            "environment": 1,
            "vary": 1,
            "several": 1,
            "significant": 1,
            "dimension": 1,
            "observable": 1,
            "single-agent": 1,
            "multiagent": 1,
            "deterministic": 1,
            "nondeterministic": 1,
            "episodic": 1,
            "sequential": 1,
            "static": 1,
            "dynamic": 1,
            "discrete": 1,
            "continuous": 1,
            "known": 1,
            "unknown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para184",
          "content": "•\nIn cases where the performance measure is unknown or hard to specify correctly, there is a significant risk of the agent optimizing the wrong objective. In such cases the agent design should reflect uncertainty about the true objective.",
          "sentence_count": 2,
          "char_count": 201,
          "prev_para_id": "chap2_para183",
          "next_para_id": "chap2_para185",
          "style_metadata": {
            "para_id": "chap2_para184",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 2
          },
          "terminology": {
            "case": 2,
            "performance": 1,
            "measure": 1,
            "unknown": 1,
            "hard": 1,
            "specify": 1,
            "significant": 1,
            "risk": 1,
            "agent": 2,
            "optimizing": 1,
            "wrong": 1,
            "objective": 2,
            "design": 1,
            "reflect": 1,
            "uncertainty": 1,
            "true": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para185",
          "content": "•\nThe\nagent program\nimplements the agent function. There exists a variety of basic agent program designs reflecting the kind of information made explicit and used in the decision process. The designs vary in efficiency, compactness, and flexibility. The appropriate design of the agent program depends on the nature of the environment.",
          "sentence_count": 4,
          "char_count": 287,
          "prev_para_id": "chap2_para184",
          "next_para_id": "chap2_para186",
          "style_metadata": {
            "para_id": "chap2_para185",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 4
          },
          "terminology": {
            "agent": 4,
            "program": 3,
            "implement": 1,
            "function": 1,
            "exists": 1,
            "variety": 1,
            "basic": 1,
            "design": 3,
            "reflecting": 1,
            "kind": 1,
            "information": 1,
            "made": 1,
            "explicit": 1,
            "used": 1,
            "decision": 1,
            "process": 1,
            "vary": 1,
            "efficiency": 1,
            "compactness": 1,
            "flexibility": 1,
            "appropriate": 1,
            "depends": 1,
            "nature": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para186",
          "content": "•\nSimple reflex agents\nrespond directly to percepts, whereas\nmodel-based reflex agents\nmaintain internal state to track aspects of the world that are not evident in the current percept.",
          "sentence_count": 1,
          "char_count": 161,
          "prev_para_id": "chap2_para185",
          "next_para_id": "chap2_para187",
          "style_metadata": {
            "para_id": "chap2_para186",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "simple": 1,
            "reflex": 2,
            "agent": 2,
            "respond": 1,
            "percept": 2,
            "model-based": 1,
            "maintain": 1,
            "internal": 1,
            "state": 1,
            "track": 1,
            "aspect": 1,
            "world": 1,
            "evident": 1,
            "current": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para187",
          "content": "Goal-based agents\nact to achieve their goals, and\nutility-based agents\ntry to maximize their own expected “happiness.”\n•\nAll agents can improve their performance through\nlearning\n.",
          "sentence_count": 1,
          "char_count": 161,
          "prev_para_id": "chap2_para186",
          "next_para_id": "chap2_para188",
          "style_metadata": {
            "para_id": "chap2_para187",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 1
          },
          "terminology": {
            "goal-based": 1,
            "agent": 3,
            "act": 1,
            "achieve": 1,
            "goal": 1,
            "utility-based": 1,
            "try": 1,
            "maximize": 1,
            "expected": 1,
            "happiness.": 1,
            "improve": 1,
            "performance": 1,
            "learning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para188",
          "content": "Bibliographical and Historical Notes\nBibliographical and Historical Notes\nThe central role of action in intelligence—the notion of practical reasoning—goes back at least as far as Aristotle’s\nNicomachean Ethics.",
          "sentence_count": 1,
          "char_count": 187,
          "prev_para_id": "chap2_para187",
          "next_para_id": "chap2_para189",
          "style_metadata": {
            "para_id": "chap2_para188",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "bibliographical": 2,
            "historical": 2,
            "note": 2,
            "central": 1,
            "role": 1,
            "action": 1,
            "intelligence—the": 1,
            "notion": 1,
            "practical": 1,
            "reasoning—goes": 1,
            "least": 1,
            "aristotle": 1,
            "nicomachean": 1,
            "ethic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para188",
              "entity_text": "Aristotle’s\nNicomachean Ethics",
              "entity_type": "ORG",
              "start_char": 180,
              "end_char": 210,
              "context": " practical reasoning—goes back at least as far as Aristotle’s\nNicomachean Ethics."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para189",
          "content": "Practical reasoning was also the subject of McCarthy’s influential paper “Programs with Common Sense” (1958). The fields of robotics and control theory are, by their very nature, concerned principally with physical agents. The\nconcept of a\ncontroller\nin control theory is identical to that of an agent in AI. Perhaps surprisingly, AI has concentrated for most of its history on isolated components of agents—question-answering systems, theorem-provers, vision systems, and so on—rather than on whole agents. The discussion of agents in the text by Genesereth and Nilsson (1987) was an influential exception. The whole-agent view is now widely accepted and is a central theme in recent texts (Padgham and Winikoff, 2004; Jones, 2007; Poole and Mackworth, 2017).",
          "sentence_count": 6,
          "char_count": 648,
          "prev_para_id": "chap2_para188",
          "next_para_id": "chap2_para190",
          "style_metadata": {
            "para_id": "chap2_para189",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 143,
            "sentence_count": 6
          },
          "terminology": {
            "practical": 1,
            "reasoning": 1,
            "subject": 1,
            "mccarthy": 1,
            "influential": 2,
            "paper": 1,
            "program": 1,
            "common": 1,
            "sense": 1,
            "field": 1,
            "robotics": 1,
            "control": 2,
            "theory": 2,
            "nature": 1,
            "concerned": 1,
            "physical": 1,
            "agent": 4,
            "concept": 1,
            "controller": 1,
            "identical": 1,
            "concentrated": 1,
            "history": 1,
            "isolated": 1,
            "component": 1,
            "agents—question-answering": 1,
            "system": 2,
            "theorem-provers": 1,
            "vision": 1,
            "whole": 1,
            "discussion": 1,
            "text": 2,
            "genesereth": 1,
            "nilsson": 1,
            "exception": 1,
            "whole-agent": 1,
            "view": 1,
            "accepted": 1,
            "central": 1,
            "theme": 1,
            "recent": 1,
            "padgham": 1,
            "winikoff": 1,
            "jones": 1,
            "poole": 1,
            "mackworth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para189",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 44,
              "end_char": 52,
              "context": "Practical reasoning was also the subject of McCarthy’s influential paper “Programs with Common Sense” "
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Programs with Common Sense",
              "entity_type": "WORK_OF_ART",
              "start_char": 74,
              "end_char": 100,
              "context": "also the subject of McCarthy’s influential paper “Programs with Common Sense” (1958). The fields of robotics and control theor"
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 305,
              "end_char": 307,
              "context": "ontrol theory is identical to that of an agent in AI. Perhaps surprisingly, AI has concentrated for mo"
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "AI",
              "entity_type": "ORG",
              "start_char": 331,
              "end_char": 333,
              "context": " to that of an agent in AI. Perhaps surprisingly, AI has concentrated for most of its history on isola"
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Genesereth",
              "entity_type": "PERSON",
              "start_char": 548,
              "end_char": 558,
              "context": "e agents. The discussion of agents in the text by Genesereth and Nilsson (1987) was an influential exception. "
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 563,
              "end_char": 570,
              "context": "iscussion of agents in the text by Genesereth and Nilsson (1987) was an influential exception. The whole-ag"
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Padgham",
              "entity_type": "PERSON",
              "start_char": 692,
              "end_char": 699,
              "context": " accepted and is a central theme in recent texts (Padgham and Winikoff, 2004; Jones, 2007; Poole and Mackwo"
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Winikoff",
              "entity_type": "PERSON",
              "start_char": 704,
              "end_char": 712,
              "context": "d is a central theme in recent texts (Padgham and Winikoff, 2004; Jones, 2007; Poole and Mackworth, 2017)."
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Jones",
              "entity_type": "GPE",
              "start_char": 720,
              "end_char": 725,
              "context": "heme in recent texts (Padgham and Winikoff, 2004; Jones, 2007; Poole and Mackworth, 2017)."
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Poole",
              "entity_type": "PRODUCT",
              "start_char": 733,
              "end_char": 738,
              "context": "t texts (Padgham and Winikoff, 2004; Jones, 2007; Poole and Mackworth, 2017)."
            },
            {
              "para_id": "chap2_para189",
              "entity_text": "Mackworth",
              "entity_type": "PERSON",
              "start_char": 743,
              "end_char": 752,
              "context": "adgham and Winikoff, 2004; Jones, 2007; Poole and Mackworth, 2017)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para190",
          "content": "Chapter 1\ntraced the roots of the concept of rationality in philosophy and economics. In AI, the concept was of peripheral interest until the mid-1980s, when it began to suffuse many discussions about the proper technical foundations of the field. A paper by Jon Doyle (1983) predicted that rational agent design would come to be seen as the core mission of AI, while other popular topics would spin off to form new disciplines.",
          "sentence_count": 3,
          "char_count": 357,
          "prev_para_id": "chap2_para189",
          "next_para_id": "chap2_para191",
          "style_metadata": {
            "para_id": "chap2_para190",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 3
          },
          "terminology": {
            "chapter": 1,
            "traced": 1,
            "root": 1,
            "concept": 2,
            "rationality": 1,
            "philosophy": 1,
            "economics": 1,
            "peripheral": 1,
            "interest": 1,
            "mid-1980s": 1,
            "began": 1,
            "many": 1,
            "discussion": 1,
            "proper": 1,
            "technical": 1,
            "foundation": 1,
            "field": 1,
            "paper": 1,
            "jon": 1,
            "doyle": 1,
            "predicted": 1,
            "rational": 1,
            "agent": 1,
            "design": 1,
            "come": 1,
            "seen": 1,
            "core": 1,
            "mission": 1,
            "popular": 1,
            "topic": 1,
            "spin": 1,
            "form": 1,
            "new": 1,
            "discipline": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para190",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 89,
              "end_char": 91,
              "context": "pt of rationality in philosophy and economics. In AI, the concept was of peripheral interest until the"
            },
            {
              "para_id": "chap2_para190",
              "entity_text": "Jon Doyle",
              "entity_type": "PERSON",
              "start_char": 259,
              "end_char": 268,
              "context": "er technical foundations of the field. A paper by Jon Doyle (1983) predicted that rational agent design would"
            },
            {
              "para_id": "chap2_para190",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 358,
              "end_char": 360,
              "context": "sign would come to be seen as the core mission of AI, while other popular topics would spin off to for"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para191",
          "content": "Careful attention to the properties of the environment and their consequences for rational agent design is most apparent in the control theory tradition—for example, classical control systems (Dorf and Bishop, 2004; Kirk, 2004) handle fully observable, deterministic environments; stochastic optimal control (Kumar and Varaiya, 1986; Bertsekas and Shreve, 2007) handles partially observable, stochastic environments; and hybrid control (Henzinger and Sastry, 1998; Cassandras and Lygeros, 2006) deals with environments containing both discrete and continuous elements. The distinction between fully and partially observable environments is also central in the\ndynamic programming\nliterature developed in the field of operations research (Puterman, 1994), which we discuss in\nChapter 16\n.",
          "sentence_count": 2,
          "char_count": 686,
          "prev_para_id": "chap2_para190",
          "next_para_id": "chap2_para192",
          "style_metadata": {
            "para_id": "chap2_para191",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 65.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 131,
            "sentence_count": 2
          },
          "terminology": {
            "careful": 1,
            "attention": 1,
            "property": 1,
            "environment": 5,
            "consequence": 1,
            "rational": 1,
            "agent": 1,
            "design": 1,
            "apparent": 1,
            "control": 4,
            "theory": 1,
            "tradition—for": 1,
            "example": 1,
            "classical": 1,
            "system": 1,
            "dorf": 1,
            "bishop": 1,
            "kirk": 1,
            "handle": 2,
            "observable": 3,
            "deterministic": 1,
            "stochastic": 2,
            "optimal": 1,
            "kumar": 1,
            "varaiya": 1,
            "bertsekas": 1,
            "shreve": 1,
            "hybrid": 1,
            "henzinger": 1,
            "sastry": 1,
            "cassandra": 1,
            "lygeros": 1,
            "deal": 1,
            "containing": 1,
            "discrete": 1,
            "continuous": 1,
            "element": 1,
            "distinction": 1,
            "central": 1,
            "dynamic": 1,
            "programming": 1,
            "literature": 1,
            "developed": 1,
            "field": 1,
            "operation": 1,
            "research": 1,
            "puterman": 1,
            "discus": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para191",
              "entity_text": "Dorf",
              "entity_type": "ORG",
              "start_char": 193,
              "end_char": 197,
              "context": "tradition—for example, classical control systems (Dorf and Bishop, 2004; Kirk, 2004) handle fully observ"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Bishop",
              "entity_type": "ORG",
              "start_char": 202,
              "end_char": 208,
              "context": "—for example, classical control systems (Dorf and Bishop, 2004; Kirk, 2004) handle fully observable, deter"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Kirk",
              "entity_type": "GPE",
              "start_char": 216,
              "end_char": 220,
              "context": "classical control systems (Dorf and Bishop, 2004; Kirk, 2004) handle fully observable, deterministic env"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Kumar",
              "entity_type": "GPE",
              "start_char": 309,
              "end_char": 314,
              "context": "inistic environments; stochastic optimal control (Kumar and Varaiya, 1986; Bertsekas and Shreve, 2007) ha"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Varaiya",
              "entity_type": "GPE",
              "start_char": 319,
              "end_char": 326,
              "context": "vironments; stochastic optimal control (Kumar and Varaiya, 1986; Bertsekas and Shreve, 2007) handles partia"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Bertsekas",
              "entity_type": "GPE",
              "start_char": 334,
              "end_char": 343,
              "context": "chastic optimal control (Kumar and Varaiya, 1986; Bertsekas and Shreve, 2007) handles partially observable, s"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Henzinger and Sastry",
              "entity_type": "ORG",
              "start_char": 437,
              "end_char": 457,
              "context": "ble, stochastic environments; and hybrid control (Henzinger and Sastry, 1998; Cassandras and Lygeros, 2006) deals with e"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Cassandras",
              "entity_type": "PERSON",
              "start_char": 465,
              "end_char": 475,
              "context": "; and hybrid control (Henzinger and Sastry, 1998; Cassandras and Lygeros, 2006) deals with environments contai"
            },
            {
              "para_id": "chap2_para191",
              "entity_text": "Lygeros",
              "entity_type": "GPE",
              "start_char": 480,
              "end_char": 487,
              "context": "ntrol (Henzinger and Sastry, 1998; Cassandras and Lygeros, 2006) deals with environments containing both di"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para192",
          "content": "Although simple reflex agents were central to behaviorist psychology (see\nChapter 1\n), most AI researchers view them as too simple to provide much leverage. (Rosenschein (1985) and Brooks (1986) questioned this assumption; see\nChapter 26\n.) A great deal of work has gone into finding efficient algorithms for keeping track of complex environments (Bar-Shalom\net al.,\n2001; Choset\net al.,\n2005; Simon, 2006), most of it in the probabilistic setting.",
          "sentence_count": 3,
          "char_count": 386,
          "prev_para_id": "chap2_para191",
          "next_para_id": "chap2_para193",
          "style_metadata": {
            "para_id": "chap2_para192",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 90,
            "sentence_count": 3
          },
          "terminology": {
            "simple": 2,
            "reflex": 1,
            "agent": 1,
            "central": 1,
            "behaviorist": 1,
            "psychology": 1,
            "see": 2,
            "chapter": 2,
            "researcher": 1,
            "view": 1,
            "provide": 1,
            "much": 1,
            "leverage": 1,
            "rosenschein": 1,
            "brook": 1,
            "questioned": 1,
            "assumption": 1,
            "great": 1,
            "deal": 1,
            "work": 1,
            "gone": 1,
            "finding": 1,
            "efficient": 1,
            "algorithm": 1,
            "keeping": 1,
            "track": 1,
            "complex": 1,
            "environment": 1,
            "bar-shalom": 1,
            "al.": 2,
            "choset": 1,
            "simon": 1,
            "probabilistic": 1,
            "setting": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para192",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 92,
              "end_char": 94,
              "context": " to behaviorist psychology (see\nChapter 1\n), most AI researchers view them as too simple to provide mu"
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "Rosenschein",
              "entity_type": "PERSON",
              "start_char": 158,
              "end_char": 169,
              "context": "iew them as too simple to provide much leverage. (Rosenschein (1985) and Brooks (1986) questioned this assumpti"
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "Brooks",
              "entity_type": "ORG",
              "start_char": 181,
              "end_char": 187,
              "context": "to provide much leverage. (Rosenschein (1985) and Brooks (1986) questioned this assumption; see\nChapter 26"
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "Bar-Shalom",
              "entity_type": "ORG",
              "start_char": 348,
              "end_char": 358,
              "context": "rithms for keeping track of complex environments (Bar-Shalom\net al.,\n2001; Choset\net al.,\n2005; Simon, 2006), "
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 362,
              "end_char": 365,
              "context": "ping track of complex environments (Bar-Shalom\net al.,\n2001; Choset\net al.,\n2005; Simon, 2006), most of"
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "Choset",
              "entity_type": "PRODUCT",
              "start_char": 373,
              "end_char": 379,
              "context": "of complex environments (Bar-Shalom\net al.,\n2001; Choset\net al.,\n2005; Simon, 2006), most of it in the pro"
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 383,
              "end_char": 386,
              "context": " environments (Bar-Shalom\net al.,\n2001; Choset\net al.,\n2005; Simon, 2006), most of it in the probabilis"
            },
            {
              "para_id": "chap2_para192",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 394,
              "end_char": 399,
              "context": "ts (Bar-Shalom\net al.,\n2001; Choset\net al.,\n2005; Simon, 2006), most of it in the probabilistic setting."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para193",
          "content": "Goal-based agents are presupposed in everything from Aristotle’s view of practical reasoning to McCarthy’s early papers on logical AI. Shakey the Robot (Fikes and Nilsson, 1971; Nilsson, 1984) was the first robotic embodiment of a logical, goal-based agent. A full logical analysis of goal-based agents appeared in Genesereth and Nilsson (1987), and a goal-based programming methodology called agent-oriented programming was developed by Shoham (1993). The agent-based approach is now extremely popular in software engineering (Ciancarini and Wooldridge, 2001). It has also infiltrated the area of operating systems, where\nautonomic computing\nrefers to computer systems and networks that monitor and control themselves with a perceive–act loop and machine learning methods (Kephart and Chess, 2003). Noting that a collection of agent programs designed to work well together in a true multiagent environment necessarily exhibits modularity—the programs share no internal state and communicate with each other only through the environment—it is common within the field of\nmultiagent systems\nto design the agent program of a single agent as a collection of autonomous sub-agents. In some cases, one can even prove that the resulting system gives the same optimal solutions as a monolithic design.",
          "sentence_count": 7,
          "char_count": 1108,
          "prev_para_id": "chap2_para192",
          "next_para_id": "chap2_para194",
          "style_metadata": {
            "para_id": "chap2_para193",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.43,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 220,
            "sentence_count": 7
          },
          "terminology": {
            "goal-based": 4,
            "agent": 6,
            "presupposed": 1,
            "everything": 1,
            "view": 1,
            "practical": 1,
            "reasoning": 1,
            "mccarthy": 1,
            "early": 1,
            "paper": 1,
            "logical": 3,
            "shakey": 1,
            "robot": 1,
            "fikes": 1,
            "nilsson": 3,
            "first": 1,
            "robotic": 1,
            "embodiment": 1,
            "full": 1,
            "analysis": 1,
            "appeared": 1,
            "genesereth": 1,
            "programming": 2,
            "methodology": 1,
            "called": 1,
            "agent-oriented": 1,
            "developed": 1,
            "shoham": 1,
            "agent-based": 1,
            "approach": 1,
            "popular": 1,
            "software": 1,
            "engineering": 1,
            "ciancarini": 1,
            "wooldridge": 1,
            "infiltrated": 1,
            "area": 1,
            "operating": 1,
            "system": 4,
            "autonomic": 1,
            "computing": 1,
            "refers": 1,
            "computer": 1,
            "network": 1,
            "monitor": 1,
            "control": 1,
            "perceive–act": 1,
            "machine": 1,
            "learning": 1,
            "method": 1,
            "kephart": 1,
            "chess": 1,
            "noting": 1,
            "collection": 2,
            "program": 3,
            "designed": 1,
            "work": 1,
            "true": 1,
            "multiagent": 2,
            "environment": 1,
            "exhibit": 1,
            "modularity—the": 1,
            "share": 1,
            "internal": 1,
            "state": 1,
            "communicate": 1,
            "environment—it": 1,
            "common": 1,
            "field": 1,
            "design": 2,
            "single": 1,
            "autonomous": 1,
            "sub-agents": 1,
            "case": 1,
            "prove": 1,
            "resulting": 1,
            "give": 1,
            "optimal": 1,
            "solution": 1,
            "monolithic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para193",
              "entity_text": "Aristotle",
              "entity_type": "ORG",
              "start_char": 53,
              "end_char": 62,
              "context": "l-based agents are presupposed in everything from Aristotle’s view of practical reasoning to McCarthy’s early"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "McCarthy",
              "entity_type": "PERSON",
              "start_char": 96,
              "end_char": 104,
              "context": "g from Aristotle’s view of practical reasoning to McCarthy’s early papers on logical AI. Shakey the Robot (F"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 163,
              "end_char": 170,
              "context": "papers on logical AI. Shakey the Robot (Fikes and Nilsson, 1971; Nilsson, 1984) was the first robotic embod"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 178,
              "end_char": 185,
              "context": "al AI. Shakey the Robot (Fikes and Nilsson, 1971; Nilsson, 1984) was the first robotic embodiment of a logi"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Genesereth",
              "entity_type": "PERSON",
              "start_char": 315,
              "end_char": 325,
              "context": "logical analysis of goal-based agents appeared in Genesereth and Nilsson (1987), and a goal-based programming "
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 330,
              "end_char": 337,
              "context": "s of goal-based agents appeared in Genesereth and Nilsson (1987), and a goal-based programming methodology "
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Shoham",
              "entity_type": "PERSON",
              "start_char": 438,
              "end_char": 444,
              "context": "alled agent-oriented programming was developed by Shoham (1993). The agent-based approach is now extremely"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Ciancarini and Wooldridge",
              "entity_type": "ORG",
              "start_char": 528,
              "end_char": 553,
              "context": "is now extremely popular in software engineering (Ciancarini and Wooldridge, 2001). It has also infiltrated the area of opera"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Kephart",
              "entity_type": "ORG",
              "start_char": 774,
              "end_char": 781,
              "context": "a perceive–act loop and machine learning methods (Kephart and Chess, 2003). Noting that a collection of age"
            },
            {
              "para_id": "chap2_para193",
              "entity_text": "Chess",
              "entity_type": "ORG",
              "start_char": 786,
              "end_char": 791,
              "context": "ct loop and machine learning methods (Kephart and Chess, 2003). Noting that a collection of agent program"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para194",
          "content": "The goal-based view of agents also dominates the cognitive psychology tradition in the area of problem solving, beginning with the enormously influential\nHuman Problem Solving\n(Newell and Simon, 1972) and running through all of Newell’s later work (Newell, 1990). Goals, further analyzed as\ndesires\n(general) and\nintentions\n(currently pursued), are central to the influential theory of agents developed by Michael Bratman (1987).",
          "sentence_count": 2,
          "char_count": 374,
          "prev_para_id": "chap2_para193",
          "next_para_id": "chap2_para195",
          "style_metadata": {
            "para_id": "chap2_para194",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 2
          },
          "terminology": {
            "goal-based": 1,
            "view": 1,
            "agent": 2,
            "dominates": 1,
            "cognitive": 1,
            "psychology": 1,
            "tradition": 1,
            "area": 1,
            "problem": 2,
            "solving": 2,
            "beginning": 1,
            "influential": 2,
            "human": 1,
            "simon": 1,
            "running": 1,
            "work": 1,
            "newell": 1,
            "goal": 1,
            "analyzed": 1,
            "desire": 1,
            "general": 1,
            "intention": 1,
            "pursued": 1,
            "central": 1,
            "theory": 1,
            "developed": 1,
            "michael": 1,
            "bratman": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para194",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 177,
              "end_char": 183,
              "context": "the enormously influential\nHuman Problem Solving\n(Newell and Simon, 1972) and running through all of Newel"
            },
            {
              "para_id": "chap2_para194",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 188,
              "end_char": 193,
              "context": "sly influential\nHuman Problem Solving\n(Newell and Simon, 1972) and running through all of Newell’s later "
            },
            {
              "para_id": "chap2_para194",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 228,
              "end_char": 234,
              "context": "ewell and Simon, 1972) and running through all of Newell’s later work (Newell, 1990). Goals, further analy"
            },
            {
              "para_id": "chap2_para194",
              "entity_text": "Newell",
              "entity_type": "ORG",
              "start_char": 249,
              "end_char": 255,
              "context": ") and running through all of Newell’s later work (Newell, 1990). Goals, further analyzed as\ndesires\n(gener"
            },
            {
              "para_id": "chap2_para194",
              "entity_text": "Michael Bratman",
              "entity_type": "PERSON",
              "start_char": 406,
              "end_char": 421,
              "context": " to the influential theory of agents developed by Michael Bratman (1987)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para195",
          "content": "As noted in\nChapter 1\n, the development of utility theory as a basis for rational behavior goes back hundreds of years. In AI, early research eschewed utilities in favor of goals, with some exceptions (Feldman and Sproull, 1977). The resurgence of interest in probabilistic methods in the 1980s led to the acceptance of maximization of expected utility as the most general framework for decision making (Horvitz\net al.,\n1988). The text by Pearl (1988) was the first in AI to cover probability and utility theory in depth; its exposition of practical methods for reasoning and decision making under uncertainty was probably the single biggest factor in the rapid shift towards utility-based agents in the 1990s (see\nChapter 15\n). The formalization of reinforcement learning within a decision-theoretic framework also contributed to this shift (Sutton, 1988). Somewhat remarkably, almost all AI research until very recently has assumed that the performance measure can be exactly and correctly specified in the form of a utility function or reward function (Hadfield-Menell\net al.,\n2017a; Russell, 2019).",
          "sentence_count": 6,
          "char_count": 938,
          "prev_para_id": "chap2_para194",
          "next_para_id": "chap2_para196",
          "style_metadata": {
            "para_id": "chap2_para195",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 200,
            "sentence_count": 6
          },
          "terminology": {
            "noted": 1,
            "chapter": 2,
            "development": 1,
            "utility": 5,
            "theory": 2,
            "basis": 1,
            "rational": 1,
            "behavior": 1,
            "go": 1,
            "hundred": 1,
            "year": 1,
            "research": 2,
            "eschewed": 1,
            "favor": 1,
            "goal": 1,
            "exception": 1,
            "feldman": 1,
            "sproull": 1,
            "resurgence": 1,
            "interest": 1,
            "probabilistic": 1,
            "method": 2,
            "led": 1,
            "acceptance": 1,
            "maximization": 1,
            "expected": 1,
            "general": 1,
            "framework": 2,
            "decision": 2,
            "making": 2,
            "horvitz": 1,
            "al.": 2,
            "text": 1,
            "pearl": 1,
            "cover": 1,
            "probability": 1,
            "depth": 1,
            "exposition": 1,
            "practical": 1,
            "reasoning": 1,
            "uncertainty": 1,
            "single": 1,
            "biggest": 1,
            "factor": 1,
            "rapid": 1,
            "shift": 2,
            "towards": 1,
            "utility-based": 1,
            "agent": 1,
            "see": 1,
            "formalization": 1,
            "reinforcement": 1,
            "learning": 1,
            "decision-theoretic": 1,
            "contributed": 1,
            "sutton": 1,
            "remarkably": 1,
            "assumed": 1,
            "performance": 1,
            "measure": 1,
            "specified": 1,
            "form": 1,
            "function": 2,
            "reward": 1,
            "hadfield-menell": 1,
            "russell": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para195",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 123,
              "end_char": 125,
              "context": "rational behavior goes back hundreds of years. In AI, early research eschewed utilities in favor of go"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Feldman",
              "entity_type": "PERSON",
              "start_char": 202,
              "end_char": 209,
              "context": "tilities in favor of goals, with some exceptions (Feldman and Sproull, 1977). The resurgence of interest in"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Sproull",
              "entity_type": "PERSON",
              "start_char": 214,
              "end_char": 221,
              "context": "favor of goals, with some exceptions (Feldman and Sproull, 1977). The resurgence of interest in probabilist"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Horvitz",
              "entity_type": "ORG",
              "start_char": 404,
              "end_char": 411,
              "context": "s the most general framework for decision making (Horvitz\net al.,\n1988). The text by Pearl (1988) was the f"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 415,
              "end_char": 418,
              "context": "general framework for decision making (Horvitz\net al.,\n1988). The text by Pearl (1988) was the first in"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 439,
              "end_char": 444,
              "context": "cision making (Horvitz\net al.,\n1988). The text by Pearl (1988) was the first in AI to cover probability a"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 469,
              "end_char": 471,
              "context": "\n1988). The text by Pearl (1988) was the first in AI to cover probability and utility theory in depth;"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Sutton",
              "entity_type": "GPE",
              "start_char": 843,
              "end_char": 849,
              "context": "eoretic framework also contributed to this shift (Sutton, 1988). Somewhat remarkably, almost all AI resear"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 890,
              "end_char": 892,
              "context": "t (Sutton, 1988). Somewhat remarkably, almost all AI research until very recently has assumed that the"
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Hadfield-Menell",
              "entity_type": "ORG",
              "start_char": 1056,
              "end_char": 1071,
              "context": "he form of a utility function or reward function (Hadfield-Menell\net al.,\n2017a; Russell, 2019)."
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 1075,
              "end_char": 1078,
              "context": "y function or reward function (Hadfield-Menell\net al.,\n2017a; Russell, 2019)."
            },
            {
              "para_id": "chap2_para195",
              "entity_text": "Russell",
              "entity_type": "PERSON",
              "start_char": 1087,
              "end_char": 1094,
              "context": "r reward function (Hadfield-Menell\net al.,\n2017a; Russell, 2019)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para196",
          "content": "The general design for learning agents portrayed in\nFigure 2.15\nis classic in the machine learning literature (Buchanan\net al.,\n1978; Mitchell, 1997). Examples of the design, as embodied in programs, go back at least as far as Arthur Samuel’s (1959, 1967) learning program for playing checkers. Learning agents are discussed in depth in\nChapters 19\n,\n21\n,\n22\n, and\n23\n.",
          "sentence_count": 3,
          "char_count": 318,
          "prev_para_id": "chap2_para195",
          "next_para_id": "chap2_para197",
          "style_metadata": {
            "para_id": "chap2_para196",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "general": 1,
            "design": 2,
            "learning": 4,
            "agent": 2,
            "portrayed": 1,
            "figure": 1,
            "classic": 1,
            "machine": 1,
            "literature": 1,
            "buchanan": 1,
            "al.": 1,
            "mitchell": 1,
            "example": 1,
            "embodied": 1,
            "program": 2,
            "least": 1,
            "arthur": 1,
            "samuel": 1,
            "playing": 1,
            "checker": 1,
            "discussed": 1,
            "depth": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para196",
              "entity_text": "Buchanan",
              "entity_type": "PERSON",
              "start_char": 111,
              "end_char": 119,
              "context": "15\nis classic in the machine learning literature (Buchanan\net al.,\n1978; Mitchell, 1997). Examples of the de"
            },
            {
              "para_id": "chap2_para196",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 123,
              "end_char": 126,
              "context": "c in the machine learning literature (Buchanan\net al.,\n1978; Mitchell, 1997). Examples of the design, a"
            },
            {
              "para_id": "chap2_para196",
              "entity_text": "Mitchell",
              "entity_type": "PERSON",
              "start_char": 134,
              "end_char": 142,
              "context": "chine learning literature (Buchanan\net al.,\n1978; Mitchell, 1997). Examples of the design, as embodied in pr"
            },
            {
              "para_id": "chap2_para196",
              "entity_text": "Arthur Samuel’s",
              "entity_type": "PERSON",
              "start_char": 227,
              "end_char": 242,
              "context": " embodied in programs, go back at least as far as Arthur Samuel’s (1959, 1967) learning program for playing checker"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para197",
          "content": "Some early papers on agent-based approaches are collected by Huhns and Singh (1998) and Wooldridge and Rao (1999). Texts on multiagent systems provide a good introduction to many aspects of agent design (Weiss, 2000a; Wooldridge, 2009). Several conference series devoted to agents began in the 1990s, including the International Workshop on Agent Theories, Architectures, and Languages (ATAL), the International Conference on Autonomous Agents (AGENTS), and the International Conference on Multi-Agent Systems (ICMAS). In 2002, these three merged to form the International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS). From 2000 to 2012 there were annual workshops on Agent-Oriented Software Engineering (AOSE). The journal\nAutonomous Agents and Multi-Agent Systems\nwas founded in 1998. Finally,\nDung Beetle Ecology\n(Hanski and Cambefort, 1991) provides a wealth of interesting information on the behavior of dung beetles. YouTube has inspiring video recordings of their activities.",
          "sentence_count": 8,
          "char_count": 870,
          "prev_para_id": "chap2_para196",
          "next_para_id": "chap2_para198",
          "style_metadata": {
            "para_id": "chap2_para197",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.25,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 178,
            "sentence_count": 8
          },
          "terminology": {
            "early": 1,
            "paper": 1,
            "agent-based": 1,
            "approach": 1,
            "collected": 1,
            "huhns": 1,
            "singh": 1,
            "wooldridge": 2,
            "rao": 1,
            "text": 1,
            "multiagent": 1,
            "system": 4,
            "provide": 1,
            "good": 1,
            "introduction": 1,
            "many": 1,
            "aspect": 1,
            "agent": 7,
            "design": 1,
            "weiss": 1,
            "several": 1,
            "conference": 4,
            "series": 1,
            "devoted": 1,
            "began": 1,
            "including": 1,
            "international": 4,
            "workshop": 2,
            "theory": 1,
            "architecture": 1,
            "language": 1,
            "atal": 1,
            "autonomous": 3,
            "multi-agent": 3,
            "icmas": 1,
            "merged": 1,
            "form": 1,
            "joint": 1,
            "aamas": 1,
            "annual": 1,
            "agent-oriented": 1,
            "software": 1,
            "engineering": 1,
            "aose": 1,
            "journal": 1,
            "founded": 1,
            "dung": 2,
            "beetle": 2,
            "ecology": 1,
            "hanski": 1,
            "cambefort": 1,
            "provides": 1,
            "interesting": 1,
            "information": 1,
            "behavior": 1,
            "youtube": 1,
            "inspiring": 1,
            "video": 1,
            "recording": 1,
            "activity": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para197",
              "entity_text": "Huhns",
              "entity_type": "ORG",
              "start_char": 61,
              "end_char": 66,
              "context": "papers on agent-based approaches are collected by Huhns and Singh (1998) and Wooldridge and Rao (1999). T"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Singh",
              "entity_type": "GPE",
              "start_char": 71,
              "end_char": 76,
              "context": "agent-based approaches are collected by Huhns and Singh (1998) and Wooldridge and Rao (1999). Texts on mu"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Wooldridge",
              "entity_type": "ORG",
              "start_char": 88,
              "end_char": 98,
              "context": "aches are collected by Huhns and Singh (1998) and Wooldridge and Rao (1999). Texts on multiagent systems provi"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Rao",
              "entity_type": "PERSON",
              "start_char": 103,
              "end_char": 106,
              "context": "cted by Huhns and Singh (1998) and Wooldridge and Rao (1999). Texts on multiagent systems provide a goo"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Weiss",
              "entity_type": "ORG",
              "start_char": 204,
              "end_char": 209,
              "context": "ood introduction to many aspects of agent design (Weiss, 2000a; Wooldridge, 2009). Several conference ser"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Wooldridge",
              "entity_type": "ORG",
              "start_char": 218,
              "end_char": 228,
              "context": "on to many aspects of agent design (Weiss, 2000a; Wooldridge, 2009). Several conference series devoted to agen"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "the International Workshop on Agent Theories",
              "entity_type": "ORG",
              "start_char": 311,
              "end_char": 355,
              "context": "s devoted to agents began in the 1990s, including the International Workshop on Agent Theories, Architectures, and Languages (ATAL), the Interna"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "the International Conference on Autonomous Agents",
              "entity_type": "ORG",
              "start_char": 394,
              "end_char": 443,
              "context": "nt Theories, Architectures, and Languages (ATAL), the International Conference on Autonomous Agents (AGENTS), and the International Conference on Mul"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "the International Conference on Multi-Agent Systems",
              "entity_type": "ORG",
              "start_char": 458,
              "end_char": 509,
              "context": "nal Conference on Autonomous Agents (AGENTS), and the International Conference on Multi-Agent Systems (ICMAS). In 2002, these three merged to form the "
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "the International Joint Conference on Autonomous Agents",
              "entity_type": "ORG",
              "start_char": 555,
              "end_char": 610,
              "context": "tems (ICMAS). In 2002, these three merged to form the International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS). From 2000 to 201"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "AOSE",
              "entity_type": "ORG",
              "start_char": 730,
              "end_char": 734,
              "context": "workshops on Agent-Oriented Software Engineering (AOSE). The journal\nAutonomous Agents and Multi-Agent S"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Autonomous Agents",
              "entity_type": "ORG",
              "start_char": 749,
              "end_char": 766,
              "context": "Oriented Software Engineering (AOSE). The journal\nAutonomous Agents and Multi-Agent Systems\nwas founded in 1998. Fina"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Dung Beetle Ecology",
              "entity_type": "PERSON",
              "start_char": 821,
              "end_char": 840,
              "context": "Multi-Agent Systems\nwas founded in 1998. Finally,\nDung Beetle Ecology\n(Hanski and Cambefort, 1991) provides a wealth of"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "Hanski and Cambefort",
              "entity_type": "PERSON",
              "start_char": 842,
              "end_char": 862,
              "context": "as founded in 1998. Finally,\nDung Beetle Ecology\n(Hanski and Cambefort, 1991) provides a wealth of interesting informati"
            },
            {
              "para_id": "chap2_para197",
              "entity_text": "YouTube",
              "entity_type": "ORG",
              "start_char": 948,
              "end_char": 955,
              "context": "ting information on the behavior of dung beetles. YouTube has inspiring video recordings of their activitie"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para198",
          "content": "1\nIf the agent uses some randomization to choose its actions, then we would have to try each sequence many times to identify the probability of each action. One might imagine that acting randomly is rather silly, but we show later in this chapter that it can be very intelligent.",
          "sentence_count": 2,
          "char_count": 231,
          "prev_para_id": "chap2_para197",
          "next_para_id": "chap2_para199",
          "style_metadata": {
            "para_id": "chap2_para198",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 2
          },
          "terminology": {
            "agent": 1,
            "us": 1,
            "randomization": 1,
            "choose": 1,
            "action": 2,
            "try": 1,
            "sequence": 1,
            "many": 1,
            "time": 1,
            "identify": 1,
            "probability": 1,
            "imagine": 1,
            "acting": 1,
            "show": 1,
            "chapter": 1,
            "intelligent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para199",
          "content": "2\nIn a real robot, it would be unlikely to have an actions like “move right” and “move left.” Instead the actions would be “spin wheels forward” and “spin wheels backward.” We have chosen the actions to be easier to follow on the page, not for ease of implementation in an actual robot.",
          "sentence_count": 1,
          "char_count": 235,
          "prev_para_id": "chap2_para198",
          "next_para_id": "chap2_para200",
          "style_metadata": {
            "para_id": "chap2_para199",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 64.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 1
          },
          "terminology": {
            "real": 1,
            "robot": 2,
            "unlikely": 1,
            "action": 3,
            "move": 2,
            "left.": 1,
            "spin": 2,
            "wheel": 2,
            "backward.": 1,
            "chosen": 1,
            "follow": 1,
            "page": 1,
            "ease": 1,
            "implementation": 1,
            "actual": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para200",
          "content": "3\nSee N. Henderson, “New door latches urged for Boeing 747 jumbo jets,”\nWashington Post,\nAugust 24, 1989.",
          "sentence_count": 1,
          "char_count": 91,
          "prev_para_id": "chap2_para199",
          "next_para_id": "chap2_para201",
          "style_metadata": {
            "para_id": "chap2_para200",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "see": 1,
            "henderson": 1,
            "new": 1,
            "door": 1,
            "latch": 1,
            "urged": 1,
            "boeing": 1,
            "jumbo": 1,
            "jet": 1,
            "washington": 1,
            "post": 1,
            "august": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap2_para200",
              "entity_text": "N. Henderson",
              "entity_type": "PERSON",
              "start_char": 6,
              "end_char": 18,
              "context": "3\nSee N. Henderson, “New door latches urged for Boeing 747 jumbo jet"
            },
            {
              "para_id": "chap2_para200",
              "entity_text": "Boeing",
              "entity_type": "ORG",
              "start_char": 48,
              "end_char": 54,
              "context": "3\nSee N. Henderson, “New door latches urged for Boeing 747 jumbo jets,”\nWashington Post,\nAugust 24, 1989"
            },
            {
              "para_id": "chap2_para200",
              "entity_text": "747",
              "entity_type": "PRODUCT",
              "start_char": 55,
              "end_char": 58,
              "context": " N. Henderson, “New door latches urged for Boeing 747 jumbo jets,”\nWashington Post,\nAugust 24, 1989."
            },
            {
              "para_id": "chap2_para200",
              "entity_text": "Washington Post",
              "entity_type": "ORG",
              "start_char": 72,
              "end_char": 87,
              "context": "ew door latches urged for Boeing 747 jumbo jets,”\nWashington Post,\nAugust 24, 1989."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para201",
          "content": "4\nThe word “sequential” is also used in computer science as the antonym of “parallel.” The two meanings are largely unrelated.",
          "sentence_count": 1,
          "char_count": 107,
          "prev_para_id": "chap2_para200",
          "next_para_id": "chap2_para202",
          "style_metadata": {
            "para_id": "chap2_para201",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "word": 1,
            "sequential": 1,
            "used": 1,
            "computer": 1,
            "science": 1,
            "antonym": 1,
            "parallel.": 1,
            "meaning": 1,
            "unrelated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para202",
          "content": "5\nThere are other choices for the agent program skeleton; for example, we could have the agent programs be\ncoroutines\nthat run asynchronously with the environment. Each such coroutine has an input and output port and consists of a loop that reads the input port for percepts and writes actions to the output port.",
          "sentence_count": 2,
          "char_count": 263,
          "prev_para_id": "chap2_para201",
          "next_para_id": "chap2_para203",
          "style_metadata": {
            "para_id": "chap2_para202",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "choice": 1,
            "agent": 2,
            "program": 2,
            "skeleton": 1,
            "example": 1,
            "coroutines": 1,
            "run": 1,
            "environment": 1,
            "coroutine": 1,
            "input": 2,
            "output": 2,
            "port": 2,
            "consists": 1,
            "loop": 1,
            "read": 1,
            "percept": 1,
            "writes": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para203",
          "content": "6\nAlso called\nsituation–action rules\n,\nproductions\n, or\nif–then rules\n.",
          "sentence_count": 1,
          "char_count": 67,
          "prev_para_id": "chap2_para202",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap2_para203",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "called": 1,
            "situation–action": 1,
            "rule": 2,
            "production": 1,
            "if–then": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap2_para204",
          "content": "7\nThe word “utility” here refers to “the quality of being useful,” not to the electric company or waterworks.",
          "sentence_count": 1,
          "char_count": 92,
          "prev_para_id": "chap2_para203",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap2_para204",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "word": 1,
            "utility": 1,
            "refers": 1,
            "quality": 1,
            "useful": 1,
            "electric": 1,
            "company": 1,
            "waterworks": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        }
      ],
      "para_count": 204,
      "char_count": 73487
    },
    {
      "chapter_num": 3,
      "title": "Chapter 3: CHAPTER",
      "paragraphs": [
        {
          "para_id": "chap3_para1",
          "content": "3\nSOLVING PROBLEMS BY SEARCHING\nIn which we see how an agent can look ahead to find a sequence of actions that will eventually achieve its goal.",
          "sentence_count": 1,
          "char_count": 120,
          "prev_para_id": "None",
          "next_para_id": "chap3_para2",
          "style_metadata": {
            "para_id": "chap3_para1",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "solving": 1,
            "problem": 1,
            "searching": 1,
            "see": 1,
            "agent": 1,
            "look": 1,
            "find": 1,
            "sequence": 1,
            "action": 1,
            "achieve": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para2",
          "content": "When the correct action to take is not immediately obvious, an agent may need to\nplan ahead\n: to consider a\nsequence\nof actions that form a path to a goal state. Such an agent is called a\nproblem-solving agent\n, and the computational process it undertakes is called\nsearch\n.",
          "sentence_count": 2,
          "char_count": 232,
          "prev_para_id": "chap3_para1",
          "next_para_id": "chap3_para3",
          "style_metadata": {
            "para_id": "chap3_para2",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.038,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 2
          },
          "terminology": {
            "correct": 1,
            "action": 2,
            "take": 1,
            "obvious": 1,
            "agent": 3,
            "need": 1,
            "plan": 1,
            "consider": 1,
            "sequence": 1,
            "form": 1,
            "path": 1,
            "goal": 1,
            "state": 1,
            "called": 2,
            "problem-solving": 1,
            "computational": 1,
            "process": 1,
            "undertakes": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para3",
          "content": "Problem-solving agents use\natomic\nrepresentations, as described in\nSection 2.4.7\n—that is, states of the world are considered as wholes, with no internal structure visible to the problem-solving algorithms. Agents that use\nfactored\nor\nstructured\nrepresentations of states are called\nplanning agents\nand are discussed in\nChapters 7\nand\n11\n.",
          "sentence_count": 2,
          "char_count": 303,
          "prev_para_id": "chap3_para2",
          "next_para_id": "chap3_para4",
          "style_metadata": {
            "para_id": "chap3_para3",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 2
          },
          "terminology": {
            "problem-solving": 2,
            "agent": 3,
            "use": 2,
            "atomic": 1,
            "representation": 2,
            "described": 1,
            "section": 1,
            "state": 2,
            "world": 1,
            "considered": 1,
            "whole": 1,
            "internal": 1,
            "structure": 1,
            "visible": 1,
            "algorithm": 1,
            "factored": 1,
            "structured": 1,
            "called": 1,
            "planning": 1,
            "discussed": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para4",
          "content": "We will cover several search algorithms. In this chapter, we consider only the simplest environments: episodic, single agent, fully observable, deterministic, static, discrete, and known. We distinguish between\ninformed\nalgorithms, in which the agent can estimate how far it is from the goal, and\nuninformed\nalgorithms, where no such estimate is available.",
          "sentence_count": 3,
          "char_count": 309,
          "prev_para_id": "chap3_para3",
          "next_para_id": "chap3_para5",
          "style_metadata": {
            "para_id": "chap3_para4",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 3
          },
          "terminology": {
            "several": 1,
            "search": 1,
            "algorithm": 3,
            "chapter": 1,
            "consider": 1,
            "simplest": 1,
            "environment": 1,
            "episodic": 1,
            "single": 1,
            "agent": 2,
            "observable": 1,
            "deterministic": 1,
            "static": 1,
            "discrete": 1,
            "known": 1,
            "distinguish": 1,
            "informed": 1,
            "estimate": 2,
            "goal": 1,
            "uninformed": 1,
            "available": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para5",
          "content": "Chapter 4\nrelaxes the constraints on environments, and\nChapter 6\nconsiders multiple agents.",
          "sentence_count": 1,
          "char_count": 82,
          "prev_para_id": "chap3_para4",
          "next_para_id": "chap3_para6",
          "style_metadata": {
            "para_id": "chap3_para5",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "chapter": 2,
            "relaxes": 1,
            "constraint": 1,
            "environment": 1,
            "considers": 1,
            "multiple": 1,
            "agent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para6",
          "content": "This chapter uses the concepts of asymptotic complexity (that is,\nO\n(\nn\n) notation). Readers unfamiliar with these concepts should consult\nAppendix A\n.",
          "sentence_count": 2,
          "char_count": 133,
          "prev_para_id": "chap3_para5",
          "next_para_id": "chap3_para7",
          "style_metadata": {
            "para_id": "chap3_para6",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 2
          },
          "terminology": {
            "chapter": 1,
            "us": 1,
            "concept": 2,
            "asymptotic": 1,
            "complexity": 1,
            "notation": 1,
            "reader": 1,
            "unfamiliar": 1,
            "consult": 1,
            "appendix": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para7",
          "content": "3.1Problem-Solving Agents\n3.1\nProblem-Solving Agents\nImagine an agent enjoying a touring vacation in Romania. The agent wants to take in the sights, improve its Romanian, enjoy the nightlife, avoid hangovers, and so on. The decision problem is a complex one. Now, suppose the agent is currently in the city of Arad and has a nonrefundable ticket to fly out of Bucharest the following day. The agent observes street signs and sees that there are three roads leading out of Arad: one toward Sibiu, one to Timisoara, and one to Zerind. None of these are the goal, so unless the agent is familiar with the geography of Romania, it will not know which road to follow.",
          "sentence_count": 6,
          "char_count": 551,
          "prev_para_id": "chap3_para6",
          "next_para_id": "chap3_para8",
          "style_metadata": {
            "para_id": "chap3_para7",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 131,
            "sentence_count": 6
          },
          "terminology": {
            "3.1problem-solving": 1,
            "agent": 7,
            "problem-solving": 1,
            "imagine": 1,
            "enjoying": 1,
            "touring": 1,
            "vacation": 1,
            "romania": 2,
            "want": 1,
            "take": 1,
            "sight": 1,
            "improve": 1,
            "romanian": 1,
            "enjoy": 1,
            "nightlife": 1,
            "avoid": 1,
            "hangover": 1,
            "decision": 1,
            "problem": 1,
            "complex": 1,
            "suppose": 1,
            "city": 1,
            "arad": 2,
            "nonrefundable": 1,
            "ticket": 1,
            "fly": 1,
            "bucharest": 1,
            "following": 1,
            "day": 1,
            "observes": 1,
            "street": 1,
            "sign": 1,
            "see": 1,
            "road": 2,
            "leading": 1,
            "sibiu": 1,
            "timisoara": 1,
            "zerind": 1,
            "none": 1,
            "goal": 1,
            "familiar": 1,
            "geography": 1,
            "know": 1,
            "follow": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para7",
              "entity_text": "Problem-Solving Agents",
              "entity_type": "ORG",
              "start_char": 30,
              "end_char": 52,
              "context": "3.1Problem-Solving Agents\n3.1\nProblem-Solving Agents\nImagine an agent enjoying a touring vacation in R"
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 101,
              "end_char": 108,
              "context": "s\nImagine an agent enjoying a touring vacation in Romania. The agent wants to take in the sights, improve i"
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 310,
              "end_char": 314,
              "context": "ow, suppose the agent is currently in the city of Arad and has a nonrefundable ticket to fly out of Buch"
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 472,
              "end_char": 476,
              "context": "nd sees that there are three roads leading out of Arad: one toward Sibiu, one to Timisoara, and one to Z"
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 489,
              "end_char": 494,
              "context": "e are three roads leading out of Arad: one toward Sibiu, one to Timisoara, and one to Zerind. None of the"
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 503,
              "end_char": 512,
              "context": "ads leading out of Arad: one toward Sibiu, one to Timisoara, and one to Zerind. None of these are the goal, s"
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 525,
              "end_char": 531,
              "context": "d: one toward Sibiu, one to Timisoara, and one to Zerind. None of these are the goal, so unless the agent "
            },
            {
              "para_id": "chap3_para7",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 615,
              "end_char": 622,
              "context": "nless the agent is familiar with the geography of Romania, it will not know which road to follow."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para8",
          "content": "1\nIf the agent has no additional information—that is, if the environment is\nunknown\n—then the agent can do no better than to execute one of the actions at random. This sad situation is discussed in\nChapter 4\n. In this chapter, we will assume our agents always have access to information about the world, such as the map in\nFigure 3.1\n. With that information, the agent can follow this four-phase problem-solving process:\nDescription\nThe road map shows the distance in miles between cities. Neamt to Iasi, 87. Iasi to Valsui, 92. Vaslui to Urziceni, 142. Urziceni to Hirsova, 98. Hirsova to Eforie, 86. Urziceni to Bucharest, 85. Bucharest to Giurgiu, 90. Bucharest to Pitesti, 101. Bucharest to Fagaras, 211. Fagaras to Sibiu, 99. Pitesti to Craiova, 138. Pitesti to Rimnicu Vilcea, 97. Rimnicu Vilcea to Sibiu, 80. Sibiu to Oradea, 151. Sibiu to Arad, 140. Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timisoara, 118. Timisoara to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to Drobeta, 75. Drobeta to Craiova, 120.",
          "sentence_count": 26,
          "char_count": 854,
          "prev_para_id": "chap3_para7",
          "next_para_id": "chap3_para9",
          "style_metadata": {
            "para_id": "chap3_para8",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.88,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 205,
            "sentence_count": 26
          },
          "terminology": {
            "agent": 4,
            "additional": 1,
            "information—that": 1,
            "environment": 1,
            "unknown": 1,
            "—then": 1,
            "execute": 1,
            "action": 1,
            "random": 1,
            "sad": 1,
            "situation": 1,
            "discussed": 1,
            "chapter": 2,
            "assume": 1,
            "access": 1,
            "information": 2,
            "world": 1,
            "map": 2,
            "figure": 1,
            "follow": 1,
            "four-phase": 1,
            "problem-solving": 1,
            "process": 1,
            "description": 1,
            "road": 1,
            "show": 1,
            "distance": 1,
            "mile": 1,
            "city": 1,
            "neamt": 1,
            "iasi": 2,
            "valsui": 1,
            "vaslui": 1,
            "urziceni": 3,
            "hirsova": 2,
            "eforie": 1,
            "bucharest": 3,
            "giurgiu": 1,
            "pitesti": 3,
            "fagaras": 2,
            "sibiu": 4,
            "craiova": 2,
            "rimnicu": 2,
            "vilcea": 2,
            "oradea": 2,
            "arad": 3,
            "zerind": 2,
            "timisoara": 2,
            "lugoj": 2,
            "mehadia": 2,
            "drobeta": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para8",
              "entity_text": "Iasi",
              "entity_type": "GPE",
              "start_char": 499,
              "end_char": 503,
              "context": "ws the distance in miles between cities. Neamt to Iasi, 87. Iasi to Valsui, 92. Vaslui to Urziceni, 142."
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Iasi",
              "entity_type": "GPE",
              "start_char": 509,
              "end_char": 513,
              "context": "tance in miles between cities. Neamt to Iasi, 87. Iasi to Valsui, 92. Vaslui to Urziceni, 142. Urziceni "
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Valsui",
              "entity_type": "ORG",
              "start_char": 517,
              "end_char": 523,
              "context": " miles between cities. Neamt to Iasi, 87. Iasi to Valsui, 92. Vaslui to Urziceni, 142. Urziceni to Hirsova"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Vaslui",
              "entity_type": "PERSON",
              "start_char": 529,
              "end_char": 535,
              "context": "en cities. Neamt to Iasi, 87. Iasi to Valsui, 92. Vaslui to Urziceni, 142. Urziceni to Hirsova, 98. Hirsov"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Hirsova",
              "entity_type": "ORG",
              "start_char": 566,
              "end_char": 573,
              "context": " Valsui, 92. Vaslui to Urziceni, 142. Urziceni to Hirsova, 98. Hirsova to Eforie, 86. Urziceni to Bucharest"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Hirsova",
              "entity_type": "ORG",
              "start_char": 579,
              "end_char": 586,
              "context": "Vaslui to Urziceni, 142. Urziceni to Hirsova, 98. Hirsova to Eforie, 86. Urziceni to Bucharest, 85. Buchare"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Eforie",
              "entity_type": "GPE",
              "start_char": 590,
              "end_char": 596,
              "context": "rziceni, 142. Urziceni to Hirsova, 98. Hirsova to Eforie, 86. Urziceni to Bucharest, 85. Bucharest to Giur"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 614,
              "end_char": 623,
              "context": "o Hirsova, 98. Hirsova to Eforie, 86. Urziceni to Bucharest, 85. Bucharest to Giurgiu, 90. Bucharest to Pites"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 629,
              "end_char": 638,
              "context": "Hirsova to Eforie, 86. Urziceni to Bucharest, 85. Bucharest to Giurgiu, 90. Bucharest to Pitesti, 101. Buchar"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Giurgiu",
              "entity_type": "GPE",
              "start_char": 642,
              "end_char": 649,
              "context": "orie, 86. Urziceni to Bucharest, 85. Bucharest to Giurgiu, 90. Bucharest to Pitesti, 101. Bucharest to Faga"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Fagaras",
              "entity_type": "GPE",
              "start_char": 695,
              "end_char": 702,
              "context": "rgiu, 90. Bucharest to Pitesti, 101. Bucharest to Fagaras, 211. Fagaras to Sibiu, 99. Pitesti to Craiova, 1"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 720,
              "end_char": 725,
              "context": "testi, 101. Bucharest to Fagaras, 211. Fagaras to Sibiu, 99. Pitesti to Craiova, 138. Pitesti to Rimnicu "
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Craiova",
              "entity_type": "GPE",
              "start_char": 742,
              "end_char": 749,
              "context": "to Fagaras, 211. Fagaras to Sibiu, 99. Pitesti to Craiova, 138. Pitesti to Rimnicu Vilcea, 97. Rimnicu Vilc"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 805,
              "end_char": 810,
              "context": " Pitesti to Rimnicu Vilcea, 97. Rimnicu Vilcea to Sibiu, 80. Sibiu to Oradea, 151. Sibiu to Arad, 140. Ar"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 825,
              "end_char": 831,
              "context": "Vilcea, 97. Rimnicu Vilcea to Sibiu, 80. Sibiu to Oradea, 151. Sibiu to Arad, 140. Arad to Zerind, 75. Zer"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 847,
              "end_char": 851,
              "context": "lcea to Sibiu, 80. Sibiu to Oradea, 151. Sibiu to Arad, 140. Arad to Zerind, 75. Zerind to Oradea, 71. A"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 858,
              "end_char": 862,
              "context": "iu, 80. Sibiu to Oradea, 151. Sibiu to Arad, 140. Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timi"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 866,
              "end_char": 872,
              "context": "Sibiu to Oradea, 151. Sibiu to Arad, 140. Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timisoara, 118"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 878,
              "end_char": 884,
              "context": "dea, 151. Sibiu to Arad, 140. Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timisoara, 118. Timisoara "
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 888,
              "end_char": 894,
              "context": "Sibiu to Arad, 140. Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timisoara, 118. Timisoara to Lugoj, "
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 900,
              "end_char": 904,
              "context": "d, 140. Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timisoara, 118. Timisoara to Lugoj, 111. Lugoj"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 908,
              "end_char": 917,
              "context": "Arad to Zerind, 75. Zerind to Oradea, 71. Arad to Timisoara, 118. Timisoara to Lugoj, 111. Lugoj to Mehadia, "
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 924,
              "end_char": 933,
              "context": "75. Zerind to Oradea, 71. Arad to Timisoara, 118. Timisoara to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to D"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 937,
              "end_char": 942,
              "context": " Oradea, 71. Arad to Timisoara, 118. Timisoara to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to Drobeta, 7"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 949,
              "end_char": 954,
              "context": " Arad to Timisoara, 118. Timisoara to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to Drobeta, 75. Drobeta t"
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Mehadia",
              "entity_type": "GPE",
              "start_char": 958,
              "end_char": 965,
              "context": "Timisoara, 118. Timisoara to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to Drobeta, 75. Drobeta to Craiova, "
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Mehadia",
              "entity_type": "GPE",
              "start_char": 971,
              "end_char": 978,
              "context": "8. Timisoara to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to Drobeta, 75. Drobeta to Craiova, 120."
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Drobeta",
              "entity_type": "PERSON",
              "start_char": 982,
              "end_char": 989,
              "context": "a to Lugoj, 111. Lugoj to Mehadia, 70. Mehadia to Drobeta, 75. Drobeta to Craiova, 120."
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Drobeta",
              "entity_type": "PERSON",
              "start_char": 995,
              "end_char": 1002,
              "context": "11. Lugoj to Mehadia, 70. Mehadia to Drobeta, 75. Drobeta to Craiova, 120."
            },
            {
              "para_id": "chap3_para8",
              "entity_text": "Craiova",
              "entity_type": "GPE",
              "start_char": 1006,
              "end_char": 1013,
              "context": "o Mehadia, 70. Mehadia to Drobeta, 75. Drobeta to Craiova, 120."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para9",
          "content": "×\nFigure 3.1\nA simplified road map of part of Romania, with road distances in miles.",
          "sentence_count": 1,
          "char_count": 71,
          "prev_para_id": "chap3_para8",
          "next_para_id": "chap3_para10",
          "style_metadata": {
            "para_id": "chap3_para9",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "simplified": 1,
            "road": 2,
            "map": 1,
            "part": 1,
            "romania": 1,
            "distance": 1,
            "mile": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para9",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 46,
              "end_char": 53,
              "context": "×\nFigure 3.1\nA simplified road map of part of Romania, with road distances in miles."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para10",
          "content": "•\nGoal formulation\n: The agent adopts the\ngoal\nof reaching Bucharest. Goals organize behavior by limiting the objectives and hence the actions to be considered.",
          "sentence_count": 2,
          "char_count": 139,
          "prev_para_id": "chap3_para9",
          "next_para_id": "chap3_para11",
          "style_metadata": {
            "para_id": "chap3_para10",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "goal": 3,
            "formulation": 1,
            "agent": 1,
            "adopts": 1,
            "reaching": 1,
            "bucharest": 1,
            "organize": 1,
            "behavior": 1,
            "limiting": 1,
            "objective": 1,
            "hence": 1,
            "action": 1,
            "considered": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para11",
          "content": "•\nProblem formulation\n: The agent devises a description of the states and actions necessary to reach the goal—an abstract model of the relevant part of the world. For our agent, one good model is to consider the actions of traveling from one city to an adjacent city, and therefore the only fact about the state of the world that will change due to an action is the current city.",
          "sentence_count": 2,
          "char_count": 312,
          "prev_para_id": "chap3_para10",
          "next_para_id": "chap3_para12",
          "style_metadata": {
            "para_id": "chap3_para11",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 74,
            "sentence_count": 2
          },
          "terminology": {
            "problem": 1,
            "formulation": 1,
            "agent": 2,
            "devise": 1,
            "description": 1,
            "state": 2,
            "action": 3,
            "necessary": 1,
            "reach": 1,
            "goal—an": 1,
            "abstract": 1,
            "model": 2,
            "relevant": 1,
            "part": 1,
            "world": 2,
            "good": 1,
            "consider": 1,
            "traveling": 1,
            "city": 3,
            "adjacent": 1,
            "fact": 1,
            "change": 1,
            "due": 1,
            "current": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para12",
          "content": "•\nSearch\n: Before taking any action in the real world, the agent simulates sequences of actions in its model, searching until it finds a sequence of actions that reaches the goal. Such a sequence is called a\nsolution\n. The agent might have to simulate multiple sequences that do not reach the goal, but eventually it will find a solution (such as going from Arad to Sibiu to Fagaras to Bucharest), or it will find that no solution is possible.",
          "sentence_count": 3,
          "char_count": 367,
          "prev_para_id": "chap3_para11",
          "next_para_id": "chap3_para13",
          "style_metadata": {
            "para_id": "chap3_para12",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.67,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 3
          },
          "terminology": {
            "search": 1,
            "taking": 1,
            "action": 3,
            "real": 1,
            "world": 1,
            "agent": 2,
            "simulates": 1,
            "sequence": 4,
            "model": 1,
            "searching": 1,
            "find": 3,
            "reach": 2,
            "goal": 2,
            "called": 1,
            "solution": 3,
            "simulate": 1,
            "multiple": 1,
            "going": 1,
            "arad": 1,
            "sibiu": 1,
            "fagaras": 1,
            "bucharest": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para12",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 358,
              "end_char": 362,
              "context": "ually it will find a solution (such as going from Arad to Sibiu to Fagaras to Bucharest), or it will fin"
            },
            {
              "para_id": "chap3_para12",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 366,
              "end_char": 371,
              "context": " will find a solution (such as going from Arad to Sibiu to Fagaras to Bucharest), or it will find that no"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para13",
          "content": "•\nExecution\n: The agent can now execute the actions in the solution, one at a time.",
          "sentence_count": 1,
          "char_count": 69,
          "prev_para_id": "chap3_para12",
          "next_para_id": "chap3_para14",
          "style_metadata": {
            "para_id": "chap3_para13",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "execution": 1,
            "agent": 1,
            "execute": 1,
            "action": 1,
            "solution": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para14",
          "content": "It is an important property that in a fully observable, deterministic, known environment,\nthe solution to any problem is a fixed sequence of actions:\ndrive to Sibiu, then Fagaras, then Bucharest. If the model is correct, then once the agent has found a solution, it can ignore its percepts while it is executing the actions—closing its eyes, so to speak—because the solution is guaranteed to lead to the goal. Control theorists call this an\nopen-loop\nsystem: ignoring the percepts breaks the loop between agent and environment. If there is a chance that the model is incorrect, or the environment is nondeterministic, then the agent would be safer using a\nclosed-loop\napproach that monitors the percepts (see\nSection 4.4\n).",
          "sentence_count": 4,
          "char_count": 613,
          "prev_para_id": "chap3_para13",
          "next_para_id": "chap3_para15",
          "style_metadata": {
            "para_id": "chap3_para14",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 4
          },
          "terminology": {
            "important": 1,
            "property": 1,
            "observable": 1,
            "deterministic": 1,
            "known": 1,
            "environment": 3,
            "solution": 3,
            "problem": 1,
            "fixed": 1,
            "sequence": 1,
            "action": 1,
            "drive": 1,
            "sibiu": 1,
            "fagaras": 1,
            "bucharest": 1,
            "model": 2,
            "correct": 1,
            "agent": 3,
            "found": 1,
            "ignore": 1,
            "percept": 3,
            "executing": 1,
            "actions—closing": 1,
            "eye": 1,
            "speak—because": 1,
            "guaranteed": 1,
            "lead": 1,
            "goal": 1,
            "control": 1,
            "theorist": 1,
            "call": 1,
            "open-loop": 1,
            "system": 1,
            "ignoring": 1,
            "break": 1,
            "loop": 1,
            "chance": 1,
            "incorrect": 1,
            "nondeterministic": 1,
            "safer": 1,
            "using": 1,
            "closed-loop": 1,
            "approach": 1,
            "monitor": 1,
            "see": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para14",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 159,
              "end_char": 164,
              "context": " problem is a fixed sequence of actions:\ndrive to Sibiu, then Fagaras, then Bucharest. If the model is co"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para15",
          "content": "In partially observable or nondeterministic environments, a solution would be a branching strategy that recommends different future actions depending on what percepts arrive. For example, the agent might plan to drive from Arad to Sibiu but might need a contingency plan in case it arrives in Zerind by accident or finds a sign saying “Drum Închis” (Road Closed).",
          "sentence_count": 2,
          "char_count": 306,
          "prev_para_id": "chap3_para14",
          "next_para_id": "chap3_para16",
          "style_metadata": {
            "para_id": "chap3_para15",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 2
          },
          "terminology": {
            "observable": 1,
            "nondeterministic": 1,
            "environment": 1,
            "solution": 1,
            "branching": 1,
            "strategy": 1,
            "recommends": 1,
            "different": 1,
            "future": 1,
            "action": 1,
            "depending": 1,
            "percept": 1,
            "arrive": 1,
            "example": 1,
            "agent": 1,
            "plan": 2,
            "drive": 1,
            "arad": 1,
            "sibiu": 1,
            "need": 1,
            "contingency": 1,
            "case": 1,
            "arrives": 1,
            "accident": 1,
            "find": 1,
            "sign": 1,
            "saying": 1,
            "drum": 1,
            "închis": 1,
            "road": 1,
            "closed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para15",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 223,
              "end_char": 227,
              "context": ". For example, the agent might plan to drive from Arad to Sibiu but might need a contingency plan in cas"
            },
            {
              "para_id": "chap3_para15",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 231,
              "end_char": 236,
              "context": "ample, the agent might plan to drive from Arad to Sibiu but might need a contingency plan in case it arri"
            },
            {
              "para_id": "chap3_para15",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 293,
              "end_char": 299,
              "context": "ght need a contingency plan in case it arrives in Zerind by accident or finds a sign saying “Drum Închis” "
            },
            {
              "para_id": "chap3_para15",
              "entity_text": "Road Closed",
              "entity_type": "WORK_OF_ART",
              "start_char": 350,
              "end_char": 361,
              "context": "by accident or finds a sign saying “Drum Închis” (Road Closed)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para16",
          "content": "3.1.1\nSearch problems and solutions\nA search\nproblem\ncan be defined formally as follows:\n•\nA set of possible\nstates\nthat the environment can be in. We call this the\nstate space\n.",
          "sentence_count": 2,
          "char_count": 156,
          "prev_para_id": "chap3_para15",
          "next_para_id": "chap3_para17",
          "style_metadata": {
            "para_id": "chap3_para16",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "search": 2,
            "problem": 2,
            "solution": 1,
            "defined": 1,
            "follows": 1,
            "set": 1,
            "possible": 1,
            "state": 2,
            "environment": 1,
            "call": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para17",
          "content": "•\nThe\ninitial state\nthat the agent starts in. For example:\nArad.",
          "sentence_count": 2,
          "char_count": 57,
          "prev_para_id": "chap3_para16",
          "next_para_id": "chap3_para18",
          "style_metadata": {
            "para_id": "chap3_para17",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 2
          },
          "terminology": {
            "initial": 1,
            "state": 1,
            "agent": 1,
            "start": 1,
            "example": 1,
            "arad": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para17",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 59,
              "end_char": 63,
              "context": "tial state\nthat the agent starts in. For example:\nArad."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para18",
          "content": "•\nA set of one or more\ngoal states\n. Sometimes there is one goal state (e.g.,\nBucharest\n), sometimes there is a small set of alternative goal states, and sometimes the goal is defined by a property that applies to many states (potentially an infinite number). For example, in a vacuum-cleaner world, the goal might be to have no dirt in any location, regardless of any other facts about the state. We can account for all three of these possibilities by specifying an I\nS\n-G\nOAL\nmethod for a problem. In this chapter we will sometimes say “the goal” for simplicity, but what we say also applies to “any one of the possible goal states.”\n•\nThe\nactions\navailable to the agent. Given a state\ns\n, A\nCTIONS\n(\ns\n) returns a finite\n2\nset of actions that can be executed in\ns\n. We say that each of these actions is\napplicable\nin\ns\n. An example:\nACTIONS\n(\nA\nr\na\nd\n)\n= {\nT\no\nS\ni\nb\ni\nu\n,\nT\no\nT\ni\nm\ni\ns\no\na\nr\na\n,\nT\no\nZ\ne\nr\ni\nn\nd\n}\n.",
          "sentence_count": 8,
          "char_count": 785,
          "prev_para_id": "chap3_para17",
          "next_para_id": "chap3_para19",
          "style_metadata": {
            "para_id": "chap3_para18",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 220,
            "sentence_count": 8
          },
          "terminology": {
            "set": 3,
            "goal": 7,
            "state": 6,
            "e.g.": 1,
            "bucharest": 1,
            "small": 1,
            "alternative": 1,
            "defined": 1,
            "property": 1,
            "applies": 2,
            "many": 1,
            "infinite": 1,
            "number": 1,
            "example": 2,
            "vacuum-cleaner": 1,
            "world": 1,
            "dirt": 1,
            "location": 1,
            "fact": 1,
            "account": 1,
            "possibility": 1,
            "specifying": 1,
            "oal": 1,
            "method": 1,
            "problem": 1,
            "chapter": 1,
            "say": 3,
            "simplicity": 1,
            "possible": 1,
            "states.": 1,
            "action": 4,
            "available": 1,
            "agent": 1,
            "given": 1,
            "ctions": 1,
            "return": 1,
            "executed": 1,
            "applicable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para18",
              "entity_text": "OAL",
              "entity_type": "ORG",
              "start_char": 474,
              "end_char": 477,
              "context": "ee of these possibilities by specifying an I\nS\n-G\nOAL\nmethod for a problem. In this chapter we will som"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para19",
          "content": "•\nA\ntransition model\n, which describes what each action does. R\nESULT\n(\ns, a\n) returns the state that results from doing action\na\nin state\ns\n. For example,\nRESULT(\nA\nr\na\nd\n,\nT\no\nZ\ne\nr\ni\nn\nd\n) =\nZ\ne\nr\ni\nn\nd\n.",
          "sentence_count": 3,
          "char_count": 187,
          "prev_para_id": "chap3_para18",
          "next_para_id": "chap3_para20",
          "style_metadata": {
            "para_id": "chap3_para19",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 3
          },
          "terminology": {
            "transition": 1,
            "model": 1,
            "describes": 1,
            "action": 2,
            "esult": 1,
            "return": 1,
            "state": 2,
            "result": 2,
            "example": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para20",
          "content": "•\nAn\naction cost function\n, denoted by A\nCTION\n-C\nOST\n(\nS,\na, sʹ\n) when we are programming or\nc(s, a, sʹ)\nwhen we are doing math, that gives the numeric cost of applying action\na\nin state\ns\nto reach state\nsʹ\n. A problem-solving agent should use a cost function that reflects its own performance measure; for example, for route-finding agents, the cost of an action might be the length in miles (as seen in\nFigure 3.1\n), or it might be the time it takes to complete the action.",
          "sentence_count": 2,
          "char_count": 402,
          "prev_para_id": "chap3_para19",
          "next_para_id": "chap3_para21",
          "style_metadata": {
            "para_id": "chap3_para20",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 54.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 109,
            "sentence_count": 2
          },
          "terminology": {
            "action": 4,
            "cost": 4,
            "function": 2,
            "denoted": 1,
            "ction": 1,
            "ost": 1,
            "programming": 1,
            "math": 1,
            "give": 1,
            "numeric": 1,
            "applying": 1,
            "state": 2,
            "reach": 1,
            "problem-solving": 1,
            "agent": 2,
            "use": 1,
            "reflects": 1,
            "performance": 1,
            "measure": 1,
            "example": 1,
            "route-finding": 1,
            "length": 1,
            "mile": 1,
            "seen": 1,
            "figure": 1,
            "time": 1,
            "take": 1,
            "complete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para21",
          "content": "A sequence of actions forms a\npath\n, and a\nsolution\nis a path from the initial state to a goal state. We assume that action costs are additive; that is, the total cost of a path is the sum of the individual action costs. An\noptimal solution\nhas the lowest path cost among all solutions. In this chapter, we assume that all action costs will be positive, to avoid certain complications.",
          "sentence_count": 4,
          "char_count": 320,
          "prev_para_id": "chap3_para20",
          "next_para_id": "chap3_para22",
          "style_metadata": {
            "para_id": "chap3_para21",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 4
          },
          "terminology": {
            "sequence": 1,
            "action": 4,
            "form": 1,
            "path": 4,
            "solution": 3,
            "initial": 1,
            "state": 2,
            "goal": 1,
            "assume": 2,
            "cost": 5,
            "additive": 1,
            "total": 1,
            "sum": 1,
            "individual": 1,
            "optimal": 1,
            "lowest": 1,
            "chapter": 1,
            "positive": 1,
            "avoid": 1,
            "certain": 1,
            "complication": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para22",
          "content": "3\nThe state space can be represented as a\ngraph\nin which the vertices are states and the directed edges between them are actions. The map of Romania shown in\nFigure 3.1\nis such a graph, where each road indicates two actions, one in each direction.",
          "sentence_count": 2,
          "char_count": 207,
          "prev_para_id": "chap3_para21",
          "next_para_id": "chap3_para23",
          "style_metadata": {
            "para_id": "chap3_para22",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 2
          },
          "terminology": {
            "state": 2,
            "space": 1,
            "represented": 1,
            "graph": 2,
            "vertex": 1,
            "directed": 1,
            "edge": 1,
            "action": 2,
            "map": 1,
            "romania": 1,
            "shown": 1,
            "figure": 1,
            "road": 1,
            "indicates": 1,
            "direction": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para22",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 141,
              "end_char": 148,
              "context": "rected edges between them are actions. The map of Romania shown in\nFigure 3.1\nis such a graph, where each r"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para23",
          "content": "3.1.2\nFormulating problems\nOur formulation of the problem of getting to Bucharest is a\nmodel\n—an abstract mathematical description—and not the real thing. Compare the simple atomic state description\nArad\nto an actual cross-country trip, where the state of the world includes so many things: the traveling companions, the current radio program, the scenery out of the window, the proximity of law enforcement officers, the distance to the next rest stop, the condition of the road, the weather, the traffic, and so on. All these considerations are left out of our model because they are irrelevant to the problem of finding a route to Bucharest.",
          "sentence_count": 3,
          "char_count": 546,
          "prev_para_id": "chap3_para22",
          "next_para_id": "chap3_para24",
          "style_metadata": {
            "para_id": "chap3_para23",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 118,
            "sentence_count": 3
          },
          "terminology": {
            "formulating": 1,
            "problem": 3,
            "formulation": 1,
            "getting": 1,
            "bucharest": 2,
            "model": 2,
            "—an": 1,
            "abstract": 1,
            "mathematical": 1,
            "description—and": 1,
            "real": 1,
            "thing": 2,
            "compare": 1,
            "simple": 1,
            "atomic": 1,
            "state": 2,
            "description": 1,
            "arad": 1,
            "actual": 1,
            "cross-country": 1,
            "trip": 1,
            "world": 1,
            "includes": 1,
            "many": 1,
            "traveling": 1,
            "companion": 1,
            "current": 1,
            "radio": 1,
            "program": 1,
            "scenery": 1,
            "window": 1,
            "proximity": 1,
            "law": 1,
            "enforcement": 1,
            "officer": 1,
            "distance": 1,
            "next": 1,
            "rest": 1,
            "stop": 1,
            "condition": 1,
            "road": 1,
            "weather": 1,
            "traffic": 1,
            "consideration": 1,
            "left": 1,
            "irrelevant": 1,
            "finding": 1,
            "route": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para23",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 72,
              "end_char": 81,
              "context": "lems\nOur formulation of the problem of getting to Bucharest is a\nmodel\n—an abstract mathematical description—"
            },
            {
              "para_id": "chap3_para23",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 199,
              "end_char": 203,
              "context": "hing. Compare the simple atomic state description\nArad\nto an actual cross-country trip, where the state "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para24",
          "content": "The process of removing detail from a representation is called\nabstraction\n. A good problem formulation has the right level of detail. If the actions were at the level of “move the right foot forward a centimeter” or “turn the steering wheel one degree left,” the agent would probably never find its way out of the parking lot, let alone to Bucharest.",
          "sentence_count": 3,
          "char_count": 292,
          "prev_para_id": "chap3_para23",
          "next_para_id": "chap3_para25",
          "style_metadata": {
            "para_id": "chap3_para24",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.33,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 3
          },
          "terminology": {
            "process": 1,
            "removing": 1,
            "detail": 2,
            "representation": 1,
            "called": 1,
            "abstraction": 1,
            "good": 1,
            "problem": 1,
            "formulation": 1,
            "level": 2,
            "action": 1,
            "move": 1,
            "right": 1,
            "foot": 1,
            "centimeter": 1,
            "turn": 1,
            "steering": 1,
            "wheel": 1,
            "degree": 1,
            "left": 1,
            "agent": 1,
            "find": 1,
            "way": 1,
            "parking": 1,
            "lot": 1,
            "let": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para25",
          "content": "Can we be more precise about the appropriate\nlevel of abstraction\n? Think of the abstract states and actions we have chosen as corresponding to large sets of detailed world states and detailed action sequences. Now consider a solution to the abstract problem: for example, the path from Arad to Sibiu to Rimnicu Vilcea to Pitesti to Bucharest. This abstract solution corresponds to a large number of more detailed paths. For example, we could drive with the radio on between Sibiu and Rimnicu Vilcea, and then switch it off for the rest of the trip.",
          "sentence_count": 5,
          "char_count": 457,
          "prev_para_id": "chap3_para24",
          "next_para_id": "chap3_para26",
          "style_metadata": {
            "para_id": "chap3_para25",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 5
          },
          "terminology": {
            "precise": 1,
            "appropriate": 1,
            "level": 1,
            "abstraction": 1,
            "think": 1,
            "abstract": 3,
            "state": 2,
            "action": 2,
            "chosen": 1,
            "corresponding": 1,
            "large": 2,
            "set": 1,
            "detailed": 3,
            "world": 1,
            "sequence": 1,
            "consider": 1,
            "solution": 2,
            "problem": 1,
            "example": 2,
            "path": 2,
            "arad": 1,
            "sibiu": 2,
            "rimnicu": 2,
            "vilcea": 2,
            "pitesti": 1,
            "bucharest": 1,
            "corresponds": 1,
            "number": 1,
            "drive": 1,
            "radio": 1,
            "switch": 1,
            "rest": 1,
            "trip": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para25",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 287,
              "end_char": 291,
              "context": " the abstract problem: for example, the path from Arad to Sibiu to Rimnicu Vilcea to Pitesti to Buchares"
            },
            {
              "para_id": "chap3_para25",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 295,
              "end_char": 300,
              "context": "tract problem: for example, the path from Arad to Sibiu to Rimnicu Vilcea to Pitesti to Bucharest. This a"
            },
            {
              "para_id": "chap3_para25",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 475,
              "end_char": 480,
              "context": "example, we could drive with the radio on between Sibiu and Rimnicu Vilcea, and then switch it off for th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para26",
          "content": "The abstraction is\nvalid\nif we can elaborate any abstract solution into a solution in the more detailed world; a sufficient condition is that for every detailed state that is “in Arad,” there is a detailed path to some state that is “in Sibiu,” and so on.",
          "sentence_count": 1,
          "char_count": 211,
          "prev_para_id": "chap3_para25",
          "next_para_id": "chap3_para27",
          "style_metadata": {
            "para_id": "chap3_para26",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 55.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 1
          },
          "terminology": {
            "abstraction": 1,
            "valid": 1,
            "elaborate": 1,
            "abstract": 1,
            "solution": 2,
            "detailed": 3,
            "world": 1,
            "sufficient": 1,
            "condition": 1,
            "state": 2,
            "arad": 1,
            "path": 1,
            "sibiu": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para26",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 179,
              "end_char": 183,
              "context": "tion is that for every detailed state that is “in Arad,” there is a detailed path to some state that is "
            },
            {
              "para_id": "chap3_para26",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 237,
              "end_char": 242,
              "context": "here is a detailed path to some state that is “in Sibiu,” and so on."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para27",
          "content": "4\nThe abstraction is\nuseful\nif carrying out each of the actions in the solution is easier than the original problem; in our case, the action “drive from Arad to Sibiu” can be carried out without further search or planning by a driver with average skill. The choice of a good abstraction thus involves removing as much detail as possible while retaining validity and ensuring that the abstract actions are easy to carry out. Were it not for the ability to construct useful abstractions, intelligent agents would be completely swamped by the real world.",
          "sentence_count": 3,
          "char_count": 461,
          "prev_para_id": "chap3_para26",
          "next_para_id": "chap3_para28",
          "style_metadata": {
            "para_id": "chap3_para27",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 102,
            "sentence_count": 3
          },
          "terminology": {
            "abstraction": 3,
            "useful": 2,
            "carrying": 1,
            "action": 3,
            "solution": 1,
            "easier": 1,
            "original": 1,
            "problem": 1,
            "case": 1,
            "drive": 1,
            "arad": 1,
            "sibiu": 1,
            "carried": 1,
            "search": 1,
            "planning": 1,
            "driver": 1,
            "average": 1,
            "skill": 1,
            "choice": 1,
            "good": 1,
            "involves": 1,
            "removing": 1,
            "much": 1,
            "detail": 1,
            "possible": 1,
            "retaining": 1,
            "validity": 1,
            "ensuring": 1,
            "abstract": 1,
            "easy": 1,
            "carry": 1,
            "ability": 1,
            "construct": 1,
            "intelligent": 1,
            "agent": 1,
            "swamped": 1,
            "real": 1,
            "world": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para27",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 153,
              "end_char": 157,
              "context": "inal problem; in our case, the action “drive from Arad to Sibiu” can be carried out without further sear"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para28",
          "content": "3.2Example Problems\n3.2\nExample Problems\nThe problem-solving approach has been applied to a vast array of task environments. We list some of the best known here, distinguishing between\nstandardized\nand\nreal-world\nproblems. A\nstandardized problem\nis intended to illustrate or exercise various problem-solving methods. It can be given a concise, exact description and hence is suitable as a benchmark for researchers to compare the performance of algorithms. A\nreal-world problem\n, such as robot navigation, is one whose solutions people actually use, and whose formulation is idiosyncratic, not standardized, because, for example, each robot has different sensors that produce different data.",
          "sentence_count": 5,
          "char_count": 602,
          "prev_para_id": "chap3_para27",
          "next_para_id": "chap3_para29",
          "style_metadata": {
            "para_id": "chap3_para28",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.8,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 5
          },
          "terminology": {
            "problem": 5,
            "example": 2,
            "problem-solving": 2,
            "approach": 1,
            "applied": 1,
            "vast": 1,
            "array": 1,
            "task": 1,
            "environment": 1,
            "list": 1,
            "known": 1,
            "distinguishing": 1,
            "standardized": 3,
            "real-world": 2,
            "intended": 1,
            "illustrate": 1,
            "exercise": 1,
            "various": 1,
            "method": 1,
            "given": 1,
            "concise": 1,
            "exact": 1,
            "description": 1,
            "hence": 1,
            "suitable": 1,
            "benchmark": 1,
            "researcher": 1,
            "compare": 1,
            "performance": 1,
            "algorithm": 1,
            "robot": 2,
            "navigation": 1,
            "solution": 1,
            "people": 1,
            "use": 1,
            "formulation": 1,
            "idiosyncratic": 1,
            "different": 2,
            "sensor": 1,
            "produce": 1,
            "data": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para29",
          "content": "3.2.1\nStandardized problems\nA\ngrid world\nproblem is a two-dimensional rectangular array of square cells in which agents can move from cell to cell. Typically the agent can move to any obstacle-free adjacent cell—horizontally or vertically and in some problems diagonally. Cells can contain objects, which\nthe agent can pick up, push, or otherwise act upon; a wall or other impassible obstacle in a cell prevents an agent from moving into that cell. The\nvacuum world\nfrom\nSection 2.1\ncan be formulated as a grid world problem as follows:\n•\nStates:\nA state of the world says which objects are in which cells. For the vacuum world, the objects are the agent and any dirt. In the simple two-cell version, the agent can be in either of the two cells, and each cell can either contain dirt or not, so there are 2 · 2 · 2 = 8 states (see\nFigure 3.2\n). In general, a vacuum environment with\nn\ncells has\nn\n· 2\nn\nstates.",
          "sentence_count": 7,
          "char_count": 763,
          "prev_para_id": "chap3_para28",
          "next_para_id": "chap3_para30",
          "style_metadata": {
            "para_id": "chap3_para29",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.71,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 187,
            "sentence_count": 7
          },
          "terminology": {
            "standardized": 1,
            "problem": 4,
            "grid": 2,
            "world": 5,
            "two-dimensional": 1,
            "rectangular": 1,
            "array": 1,
            "square": 1,
            "cell": 10,
            "agent": 6,
            "move": 2,
            "obstacle-free": 1,
            "adjacent": 1,
            "contain": 2,
            "object": 3,
            "pick": 1,
            "push": 1,
            "act": 1,
            "wall": 1,
            "impassible": 1,
            "obstacle": 1,
            "prevents": 1,
            "moving": 1,
            "vacuum": 3,
            "section": 1,
            "formulated": 1,
            "follows": 1,
            "state": 4,
            "say": 1,
            "simple": 1,
            "two-cell": 1,
            "version": 1,
            "dirt": 1,
            "see": 1,
            "general": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para30",
          "content": "•\nInitial state:\nAny state can be designated as the initial state.",
          "sentence_count": 1,
          "char_count": 57,
          "prev_para_id": "chap3_para29",
          "next_para_id": "chap3_para31",
          "style_metadata": {
            "para_id": "chap3_para30",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "initial": 2,
            "state": 3,
            "designated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para31",
          "content": "•\nActions:\nIn the two-cell world we defined three actions:\nSuck,\nmove\nLeft,\nand move\nRight.",
          "sentence_count": 1,
          "char_count": 83,
          "prev_para_id": "chap3_para30",
          "next_para_id": "chap3_para32",
          "style_metadata": {
            "para_id": "chap3_para31",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "action": 2,
            "two-cell": 1,
            "world": 1,
            "defined": 1,
            "suck": 1,
            "move": 2,
            "left": 1,
            "right": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para31",
              "entity_text": "Suck",
              "entity_type": "PERSON",
              "start_char": 59,
              "end_char": 63,
              "context": ":\nIn the two-cell world we defined three actions:\nSuck,\nmove\nLeft,\nand move\nRight."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para32",
          "content": "In a two-dimensional multi-cell world we need more movement actions. We could add\nUpward\nand\nDownward,\ngiving us four\nabsolute\nmovement actions, or we could switch to\negocentric actions\n, defined relative to the viewpoint of the agent—for example,\nForward, Backward, TurnRight,\nand\nTurnLeft.",
          "sentence_count": 2,
          "char_count": 259,
          "prev_para_id": "chap3_para31",
          "next_para_id": "chap3_para33",
          "style_metadata": {
            "para_id": "chap3_para32",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 2
          },
          "terminology": {
            "two-dimensional": 1,
            "multi-cell": 1,
            "world": 1,
            "need": 1,
            "movement": 2,
            "action": 3,
            "add": 1,
            "downward": 1,
            "giving": 1,
            "absolute": 1,
            "switch": 1,
            "egocentric": 1,
            "defined": 1,
            "relative": 1,
            "viewpoint": 1,
            "agent—for": 1,
            "example": 1,
            "turnright": 1,
            "turnleft": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para32",
              "entity_text": "Backward",
              "entity_type": "PERSON",
              "start_char": 257,
              "end_char": 265,
              "context": " the viewpoint of the agent—for example,\nForward, Backward, TurnRight,\nand\nTurnLeft."
            },
            {
              "para_id": "chap3_para32",
              "entity_text": "TurnRight",
              "entity_type": "ORG",
              "start_char": 267,
              "end_char": 276,
              "context": "oint of the agent—for example,\nForward, Backward, TurnRight,\nand\nTurnLeft."
            },
            {
              "para_id": "chap3_para32",
              "entity_text": "TurnLeft",
              "entity_type": "PRODUCT",
              "start_char": 282,
              "end_char": 290,
              "context": "nt—for example,\nForward, Backward, TurnRight,\nand\nTurnLeft."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para33",
          "content": "•\nTransition model:\nSuck\nremoves any dirt from the agent’s cell;\nForward\nmoves the agent ahead one cell in the direction it is facing, unless it hits a wall, in which case the action has no effect.",
          "sentence_count": 1,
          "char_count": 166,
          "prev_para_id": "chap3_para32",
          "next_para_id": "chap3_para34",
          "style_metadata": {
            "para_id": "chap3_para33",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 1
          },
          "terminology": {
            "transition": 1,
            "model": 1,
            "suck": 1,
            "remove": 1,
            "dirt": 1,
            "agent": 2,
            "cell": 2,
            "move": 1,
            "direction": 1,
            "facing": 1,
            "hit": 1,
            "wall": 1,
            "case": 1,
            "action": 1,
            "effect": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para34",
          "content": "Backward\nmoves the agent in the opposite direction, while\nTurnRight\nand\nTurnLeft\nchange the direction it is facing by 90°.",
          "sentence_count": 1,
          "char_count": 108,
          "prev_para_id": "chap3_para33",
          "next_para_id": "chap3_para35",
          "style_metadata": {
            "para_id": "chap3_para34",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 1
          },
          "terminology": {
            "backward": 1,
            "move": 1,
            "agent": 1,
            "opposite": 1,
            "direction": 2,
            "turnright": 1,
            "turnleft": 1,
            "change": 1,
            "facing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para34",
              "entity_text": "TurnRight",
              "entity_type": "ORG",
              "start_char": 58,
              "end_char": 67,
              "context": "\nmoves the agent in the opposite direction, while\nTurnRight\nand\nTurnLeft\nchange the direction it is facing by"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para35",
          "content": "•\nGoal states:\nThe states in which every cell is clean.",
          "sentence_count": 1,
          "char_count": 47,
          "prev_para_id": "chap3_para34",
          "next_para_id": "chap3_para36",
          "style_metadata": {
            "para_id": "chap3_para35",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "goal": 1,
            "state": 2,
            "cell": 1,
            "clean": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para36",
          "content": "•\nAction cost:\nEach action costs 1.",
          "sentence_count": 1,
          "char_count": 31,
          "prev_para_id": "chap3_para35",
          "next_para_id": "chap3_para37",
          "style_metadata": {
            "para_id": "chap3_para36",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "action": 2,
            "cost": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para37",
          "content": "Description\nA square labeled Start state has three rows and three columns. Row 1: Column 1, 7. Column 2, 2. Column 3, 4. Row 2: Column 1, 5. Column 2, blank. Column 3, 6. Row 3: Column 1, 8. Column 2, 3. Column 3, 1. Another square labeled Goal state has three rows and three columns. Row 1: Column 1, blank. Column 2, 1. Column 3, 2. Row 2: Column 1, 3. Column 2, 4. Column 3, 5. Row 3: Column 1, 6. Column 2, 7. Column 3, 8.",
          "sentence_count": 20,
          "char_count": 339,
          "prev_para_id": "chap3_para36",
          "next_para_id": "chap3_para38",
          "style_metadata": {
            "para_id": "chap3_para37",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.9,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 118,
            "sentence_count": 20
          },
          "terminology": {
            "description": 1,
            "square": 2,
            "labeled": 2,
            "start": 1,
            "state": 2,
            "row": 8,
            "column": 20,
            "blank": 2,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para37",
              "entity_text": "Start",
              "entity_type": "PRODUCT",
              "start_char": 29,
              "end_char": 34,
              "context": "Description\nA square labeled Start state has three rows and three columns. Row 1: Co"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para38",
          "content": "×\nFigure 3.2\nThe state-space graph for the two-cell vacuum world. There are 8 states and three actions for each state: L =\nLeft\n, R =\nRight,\nS =\nSuck.",
          "sentence_count": 2,
          "char_count": 127,
          "prev_para_id": "chap3_para37",
          "next_para_id": "chap3_para39",
          "style_metadata": {
            "para_id": "chap3_para38",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "state-space": 1,
            "graph": 1,
            "two-cell": 1,
            "vacuum": 1,
            "world": 1,
            "state": 2,
            "action": 1,
            "left": 1,
            "right": 1,
            "suck": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para39",
          "content": "Another type of grid world is the\nsokoban puzzle\n, in which the agent’s goal is to push a number of boxes, scattered about the grid, to designated storage locations. There can be at most one box per cell. When an agent moves forward into a cell containing a box and there is an empty cell on the other side of the box, then both the box and the agent move forward.",
          "sentence_count": 3,
          "char_count": 295,
          "prev_para_id": "chap3_para38",
          "next_para_id": "chap3_para40",
          "style_metadata": {
            "para_id": "chap3_para39",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 3
          },
          "terminology": {
            "type": 1,
            "grid": 2,
            "world": 1,
            "sokoban": 1,
            "puzzle": 1,
            "agent": 3,
            "goal": 1,
            "push": 1,
            "number": 1,
            "box": 5,
            "scattered": 1,
            "designated": 1,
            "storage": 1,
            "location": 1,
            "cell": 3,
            "move": 2,
            "containing": 1,
            "empty": 1,
            "side": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para40",
          "content": "The agent can’t push a box into another box or a wall. For a world with\nn\nnon-obstacle cells and\nb\nboxes, there are\nn\n×\nn!/\n(\nb\n!(\nn\n–\nb\n)!) states; for example on an 8 × 8 grid with a dozen boxes, there are over 200 trillion states.",
          "sentence_count": 4,
          "char_count": 195,
          "prev_para_id": "chap3_para39",
          "next_para_id": "chap3_para41",
          "style_metadata": {
            "para_id": "chap3_para40",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 4
          },
          "terminology": {
            "agent": 1,
            "push": 1,
            "box": 4,
            "wall": 1,
            "world": 1,
            "non-obstacle": 1,
            "cell": 1,
            "state": 2,
            "example": 1,
            "grid": 1,
            "dozen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para41",
          "content": "In a\nsliding-tile puzzle\n, a number of tiles (sometimes called blocks or pieces) are arranged in a grid with one or more blank spaces so that some of the tiles can slide into the blank space. One variant is the Rush Hour puzzle, in which cars and trucks slide around a 6 × 6 grid in an attempt to free a car from the traffic jam. Perhaps the best-known variant is the\n8-puzzle\n(see\nFigure 3.3\n), which consists of a 3 × 3 grid with eight numbered tiles and one blank space, and the\n15-puzzle\non a 4 × 4 grid. The object is to reach a specified goal state, such as the one shown on the right of the figure. The standard formulation of the 8 puzzle is as follows:\nDescription\nTwo squares with a common vertical side represent a state. Each square represents a cell. Eight states are arranged in three rows. Th top row contains two states, the middle row contains four states, and the bottom row contains two states. The first state of the top row has a vacuum cleaner and dirt in the left cell and dirt in the right cell. The second state of the top row has dirt in the left cell and a vacuum cleaner and dirt in the right cell. An arrow labeled L from the left cell of the first state loops back to the same cell. An arrow labeled R from the right cell of the first state points to the left cell of the second state. An arrow labeled L from the left cell of the second state points to the right cell of the first state. An arrow labeled R from the right cell of the second state loops back to the same cell. An arrow labeled S from the first state in the top row points to the first state in the middle row. The first state in the middle row has a vacuum cleaner in the left cell and dirt in the right cell. An arrow labeled L from the left cell of the first state loops back to the same cell. An arrow labeled S from the left cell of the first state points to the right cell of the same state. The second state in the middle row has an empty left cell and a vacuum cleaner and dirt in the right cell. An arrow labeled R from the right cell of the second state loops back to the same cell. An arrow labeled R from the right cell of the first state points to the left cell of the second state. An arrow labeled L from the left cell of the second state points to the right cell of the first state. The third state in the middle row has a vacuum cleaner and dirt in the left cell and an empty right cell. An arrow labeled L from the left cell of the third state loops back to the same cell. The fourth state in the middle row has dirt in the left cell and a vacuum cleaner in the right cell. An arrow labeled R from the right cell of the fourth state loops back to the same cell. An arrow labeled S from the left cell of the fourth state points to the right cell of the same state. An arrow labeled R from the right cell of the third state points to the left cell of the fourth state. An arrow labeled L from the left cell of the fourth state points to the right cell of the third state. An arrow labeled S from the second state in the top row points to the fourth state in the middle row. An arrow from the third state in the middle row points to the first state of the bottom row. The first state on the bottom row has a vacuum cleaner in the left cell and an empty right cell. An arrow labeled L from the left cell of the first state loops back to the same cell. An arrow labeled S from the left cell of the first state points to the right cell of the same state. The second state in the bottom row has an empty left cell and a vacuum cleaner in the right cell. An arrow labeled R from the right cell of the second state loops back to the same cell. An arrow labeled S from the left cell of the second state points to the right cell of the same state. An arrow labeled R from the right cell of the first state points to the left cell of the second state. An arrow labeled L from the left cell of the second state points to the right cell of the first state. An arrow labeled S from the second state in the middle row points to the second state in the third row.",
          "sentence_count": 40,
          "char_count": 3246,
          "prev_para_id": "chap3_para40",
          "next_para_id": "chap3_para42",
          "style_metadata": {
            "para_id": "chap3_para41",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.88,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 875,
            "sentence_count": 40
          },
          "terminology": {
            "sliding-tile": 1,
            "puzzle": 3,
            "number": 1,
            "tile": 3,
            "called": 1,
            "block": 1,
            "piece": 1,
            "arranged": 2,
            "grid": 4,
            "blank": 3,
            "space": 3,
            "variant": 2,
            "rush": 1,
            "hour": 1,
            "car": 2,
            "truck": 1,
            "slide": 1,
            "attempt": 1,
            "free": 1,
            "traffic": 1,
            "jam": 1,
            "best-known": 1,
            "8-puzzle": 1,
            "see": 1,
            "figure": 2,
            "consists": 1,
            "numbered": 1,
            "15-puzzle": 1,
            "object": 1,
            "reach": 1,
            "specified": 1,
            "goal": 1,
            "state": 54,
            "shown": 1,
            "right": 6,
            "standard": 1,
            "formulation": 1,
            "follows": 1,
            "description": 1,
            "square": 2,
            "common": 1,
            "vertical": 1,
            "side": 1,
            "represent": 1,
            "represents": 1,
            "cell": 57,
            "row": 20,
            "top": 5,
            "contains": 3,
            "middle": 9,
            "bottom": 4,
            "first": 9,
            "vacuum": 8,
            "cleaner": 8,
            "dirt": 8,
            "left": 17,
            "second": 16,
            "arrow": 21,
            "labeled": 23,
            "loop": 8,
            "point": 16,
            "empty": 2,
            "third": 6,
            "fourth": 6,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para42",
          "content": "×\nFigure 3.3\nA typical instance of the 8-puzzle.",
          "sentence_count": 1,
          "char_count": 42,
          "prev_para_id": "chap3_para41",
          "next_para_id": "chap3_para43",
          "style_metadata": {
            "para_id": "chap3_para42",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "typical": 1,
            "instance": 1,
            "8-puzzle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para43",
          "content": "•\nStates:\nA state description specifies the location of each of the tiles.",
          "sentence_count": 1,
          "char_count": 64,
          "prev_para_id": "chap3_para42",
          "next_para_id": "chap3_para44",
          "style_metadata": {
            "para_id": "chap3_para43",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "state": 2,
            "description": 1,
            "specifies": 1,
            "location": 1,
            "tile": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para44",
          "content": "•\nInitial state:\nAny state can be designated as the initial state. Note that a parity property partitions the state space—any given goal can be reached from exactly half of the possible initial states (see Exercise\n3.PART\n).",
          "sentence_count": 2,
          "char_count": 191,
          "prev_para_id": "chap3_para43",
          "next_para_id": "chap3_para45",
          "style_metadata": {
            "para_id": "chap3_para44",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 2
          },
          "terminology": {
            "initial": 3,
            "state": 5,
            "designated": 1,
            "note": 1,
            "parity": 1,
            "property": 1,
            "partition": 1,
            "space—any": 1,
            "given": 1,
            "goal": 1,
            "reached": 1,
            "possible": 1,
            "see": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para45",
          "content": "•\nActions:\nWhile in the physical world it is a tile that slides, the simplest way of describing an action is to think of the blank space moving\nLeft, Right, Up,\nor\nDown.",
          "sentence_count": 1,
          "char_count": 142,
          "prev_para_id": "chap3_para44",
          "next_para_id": "chap3_para46",
          "style_metadata": {
            "para_id": "chap3_para45",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 1
          },
          "terminology": {
            "action": 2,
            "physical": 1,
            "world": 1,
            "tile": 1,
            "slide": 1,
            "simplest": 1,
            "way": 1,
            "describing": 1,
            "think": 1,
            "blank": 1,
            "space": 1,
            "moving": 1,
            "left": 1,
            "right": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para46",
          "content": "If the blank is at an edge or corner then not all actions will be applicable.",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap3_para45",
          "next_para_id": "chap3_para47",
          "style_metadata": {
            "para_id": "chap3_para46",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 17,
            "sentence_count": 1
          },
          "terminology": {
            "blank": 1,
            "edge": 1,
            "corner": 1,
            "action": 1,
            "applicable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para47",
          "content": "•\nTransition model:\nMaps a state and action to a resulting state; for example, if we apply\nLeft\nto the start state in\nFigure 3.3\n, the resulting state has the 5 and the blank switched.",
          "sentence_count": 1,
          "char_count": 155,
          "prev_para_id": "chap3_para46",
          "next_para_id": "chap3_para48",
          "style_metadata": {
            "para_id": "chap3_para47",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 1
          },
          "terminology": {
            "transition": 1,
            "model": 1,
            "map": 1,
            "state": 4,
            "action": 1,
            "resulting": 2,
            "example": 1,
            "apply": 1,
            "left": 1,
            "start": 1,
            "figure": 1,
            "blank": 1,
            "switched": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para48",
          "content": "•\nGoal state:\nAlthough any state could be the goal, we typically specify a state with the numbers in order, as in\nFigure 3.3\n.",
          "sentence_count": 1,
          "char_count": 106,
          "prev_para_id": "chap3_para47",
          "next_para_id": "chap3_para49",
          "style_metadata": {
            "para_id": "chap3_para48",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "goal": 2,
            "state": 3,
            "specify": 1,
            "number": 1,
            "order": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para49",
          "content": "•\nAction cost:\nEach action costs 1.",
          "sentence_count": 1,
          "char_count": 31,
          "prev_para_id": "chap3_para48",
          "next_para_id": "chap3_para50",
          "style_metadata": {
            "para_id": "chap3_para49",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "action": 2,
            "cost": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para50",
          "content": "Note that every problem formulation involves abstractions. The 8-puzzle actions are abstracted to their beginning and final states, ignoring the intermediate locations where the tile is sliding. We have abstracted away actions such as shaking the board when tiles get stuck and ruled out extracting the tiles with a knife and putting them back again. We are left with a description of the rules, avoiding all the details of physical manipulations.",
          "sentence_count": 4,
          "char_count": 377,
          "prev_para_id": "chap3_para49",
          "next_para_id": "chap3_para51",
          "style_metadata": {
            "para_id": "chap3_para50",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 4
          },
          "terminology": {
            "note": 1,
            "problem": 1,
            "formulation": 1,
            "involves": 1,
            "abstraction": 1,
            "8-puzzle": 1,
            "action": 2,
            "abstracted": 2,
            "beginning": 1,
            "final": 1,
            "state": 1,
            "ignoring": 1,
            "intermediate": 1,
            "location": 1,
            "sliding": 1,
            "shaking": 1,
            "board": 1,
            "tile": 2,
            "get": 1,
            "stuck": 1,
            "ruled": 1,
            "extracting": 1,
            "knife": 1,
            "putting": 1,
            "left": 1,
            "description": 1,
            "rule": 1,
            "avoiding": 1,
            "detail": 1,
            "physical": 1,
            "manipulation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para51",
          "content": "Our final standardized problem was devised by Donald Knuth (1964) and illustrates how infinite state spaces can arise. Knuth conjectured that starting with the number 4, a sequence\nof square root, floor, and factorial operations can reach any desired positive integer. For example, we can reach 5 from 4 as follows:\n⌊\n(\n4\n!",
          "sentence_count": 3,
          "char_count": 274,
          "prev_para_id": "chap3_para50",
          "next_para_id": "chap3_para52",
          "style_metadata": {
            "para_id": "chap3_para51",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.33,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 3
          },
          "terminology": {
            "final": 1,
            "standardized": 1,
            "problem": 1,
            "devised": 1,
            "donald": 1,
            "knuth": 2,
            "illustrates": 1,
            "infinite": 1,
            "state": 1,
            "space": 1,
            "arise": 1,
            "conjectured": 1,
            "starting": 1,
            "number": 1,
            "sequence": 1,
            "square": 1,
            "root": 1,
            "floor": 1,
            "factorial": 1,
            "operation": 1,
            "reach": 2,
            "desired": 1,
            "positive": 1,
            "integer": 1,
            "example": 1,
            "follows": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para51",
              "entity_text": "Donald Knuth",
              "entity_type": "PERSON",
              "start_char": 46,
              "end_char": 58,
              "context": "Our final standardized problem was devised by Donald Knuth (1964) and illustrates how infinite state spaces "
            },
            {
              "para_id": "chap3_para51",
              "entity_text": "Knuth",
              "entity_type": "ORG",
              "start_char": 119,
              "end_char": 124,
              "context": " illustrates how infinite state spaces can arise. Knuth conjectured that starting with the number 4, a se"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para52",
          "content": ")\n!",
          "sentence_count": 1,
          "char_count": 3,
          "prev_para_id": "chap3_para51",
          "next_para_id": "chap3_para53",
          "style_metadata": {
            "para_id": "chap3_para52",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 2.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 2,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para53",
          "content": "⌋\n=\n5.",
          "sentence_count": 1,
          "char_count": 6,
          "prev_para_id": "chap3_para52",
          "next_para_id": "chap3_para54",
          "style_metadata": {
            "para_id": "chap3_para53",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para54",
          "content": "The problem definition is simple:\n•\nStates:\nPositive real numbers.",
          "sentence_count": 1,
          "char_count": 60,
          "prev_para_id": "chap3_para53",
          "next_para_id": "chap3_para55",
          "style_metadata": {
            "para_id": "chap3_para54",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "problem": 1,
            "definition": 1,
            "simple": 1,
            "state": 1,
            "positive": 1,
            "real": 1,
            "number": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para55",
          "content": "•\nInitial state:\n4.",
          "sentence_count": 1,
          "char_count": 18,
          "prev_para_id": "chap3_para54",
          "next_para_id": "chap3_para56",
          "style_metadata": {
            "para_id": "chap3_para55",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 6,
            "sentence_count": 1
          },
          "terminology": {
            "initial": 1,
            "state": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para56",
          "content": "•\nActions:\nApply square root, floor, or factorial operation (factorial for integers only).",
          "sentence_count": 1,
          "char_count": 80,
          "prev_para_id": "chap3_para55",
          "next_para_id": "chap3_para57",
          "style_metadata": {
            "para_id": "chap3_para56",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "action": 1,
            "apply": 1,
            "square": 1,
            "root": 1,
            "floor": 1,
            "factorial": 2,
            "operation": 1,
            "integer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para57",
          "content": "•\nTransition model:\nAs given by the mathematical definitions of the operations.",
          "sentence_count": 1,
          "char_count": 70,
          "prev_para_id": "chap3_para56",
          "next_para_id": "chap3_para58",
          "style_metadata": {
            "para_id": "chap3_para57",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "transition": 1,
            "model": 1,
            "given": 1,
            "mathematical": 1,
            "definition": 1,
            "operation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para58",
          "content": "•\nGoal state:\nThe desired positive integer.",
          "sentence_count": 1,
          "char_count": 39,
          "prev_para_id": "chap3_para57",
          "next_para_id": "chap3_para59",
          "style_metadata": {
            "para_id": "chap3_para58",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "goal": 1,
            "state": 1,
            "desired": 1,
            "positive": 1,
            "integer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para59",
          "content": "•\nAction cost:\nEach action costs 1.",
          "sentence_count": 1,
          "char_count": 31,
          "prev_para_id": "chap3_para58",
          "next_para_id": "chap3_para60",
          "style_metadata": {
            "para_id": "chap3_para59",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "action": 2,
            "cost": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para60",
          "content": "The state space for this problem is infinite: for any integer greater than 2 the factorial operator will always yield a larger integer. The problem is interesting because it explores very large numbers: the shortest path to 5 goes through (4!)! = 620,448,401,733,239,439,360,000. Infinite state spaces arise frequently in tasks involving the generation of mathematical expressions, circuits, proofs, programs, and other recursively defined objects.",
          "sentence_count": 4,
          "char_count": 385,
          "prev_para_id": "chap3_para59",
          "next_para_id": "chap3_para61",
          "style_metadata": {
            "para_id": "chap3_para60",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 4
          },
          "terminology": {
            "state": 2,
            "space": 2,
            "problem": 2,
            "infinite": 2,
            "integer": 2,
            "greater": 1,
            "factorial": 1,
            "operator": 1,
            "larger": 1,
            "interesting": 1,
            "explores": 1,
            "large": 1,
            "number": 1,
            "shortest": 1,
            "path": 1,
            "go": 1,
            "arise": 1,
            "task": 1,
            "involving": 1,
            "generation": 1,
            "mathematical": 1,
            "expression": 1,
            "circuit": 1,
            "proof": 1,
            "program": 1,
            "defined": 1,
            "object": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para61",
          "content": "3.2.2\nReal-world problems\nWe have already seen how the\nroute-finding problem\nis defined in terms of specified locations and transitions along edges between them. Route-finding algorithms are used in a variety of applications. Some, such as Web sites and in-car systems that provide driving directions, are relatively straightforward extensions of the Romania example. (The main complications are varying costs due to traffic-dependent delays, and rerouting due to road closures.) Others, such as routing video streams in computer networks, military operations planning, and airline travel-planning systems, involve much more complex specifications. Consider the airline travel problems that must be solved by a travel-planning Web site:\n•\nStates:\nEach state obviously includes a location (e.g., an airport) and the current time. Furthermore, because the cost of an action (a flight segment) may depend on previous segments, their fare bases, and their status as domestic or international, the state must record extra information about these “historical” aspects.",
          "sentence_count": 7,
          "char_count": 916,
          "prev_para_id": "chap3_para60",
          "next_para_id": "chap3_para62",
          "style_metadata": {
            "para_id": "chap3_para61",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 26.14,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore"
            ],
            "word_count": 183,
            "sentence_count": 7
          },
          "terminology": {
            "real-world": 1,
            "problem": 3,
            "seen": 1,
            "route-finding": 2,
            "defined": 1,
            "term": 1,
            "specified": 1,
            "location": 2,
            "transition": 1,
            "edge": 1,
            "algorithm": 1,
            "used": 1,
            "variety": 1,
            "application": 1,
            "web": 2,
            "site": 2,
            "in-car": 1,
            "system": 2,
            "driving": 1,
            "direction": 1,
            "straightforward": 1,
            "extension": 1,
            "romania": 1,
            "example": 1,
            "main": 1,
            "complication": 1,
            "varying": 1,
            "cost": 2,
            "due": 2,
            "traffic-dependent": 1,
            "delay": 1,
            "rerouting": 1,
            "road": 1,
            "closure": 1,
            "others": 1,
            "routing": 1,
            "video": 1,
            "stream": 1,
            "computer": 1,
            "network": 1,
            "military": 1,
            "operation": 1,
            "planning": 1,
            "airline": 2,
            "travel-planning": 2,
            "involve": 1,
            "much": 1,
            "complex": 1,
            "specification": 1,
            "consider": 1,
            "travel": 1,
            "solved": 1,
            "state": 3,
            "includes": 1,
            "airport": 1,
            "current": 1,
            "time": 1,
            "furthermore": 1,
            "action": 1,
            "flight": 1,
            "segment": 2,
            "depend": 1,
            "previous": 1,
            "fare": 1,
            "base": 1,
            "status": 1,
            "domestic": 1,
            "international": 1,
            "record": 1,
            "extra": 1,
            "information": 1,
            "historical": 1,
            "aspect": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para61",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 351,
              "end_char": 358,
              "context": " are relatively straightforward extensions of the Romania example. (The main complications are varying cost"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para62",
          "content": "•\nInitial state:\nThe user’s home airport.",
          "sentence_count": 1,
          "char_count": 37,
          "prev_para_id": "chap3_para61",
          "next_para_id": "chap3_para63",
          "style_metadata": {
            "para_id": "chap3_para62",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "initial": 1,
            "state": 1,
            "user": 1,
            "home": 1,
            "airport": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para63",
          "content": "•\nActions:\nTake any flight from the current location, in any seat class, leaving after the current time, leaving enough time for within-airport transfer if needed.",
          "sentence_count": 1,
          "char_count": 140,
          "prev_para_id": "chap3_para62",
          "next_para_id": "chap3_para64",
          "style_metadata": {
            "para_id": "chap3_para63",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "action": 1,
            "take": 1,
            "flight": 1,
            "current": 2,
            "location": 1,
            "seat": 1,
            "class": 1,
            "leaving": 2,
            "time": 2,
            "enough": 1,
            "within-airport": 1,
            "transfer": 1,
            "needed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para64",
          "content": "•\nTransition model:\nThe state resulting from taking a flight will have the flight’s destination as the new location and the flight’s arrival time as the new time.",
          "sentence_count": 1,
          "char_count": 137,
          "prev_para_id": "chap3_para63",
          "next_para_id": "chap3_para65",
          "style_metadata": {
            "para_id": "chap3_para64",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "transition": 1,
            "model": 1,
            "state": 1,
            "resulting": 1,
            "taking": 1,
            "flight": 3,
            "destination": 1,
            "new": 2,
            "location": 1,
            "arrival": 1,
            "time": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para65",
          "content": "•\nGoal state:\nA destination city. Sometimes the goal can be more complex, such as “arrive at the destination on a nonstop flight.”\n•\nAction cost:\nA combination of monetary cost, waiting time, flight time, customs and immigration procedures, seat quality, time of day, type of airplane, frequent-flyer reward points, and so on.",
          "sentence_count": 2,
          "char_count": 279,
          "prev_para_id": "chap3_para64",
          "next_para_id": "chap3_para66",
          "style_metadata": {
            "para_id": "chap3_para65",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 2
          },
          "terminology": {
            "goal": 2,
            "state": 1,
            "destination": 2,
            "city": 1,
            "complex": 1,
            "arrive": 1,
            "nonstop": 1,
            "flight.": 1,
            "action": 1,
            "cost": 2,
            "combination": 1,
            "monetary": 1,
            "waiting": 1,
            "time": 3,
            "flight": 1,
            "custom": 1,
            "immigration": 1,
            "procedure": 1,
            "seat": 1,
            "quality": 1,
            "day": 1,
            "type": 1,
            "airplane": 1,
            "frequent-flyer": 1,
            "reward": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para66",
          "content": "Commercial travel advice systems use a problem formulation of this kind, with many additional complications to handle the airlines’ byzantine fare structures. Any seasoned traveler knows, however, that not all air travel goes according to plan. A really good system should include contingency plans—what happens if this flight is delayed and the connection is missed?",
          "sentence_count": 3,
          "char_count": 313,
          "prev_para_id": "chap3_para65",
          "next_para_id": "chap3_para67",
          "style_metadata": {
            "para_id": "chap3_para66",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 20.67,
            "passive_voice_ratio": 0.032,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 62,
            "sentence_count": 3
          },
          "terminology": {
            "commercial": 1,
            "travel": 2,
            "advice": 1,
            "system": 2,
            "use": 1,
            "problem": 1,
            "formulation": 1,
            "kind": 1,
            "many": 1,
            "additional": 1,
            "complication": 1,
            "handle": 1,
            "airline": 1,
            "byzantine": 1,
            "fare": 1,
            "structure": 1,
            "seasoned": 1,
            "traveler": 1,
            "know": 1,
            "air": 1,
            "go": 1,
            "according": 1,
            "plan": 1,
            "good": 1,
            "include": 1,
            "contingency": 1,
            "happens": 1,
            "flight": 1,
            "delayed": 1,
            "connection": 1,
            "missed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para67",
          "content": "Touring problems\ndescribe a set of locations that must be visited, rather than a single goal destination. The\ntraveling salesperson problem (TSP)\nis a touring problem in which every city on a map must be visited. The aim is to find a tour with cost <\nC\n(or in the optimization version, to find a tour with the lowest cost possible). An enormous amount of effort has been expended to improve the capabilities of TSP algorithms. The algorithms can also be extended to handle fleets of vehicles. For example, a search and optimization algorithm for routing school buses in Boston saved $5 million, cut traffic and air pollution, and saved time for drivers and students (Bertsimas\net al.,\n2019). In addition to planning trips, search algorithms have been used for tasks such as planning the movements of automatic circuit-board drills and of stocking machines on shop floors.",
          "sentence_count": 7,
          "char_count": 732,
          "prev_para_id": "chap3_para66",
          "next_para_id": "chap3_para68",
          "style_metadata": {
            "para_id": "chap3_para67",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 168,
            "sentence_count": 7
          },
          "terminology": {
            "touring": 2,
            "problem": 3,
            "describe": 1,
            "set": 1,
            "location": 1,
            "visited": 2,
            "single": 1,
            "goal": 1,
            "destination": 1,
            "traveling": 1,
            "salesperson": 1,
            "tsp": 2,
            "city": 1,
            "map": 1,
            "aim": 1,
            "find": 2,
            "tour": 2,
            "cost": 2,
            "optimization": 2,
            "version": 1,
            "lowest": 1,
            "possible": 1,
            "enormous": 1,
            "amount": 1,
            "effort": 1,
            "expended": 1,
            "improve": 1,
            "capability": 1,
            "algorithm": 3,
            "extended": 1,
            "handle": 1,
            "fleet": 1,
            "vehicle": 1,
            "example": 1,
            "search": 2,
            "routing": 1,
            "school": 1,
            "bus": 1,
            "boston": 1,
            "saved": 2,
            "cut": 1,
            "traffic": 1,
            "air": 1,
            "pollution": 1,
            "time": 1,
            "driver": 1,
            "student": 1,
            "bertsimas": 1,
            "al.": 1,
            "addition": 1,
            "planning": 2,
            "trip": 1,
            "used": 1,
            "task": 1,
            "movement": 1,
            "automatic": 1,
            "circuit-board": 1,
            "drill": 1,
            "stocking": 1,
            "machine": 1,
            "shop": 1,
            "floor": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para67",
              "entity_text": "Boston",
              "entity_type": "GPE",
              "start_char": 570,
              "end_char": 576,
              "context": "ptimization algorithm for routing school buses in Boston saved $5 million, cut traffic and air pollution, "
            },
            {
              "para_id": "chap3_para67",
              "entity_text": "Bertsimas",
              "entity_type": "PERSON",
              "start_char": 667,
              "end_char": 676,
              "context": "llution, and saved time for drivers and students (Bertsimas\net al.,\n2019). In addition to planning trips, sea"
            },
            {
              "para_id": "chap3_para67",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 680,
              "end_char": 683,
              "context": "saved time for drivers and students (Bertsimas\net al.,\n2019). In addition to planning trips, search alg"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para68",
          "content": "A\nVLSI layout\nproblem requires positioning millions of components and connections on a chip to minimize area, minimize circuit delays, minimize stray capacitances, and maximize manufacturing yield. The layout problem comes after the logical design phase and is usually split into two parts:\ncell layout\nand\nchannel routing\n. In cell layout, the primitive components of the circuit are grouped into cells, each of which performs some recognized function. Each cell has a fixed footprint (size and shape) and requires a certain number of connections to each of the other cells. The aim is to place the cells on the chip so that they do not overlap and so that there is room for the connecting wires to be placed between the cells. Channel routing finds a specific route for each wire through the gaps between the cells. These search problems are extremely complex, but definitely worth solving.",
          "sentence_count": 7,
          "char_count": 751,
          "prev_para_id": "chap3_para67",
          "next_para_id": "chap3_para69",
          "style_metadata": {
            "para_id": "chap3_para68",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.29,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 163,
            "sentence_count": 7
          },
          "terminology": {
            "vlsi": 1,
            "layout": 2,
            "problem": 3,
            "requires": 2,
            "positioning": 1,
            "million": 1,
            "component": 2,
            "connection": 2,
            "chip": 2,
            "minimize": 3,
            "area": 1,
            "circuit": 2,
            "delay": 1,
            "stray": 1,
            "capacitance": 1,
            "maximize": 1,
            "manufacturing": 1,
            "yield": 1,
            "come": 1,
            "logical": 1,
            "design": 1,
            "phase": 1,
            "split": 1,
            "part": 1,
            "cell": 8,
            "channel": 2,
            "routing": 2,
            "primitive": 1,
            "grouped": 1,
            "performs": 1,
            "recognized": 1,
            "function": 1,
            "fixed": 1,
            "footprint": 1,
            "size": 1,
            "shape": 1,
            "certain": 1,
            "number": 1,
            "aim": 1,
            "place": 1,
            "overlap": 1,
            "room": 1,
            "connecting": 1,
            "wire": 2,
            "placed": 1,
            "find": 1,
            "specific": 1,
            "route": 1,
            "gap": 1,
            "search": 1,
            "complex": 1,
            "solving": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para69",
          "content": "Robot navigation\nis a generalization of the route-finding problem described earlier. Rather than following distinct paths (such as the roads in Romania), a robot can roam around, in effect making its own paths. For a circular robot moving on a flat surface, the space is essentially two-dimensional. When the robot has arms and legs that must also be controlled, the search space becomes many-dimensional—one dimension for each joint angle. Advanced techniques are required just to make the essentially continuous search space finite (see\nChapter 26\n). In addition to the complexity of the problem, real robots must also deal with errors in their sensor readings and motor controls, with partial observability, and with other agents that might alter the environment.",
          "sentence_count": 6,
          "char_count": 650,
          "prev_para_id": "chap3_para68",
          "next_para_id": "chap3_para70",
          "style_metadata": {
            "para_id": "chap3_para69",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 6
          },
          "terminology": {
            "robot": 5,
            "navigation": 1,
            "generalization": 1,
            "route-finding": 1,
            "problem": 2,
            "described": 1,
            "following": 1,
            "distinct": 1,
            "path": 2,
            "road": 1,
            "romania": 1,
            "roam": 1,
            "effect": 1,
            "making": 1,
            "circular": 1,
            "moving": 1,
            "flat": 1,
            "surface": 1,
            "space": 3,
            "two-dimensional": 1,
            "arm": 1,
            "leg": 1,
            "controlled": 1,
            "search": 2,
            "becomes": 1,
            "many-dimensional—one": 1,
            "dimension": 1,
            "joint": 1,
            "angle": 1,
            "advanced": 1,
            "technique": 1,
            "required": 1,
            "make": 1,
            "continuous": 1,
            "finite": 1,
            "see": 1,
            "chapter": 1,
            "addition": 1,
            "complexity": 1,
            "real": 1,
            "deal": 1,
            "error": 1,
            "sensor": 1,
            "reading": 1,
            "motor": 1,
            "control": 1,
            "partial": 1,
            "observability": 1,
            "agent": 1,
            "alter": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para69",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 144,
              "end_char": 151,
              "context": "an following distinct paths (such as the roads in Romania), a robot can roam around, in effect making its o"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para70",
          "content": "Automatic assembly sequencing\nof complex objects (such as electric motors) by a robot has been standard industry practice since the 1970s. Algorithms first find a feasible assembly sequence and then work to optimize the process. Minimizing the amount of manual human labor on the assembly line can produce significant savings in time and cost. In assembly problems, the aim is to find an order in which to assemble the parts of some object. If the wrong order is chosen, there will be no way to add some part later in the sequence without undoing some of the work already done. Checking an action in the sequence for feasibility is a difficult geometrical search problem closely related to robot navigation. Thus, the generation of legal actions is the expensive part of assembly sequencing. Any practical algorithm must avoid exploring all but a tiny fraction of the state space. One important assembly problem is\nprotein design\n, in which the goal is to find a sequence of amino acids that will fold into a three-dimensional protein with the right properties to cure some disease.",
          "sentence_count": 9,
          "char_count": 904,
          "prev_para_id": "chap3_para69",
          "next_para_id": "chap3_para71",
          "style_metadata": {
            "para_id": "chap3_para70",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.78,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 196,
            "sentence_count": 9
          },
          "terminology": {
            "automatic": 1,
            "assembly": 4,
            "sequencing": 2,
            "complex": 1,
            "object": 2,
            "electric": 1,
            "motor": 1,
            "robot": 2,
            "standard": 1,
            "industry": 1,
            "practice": 1,
            "algorithm": 2,
            "first": 1,
            "find": 3,
            "feasible": 1,
            "sequence": 4,
            "work": 2,
            "optimize": 1,
            "process": 1,
            "minimizing": 1,
            "amount": 1,
            "manual": 1,
            "human": 1,
            "labor": 1,
            "line": 1,
            "produce": 1,
            "significant": 1,
            "saving": 1,
            "time": 1,
            "cost": 1,
            "problem": 3,
            "aim": 1,
            "order": 2,
            "assemble": 1,
            "part": 3,
            "wrong": 1,
            "chosen": 1,
            "way": 1,
            "undoing": 1,
            "done": 1,
            "checking": 1,
            "action": 2,
            "feasibility": 1,
            "difficult": 1,
            "geometrical": 1,
            "search": 1,
            "related": 1,
            "navigation": 1,
            "generation": 1,
            "legal": 1,
            "expensive": 1,
            "practical": 1,
            "avoid": 1,
            "exploring": 1,
            "tiny": 1,
            "fraction": 1,
            "state": 1,
            "space": 1,
            "important": 1,
            "protein": 2,
            "design": 1,
            "goal": 1,
            "amino": 1,
            "acid": 1,
            "fold": 1,
            "three-dimensional": 1,
            "right": 1,
            "property": 1,
            "cure": 1,
            "disease": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para70",
              "entity_text": "Automatic",
              "entity_type": "GPE",
              "start_char": 0,
              "end_char": 9,
              "context": "Automatic assembly sequencing\nof complex objects (such as e"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para71",
          "content": "3.3Search Algorithms\n3.3\nSearch Algorithms\nA\nsearch algorithm\ntakes a search problem as input and returns a solution, or an indication of failure. In this chapter we consider algorithms that superimpose a\nsearch tree\nover the state-space graph, forming various paths from the initial state, trying to find a path that reaches a goal state. Each\nnode\nin the search tree corresponds to a state in the state space and the edges in the search tree correspond to actions. The root of the tree corresponds to the initial state of the problem.",
          "sentence_count": 4,
          "char_count": 454,
          "prev_para_id": "chap3_para70",
          "next_para_id": "chap3_para72",
          "style_metadata": {
            "para_id": "chap3_para71",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 4
          },
          "terminology": {
            "algorithm": 4,
            "search": 6,
            "take": 1,
            "problem": 2,
            "input": 1,
            "return": 1,
            "solution": 1,
            "indication": 1,
            "failure": 1,
            "chapter": 1,
            "consider": 1,
            "superimpose": 1,
            "tree": 4,
            "state-space": 1,
            "graph": 1,
            "forming": 1,
            "various": 1,
            "path": 2,
            "initial": 2,
            "state": 5,
            "trying": 1,
            "find": 1,
            "reach": 1,
            "goal": 1,
            "node": 1,
            "corresponds": 2,
            "space": 1,
            "edge": 1,
            "correspond": 1,
            "action": 1,
            "root": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para71",
              "entity_text": "Algorithms",
              "entity_type": "PERSON",
              "start_char": 10,
              "end_char": 20,
              "context": "3.3Search Algorithms\n3.3\nSearch Algorithms\nA\nsearch algorithm\ntakes a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para72",
          "content": "It is important to understand the distinction between the state space and the search tree. The state space describes the (possibly infinite) set of states in the world, and the actions that allow transitions from one state to another. The search tree describes paths between these states, reaching towards the goal. The search tree may have multiple paths to (and thus multiple nodes for) any given state, but each node in the tree has a unique path back to the root (as in all trees).",
          "sentence_count": 4,
          "char_count": 401,
          "prev_para_id": "chap3_para71",
          "next_para_id": "chap3_para73",
          "style_metadata": {
            "para_id": "chap3_para72",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 98,
            "sentence_count": 4
          },
          "terminology": {
            "important": 1,
            "understand": 1,
            "distinction": 1,
            "state": 6,
            "space": 2,
            "search": 3,
            "tree": 5,
            "describes": 2,
            "infinite": 1,
            "set": 1,
            "world": 1,
            "action": 1,
            "allow": 1,
            "transition": 1,
            "path": 3,
            "reaching": 1,
            "towards": 1,
            "goal": 1,
            "multiple": 2,
            "node": 2,
            "given": 1,
            "unique": 1,
            "root": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para73",
          "content": "Figure 3.4\nshows the first few steps in finding a path from Arad to Bucharest. The root node of the search tree is at the initial state,\nArad.",
          "sentence_count": 2,
          "char_count": 117,
          "prev_para_id": "chap3_para72",
          "next_para_id": "chap3_para74",
          "style_metadata": {
            "para_id": "chap3_para73",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "first": 1,
            "step": 1,
            "finding": 1,
            "path": 1,
            "arad": 2,
            "bucharest": 1,
            "root": 1,
            "node": 1,
            "search": 1,
            "tree": 1,
            "initial": 1,
            "state": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para73",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 60,
              "end_char": 64,
              "context": "\nshows the first few steps in finding a path from Arad to Bucharest. The root node of the search tree is"
            },
            {
              "para_id": "chap3_para73",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 137,
              "end_char": 141,
              "context": " node of the search tree is at the initial state,\nArad."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para74",
          "content": "We can\nexpand\nthe node, by considering\nthe available A\nCTIONS\nfor that state, using the R\nESULT\nfunction to see where those actions lead to, and\ngenerating\na new node (called a\nchild node\nor\nsuccessor node\n) for each of the resulting states. Each child node has\nArad\nas its\nparent node\n.",
          "sentence_count": 2,
          "char_count": 250,
          "prev_para_id": "chap3_para73",
          "next_para_id": "chap3_para75",
          "style_metadata": {
            "para_id": "chap3_para74",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 60,
            "sentence_count": 2
          },
          "terminology": {
            "expand": 1,
            "node": 5,
            "considering": 1,
            "available": 1,
            "ctions": 1,
            "state": 2,
            "using": 1,
            "esult": 1,
            "function": 1,
            "see": 1,
            "action": 1,
            "lead": 1,
            "generating": 1,
            "new": 1,
            "called": 1,
            "child": 2,
            "successor": 1,
            "resulting": 1,
            "arad": 1,
            "parent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para74",
              "entity_text": "node\n",
              "entity_type": "PERSON",
              "start_char": 201,
              "end_char": 206,
              "context": "ting\na new node (called a\nchild node\nor\nsuccessor node\n) for each of the resulting states. Each child nod"
            },
            {
              "para_id": "chap3_para74",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 262,
              "end_char": 266,
              "context": "each of the resulting states. Each child node has\nArad\nas its\nparent node\n."
            },
            {
              "para_id": "chap3_para74",
              "entity_text": "node\n",
              "entity_type": "PERSON",
              "start_char": 281,
              "end_char": 286,
              "context": "ng states. Each child node has\nArad\nas its\nparent node\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para75",
          "content": "Description\nSearch tree 1: The root node is lavender-colored and all other nodes are in faint dashed lines. Root node Arad has three child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child nodes: Arad and Lugoj. Node Zerind has two child nodes: Arad and Oradea. Search tree 2: The root node is lavender colored. Root node Arad has three green-colored child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes in faint dashed lines: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in faint dashed lines: Arad and Oradea. Search tree 3: The root node is lavender colored. Root node Arad has three child nodes: lavender-colored Sibiu, green-colored Timisoara, and green-colored Zerind. Node Sibiu has four green-colored child nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in faint dashed lines: Arad and Oradea.",
          "sentence_count": 15,
          "char_count": 946,
          "prev_para_id": "chap3_para74",
          "next_para_id": "chap3_para76",
          "style_metadata": {
            "para_id": "chap3_para75",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.27,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 229,
            "sentence_count": 15
          },
          "terminology": {
            "description": 1,
            "search": 3,
            "tree": 3,
            "root": 6,
            "node": 28,
            "lavender-colored": 2,
            "faint": 6,
            "dashed": 6,
            "line": 6,
            "child": 12,
            "sibiu": 6,
            "timisoara": 6,
            "zerind": 6,
            "arad": 6,
            "fagaras": 3,
            "oradea": 6,
            "rimnicu": 3,
            "vilcea": 3,
            "lugoj": 3,
            "lavender": 2,
            "colored": 2,
            "green-colored": 4,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para75",
              "entity_text": "Root node Arad",
              "entity_type": "PERSON",
              "start_char": 108,
              "end_char": 122,
              "context": "ed and all other nodes are in faint dashed lines. Root node Arad has three child nodes: Sibiu, Timisoara, and Zeri"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 146,
              "end_char": 151,
              "context": "shed lines. Root node Arad has three child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 153,
              "end_char": 162,
              "context": "nes. Root node Arad has three child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes: Ara"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 168,
              "end_char": 174,
              "context": "Arad has three child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes: Arad, Fagaras, "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Sibiu",
              "entity_type": "PERSON",
              "start_char": 176,
              "end_char": 186,
              "context": " three child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes: Arad, Fagaras, Oradea, and "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 209,
              "end_char": 213,
              "context": "ara, and Zerind. Node Sibiu has four child nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timiso"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 224,
              "end_char": 230,
              "context": ". Node Sibiu has four child nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Timisoara",
              "entity_type": "PERSON",
              "start_char": 252,
              "end_char": 266,
              "context": "nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child nodes: Arad and Lugoj. Node Zerind "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 288,
              "end_char": 292,
              "context": "mnicu Vilcea. Node Timisoara has two child nodes: Arad and Lugoj. Node Zerind has two child nodes: Arad "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 297,
              "end_char": 302,
              "context": "cea. Node Timisoara has two child nodes: Arad and Lugoj. Node Zerind has two child nodes: Arad and Oradea"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Zerind",
              "entity_type": "PERSON",
              "start_char": 304,
              "end_char": 315,
              "context": "de Timisoara has two child nodes: Arad and Lugoj. Node Zerind has two child nodes: Arad and Oradea. Search tree"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 337,
              "end_char": 341,
              "context": " Arad and Lugoj. Node Zerind has two child nodes: Arad and Oradea. Search tree 2: The root node is laven"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 346,
              "end_char": 352,
              "context": " Lugoj. Node Zerind has two child nodes: Arad and Oradea. Search tree 2: The root node is lavender colored"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Root node Arad",
              "entity_type": "PERSON",
              "start_char": 404,
              "end_char": 418,
              "context": "Search tree 2: The root node is lavender colored. Root node Arad has three green-colored child nodes: Sibiu, Timis"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 456,
              "end_char": 461,
              "context": "ot node Arad has three green-colored child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 463,
              "end_char": 472,
              "context": " Arad has three green-colored child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes in f"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 478,
              "end_char": 484,
              "context": " green-colored child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes in faint dashed "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Sibiu",
              "entity_type": "PERSON",
              "start_char": 486,
              "end_char": 496,
              "context": "olored child nodes: Sibiu, Timisoara, and Zerind. Node Sibiu has four child nodes in faint dashed lines: Arad,"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 541,
              "end_char": 545,
              "context": "Sibiu has four child nodes in faint dashed lines: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timiso"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 556,
              "end_char": 562,
              "context": "child nodes in faint dashed lines: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Timisoara",
              "entity_type": "PERSON",
              "start_char": 584,
              "end_char": 598,
              "context": "lines: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child nodes in faint dashed lines: Arad a"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 642,
              "end_char": 646,
              "context": "isoara has two child nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in fai"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 651,
              "end_char": 656,
              "context": "s two child nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in faint dashed "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Zerind",
              "entity_type": "PERSON",
              "start_char": 658,
              "end_char": 669,
              "context": "hild nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in faint dashed lines: Arad a"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 713,
              "end_char": 717,
              "context": "Zerind has two child nodes in faint dashed lines: Arad and Oradea. Search tree 3: The root node is laven"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 722,
              "end_char": 728,
              "context": "s two child nodes in faint dashed lines: Arad and Oradea. Search tree 3: The root node is lavender colored"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Root node Arad",
              "entity_type": "PERSON",
              "start_char": 780,
              "end_char": 794,
              "context": "Search tree 3: The root node is lavender colored. Root node Arad has three child nodes: lavender-colored Sibiu, gr"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 835,
              "end_char": 840,
              "context": "node Arad has three child nodes: lavender-colored Sibiu, green-colored Timisoara, and green-colored Zerin"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 856,
              "end_char": 865,
              "context": "hild nodes: lavender-colored Sibiu, green-colored Timisoara, and green-colored Zerind. Node Sibiu has four gr"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 885,
              "end_char": 891,
              "context": "Sibiu, green-colored Timisoara, and green-colored Zerind. Node Sibiu has four green-colored child nodes: A"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Sibiu",
              "entity_type": "PERSON",
              "start_char": 893,
              "end_char": 903,
              "context": "reen-colored Timisoara, and green-colored Zerind. Node Sibiu has four green-colored child nodes: Arad, Fagaras"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 940,
              "end_char": 944,
              "context": "d. Node Sibiu has four green-colored child nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timiso"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 955,
              "end_char": 961,
              "context": "as four green-colored child nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Timisoara",
              "entity_type": "PERSON",
              "start_char": 983,
              "end_char": 997,
              "context": "nodes: Arad, Fagaras, Oradea, and Rimnicu Vilcea. Node Timisoara has two child nodes in faint dashed lines: Arad a"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 1041,
              "end_char": 1045,
              "context": "isoara has two child nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in fai"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 1050,
              "end_char": 1055,
              "context": "s two child nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in faint dashed "
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Node Zerind",
              "entity_type": "PERSON",
              "start_char": 1057,
              "end_char": 1068,
              "context": "hild nodes in faint dashed lines: Arad and Lugoj. Node Zerind has two child nodes in faint dashed lines: Arad a"
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 1112,
              "end_char": 1116,
              "context": "Zerind has two child nodes in faint dashed lines: Arad and Oradea."
            },
            {
              "para_id": "chap3_para75",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 1121,
              "end_char": 1127,
              "context": "s two child nodes in faint dashed lines: Arad and Oradea."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para76",
          "content": "×\nFigure 3.4\nThree partial search trees for finding a route from Arad to Bucharest. Nodes that have been\nexpanded\nare lavender with bold letters; nodes on the frontier that have been\ngenerated\nbut not yet expanded are in green; the set of states corresponding to these two types of nodes are said to have been\nreached.",
          "sentence_count": 2,
          "char_count": 269,
          "prev_para_id": "chap3_para75",
          "next_para_id": "chap3_para77",
          "style_metadata": {
            "para_id": "chap3_para76",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "partial": 1,
            "search": 1,
            "tree": 1,
            "finding": 1,
            "route": 1,
            "arad": 1,
            "bucharest": 1,
            "node": 3,
            "expanded": 2,
            "lavender": 1,
            "bold": 1,
            "letter": 1,
            "generated": 1,
            "green": 1,
            "set": 1,
            "state": 1,
            "corresponding": 1,
            "type": 1,
            "said": 1,
            "reached": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para76",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 65,
              "end_char": 69,
              "context": "ree partial search trees for finding a route from Arad to Bucharest. Nodes that have been\nexpanded\nare l"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para77",
          "content": "Nodes that could be generated next are shown in faint dashed lines. Notice in the bottom tree there is a cycle from Arad to Sibiu to Arad; that can’t be an optimal path, so search should not continue from there.",
          "sentence_count": 2,
          "char_count": 172,
          "prev_para_id": "chap3_para76",
          "next_para_id": "chap3_para78",
          "style_metadata": {
            "para_id": "chap3_para77",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "node": 1,
            "generated": 1,
            "next": 1,
            "shown": 1,
            "faint": 1,
            "dashed": 1,
            "line": 1,
            "bottom": 1,
            "tree": 1,
            "cycle": 1,
            "arad": 2,
            "sibiu": 1,
            "optimal": 1,
            "path": 1,
            "search": 1,
            "continue": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para77",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 116,
              "end_char": 120,
              "context": ". Notice in the bottom tree there is a cycle from Arad to Sibiu to Arad; that can’t be an optimal path, "
            },
            {
              "para_id": "chap3_para77",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 124,
              "end_char": 129,
              "context": " in the bottom tree there is a cycle from Arad to Sibiu to Arad; that can’t be an optimal path, so search"
            },
            {
              "para_id": "chap3_para77",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 133,
              "end_char": 137,
              "context": "ottom tree there is a cycle from Arad to Sibiu to Arad; that can’t be an optimal path, so search should "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para78",
          "content": "Now we must choose which of these three child nodes to consider next. This is the essence of search—following up one option now and putting the others aside for later. Suppose we choose to expand Sibiu first.",
          "sentence_count": 3,
          "char_count": 172,
          "prev_para_id": "chap3_para77",
          "next_para_id": "chap3_para79",
          "style_metadata": {
            "para_id": "chap3_para78",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 3
          },
          "terminology": {
            "choose": 2,
            "child": 1,
            "node": 1,
            "consider": 1,
            "next": 1,
            "essence": 1,
            "search—following": 1,
            "option": 1,
            "putting": 1,
            "others": 1,
            "suppose": 1,
            "expand": 1,
            "sibiu": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para78",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 196,
              "end_char": 201,
              "context": "hers aside for later. Suppose we choose to expand Sibiu first."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para79",
          "content": "Figure 3.4\n(bottom) shows the result: a set of 6 unexpanded nodes (outlined in bold). We call this the\nfrontier\nof the search tree. We say that any state that has had a node generated for it has been\nreached\n(whether or not that node has been expanded).",
          "sentence_count": 3,
          "char_count": 211,
          "prev_para_id": "chap3_para78",
          "next_para_id": "chap3_para80",
          "style_metadata": {
            "para_id": "chap3_para79",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "bottom": 1,
            "show": 1,
            "result": 1,
            "set": 1,
            "unexpanded": 1,
            "node": 3,
            "outlined": 1,
            "bold": 1,
            "call": 1,
            "search": 1,
            "tree": 1,
            "say": 1,
            "state": 1,
            "generated": 1,
            "reached": 1,
            "expanded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para79",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 229,
              "end_char": 233,
              "context": "ated for it has been\nreached\n(whether or not that node has been expanded)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para80",
          "content": "5\nFigure 3.5\nshows the search tree superimposed on the state-space graph.",
          "sentence_count": 1,
          "char_count": 64,
          "prev_para_id": "chap3_para79",
          "next_para_id": "chap3_para81",
          "style_metadata": {
            "para_id": "chap3_para80",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "search": 1,
            "tree": 1,
            "superimposed": 1,
            "state-space": 1,
            "graph": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para81",
          "content": "Description\nIn all three parts, paths to Arad from Zerind, Sibiu, and Timisoara are highlighted and marked in red. Part 1: The highlighted paths are shown. Part 2: Paths in part 1 are shown. Additionally, paths to Sibiu from Fagaras and Rimnicu Vilcea are highlighted and marked in red. Paths to Zerind from Oradea and to Timisoara from Lugoj are highlighted and marked in red. Part 3: All paths in part 2 are shown. Additionally, paths to Lugoj from Mehadia and to Fagaras from Bucharest are highlighted and marked in red. Paths to Rimnicu Vilcea from Craiova and Pitesti are highlighted and marked in red.",
          "sentence_count": 8,
          "char_count": 504,
          "prev_para_id": "chap3_para80",
          "next_para_id": "chap3_para82",
          "style_metadata": {
            "para_id": "chap3_para81",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.12,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "part": 6,
            "path": 8,
            "zerind": 1,
            "sibiu": 2,
            "timisoara": 2,
            "highlighted": 6,
            "marked": 4,
            "red": 5,
            "shown": 3,
            "fagaras": 2,
            "rimnicu": 2,
            "oradea": 1,
            "lugoj": 2,
            "mehadia": 1,
            "vilcea": 1,
            "craiova": 1,
            "pitesti": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para81",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 41,
              "end_char": 45,
              "context": "Description\nIn all three parts, paths to Arad from Zerind, Sibiu, and Timisoara are highlighted"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Zerind",
              "entity_type": "GPE",
              "start_char": 51,
              "end_char": 57,
              "context": "escription\nIn all three parts, paths to Arad from Zerind, Sibiu, and Timisoara are highlighted and marked "
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 59,
              "end_char": 64,
              "context": "on\nIn all three parts, paths to Arad from Zerind, Sibiu, and Timisoara are highlighted and marked in red."
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 70,
              "end_char": 79,
              "context": "hree parts, paths to Arad from Zerind, Sibiu, and Timisoara are highlighted and marked in red. Part 1: The hi"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 214,
              "end_char": 219,
              "context": "Paths in part 1 are shown. Additionally, paths to Sibiu from Fagaras and Rimnicu Vilcea are highlighted a"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Fagaras",
              "entity_type": "GPE",
              "start_char": 225,
              "end_char": 232,
              "context": "rt 1 are shown. Additionally, paths to Sibiu from Fagaras and Rimnicu Vilcea are highlighted and marked in "
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 296,
              "end_char": 302,
              "context": "ilcea are highlighted and marked in red. Paths to Zerind from Oradea and to Timisoara from Lugoj are highl"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 308,
              "end_char": 314,
              "context": "ghlighted and marked in red. Paths to Zerind from Oradea and to Timisoara from Lugoj are highlighted and m"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 322,
              "end_char": 331,
              "context": "marked in red. Paths to Zerind from Oradea and to Timisoara from Lugoj are highlighted and marked in red. Par"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 337,
              "end_char": 342,
              "context": "Paths to Zerind from Oradea and to Timisoara from Lugoj are highlighted and marked in red. Part 3: All pa"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 440,
              "end_char": 445,
              "context": "paths in part 2 are shown. Additionally, paths to Lugoj from Mehadia and to Fagaras from Bucharest are hi"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Mehadia",
              "entity_type": "GPE",
              "start_char": 451,
              "end_char": 458,
              "context": "rt 2 are shown. Additionally, paths to Lugoj from Mehadia and to Fagaras from Bucharest are highlighted and"
            },
            {
              "para_id": "chap3_para81",
              "entity_text": "Craiova",
              "entity_type": "GPE",
              "start_char": 553,
              "end_char": 560,
              "context": "d and marked in red. Paths to Rimnicu Vilcea from Craiova and Pitesti are highlighted and marked in red."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para82",
          "content": "×\nFigure 3.5\nA sequence of search trees generated by a graph search on the Romania problem of\nFigure 3.1\n. At each stage, we have expanded every node on the frontier, extending every path with all applicable actions that don’t result in a state that has already been reached. Notice that at the third stage, the topmost city (Oradea) has two successors, both of which have already been reached by other paths, so no paths are extended from Oradea.",
          "sentence_count": 3,
          "char_count": 372,
          "prev_para_id": "chap3_para81",
          "next_para_id": "chap3_para83",
          "style_metadata": {
            "para_id": "chap3_para82",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 2,
            "sequence": 1,
            "search": 2,
            "tree": 1,
            "generated": 1,
            "graph": 1,
            "romania": 1,
            "problem": 1,
            "stage": 2,
            "expanded": 1,
            "node": 1,
            "extending": 1,
            "path": 3,
            "applicable": 1,
            "action": 1,
            "result": 1,
            "state": 1,
            "reached": 2,
            "notice": 1,
            "third": 1,
            "topmost": 1,
            "city": 1,
            "oradea": 2,
            "successor": 1,
            "extended": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para82",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 75,
              "end_char": 82,
              "context": "f search trees generated by a graph search on the Romania problem of\nFigure 3.1\n. At each stage, we have ex"
            },
            {
              "para_id": "chap3_para82",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 326,
              "end_char": 332,
              "context": "Notice that at the third stage, the topmost city (Oradea) has two successors, both of which have already b"
            },
            {
              "para_id": "chap3_para82",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 440,
              "end_char": 446,
              "context": "hed by other paths, so no paths are extended from Oradea."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para83",
          "content": "Note that the frontier\nseparates\ntwo regions of the state-space graph: an interior region where every state has been expanded, and an exterior region of states that have not yet been reached. This property is illustrated in\nFigure 3.6\n.",
          "sentence_count": 2,
          "char_count": 201,
          "prev_para_id": "chap3_para82",
          "next_para_id": "chap3_para84",
          "style_metadata": {
            "para_id": "chap3_para83",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.023,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 43,
            "sentence_count": 2
          },
          "terminology": {
            "note": 1,
            "frontier": 1,
            "separate": 1,
            "region": 3,
            "state-space": 1,
            "graph": 1,
            "interior": 1,
            "state": 2,
            "expanded": 1,
            "exterior": 1,
            "reached": 1,
            "property": 1,
            "illustrated": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para84",
          "content": "Description\nEach rectangular grid has 25 nodes made of five rows and five columns. Each row contains five nodes. The nodes are connected by the paths along the five vertical and five horizontal grid lines.",
          "sentence_count": 3,
          "char_count": 172,
          "prev_para_id": "chap3_para83",
          "next_para_id": "chap3_para85",
          "style_metadata": {
            "para_id": "chap3_para84",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 3
          },
          "terminology": {
            "description": 1,
            "rectangular": 1,
            "grid": 2,
            "node": 3,
            "made": 1,
            "row": 2,
            "column": 1,
            "contains": 1,
            "connected": 1,
            "path": 1,
            "vertical": 1,
            "horizontal": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para85",
          "content": "Part (“a”): The node in the third column of the third row is lavender-colored and the nodes that are vertically and horizontally adjacent to it are green-colored. The four paths between the lavender node and green nodes are colored in lavender. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 3,
          "char_count": 247,
          "prev_para_id": "chap3_para84",
          "next_para_id": "chap3_para86",
          "style_metadata": {
            "para_id": "chap3_para85",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "third": 2,
            "column": 1,
            "row": 1,
            "lavender-colored": 1,
            "node": 3,
            "adjacent": 1,
            "green-colored": 1,
            "path": 2,
            "green": 1,
            "colored": 1,
            "lavender": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para85",
              "entity_text": "node",
              "entity_type": "PERSON",
              "start_char": 199,
              "end_char": 203,
              "context": "reen-colored. The four paths between the lavender node and green nodes are colored in lavender. All othe"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para86",
          "content": "Part (b): The two nodes in the third column of the second and third rows are lavender-colored and each of the two has three green-colored adjacent nodes. The paths between the lavender nodes and the green nodes are colored in lavender. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 3,
          "char_count": 238,
          "prev_para_id": "chap3_para85",
          "next_para_id": "chap3_para87",
          "style_metadata": {
            "para_id": "chap3_para86",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "node": 5,
            "third": 2,
            "column": 1,
            "second": 1,
            "row": 1,
            "lavender-colored": 1,
            "green-colored": 1,
            "adjacent": 1,
            "path": 2,
            "lavender": 2,
            "green": 1,
            "colored": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para87",
          "content": "Part (c): Five nodes are lavender-colored and are in the following positions: rows 2, 3, and 4 of column 3, and columns 2 and 4 of row 3. The paths from the lavender node at column 3, row 3 to the other four lavender nodes are colored in lavender. The lavender node at row 2 column 3 has three green-colored nodes to the right, left, and top, and the paths from the lavender node to these green nodes are in lavender. The lavender node at row 3, column 4 has two green nodes to the right and below, and the paths from the lavender node to these green nodes are in lavender. The lavender node at row 4, column 3 has two green nodes to the left and below, and the paths from the lavender node to these green nodes are in lavender. The lavender node at row 3, column 2 has one green node to the left, and the path from the lavender node to this green node is in lavender. All other nodes and the paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 743,
          "prev_para_id": "chap3_para86",
          "next_para_id": "chap3_para88",
          "style_metadata": {
            "para_id": "chap3_para87",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 206,
            "sentence_count": 7
          },
          "terminology": {
            "part": 1,
            "node": 20,
            "lavender-colored": 1,
            "following": 1,
            "position": 1,
            "row": 7,
            "column": 7,
            "path": 6,
            "lavender": 15,
            "colored": 1,
            "green-colored": 1,
            "right": 2,
            "left": 3,
            "top": 1,
            "green": 7,
            "faint": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para88",
          "content": "×\nFigure 3.6\nThe separation property of graph search, illustrated on a rectangular-grid problem. The frontier (green) separates the interior (lavender) from the exterior (faint dashed). The frontier is the set of nodes (and corresponding states) that have been reached but not yet expanded; the interior is the set of nodes (and corresponding states) that have been expanded; and the exterior is the set of states that have not been reached. In (a), just the root has been expanded. In (b), the top frontier node is expanded. In (c), the remaining successors of the root are expanded in clockwise order.",
          "sentence_count": 6,
          "char_count": 506,
          "prev_para_id": "chap3_para87",
          "next_para_id": "chap3_para89",
          "style_metadata": {
            "para_id": "chap3_para88",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.33,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 6
          },
          "terminology": {
            "figure": 1,
            "separation": 1,
            "property": 1,
            "graph": 1,
            "search": 1,
            "illustrated": 1,
            "rectangular-grid": 1,
            "problem": 1,
            "frontier": 3,
            "green": 1,
            "separate": 1,
            "interior": 2,
            "lavender": 1,
            "exterior": 2,
            "faint": 1,
            "dashed": 1,
            "set": 3,
            "node": 3,
            "corresponding": 2,
            "state": 3,
            "reached": 2,
            "expanded": 5,
            "root": 2,
            "top": 1,
            "remaining": 1,
            "successor": 1,
            "clockwise": 1,
            "order": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para88",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 508,
              "end_char": 512,
              "context": " root has been expanded. In (b), the top frontier node is expanded. In (c), the remaining successors of "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para89",
          "content": "3.3.1\nBest-first search\nHow do we decide which node from the frontier to expand next? A very general approach is called\nbest-first search\n, in which we choose a node,\nn\n, with minimum value of some\nevaluation function\n,\nf\n(\nn\n)\n.",
          "sentence_count": 2,
          "char_count": 198,
          "prev_para_id": "chap3_para88",
          "next_para_id": "chap3_para90",
          "style_metadata": {
            "para_id": "chap3_para89",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.021,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 2
          },
          "terminology": {
            "best-first": 2,
            "search": 2,
            "decide": 1,
            "next": 1,
            "general": 1,
            "approach": 1,
            "called": 1,
            "choose": 1,
            "minimum": 1,
            "value": 1,
            "evaluation": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para89",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 47,
              "end_char": 51,
              "context": "3.3.1\nBest-first search\nHow do we decide which node from the frontier to expand next? A very general "
            },
            {
              "para_id": "chap3_para89",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 161,
              "end_char": 165,
              "context": "s called\nbest-first search\n, in which we choose a node,\nn\n, with minimum value of some\nevaluation functi"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para90",
          "content": "Figure 3.7\nshows the algorithm. On each iteration we choose a node on the frontier with minimum\nf\n(\nn\n) value, return it if its state is a goal state, and otherwise apply E\nXPAND\nto generate child nodes. Each child node is added to the frontier if it has not been reached before, or is re-added if it is now being reached with a path that has a lower path cost than any previous path. The algorithm returns either an indication of failure, or a node that represents a path to a goal. By employing different\nf\n(\nn\n) functions, we get different specific algorithms, which this chapter will cover.",
          "sentence_count": 5,
          "char_count": 493,
          "prev_para_id": "chap3_para89",
          "next_para_id": "chap3_para91",
          "style_metadata": {
            "para_id": "chap3_para90",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.8,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 124,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "algorithm": 3,
            "iteration": 1,
            "choose": 1,
            "node": 3,
            "minimum": 1,
            "value": 1,
            "return": 2,
            "state": 2,
            "goal": 2,
            "xpand": 1,
            "generate": 1,
            "child": 2,
            "added": 1,
            "frontier": 1,
            "reached": 2,
            "re-added": 1,
            "path": 4,
            "cost": 1,
            "previous": 1,
            "indication": 1,
            "failure": 1,
            "represents": 1,
            "employing": 1,
            "different": 2,
            "function": 1,
            "get": 1,
            "specific": 1,
            "chapter": 1,
            "cover": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para90",
              "entity_text": "XPAND",
              "entity_type": "PERSON",
              "start_char": 173,
              "end_char": 178,
              "context": " its state is a goal state, and otherwise apply E\nXPAND\nto generate child nodes. Each child node is added"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para91",
          "content": "Description\nAll the four binary trees have the root node labeled \"A\". Node \"A\" has two child nodes labeled B and C. Node B has two child nodes labeled D and E. Node C has two child nodes labeled F and G. Binary Tree 1: Node \"A\" is green-colored and a right arrowhead points to node \"A\". All other nodes and paths are in faint dashed lines. Binary Tree 2: Node \"A\" is lavender-colored. Nodes B and C are green-colored. The right arrowhead points to node B. The two paths from node \"A\" to B and C are solid lines. All other nodes and paths are in faint dashed lines. Binary Tree 3: Nodes \"A\" and B are lavender-colored. Nodes C, D, and E are green-colored. The right arrowhead points to node C. The two paths from node \"A\" to B and C are solid lines. The two paths from node B to D and E are solid lines as well. All other nodes and paths are in faint dashed lines. Binary Tree 4: Nodes \"A\", B, and C are lavender-colored. Other nodes are green-colored. The right arrowhead points to node D. All paths are solid lines.",
          "sentence_count": 16,
          "char_count": 821,
          "prev_para_id": "chap3_para90",
          "next_para_id": "chap3_para92",
          "style_metadata": {
            "para_id": "chap3_para91",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.88,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 238,
            "sentence_count": 16
          },
          "terminology": {
            "description": 1,
            "binary": 5,
            "tree": 5,
            "root": 1,
            "labeled": 4,
            "child": 3,
            "node": 12,
            "green-colored": 4,
            "right": 4,
            "arrowhead": 4,
            "point": 4,
            "path": 7,
            "dashed": 3,
            "line": 7,
            "lavender-colored": 3,
            "solid": 4,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para91",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 70,
              "end_char": 74,
              "context": "four binary trees have the root node labeled \"A\". Node \"A\" has two child nodes labeled B and C. Node B h"
            },
            {
              "para_id": "chap3_para91",
              "entity_text": "C. Node",
              "entity_type": "PERSON",
              "start_char": 113,
              "end_char": 120,
              "context": "d \"A\". Node \"A\" has two child nodes labeled B and C. Node B has two child nodes labeled D and E. Node C has"
            },
            {
              "para_id": "chap3_para91",
              "entity_text": "E. Node C",
              "entity_type": "PERSON",
              "start_char": 157,
              "end_char": 166,
              "context": "B and C. Node B has two child nodes labeled D and E. Node C has two child nodes labeled F and G. Binary Tree "
            },
            {
              "para_id": "chap3_para91",
              "entity_text": "F and G. Binary Tree 1",
              "entity_type": "PRODUCT",
              "start_char": 195,
              "end_char": 217,
              "context": "beled D and E. Node C has two child nodes labeled F and G. Binary Tree 1: Node \"A\" is green-colored and a right arrowhead "
            },
            {
              "para_id": "chap3_para91",
              "entity_text": "Binary Tree 2",
              "entity_type": "PERSON",
              "start_char": 340,
              "end_char": 353,
              "context": " other nodes and paths are in faint dashed lines. Binary Tree 2: Node \"A\" is lavender-colored. Nodes B and C are "
            },
            {
              "para_id": "chap3_para91",
              "entity_text": "Binary Tree",
              "entity_type": "PERSON",
              "start_char": 565,
              "end_char": 576,
              "context": " other nodes and paths are in faint dashed lines. Binary Tree 3: Nodes \"A\" and B are lavender-colored. Nodes C,"
            },
            {
              "para_id": "chap3_para91",
              "entity_text": "Binary Tree 4: Nodes",
              "entity_type": "PRODUCT",
              "start_char": 864,
              "end_char": 884,
              "context": " other nodes and paths are in faint dashed lines. Binary Tree 4: Nodes \"A\", B, and C are lavender-colored. Other nodes a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para92",
          "content": "×\nFigure 3.7\nThe best-first search algorithm, and the function for expanding a node. The data structures used here are described in\nSection 3.3.2\n. See\nAppendix B\nfor\nyield\n.",
          "sentence_count": 3,
          "char_count": 152,
          "prev_para_id": "chap3_para91",
          "next_para_id": "chap3_para93",
          "style_metadata": {
            "para_id": "chap3_para92",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "best-first": 1,
            "search": 1,
            "algorithm": 1,
            "function": 1,
            "expanding": 1,
            "node": 1,
            "data": 1,
            "structure": 1,
            "used": 1,
            "described": 1,
            "section": 1,
            "see": 1,
            "appendix": 1,
            "yield": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para92",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 79,
              "end_char": 83,
              "context": "earch algorithm, and the function for expanding a node. The data structures used here are described in\nS"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para93",
          "content": "3.3.2\nSearch data structures\nSearch algorithms require a data structure to keep track of the search tree. A\nnode\nin the tree is represented by a data structure with four components:\n•\nnode\n.S\nTATE\n: the state to which the node corresponds;\n•\nnode\n.P\nARENT\n: the node in the tree that generated this node;\n•\nnode\n.A\nCTION\n: the action that was applied to the parent’s state to generate this node;\n•\nnode\n.P\nATH\n-C\nOST\n: the total cost of the path from the initial state to this node. In mathematical formulas, we use\ng\n(\nnode\n) as a synonym for P\nATH\n-C\nOST\n.",
          "sentence_count": 3,
          "char_count": 480,
          "prev_para_id": "chap3_para92",
          "next_para_id": "chap3_para94",
          "style_metadata": {
            "para_id": "chap3_para93",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.67,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 122,
            "sentence_count": 3
          },
          "terminology": {
            "search": 3,
            "data": 3,
            "structure": 3,
            "algorithm": 1,
            "require": 1,
            "keep": 1,
            "track": 1,
            "tree": 3,
            "node": 11,
            "represented": 1,
            "component": 1,
            "tate": 1,
            "state": 3,
            "corresponds": 1,
            "arent": 1,
            "generated": 1,
            "ction": 1,
            "action": 1,
            "applied": 1,
            "parent": 1,
            "generate": 1,
            "ath": 2,
            "ost": 2,
            "total": 1,
            "cost": 1,
            "path": 1,
            "initial": 1,
            "mathematical": 1,
            "formula": 1,
            "use": 1,
            "synonym": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para94",
          "content": "Following the P\nARENT\npointers back from a node allows us to recover the states and actions along the path to that node. Doing this from a goal node gives us the solution.",
          "sentence_count": 2,
          "char_count": 141,
          "prev_para_id": "chap3_para93",
          "next_para_id": "chap3_para95",
          "style_metadata": {
            "para_id": "chap3_para94",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "following": 1,
            "arent": 1,
            "pointer": 1,
            "node": 3,
            "allows": 1,
            "recover": 1,
            "state": 1,
            "action": 1,
            "path": 1,
            "goal": 1,
            "give": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para94",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 43,
              "end_char": 47,
              "context": "Following the P\nARENT\npointers back from a node allows us to recover the states and actions along"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para95",
          "content": "We need a data structure to store the\nfrontier\n. The appropriate choice is a\nqueue\nof some kind, because the operations on a frontier are:\n•\nI\nS\n-E\nMPTY(\nfrontier\n) returns true only if there are no nodes in the frontier.",
          "sentence_count": 2,
          "char_count": 189,
          "prev_para_id": "chap3_para94",
          "next_para_id": "chap3_para96",
          "style_metadata": {
            "para_id": "chap3_para95",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "need": 1,
            "data": 1,
            "structure": 1,
            "store": 1,
            "frontier": 4,
            "appropriate": 1,
            "choice": 1,
            "queue": 1,
            "kind": 1,
            "operation": 1,
            "mpty": 1,
            "return": 1,
            "true": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para96",
          "content": "•\nP\nOP\n(\nfrontier\n) removes the top node from the frontier and returns it.",
          "sentence_count": 1,
          "char_count": 64,
          "prev_para_id": "chap3_para95",
          "next_para_id": "chap3_para97",
          "style_metadata": {
            "para_id": "chap3_para96",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 17,
            "sentence_count": 1
          },
          "terminology": {
            "frontier": 2,
            "remove": 1,
            "top": 1,
            "node": 1,
            "return": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para97",
          "content": "•\nT\nOP\n(\nfrontier\n) returns (but does not remove) the top node of the frontier.",
          "sentence_count": 1,
          "char_count": 68,
          "prev_para_id": "chap3_para96",
          "next_para_id": "chap3_para98",
          "style_metadata": {
            "para_id": "chap3_para97",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "frontier": 2,
            "return": 1,
            "remove": 1,
            "top": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para98",
          "content": "•\nA\nDD\n(\nnode\n,\nfrontier\n) inserts node into its proper place in the queue.",
          "sentence_count": 1,
          "char_count": 66,
          "prev_para_id": "chap3_para97",
          "next_para_id": "chap3_para99",
          "style_metadata": {
            "para_id": "chap3_para98",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "frontier": 1,
            "insert": 1,
            "node": 1,
            "proper": 1,
            "place": 1,
            "queue": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para99",
          "content": "Three kinds of queues are used in search algorithms:\n•\nA\npriority queue\nfirst pops the node with the minimum cost according to some evaluation function,\nf\n. It is used in best-first search.",
          "sentence_count": 2,
          "char_count": 162,
          "prev_para_id": "chap3_para98",
          "next_para_id": "chap3_para100",
          "style_metadata": {
            "para_id": "chap3_para99",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.027,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "kind": 1,
            "queue": 2,
            "used": 2,
            "search": 2,
            "algorithm": 1,
            "priority": 1,
            "first": 1,
            "pop": 1,
            "minimum": 1,
            "cost": 1,
            "according": 1,
            "evaluation": 1,
            "function": 1,
            "best-first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para100",
          "content": "•\nA\nFIFO queue\nor first-in-first-out queue first pops the node that was added to the queue first; we shall see it is used in breadth-first search.",
          "sentence_count": 1,
          "char_count": 123,
          "prev_para_id": "chap3_para99",
          "next_para_id": "chap3_para101",
          "style_metadata": {
            "para_id": "chap3_para100",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 9.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.069,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "fifo": 1,
            "queue": 3,
            "first-in-first-out": 1,
            "pop": 1,
            "node": 1,
            "added": 1,
            "see": 1,
            "used": 1,
            "breadth-first": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para101",
          "content": "•\nA\nLIFO queue\nor last-in-first-out queue (also known as a\nstack\n) pops first the most recently added node; we shall see it is used in depth-first search.",
          "sentence_count": 1,
          "char_count": 131,
          "prev_para_id": "chap3_para100",
          "next_para_id": "chap3_para102",
          "style_metadata": {
            "para_id": "chap3_para101",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.031,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 1
          },
          "terminology": {
            "lifo": 1,
            "queue": 2,
            "last-in-first-out": 1,
            "known": 1,
            "stack": 1,
            "pop": 1,
            "added": 1,
            "node": 1,
            "see": 1,
            "used": 1,
            "depth-first": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para101",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 102,
              "end_char": 106,
              "context": "n as a\nstack\n) pops first the most recently added node; we shall see it is used in depth-first search."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para102",
          "content": "The reached states can be stored as a lookup table (e.g. a hash table) where each key is a state and each value is the node for that state.",
          "sentence_count": 2,
          "char_count": 111,
          "prev_para_id": "chap3_para101",
          "next_para_id": "chap3_para103",
          "style_metadata": {
            "para_id": "chap3_para102",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "reached": 1,
            "state": 3,
            "stored": 1,
            "table": 2,
            "e.g": 1,
            "hash": 1,
            "key": 1,
            "value": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para103",
          "content": "3.3.3\nRedundant paths\nThe search tree shown in\nFigure 3.4\n(bottom) includes a path from Arad to Sibiu and back to Arad again. We say that\nArad\nis a\nrepeated state\nin the search tree, generated in this case by a\ncycle\n(also known as a\nloopy path\n). So even though the state space has only 20 states, the complete search tree is\ninfinite\nbecause there is no limit to how often one can traverse a loop.",
          "sentence_count": 3,
          "char_count": 336,
          "prev_para_id": "chap3_para102",
          "next_para_id": "chap3_para104",
          "style_metadata": {
            "para_id": "chap3_para103",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 86,
            "sentence_count": 3
          },
          "terminology": {
            "redundant": 1,
            "path": 3,
            "search": 3,
            "tree": 3,
            "shown": 1,
            "figure": 1,
            "bottom": 1,
            "includes": 1,
            "arad": 2,
            "sibiu": 1,
            "say": 1,
            "repeated": 1,
            "state": 3,
            "generated": 1,
            "case": 1,
            "cycle": 1,
            "known": 1,
            "loopy": 1,
            "space": 1,
            "complete": 1,
            "infinite": 1,
            "limit": 1,
            "traverse": 1,
            "loop": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para103",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 88,
              "end_char": 92,
              "context": "shown in\nFigure 3.4\n(bottom) includes a path from Arad to Sibiu and back to Arad again. We say that\nArad"
            },
            {
              "para_id": "chap3_para103",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 96,
              "end_char": 101,
              "context": "\nFigure 3.4\n(bottom) includes a path from Arad to Sibiu and back to Arad again. We say that\nArad\nis a\nrep"
            },
            {
              "para_id": "chap3_para103",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 114,
              "end_char": 118,
              "context": "m) includes a path from Arad to Sibiu and back to Arad again. We say that\nArad\nis a\nrepeated state\nin th"
            },
            {
              "para_id": "chap3_para103",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 138,
              "end_char": 142,
              "context": "Arad to Sibiu and back to Arad again. We say that\nArad\nis a\nrepeated state\nin the search tree, generated"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para104",
          "content": "A cycle is a special case of a\nredundant path\n. For example, we can get to Sibiu via the path Arad–Sibiu (140 miles long) or the path Arad–Zerind–Oradea–Sibiu (297 miles long). This second path is redundant—it’s just a worse way to get to the same state—and need not be considered in our quest for optimal paths.",
          "sentence_count": 3,
          "char_count": 258,
          "prev_para_id": "chap3_para103",
          "next_para_id": "chap3_para105",
          "style_metadata": {
            "para_id": "chap3_para104",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 3
          },
          "terminology": {
            "cycle": 1,
            "special": 1,
            "case": 1,
            "redundant": 1,
            "path": 5,
            "example": 1,
            "get": 2,
            "sibiu": 1,
            "arad–sibiu": 1,
            "mile": 2,
            "arad–zerind–oradea–sibiu": 1,
            "second": 1,
            "redundant—it": 1,
            "worse": 1,
            "way": 1,
            "state—and": 1,
            "need": 1,
            "considered": 1,
            "quest": 1,
            "optimal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para104",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 75,
              "end_char": 80,
              "context": " of a\nredundant path\n. For example, we can get to Sibiu via the path Arad–Sibiu (140 miles long) or the p"
            },
            {
              "para_id": "chap3_para104",
              "entity_text": "Arad–Sibiu",
              "entity_type": "ORG",
              "start_char": 94,
              "end_char": 104,
              "context": "h\n. For example, we can get to Sibiu via the path Arad–Sibiu (140 miles long) or the path Arad–Zerind–Oradea–S"
            },
            {
              "para_id": "chap3_para104",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 134,
              "end_char": 138,
              "context": " the path Arad–Sibiu (140 miles long) or the path Arad–Zerind–Oradea–Sibiu (297 miles long). This second"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para105",
          "content": "Consider an agent in a 10 × 10 grid world, with the ability to move to any of 8 adjacent squares. If there are no obstacles, the agent can reach any of the 100 squares in 9 moves or fewer. But the number of paths of length 9 is almost 8\n9\n(a bit less because of the edges of the grid), or more than 100 million. In other words, the average cell can be reached by over a million redundant paths of length 9, and if we eliminate redundant paths, we can complete a search roughly a million times faster. As the saying goes,\nalgorithms that cannot remember the past are doomed to repeat it.",
          "sentence_count": 5,
          "char_count": 474,
          "prev_para_id": "chap3_para104",
          "next_para_id": "chap3_para106",
          "style_metadata": {
            "para_id": "chap3_para105",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 131,
            "sentence_count": 5
          },
          "terminology": {
            "consider": 1,
            "agent": 2,
            "grid": 2,
            "world": 1,
            "ability": 1,
            "move": 2,
            "adjacent": 1,
            "square": 2,
            "obstacle": 1,
            "reach": 1,
            "fewer": 1,
            "number": 1,
            "path": 3,
            "bit": 1,
            "less": 1,
            "edge": 1,
            "word": 1,
            "average": 1,
            "cell": 1,
            "reached": 1,
            "redundant": 2,
            "length": 1,
            "eliminate": 1,
            "complete": 1,
            "search": 1,
            "time": 1,
            "saying": 1,
            "go": 1,
            "remember": 1,
            "past": 1,
            "doomed": 1,
            "repeat": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para106",
          "content": "There are three approaches to this issue.",
          "sentence_count": 1,
          "char_count": 35,
          "prev_para_id": "chap3_para105",
          "next_para_id": "chap3_para107",
          "style_metadata": {
            "para_id": "chap3_para106",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 8,
            "sentence_count": 1
          },
          "terminology": {
            "approach": 1,
            "issue": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para107",
          "content": "First, we can remember all previously reached states (as best-first search does), allowing us to detect all redundant paths, and keep only the best path to each state. This is appropriate for state spaces where there are many redundant paths, and is the preferred choice when the table of reached states will fit in memory.",
          "sentence_count": 2,
          "char_count": 269,
          "prev_para_id": "chap3_para106",
          "next_para_id": "chap3_para108",
          "style_metadata": {
            "para_id": "chap3_para107",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "first": 1,
            "remember": 1,
            "reached": 2,
            "state": 4,
            "best-first": 1,
            "search": 1,
            "allowing": 1,
            "detect": 1,
            "redundant": 2,
            "path": 3,
            "keep": 1,
            "best": 1,
            "appropriate": 1,
            "space": 1,
            "many": 1,
            "preferred": 1,
            "choice": 1,
            "table": 1,
            "fit": 1,
            "memory": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para108",
          "content": "Second, we can not worry about repeating the past. There are some problem formulations where it is rare or impossible for two paths to reach the same state. An example would be an assembly problem where each action adds a part to an evolving assemblage, and there is an ordering of parts so that it is possible to add\nA\nand then\nB\n, but not\nB\nand then\nA\n. For those problems, we could save memory space if we\ndon’t\ntrack reached states and we don’t check for redundant paths. We call a search algorithm a\ngraph search\nif it checks for redundant paths and a\ntree-like search\n6\nif it does not check. The B\nEST\n-F\nIRST\n-S\nEARCH\nalgorithm\nin\nFigure 3.7\nis a graph search algorithm; if we remove all references to\nreached\nwe get a treelike search that uses less memory but will examine redundant paths to the same state, and thus will run slower.",
          "sentence_count": 6,
          "char_count": 706,
          "prev_para_id": "chap3_para107",
          "next_para_id": "chap3_para109",
          "style_metadata": {
            "para_id": "chap3_para108",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 176,
            "sentence_count": 6
          },
          "terminology": {
            "second": 1,
            "worry": 1,
            "repeating": 1,
            "past": 1,
            "problem": 3,
            "formulation": 1,
            "rare": 1,
            "impossible": 1,
            "path": 4,
            "reach": 1,
            "state": 3,
            "example": 1,
            "action": 1,
            "add": 2,
            "part": 2,
            "evolving": 1,
            "assemblage": 1,
            "ordering": 1,
            "possible": 1,
            "save": 1,
            "memory": 2,
            "space": 1,
            "track": 1,
            "reached": 2,
            "check": 3,
            "redundant": 3,
            "call": 1,
            "search": 5,
            "algorithm": 3,
            "graph": 2,
            "tree-like": 1,
            "est": 1,
            "irst": 1,
            "earch": 1,
            "figure": 1,
            "remove": 1,
            "reference": 1,
            "get": 1,
            "treelike": 1,
            "us": 1,
            "less": 1,
            "examine": 1,
            "run": 1,
            "slower": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para109",
          "content": "Third, we can compromise and check for cycles, but not for redundant paths in general. Since each node has a chain of parent pointers, we can check for cycles with no need for additional memory by following up the chain of parents to see if the state at the end of the path has appeared earlier in the path. Some implementations follow this chain all the way up, and thus eliminate all cycles; other implementations follow only a few links (e.g., to the parent, grandparent, and great-grandparent), and thus take only a constant amount of time, while eliminating all short cycles (and relying on other mechanisms to deal with long cycles).",
          "sentence_count": 3,
          "char_count": 529,
          "prev_para_id": "chap3_para108",
          "next_para_id": "chap3_para110",
          "style_metadata": {
            "para_id": "chap3_para109",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 3
          },
          "terminology": {
            "third": 1,
            "compromise": 1,
            "check": 2,
            "cycle": 5,
            "redundant": 1,
            "path": 3,
            "general": 1,
            "node": 1,
            "chain": 3,
            "parent": 3,
            "pointer": 1,
            "need": 1,
            "additional": 1,
            "memory": 1,
            "following": 1,
            "see": 1,
            "state": 1,
            "end": 1,
            "appeared": 1,
            "earlier": 1,
            "implementation": 2,
            "follow": 2,
            "way": 1,
            "eliminate": 1,
            "link": 1,
            "e.g.": 1,
            "grandparent": 1,
            "great-grandparent": 1,
            "take": 1,
            "constant": 1,
            "amount": 1,
            "time": 1,
            "eliminating": 1,
            "short": 1,
            "relying": 1,
            "mechanism": 1,
            "deal": 1,
            "long": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para110",
          "content": "3.3.4\nMeasuring problem-solving performance\nBefore we get into the design of various search algorithms, we will consider the criteria used to choose among them. We can evaluate an algorithm’s performance in four ways:\n•\nCompleteness:\nIs the algorithm guaranteed to find a solution when there is one, and to correctly report failure when there is not?",
          "sentence_count": 2,
          "char_count": 300,
          "prev_para_id": "chap3_para109",
          "next_para_id": "chap3_para111",
          "style_metadata": {
            "para_id": "chap3_para110",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 2
          },
          "terminology": {
            "measuring": 1,
            "problem-solving": 1,
            "performance": 2,
            "get": 1,
            "design": 1,
            "various": 1,
            "search": 1,
            "algorithm": 3,
            "consider": 1,
            "criterion": 1,
            "used": 1,
            "choose": 1,
            "evaluate": 1,
            "way": 1,
            "guaranteed": 1,
            "find": 1,
            "solution": 1,
            "report": 1,
            "failure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para111",
          "content": "•\nCost optimality:\nDoes it find a solution with the lowest path cost of all solutions?",
          "sentence_count": 1,
          "char_count": 73,
          "prev_para_id": "chap3_para110",
          "next_para_id": "chap3_para112",
          "style_metadata": {
            "para_id": "chap3_para111",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "cost": 2,
            "optimality": 1,
            "find": 1,
            "solution": 2,
            "lowest": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para112",
          "content": "7\n•\nTime complexity:\nHow long does it take to find a solution? This can be measured in seconds, or more abstractly by the number of states and actions considered.",
          "sentence_count": 2,
          "char_count": 136,
          "prev_para_id": "chap3_para111",
          "next_para_id": "chap3_para113",
          "style_metadata": {
            "para_id": "chap3_para112",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 2
          },
          "terminology": {
            "time": 1,
            "complexity": 1,
            "take": 1,
            "find": 1,
            "solution": 1,
            "measured": 1,
            "second": 1,
            "number": 1,
            "state": 1,
            "action": 1,
            "considered": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para113",
          "content": "•\nSpace complexity:\nHow much memory is needed to perform the search?",
          "sentence_count": 1,
          "char_count": 59,
          "prev_para_id": "chap3_para112",
          "next_para_id": "chap3_para114",
          "style_metadata": {
            "para_id": "chap3_para113",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.071,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "space": 1,
            "complexity": 1,
            "much": 1,
            "memory": 1,
            "needed": 1,
            "perform": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para114",
          "content": "To understand completeness, consider a search problem with a single goal. That goal could be anywhere in the state space; therefore a complete algorithm must be capable of systematically exploring every state that is reachable from the initial state. In finite state spaces that is straightforward to achieve: as long as we keep track of paths and cut off ones that are cycles (e.g. Arad to Sibiu to Arad), eventually we will reach every reachable state.",
          "sentence_count": 4,
          "char_count": 379,
          "prev_para_id": "chap3_para113",
          "next_para_id": "chap3_para115",
          "style_metadata": {
            "para_id": "chap3_para114",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 86,
            "sentence_count": 4
          },
          "terminology": {
            "understand": 1,
            "completeness": 1,
            "consider": 1,
            "search": 1,
            "problem": 1,
            "single": 1,
            "goal": 2,
            "anywhere": 1,
            "state": 5,
            "space": 2,
            "complete": 1,
            "algorithm": 1,
            "capable": 1,
            "exploring": 1,
            "reachable": 2,
            "initial": 1,
            "finite": 1,
            "straightforward": 1,
            "keep": 1,
            "track": 1,
            "path": 1,
            "cut": 1,
            "one": 1,
            "cycle": 1,
            "e.g": 1,
            "arad": 2,
            "sibiu": 1,
            "reach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para114",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 383,
              "end_char": 387,
              "context": "k of paths and cut off ones that are cycles (e.g. Arad to Sibiu to Arad), eventually we will reach every"
            },
            {
              "para_id": "chap3_para114",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 391,
              "end_char": 396,
              "context": "hs and cut off ones that are cycles (e.g. Arad to Sibiu to Arad), eventually we will reach every reachabl"
            },
            {
              "para_id": "chap3_para114",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 400,
              "end_char": 404,
              "context": "t off ones that are cycles (e.g. Arad to Sibiu to Arad), eventually we will reach every reachable state."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para115",
          "content": "In infinite state spaces, more care is necessary. For example, an algorithm that repeatedly applied the “factorial” operator in Knuth’s “4” problem would follow an infinite path from 4 to 4! to (4!)!, and so on. Similarly, on an infinite grid with no obstacles, repeatedly moving forward in a straight line also follows an infinite path of new states. In both cases the algorithm never returns to a state it has reached before, but is incomplete because wide expanses of the state space are never reached.",
          "sentence_count": 6,
          "char_count": 420,
          "prev_para_id": "chap3_para114",
          "next_para_id": "chap3_para116",
          "style_metadata": {
            "para_id": "chap3_para115",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 107,
            "sentence_count": 6
          },
          "terminology": {
            "infinite": 4,
            "state": 4,
            "space": 2,
            "care": 1,
            "necessary": 1,
            "example": 1,
            "algorithm": 2,
            "applied": 1,
            "factorial": 1,
            "operator": 1,
            "knuth": 1,
            "problem": 1,
            "follow": 1,
            "path": 2,
            "grid": 1,
            "obstacle": 1,
            "moving": 1,
            "straight": 1,
            "line": 1,
            "follows": 1,
            "new": 1,
            "case": 1,
            "return": 1,
            "reached": 2,
            "incomplete": 1,
            "wide": 1,
            "expanse": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para115",
              "entity_text": "Knuth",
              "entity_type": "ORG",
              "start_char": 128,
              "end_char": 133,
              "context": "at repeatedly applied the “factorial” operator in Knuth’s “4” problem would follow an infinite path from "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para116",
          "content": "To be complete, a search algorithm must be\nsystematic\nin the way it explores an infinite state space, making sure it can eventually reach any state that is connected to the initial state. For example, on the infinite grid, one kind of systematic search is a spiral path that covers all the cells that are\ns\nsteps from the origin before moving out to cells that are\ns\n+ 1 steps away. Unfortunately, in an infinite state space with no solution, a sound algorithm needs to keep searching forever; it can’t terminate because it can’t know if the next state will be a goal.",
          "sentence_count": 3,
          "char_count": 471,
          "prev_para_id": "chap3_para115",
          "next_para_id": "chap3_para117",
          "style_metadata": {
            "para_id": "chap3_para116",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.33,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 118,
            "sentence_count": 3
          },
          "terminology": {
            "complete": 1,
            "search": 2,
            "algorithm": 2,
            "systematic": 2,
            "way": 1,
            "explores": 1,
            "infinite": 3,
            "state": 5,
            "space": 2,
            "making": 1,
            "sure": 1,
            "reach": 1,
            "connected": 1,
            "initial": 1,
            "example": 1,
            "grid": 1,
            "kind": 1,
            "spiral": 1,
            "path": 1,
            "cover": 1,
            "cell": 2,
            "step": 2,
            "origin": 1,
            "moving": 1,
            "unfortunately": 1,
            "solution": 1,
            "sound": 1,
            "need": 1,
            "keep": 1,
            "searching": 1,
            "know": 1,
            "next": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para117",
          "content": "Time and space complexity are considered with respect to some measure of the problem difficulty. In theoretical computer science, the typical measure is the size of the state-space graph, |\nV\n| + |\nE\n|, where |\nV\n| is the number of vertices (state nodes) of the graph and |\nE\n|\nis the number of edges (distinct state/action pairs). This is appropriate when the graph is an explicit data structure, such as the map of Romania. But in many AI problems, the graph is represented only\nimplicitly\nby the initial state, actions, and transition model. For an implicit state space, complexity can be measured in terms of\nd\n, the\ndepth\nor number of actions in an optimal solution;\nm\n, the maximum number of actions in any path; and\nb\n, the\nbranching factor\nor number of successors of a node that need to be considered.",
          "sentence_count": 5,
          "char_count": 681,
          "prev_para_id": "chap3_para116",
          "next_para_id": "chap3_para118",
          "style_metadata": {
            "para_id": "chap3_para117",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.8,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 169,
            "sentence_count": 5
          },
          "terminology": {
            "time": 1,
            "space": 2,
            "complexity": 2,
            "considered": 2,
            "respect": 1,
            "measure": 2,
            "problem": 2,
            "difficulty": 1,
            "theoretical": 1,
            "computer": 1,
            "science": 1,
            "typical": 1,
            "size": 1,
            "state-space": 1,
            "graph": 4,
            "number": 5,
            "vertex": 1,
            "state": 3,
            "node": 2,
            "edge": 1,
            "distinct": 1,
            "state/action": 1,
            "pair": 1,
            "appropriate": 1,
            "explicit": 1,
            "data": 1,
            "structure": 1,
            "map": 1,
            "many": 1,
            "represented": 1,
            "initial": 1,
            "action": 3,
            "transition": 1,
            "model": 1,
            "implicit": 1,
            "measured": 1,
            "term": 1,
            "depth": 1,
            "optimal": 1,
            "solution": 1,
            "maximum": 1,
            "path": 1,
            "branching": 1,
            "factor": 1,
            "successor": 1,
            "need": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para117",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 417,
              "end_char": 424,
              "context": "is an explicit data structure, such as the map of Romania. But in many AI problems, the graph is represente"
            },
            {
              "para_id": "chap3_para117",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 438,
              "end_char": 440,
              "context": "tructure, such as the map of Romania. But in many AI problems, the graph is represented only\nimplicitl"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para118",
          "content": "3.4Uninformed Search Strategies\n3.4\nUninformed Search Strategies\nAn uninformed search algorithm is given no clue about how close a state is to the goal(s). For example, consider our agent in Arad with the goal of reaching Bucharest. An uninformed agent with no knowledge of Romanian geography has no clue whether going to Zerind or Sibiu is a better first step. In contrast, an informed agent (\nSection 3.5\n) who knows the location of each city knows that Sibiu is much closer to Bucharest and thus more likely to be on the shortest path.",
          "sentence_count": 4,
          "char_count": 450,
          "prev_para_id": "chap3_para117",
          "next_para_id": "chap3_para119",
          "style_metadata": {
            "para_id": "chap3_para118",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 4
          },
          "terminology": {
            "search": 3,
            "strategy": 2,
            "uninformed": 3,
            "algorithm": 1,
            "given": 1,
            "clue": 2,
            "state": 1,
            "goal": 2,
            "example": 1,
            "consider": 1,
            "agent": 3,
            "arad": 1,
            "reaching": 1,
            "bucharest": 2,
            "knowledge": 1,
            "romanian": 1,
            "geography": 1,
            "going": 1,
            "zerind": 1,
            "sibiu": 1,
            "first": 1,
            "step": 1,
            "contrast": 1,
            "informed": 1,
            "section": 1,
            "know": 2,
            "location": 1,
            "city": 1,
            "much": 1,
            "closer": 1,
            "likely": 1,
            "shortest": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para118",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 191,
              "end_char": 195,
              "context": "o the goal(s). For example, consider our agent in Arad with the goal of reaching Bucharest. An uninforme"
            },
            {
              "para_id": "chap3_para118",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 322,
              "end_char": 328,
              "context": "f Romanian geography has no clue whether going to Zerind or Sibiu is a better first step. In contrast, an "
            },
            {
              "para_id": "chap3_para118",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 332,
              "end_char": 337,
              "context": " geography has no clue whether going to Zerind or Sibiu is a better first step. In contrast, an informed "
            },
            {
              "para_id": "chap3_para118",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 456,
              "end_char": 461,
              "context": "\n) who knows the location of each city knows that Sibiu is much closer to Bucharest and thus more likely "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para119",
          "content": "3.4.1\nBreadth-first search\nWhen all actions have the same cost, an appropriate strategy is\nbreadth-first search\n, in which the root node is expanded first, then all the successors of the root node are expanded next, then\ntheir\nsuccessors, and so on. This is a systematic search strategy that is therefore complete even on infinite state spaces. We could implement breadth-first search as a call to B\nEST\n-F\nIRST\n-S\nEARCH\nwhere the evaluation function\nf\n(\nn\n) is the depth of the node—that is, the number of actions it takes to reach the node.",
          "sentence_count": 3,
          "char_count": 462,
          "prev_para_id": "chap3_para118",
          "next_para_id": "chap3_para120",
          "style_metadata": {
            "para_id": "chap3_para119",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 35.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 105,
            "sentence_count": 3
          },
          "terminology": {
            "breadth-first": 3,
            "search": 4,
            "action": 2,
            "cost": 1,
            "appropriate": 1,
            "strategy": 2,
            "root": 2,
            "node": 2,
            "expanded": 2,
            "first": 1,
            "successor": 2,
            "next": 1,
            "systematic": 1,
            "complete": 1,
            "infinite": 1,
            "state": 1,
            "space": 1,
            "implement": 1,
            "call": 1,
            "est": 1,
            "irst": 1,
            "earch": 1,
            "evaluation": 1,
            "function": 1,
            "depth": 1,
            "number": 1,
            "take": 1,
            "reach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para119",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 132,
              "end_char": 136,
              "context": "ategy is\nbreadth-first search\n, in which the root node is expanded first, then all the successors of the"
            },
            {
              "para_id": "chap3_para119",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 479,
              "end_char": 483,
              "context": "e evaluation function\nf\n(\nn\n) is the depth of the node—that is, the number of actions it takes to reach "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para120",
          "content": "However, we can get additional efficiency with a couple of tricks. A first-in-first-out queue will be faster than a priority queue, and will give us the correct order of nodes: new nodes (which are always deeper than their parents) go to the back of the queue, and old nodes, which are shallower than the new nodes, get expanded first. In addition,\nreached\ncan be a set of states rather than a mapping from states to nodes, because once we’ve reached a state, we can never find a better path to the state. That also means we can do an\nearly goal test\n, checking whether a node is a solution as soon as it is\ngenerated,\nrather than the\nlate goal test\nthat best-first search uses, waiting until a node is popped off the queue.",
          "sentence_count": 4,
          "char_count": 598,
          "prev_para_id": "chap3_para119",
          "next_para_id": "chap3_para121",
          "style_metadata": {
            "para_id": "chap3_para120",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 38.5,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 154,
            "sentence_count": 4
          },
          "terminology": {
            "get": 2,
            "additional": 1,
            "efficiency": 1,
            "couple": 1,
            "trick": 1,
            "first-in-first-out": 1,
            "queue": 3,
            "faster": 1,
            "priority": 1,
            "give": 1,
            "correct": 1,
            "order": 1,
            "node": 6,
            "new": 2,
            "deeper": 1,
            "parent": 1,
            "old": 1,
            "shallower": 1,
            "expanded": 1,
            "first": 1,
            "addition": 1,
            "reached": 2,
            "set": 1,
            "state": 4,
            "mapping": 1,
            "find": 1,
            "better": 1,
            "path": 1,
            "mean": 1,
            "early": 1,
            "goal": 2,
            "test": 2,
            "checking": 1,
            "solution": 1,
            "generated": 1,
            "late": 1,
            "best-first": 1,
            "search": 1,
            "us": 1,
            "waiting": 1,
            "popped": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para120",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 695,
              "end_char": 699,
              "context": "test\nthat best-first search uses, waiting until a node is popped off the queue."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para121",
          "content": "Figure 3.8\nshows the progress of a breadth-first search on a binary tree, and\nFigure 3.9\nshows the algorithm with the early-goal efficiency enhancements.",
          "sentence_count": 1,
          "char_count": 133,
          "prev_para_id": "chap3_para120",
          "next_para_id": "chap3_para122",
          "style_metadata": {
            "para_id": "chap3_para121",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 2,
            "show": 2,
            "progress": 1,
            "breadth-first": 1,
            "search": 1,
            "binary": 1,
            "tree": 1,
            "algorithm": 1,
            "early-goal": 1,
            "efficiency": 1,
            "enhancement": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para122",
          "content": "Description\nSibiu to Fagaras, 99. Fagaras to Bucharest, 211. Sibiu to Rimnicu Vilcea, 80. Rimnicu Vilcea to Pitesti, 97. Pitesti to Bucharest, 101.",
          "sentence_count": 5,
          "char_count": 126,
          "prev_para_id": "chap3_para121",
          "next_para_id": "chap3_para123",
          "style_metadata": {
            "para_id": "chap3_para122",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 5
          },
          "terminology": {
            "description": 1,
            "sibiu": 2,
            "fagaras": 2,
            "rimnicu": 2,
            "vilcea": 2,
            "pitesti": 2,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para122",
              "entity_text": "Description\nSibiu",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 17,
              "context": "Description\nSibiu to Fagaras, 99. Fagaras to Bucharest, 211. Sibiu "
            },
            {
              "para_id": "chap3_para122",
              "entity_text": "Fagaras",
              "entity_type": "GPE",
              "start_char": 21,
              "end_char": 28,
              "context": "Description\nSibiu to Fagaras, 99. Fagaras to Bucharest, 211. Sibiu to Rimnicu "
            },
            {
              "para_id": "chap3_para122",
              "entity_text": "Bucharest",
              "entity_type": "GPE",
              "start_char": 45,
              "end_char": 54,
              "context": "Description\nSibiu to Fagaras, 99. Fagaras to Bucharest, 211. Sibiu to Rimnicu Vilcea, 80. Rimnicu Vilcea"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para123",
          "content": "×\nFigure 3.8\nBreadth-first search on a simple binary tree. At each stage, the node to be expanded next is indicated by the triangular marker.",
          "sentence_count": 2,
          "char_count": 119,
          "prev_para_id": "chap3_para122",
          "next_para_id": "chap3_para124",
          "style_metadata": {
            "para_id": "chap3_para123",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "breadth-first": 1,
            "search": 1,
            "simple": 1,
            "binary": 1,
            "tree": 1,
            "stage": 1,
            "expanded": 1,
            "next": 1,
            "indicated": 1,
            "triangular": 1,
            "marker": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para124",
          "content": "Description\nThe binary trees have the root node labeled “A”. Node “A” has two child nodes labeled B and C. Node B has two child nodes labeled D and E. Node C has two child nodes labeled F and G. Node D has two child nodes labeled H and I. Node E has two child nodes labeled J and K. Node F has two child nodes labeled L and M. Node G has two child nodes labeled N and O.",
          "sentence_count": 2,
          "char_count": 292,
          "prev_para_id": "chap3_para123",
          "next_para_id": "chap3_para125",
          "style_metadata": {
            "para_id": "chap3_para124",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 43.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 86,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "binary": 1,
            "tree": 1,
            "root": 1,
            "labeled": 8,
            "child": 7,
            "node": 7,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para124",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 61,
              "end_char": 65,
              "context": "\nThe binary trees have the root node labeled “A”. Node “A” has two child nodes labeled B and C. Node B h"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "C. Node",
              "entity_type": "PERSON",
              "start_char": 104,
              "end_char": 111,
              "context": "d “A”. Node “A” has two child nodes labeled B and C. Node B has two child nodes labeled D and E. Node C has"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "E. Node C",
              "entity_type": "PERSON",
              "start_char": 148,
              "end_char": 157,
              "context": "B and C. Node B has two child nodes labeled D and E. Node C has two child nodes labeled F and G. Node D has t"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 186,
              "end_char": 187,
              "context": "beled D and E. Node C has two child nodes labeled F and G. Node D has two child nodes labeled H and I"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "G. Node",
              "entity_type": "PERSON",
              "start_char": 192,
              "end_char": 199,
              "context": "D and E. Node C has two child nodes labeled F and G. Node D has two child nodes labeled H and I. Node E has"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "H",
              "entity_type": "ORG",
              "start_char": 230,
              "end_char": 231,
              "context": "beled F and G. Node D has two child nodes labeled H and I. Node E has two child nodes labeled J and K"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "I. Node",
              "entity_type": "PERSON",
              "start_char": 236,
              "end_char": 243,
              "context": "F and G. Node D has two child nodes labeled H and I. Node E has two child nodes labeled J and K. Node F has"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "L",
              "entity_type": "PRODUCT",
              "start_char": 318,
              "end_char": 319,
              "context": "beled J and K. Node F has two child nodes labeled L and M. Node G has two child nodes labeled N and O"
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "M. Node G",
              "entity_type": "PERSON",
              "start_char": 324,
              "end_char": 333,
              "context": "J and K. Node F has two child nodes labeled L and M. Node G has two child nodes labeled N and O."
            },
            {
              "para_id": "chap3_para124",
              "entity_text": "N",
              "entity_type": "ORG",
              "start_char": 362,
              "end_char": 363,
              "context": "beled L and M. Node G has two child nodes labeled N and O."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para125",
          "content": "Binary Tree 1: Node “A” is green-colored. An arrowhead points to “A”. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 3,
          "char_count": 101,
          "prev_para_id": "chap3_para124",
          "next_para_id": "chap3_para126",
          "style_metadata": {
            "para_id": "chap3_para125",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 3
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "node": 1,
            "path": 1,
            "faint": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para126",
          "content": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-colored. An arrowhead points to B. The paths from node “A” are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 162,
          "prev_para_id": "chap3_para125",
          "next_para_id": "chap3_para127",
          "style_metadata": {
            "para_id": "chap3_para126",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para126",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para127",
          "content": "Binary Tree 3: Nodes “A” and B are lavender-colored. Nodes C, D, and E are green-colored. An arrowhead points to D. The paths from nodes “A” and B are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 176,
          "prev_para_id": "chap3_para126",
          "next_para_id": "chap3_para128",
          "style_metadata": {
            "para_id": "chap3_para127",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para128",
          "content": "Binary Tree 4: Nodes “A”, B, and D are lavender-colored. Nodes C, E, H, and I are green-colored. An arrowhead points to H. The paths from “A”, B, and D are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 179,
          "prev_para_id": "chap3_para127",
          "next_para_id": "chap3_para129",
          "style_metadata": {
            "para_id": "chap3_para128",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para129",
          "content": "Binary Tree 5: Nodes “A”, B, and D are lavender-colored. Nodes C, E, and I are green-colored. An arrowhead points to I. The paths from “A” and B are solid lines. The path between D and I is a solid line. The path from D to H and node H are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 241,
          "prev_para_id": "chap3_para128",
          "next_para_id": "chap3_para130",
          "style_metadata": {
            "para_id": "chap3_para129",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.14,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 7
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 2,
            "line": 3,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para129",
              "entity_text": "I.",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 119,
              "context": ", and I are green-colored. An arrowhead points to I. The paths from “A” and B are solid lines. The pat"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para130",
          "content": "Binary Tree 6: Nodes “A” and B are lavender-colored. Nodes E and C are green-colored. An arrowhead points to E. The paths from “A” are solid lines. The path between B and E is a solid line. The path from B to D, node D, and the child nodes of D are all faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 6,
          "char_count": 252,
          "prev_para_id": "chap3_para129",
          "next_para_id": "chap3_para131",
          "style_metadata": {
            "para_id": "chap3_para130",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 6
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 4,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 2,
            "line": 3,
            "child": 1,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para131",
          "content": "Binary Tree 7: Nodes “A”, B, and E are lavender-colored. Nodes C, J, and K are green-colored. An arrowhead points to J. The paths from “A” and E are solid lines. The path between B and E is a solid line. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 6,
          "char_count": 206,
          "prev_para_id": "chap3_para130",
          "next_para_id": "chap3_para132",
          "style_metadata": {
            "para_id": "chap3_para131",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 6
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 3,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para131",
              "entity_text": "J. The",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 123,
              "context": ", and K are green-colored. An arrowhead points to J. The paths from “A” and E are solid lines. The path be"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para132",
          "content": "Binary Tree 8: Nodes “A”, B, and E are lavender-colored. Nodes C and K are green-colored. An arrowhead points to K. The paths from “A” are solid lines. The path between B and E is a solid line. The path between K and E is a solid line. The path from E to J and node J are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 266,
          "prev_para_id": "chap3_para131",
          "next_para_id": "chap3_para133",
          "style_metadata": {
            "para_id": "chap3_para132",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 7
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 4,
            "solid": 3,
            "line": 4,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para133",
          "content": "Binary Tree 9: Node “A” is lavender-colored and node C is green-colored. An arrowhead points to C. The path between “A” and C is a solid line. The path from “A” to B, node B, and all child nodes of B are faded. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 211,
          "prev_para_id": "chap3_para132",
          "next_para_id": "chap3_para134",
          "style_metadata": {
            "para_id": "chap3_para133",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 4,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 1,
            "line": 2,
            "child": 1,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para133",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 9: Node “A” is lavender-colored and node C is green-color"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para134",
          "content": "Binary Tree 10: Nodes “A” and C are lavender-colored. Nodes F and G are green-colored. An arrowhead points to F. The paths from C are solid lines. The path between “A” and C is a solid line. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 197,
          "prev_para_id": "chap3_para133",
          "next_para_id": "chap3_para135",
          "style_metadata": {
            "para_id": "chap3_para134",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 3,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para134",
              "entity_text": "Nodes F and G",
              "entity_type": "PRODUCT",
              "start_char": 54,
              "end_char": 67,
              "context": "ry Tree 10: Nodes “A” and C are lavender-colored. Nodes F and G are green-colored. An arrowhead points to F. The "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para135",
          "content": "Binary Tree 11: Nodes “A”, C, and F are lavender-colored. Nodes G, L, and M are green-colored. An arrowhead points to L. The paths from C and F are solid lines. The path between “A” and C is a solid line. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 207,
          "prev_para_id": "chap3_para134",
          "next_para_id": "chap3_para136",
          "style_metadata": {
            "para_id": "chap3_para135",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 3,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para135",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 34,
              "end_char": 35,
              "context": "Binary Tree 11: Nodes “A”, C, and F are lavender-colored. Nodes G, L, and M are green"
            },
            {
              "para_id": "chap3_para135",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 142,
              "end_char": 143,
              "context": "d. An arrowhead points to L. The paths from C and F are solid lines. The path between “A” and C is a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para136",
          "content": "Binary Tree 12: Nodes “A”, C, and F are lavender-colored. Nodes G and M are green-colored. An arrowhead points to M. The paths from C are solid lines. The path between “A” and C is a solid line. The path between F and M is a solid line. The path from F to L and node L are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 267,
          "prev_para_id": "chap3_para135",
          "next_para_id": "chap3_para137",
          "style_metadata": {
            "para_id": "chap3_para136",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 7
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 4,
            "solid": 3,
            "line": 4,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para136",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 34,
              "end_char": 35,
              "context": "Binary Tree 12: Nodes “A”, C, and F are lavender-colored. Nodes G and M are green-col"
            },
            {
              "para_id": "chap3_para136",
              "entity_text": "F and M",
              "entity_type": "PRODUCT",
              "start_char": 212,
              "end_char": 219,
              "context": "tween “A” and C is a solid line. The path between F and M is a solid line. The path from F to L and node L "
            },
            {
              "para_id": "chap3_para136",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 251,
              "end_char": 252,
              "context": "th between F and M is a solid line. The path from F to L and node L are faded out. All other nodes an"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para137",
          "content": "×\nFigure 3.9\nBreadth-first search and uniform-cost search algorithms.",
          "sentence_count": 1,
          "char_count": 63,
          "prev_para_id": "chap3_para136",
          "next_para_id": "chap3_para138",
          "style_metadata": {
            "para_id": "chap3_para137",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "breadth-first": 1,
            "search": 2,
            "uniform-cost": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para138",
          "content": "Breadth-first search always finds a solution with a minimal number of actions, because when it is generating nodes at depth\nd\n, it has already generated all the nodes at depth\nd –\n1, so if one of them were a solution, it would have been found. That means it is cost-optimal\nfor problems where all actions have the same cost, but not for problems that don’t have that property. It is complete in either case. In terms of time and space, imagine searching a uniform tree where every state has\nb\nsuccessors. The root of the search tree generates\nb\nnodes, each of which generates\nb\nmore nodes, for a total of\nb\n2\nat the second level. Each of these generates\nb\nmore nodes, yielding\nb\n3\nnodes at the third level, and so on. Now suppose that the solution is at depth\nd\n. Then the total number of nodes generated is\n1\n+\nb\n+\nb\n2\n+\nb\n3\n+\n⋯\n+\nb\nd\n=\nO\n(\nb\nd\n)\nAll the nodes remain in memory, so both time and space complexity are\nO\n(\nb\nd\n). Exponential bounds like that are scary. As a typical real-world example, consider a problem with branching factor\nb =\n10, processing speed 1 million nodes/second, and memory requirements of 1 Kbyte/node. A search to depth\nd =\n10 would take less than 3 hours, but would require 10 terabytes of memory.",
          "sentence_count": 11,
          "char_count": 1037,
          "prev_para_id": "chap3_para137",
          "next_para_id": "chap3_para139",
          "style_metadata": {
            "para_id": "chap3_para138",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.55,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 270,
            "sentence_count": 11
          },
          "terminology": {
            "breadth-first": 1,
            "search": 3,
            "find": 1,
            "solution": 3,
            "minimal": 1,
            "number": 2,
            "action": 2,
            "generating": 1,
            "node": 7,
            "depth": 4,
            "generated": 2,
            "found": 1,
            "mean": 1,
            "cost-optimal": 1,
            "problem": 3,
            "cost": 1,
            "property": 1,
            "complete": 1,
            "case": 1,
            "term": 1,
            "time": 2,
            "space": 2,
            "imagine": 1,
            "searching": 1,
            "uniform": 1,
            "tree": 2,
            "state": 1,
            "successor": 1,
            "root": 1,
            "generates": 3,
            "total": 2,
            "second": 1,
            "level": 2,
            "yielding": 1,
            "third": 1,
            "suppose": 1,
            "remain": 1,
            "memory": 3,
            "complexity": 1,
            "exponential": 1,
            "bound": 1,
            "scary": 1,
            "typical": 1,
            "real-world": 1,
            "example": 1,
            "consider": 1,
            "branching": 1,
            "factor": 1,
            "processing": 1,
            "speed": 1,
            "nodes/second": 1,
            "requirement": 1,
            "kbyte/node": 1,
            "take": 1,
            "less": 1,
            "hour": 1,
            "require": 1,
            "terabyte": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para139",
          "content": "The memory requirements are a bigger problem for breadth-first search than the execution time.",
          "sentence_count": 1,
          "char_count": 81,
          "prev_para_id": "chap3_para138",
          "next_para_id": "chap3_para140",
          "style_metadata": {
            "para_id": "chap3_para139",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "memory": 1,
            "requirement": 1,
            "bigger": 1,
            "problem": 1,
            "breadth-first": 1,
            "search": 1,
            "execution": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para140",
          "content": "But time is still an important factor. At depth\nd =\n14, even with infinite memory, the search would take 3.5 years. In general,\nexponential-complexity search problems cannot be solved by uninformed search for any but the smallest instances.",
          "sentence_count": 3,
          "char_count": 205,
          "prev_para_id": "chap3_para139",
          "next_para_id": "chap3_para141",
          "style_metadata": {
            "para_id": "chap3_para140",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 3
          },
          "terminology": {
            "time": 1,
            "important": 1,
            "factor": 1,
            "depth": 1,
            "infinite": 1,
            "memory": 1,
            "search": 3,
            "take": 1,
            "year": 1,
            "general": 1,
            "exponential-complexity": 1,
            "problem": 1,
            "solved": 1,
            "uninformed": 1,
            "smallest": 1,
            "instance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para141",
          "content": "3.4.2\nDijkstra’s algorithm or uniform-cost search\nWhen actions have different costs, an obvious choice is to use best-first search where the evaluation function is the cost of the path from the root to the current node. This is called Dijkstra’s algorithm by the theoretical computer science community, and\nuniform-cost search\nby the AI community. The idea is that while breadth-first search spreads out in waves of uniform depth—first depth 1, then depth 2, and so on—uniform-cost search spreads out in waves of uniform path-cost. The algorithm can be implemented as a call to B\nEST\n-F\nIRST\n-S\nEARCH\nwith P\nATH\n-C\nOST\nas the evaluation function, as shown in\nFigure 3.9\n.",
          "sentence_count": 4,
          "char_count": 574,
          "prev_para_id": "chap3_para140",
          "next_para_id": "chap3_para142",
          "style_metadata": {
            "para_id": "chap3_para141",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 126,
            "sentence_count": 4
          },
          "terminology": {
            "dijkstra": 2,
            "algorithm": 2,
            "uniform-cost": 2,
            "search": 5,
            "action": 1,
            "different": 1,
            "cost": 2,
            "obvious": 1,
            "choice": 1,
            "use": 1,
            "best-first": 1,
            "evaluation": 2,
            "function": 2,
            "path": 1,
            "root": 1,
            "current": 1,
            "node": 1,
            "called": 1,
            "theoretical": 1,
            "computer": 1,
            "science": 1,
            "community": 2,
            "idea": 1,
            "breadth-first": 1,
            "spread": 2,
            "wave": 2,
            "uniform": 2,
            "depth—first": 1,
            "depth": 2,
            "on—uniform-cost": 1,
            "path-cost": 1,
            "implemented": 1,
            "call": 1,
            "est": 1,
            "irst": 1,
            "earch": 1,
            "ath": 1,
            "ost": 1,
            "shown": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para141",
              "entity_text": "Dijkstra",
              "entity_type": "ORG",
              "start_char": 6,
              "end_char": 14,
              "context": "3.4.2\nDijkstra’s algorithm or uniform-cost search\nWhen actions h"
            },
            {
              "para_id": "chap3_para141",
              "entity_text": "Dijkstra",
              "entity_type": "ORG",
              "start_char": 235,
              "end_char": 243,
              "context": "from the root to the current node. This is called Dijkstra’s algorithm by the theoretical computer science c"
            },
            {
              "para_id": "chap3_para141",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 334,
              "end_char": 336,
              "context": "science community, and\nuniform-cost search\nby the AI community. The idea is that while breadth-first s"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para142",
          "content": "Consider\nFigure 3.10\n, where the problem is to get from Sibiu to Bucharest. The successors of Sibiu are Rimnicu Vilcea and Fagaras, with costs 80 and 99, respectively. The least-cost node, Rimnicu Vilcea, is expanded next, adding Pitesti with cost 80 + 97 = 177. The least-cost node is now Fagaras, so it is expanded, adding Bucharest with cost 99 + 211 = 310. Bucharest is the goal, but the algorithm tests for goals only when it expands a node, not when it generates a node, so it has not yet detected that this is a path to the goal.",
          "sentence_count": 5,
          "char_count": 438,
          "prev_para_id": "chap3_para141",
          "next_para_id": "chap3_para143",
          "style_metadata": {
            "para_id": "chap3_para142",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.8,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 5
          },
          "terminology": {
            "consider": 1,
            "figure": 1,
            "problem": 1,
            "get": 1,
            "sibiu": 2,
            "bucharest": 3,
            "successor": 1,
            "rimnicu": 2,
            "vilcea": 2,
            "fagaras": 2,
            "cost": 3,
            "least-cost": 2,
            "node": 4,
            "expanded": 2,
            "next": 1,
            "adding": 2,
            "pitesti": 1,
            "goal": 3,
            "algorithm": 1,
            "test": 1,
            "expands": 1,
            "generates": 1,
            "detected": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para142",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 56,
              "end_char": 61,
              "context": "er\nFigure 3.10\n, where the problem is to get from Sibiu to Bucharest. The successors of Sibiu are Rimnicu"
            },
            {
              "para_id": "chap3_para142",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 94,
              "end_char": 99,
              "context": "to get from Sibiu to Bucharest. The successors of Sibiu are Rimnicu Vilcea and Fagaras, with costs 80 and"
            },
            {
              "para_id": "chap3_para142",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 183,
              "end_char": 187,
              "context": "ith costs 80 and 99, respectively. The least-cost node, Rimnicu Vilcea, is expanded next, adding Pitesti"
            },
            {
              "para_id": "chap3_para142",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 278,
              "end_char": 282,
              "context": "g Pitesti with cost 80 + 97 = 177. The least-cost node is now Fagaras, so it is expanded, adding Buchare"
            },
            {
              "para_id": "chap3_para142",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 361,
              "end_char": 370,
              "context": "anded, adding Bucharest with cost 99 + 211 = 310. Bucharest is the goal, but the algorithm tests for goals on"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para143",
          "content": "×\nFigure 3.10\nPart of the Romania state space, selected to illustrate uniform-cost search.",
          "sentence_count": 1,
          "char_count": 79,
          "prev_para_id": "chap3_para142",
          "next_para_id": "chap3_para144",
          "style_metadata": {
            "para_id": "chap3_para143",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "part": 1,
            "romania": 1,
            "state": 1,
            "space": 1,
            "selected": 1,
            "illustrate": 1,
            "uniform-cost": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para143",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 26,
              "end_char": 33,
              "context": "×\nFigure 3.10\nPart of the Romania state space, selected to illustrate uniform-cost "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para144",
          "content": "The algorithm continues on, choosing Pitesti for expansion next and adding a second path to Bucharest with cost 80 + 97 + 101 = 278. It has a lower cost, so it replaces the previous path in\nreached\nand is added to the\nfrontier.",
          "sentence_count": 2,
          "char_count": 187,
          "prev_para_id": "chap3_para143",
          "next_para_id": "chap3_para145",
          "style_metadata": {
            "para_id": "chap3_para144",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.021,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 2
          },
          "terminology": {
            "algorithm": 1,
            "continues": 1,
            "choosing": 1,
            "pitesti": 1,
            "expansion": 1,
            "adding": 1,
            "second": 1,
            "path": 2,
            "bucharest": 1,
            "cost": 2,
            "lower": 1,
            "replaces": 1,
            "previous": 1,
            "reached": 1,
            "added": 1,
            "frontier": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para145",
          "content": "It turns out this node now has the lowest cost, so it is considered next, found to be a goal, and returned. Note that if we had checked for a goal upon generating a node rather than when expanding the lowest-cost node, then we would have returned a higher-cost path (the one through Fagaras).",
          "sentence_count": 2,
          "char_count": 239,
          "prev_para_id": "chap3_para144",
          "next_para_id": "chap3_para146",
          "style_metadata": {
            "para_id": "chap3_para145",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 2
          },
          "terminology": {
            "turn": 1,
            "lowest": 1,
            "cost": 1,
            "considered": 1,
            "next": 1,
            "found": 1,
            "goal": 2,
            "returned": 2,
            "checked": 1,
            "generating": 1,
            "node": 2,
            "expanding": 1,
            "lowest-cost": 1,
            "higher-cost": 1,
            "path": 1,
            "fagaras": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para145",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 165,
              "end_char": 169,
              "context": "at if we had checked for a goal upon generating a node rather than when expanding the lowest-cost node, "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para146",
          "content": "The complexity of uniform-cost search is characterized in terms of\nC\n*, the cost of the optimal solution,\n8\nand\nϵ\n, a lower bound on the cost of each action, with\nϵ\n> 0. Then the algorithm’s worst-case time and space complexity is\nO\n(\nb\n1+⌊\nC*/ϵ\n⌋\n), which can be much greater than\nb\nd\n. This is because uniform-cost search can explore large trees of actions with low costs before exploring paths involving a high-cost and perhaps useful action. When all action costs are equal,\nb\n1+⌊\nC*/ϵ\n⌋\nis just\nb\nd\n+1\n, and uniform-cost search is similar to breadth-first search.",
          "sentence_count": 4,
          "char_count": 488,
          "prev_para_id": "chap3_para145",
          "next_para_id": "chap3_para147",
          "style_metadata": {
            "para_id": "chap3_para146",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.25,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 4
          },
          "terminology": {
            "complexity": 2,
            "uniform-cost": 3,
            "search": 4,
            "characterized": 1,
            "term": 1,
            "cost": 4,
            "optimal": 1,
            "solution": 1,
            "bound": 1,
            "action": 4,
            "worst-case": 1,
            "time": 1,
            "space": 1,
            "much": 1,
            "greater": 1,
            "large": 1,
            "tree": 1,
            "low": 1,
            "exploring": 1,
            "path": 1,
            "involving": 1,
            "high-cost": 1,
            "useful": 1,
            "equal": 1,
            "similar": 1,
            "breadth-first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para147",
          "content": "Uniform-cost search is complete and is cost-optimal, because the first solution it finds will have a cost that is at least as low as the cost of any other node in the frontier. Uniform-cost search considers all paths systematically in order of increasing cost, never getting caught going down a single infinite path (assuming that all action costs are >\nϵ\n> 0).",
          "sentence_count": 2,
          "char_count": 301,
          "prev_para_id": "chap3_para146",
          "next_para_id": "chap3_para148",
          "style_metadata": {
            "para_id": "chap3_para147",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 2
          },
          "terminology": {
            "uniform-cost": 2,
            "search": 2,
            "complete": 1,
            "cost-optimal": 1,
            "first": 1,
            "solution": 1,
            "find": 1,
            "cost": 4,
            "least": 1,
            "low": 1,
            "node": 1,
            "considers": 1,
            "path": 2,
            "order": 1,
            "increasing": 1,
            "getting": 1,
            "caught": 1,
            "going": 1,
            "single": 1,
            "infinite": 1,
            "assuming": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para148",
          "content": "3.4.3\nDepth-first search and the problem of memory\nDepth-first search\nalways expands the\ndeepest\nnode in the frontier first. It could be implemented as a call to B\nEST\n-F\nIRST\n-S\nEARCH\nwhere the evaluation function\nf\nis the negative of the depth. However, it is usually implemented not as a graph search but as a tree-like search that does not keep a table of reached states. The progress of the search is illustrated in\nFigure 3.11\n; search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. The search then “backs up” to the next deepest node that still has\nunexpanded successors. Depth-first search is not cost-optimal; it returns the first solution it finds, even if it is not cheapest.",
          "sentence_count": 6,
          "char_count": 625,
          "prev_para_id": "chap3_para147",
          "next_para_id": "chap3_para149",
          "style_metadata": {
            "para_id": "chap3_para148",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 141,
            "sentence_count": 6
          },
          "terminology": {
            "depth-first": 3,
            "search": 9,
            "problem": 1,
            "memory": 1,
            "expands": 1,
            "deepest": 3,
            "node": 3,
            "frontier": 1,
            "implemented": 2,
            "call": 1,
            "est": 1,
            "irst": 1,
            "earch": 1,
            "evaluation": 1,
            "function": 1,
            "negative": 1,
            "depth": 1,
            "graph": 1,
            "tree-like": 1,
            "keep": 1,
            "table": 1,
            "reached": 1,
            "state": 1,
            "illustrated": 1,
            "figure": 1,
            "proceeds": 1,
            "level": 1,
            "tree": 1,
            "successor": 2,
            "back": 1,
            "unexpanded": 1,
            "cost-optimal": 1,
            "return": 1,
            "first": 1,
            "solution": 1,
            "find": 1,
            "cheapest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para148",
              "entity_text": "3.4.3\nDepth-first",
              "entity_type": "PRODUCT",
              "start_char": 0,
              "end_char": 17,
              "context": "3.4.3\nDepth-first search and the problem of memory\nDepth-first sear"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para149",
          "content": "×\nFigure 3.11\nA dozen steps (left to right, top to bottom) in the progress of a depth-first search on a binary tree from start state A to goal M. The frontier is in green, with a triangle marking the node to be expanded next. Previously expanded nodes are lavender, and potential future nodes have faint dashed lines. Expanded nodes with no descendants in the frontier (very faint lines) can be discarded.",
          "sentence_count": 3,
          "char_count": 336,
          "prev_para_id": "chap3_para148",
          "next_para_id": "chap3_para150",
          "style_metadata": {
            "para_id": "chap3_para149",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "dozen": 1,
            "step": 1,
            "left": 1,
            "right": 1,
            "top": 1,
            "bottom": 1,
            "progress": 1,
            "depth-first": 1,
            "search": 1,
            "binary": 1,
            "tree": 1,
            "start": 1,
            "state": 1,
            "goal": 1,
            "frontier": 1,
            "green": 1,
            "triangle": 1,
            "marking": 1,
            "expanded": 3,
            "next": 1,
            "node": 3,
            "potential": 1,
            "future": 1,
            "faint": 2,
            "dashed": 1,
            "line": 2,
            "descendant": 1,
            "discarded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para150",
          "content": "For finite state spaces that are trees it is efficient and complete; for acyclic state spaces it may end up expanding the same state many times via different paths, but will (eventually) systematically explore the entire space.",
          "sentence_count": 1,
          "char_count": 191,
          "prev_para_id": "chap3_para149",
          "next_para_id": "chap3_para151",
          "style_metadata": {
            "para_id": "chap3_para150",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 1
          },
          "terminology": {
            "finite": 1,
            "state": 3,
            "space": 3,
            "tree": 1,
            "efficient": 1,
            "complete": 1,
            "acyclic": 1,
            "end": 1,
            "expanding": 1,
            "many": 1,
            "time": 1,
            "different": 1,
            "path": 1,
            "explore": 1,
            "entire": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para151",
          "content": "In cyclic state spaces it can get stuck in an infinite loop; therefore some implementations of depth-first search check each new node for cycles. Finally, in infinite state spaces, depth-first search is not systematic: it can get stuck going down an infinite path, even if there are no cycles. Thus, depth-first search is incomplete.",
          "sentence_count": 3,
          "char_count": 280,
          "prev_para_id": "chap3_para150",
          "next_para_id": "chap3_para152",
          "style_metadata": {
            "para_id": "chap3_para151",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 63,
            "sentence_count": 3
          },
          "terminology": {
            "cyclic": 1,
            "state": 2,
            "space": 2,
            "get": 2,
            "stuck": 2,
            "infinite": 3,
            "loop": 1,
            "implementation": 1,
            "depth-first": 3,
            "search": 3,
            "check": 1,
            "new": 1,
            "node": 1,
            "cycle": 2,
            "systematic": 1,
            "going": 1,
            "path": 1,
            "incomplete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para152",
          "content": "With all this bad news, why would anyone consider using depth-first search rather than breadth-first or best-first? The answer is that for problems where a tree-like search is feasible, depth-first search has much smaller needs for memory. We don’t keep a\nreached\ntable at all, and the frontier is very small: think of the frontier in breadth-first search as the surface of an ever-expanding sphere, while the frontier in depth-first search is just a radius of the sphere.",
          "sentence_count": 3,
          "char_count": 397,
          "prev_para_id": "chap3_para151",
          "next_para_id": "chap3_para153",
          "style_metadata": {
            "para_id": "chap3_para152",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "bad": 1,
            "news": 1,
            "anyone": 1,
            "consider": 1,
            "using": 1,
            "depth-first": 3,
            "search": 5,
            "breadth-first": 2,
            "best-first": 1,
            "answer": 1,
            "problem": 1,
            "tree-like": 1,
            "feasible": 1,
            "much": 1,
            "smaller": 1,
            "need": 1,
            "memory": 1,
            "keep": 1,
            "reached": 1,
            "table": 1,
            "small": 1,
            "think": 1,
            "frontier": 1,
            "surface": 1,
            "ever-expanding": 1,
            "radius": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para153",
          "content": "For a finite tree-shaped state-space like the one in\nFigure 3.11\n, a depth-first tree-like search takes time proportional to the number of states, and has memory complexity of only\nO\n(\nbm\n)\n,\nwhere\nb\nis the branching factor and\nm\nis the maximum depth of the tree. Some problems that would require exabytes of memory with breadth-first search can be handled with only kilobytes using depth-first search. Because of its parsimonious use of memory, depth-first tree-like search has been adopted as the basic workhorse of many areas of AI, including constraint satisfaction (\nChapter 5\n), propositional satisfiability (\nChapter 7\n), and logic programming (\nChapter 9\n).",
          "sentence_count": 3,
          "char_count": 572,
          "prev_para_id": "chap3_para152",
          "next_para_id": "chap3_para154",
          "style_metadata": {
            "para_id": "chap3_para153",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 120,
            "sentence_count": 3
          },
          "terminology": {
            "finite": 1,
            "tree-shaped": 1,
            "state-space": 1,
            "figure": 1,
            "depth-first": 3,
            "tree-like": 2,
            "search": 4,
            "take": 1,
            "time": 1,
            "proportional": 1,
            "number": 1,
            "state": 1,
            "memory": 3,
            "complexity": 1,
            "branching": 1,
            "factor": 1,
            "maximum": 1,
            "depth": 1,
            "tree": 1,
            "problem": 1,
            "require": 1,
            "exabyte": 1,
            "breadth-first": 1,
            "handled": 1,
            "kilobyte": 1,
            "using": 1,
            "parsimonious": 1,
            "use": 1,
            "adopted": 1,
            "basic": 1,
            "workhorse": 1,
            "many": 1,
            "area": 1,
            "including": 1,
            "constraint": 1,
            "satisfaction": 1,
            "chapter": 3,
            "propositional": 1,
            "satisfiability": 1,
            "logic": 1,
            "programming": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para153",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 532,
              "end_char": 534,
              "context": "n adopted as the basic workhorse of many areas of AI, including constraint satisfaction (\nChapter 5\n),"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para154",
          "content": "A variant of depth-first search called\nbacktracking search\nuses even less memory. (See\nChapter 5\nfor more details.) In backtracking, only one successor is generated at a time rather than all successors; each partially expanded node remembers which successor to generate next. In addition, successors are generated by\nmodifying\nthe current state description directly rather than allocating memory for a brand-new state. This reduces the memory requirements to just one state description and a path of\nO\n(\nm\n) actions; a significant savings over\nO\n(\nbm\n) states for depth-first search. With backtracking we also have the option of maintaining an efficient set data structure for the states on the current path, allowing us to check for a cyclic path in\nO\n(1) time rather than\nO\n(\nm\n). For backtracking to work, we must be able to\nundo\neach action when we backtrack. Backtracking is critical to the success of many problems with large state descriptions, such as robotic assembly.",
          "sentence_count": 8,
          "char_count": 836,
          "prev_para_id": "chap3_para153",
          "next_para_id": "chap3_para155",
          "style_metadata": {
            "para_id": "chap3_para154",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.88,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 183,
            "sentence_count": 8
          },
          "terminology": {
            "variant": 1,
            "depth-first": 2,
            "search": 3,
            "called": 1,
            "backtracking": 5,
            "us": 1,
            "less": 1,
            "memory": 3,
            "see": 1,
            "chapter": 1,
            "detail": 1,
            "successor": 4,
            "generated": 2,
            "time": 2,
            "expanded": 1,
            "node": 1,
            "remembers": 1,
            "generate": 1,
            "next": 1,
            "addition": 1,
            "modifying": 1,
            "current": 2,
            "state": 6,
            "description": 3,
            "allocating": 1,
            "brand-new": 1,
            "reduces": 1,
            "requirement": 1,
            "path": 3,
            "action": 2,
            "significant": 1,
            "saving": 1,
            "option": 1,
            "maintaining": 1,
            "efficient": 1,
            "set": 1,
            "data": 1,
            "structure": 1,
            "allowing": 1,
            "check": 1,
            "cyclic": 1,
            "work": 1,
            "able": 1,
            "undo": 1,
            "backtrack": 1,
            "critical": 1,
            "success": 1,
            "many": 1,
            "problem": 1,
            "large": 1,
            "robotic": 1,
            "assembly": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para154",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 227,
              "end_char": 231,
              "context": "ther than all successors; each partially expanded node remembers which successor to generate next. In ad"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para155",
          "content": "3.4.4\nDepth-limited and iterative deepening search\nTo keep depth-first search from wandering down an infinite path, we can use\ndepth-limited search\n, a version of depth-first search in which we supply a depth limit,\nl\n, and treat all nodes at depth\nl\nas if they had no successors (see\nFigure 3.12\n). The time complexity is\nO\n(\nb\nl\n) and the space complexity is\nO\n(\nbl\n)\n.",
          "sentence_count": 2,
          "char_count": 320,
          "prev_para_id": "chap3_para154",
          "next_para_id": "chap3_para156",
          "style_metadata": {
            "para_id": "chap3_para155",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 2
          },
          "terminology": {
            "depth-limited": 2,
            "iterative": 1,
            "deepening": 1,
            "search": 4,
            "keep": 1,
            "depth-first": 2,
            "wandering": 1,
            "infinite": 1,
            "path": 1,
            "use": 1,
            "version": 1,
            "supply": 1,
            "depth": 2,
            "limit": 1,
            "treat": 1,
            "node": 1,
            "successor": 1,
            "see": 1,
            "time": 1,
            "complexity": 2,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para156",
          "content": "Unfortunately, if we make a poor choice for\nl\nthe algorithm will fail to reach the solution, making it incomplete again.",
          "sentence_count": 1,
          "char_count": 102,
          "prev_para_id": "chap3_para155",
          "next_para_id": "chap3_para157",
          "style_metadata": {
            "para_id": "chap3_para156",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "make": 1,
            "poor": 1,
            "choice": 1,
            "algorithm": 1,
            "fail": 1,
            "reach": 1,
            "solution": 1,
            "making": 1,
            "incomplete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para157",
          "content": "Since depth-first search is a tree-like search, we can’t keep it from wasting time on redundant paths in general, but we can eliminate cycles at the cost of some computation time. If we look only a few links up in the parent chain we can catch most cycles; longer cycles are handled by the depth limit.",
          "sentence_count": 2,
          "char_count": 247,
          "prev_para_id": "chap3_para156",
          "next_para_id": "chap3_para158",
          "style_metadata": {
            "para_id": "chap3_para157",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "depth-first": 1,
            "search": 2,
            "tree-like": 1,
            "keep": 1,
            "wasting": 1,
            "time": 2,
            "redundant": 1,
            "path": 1,
            "general": 1,
            "eliminate": 1,
            "cycle": 3,
            "cost": 1,
            "computation": 1,
            "look": 1,
            "link": 1,
            "parent": 1,
            "chain": 1,
            "catch": 1,
            "handled": 1,
            "depth": 1,
            "limit": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para158",
          "content": "Sometimes a good depth limit can be chosen based on knowledge of the problem. For example, on the map of Romania there are 20 cities. Therefore,\nl\n= 19 is a valid limit. But if we studied the map carefully, we would discover that any city can be reached from any other city in at most 9 actions. This number, known as the\ndiameter\nof the state-space graph, gives us a better depth limit, which leads to a more efficient depth-limited search. However, for most problems we will not know a good depth limit until we have solved the problem.",
          "sentence_count": 6,
          "char_count": 443,
          "prev_para_id": "chap3_para157",
          "next_para_id": "chap3_para159",
          "style_metadata": {
            "para_id": "chap3_para158",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 18.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore",
              "however"
            ],
            "word_count": 113,
            "sentence_count": 6
          },
          "terminology": {
            "good": 2,
            "depth": 3,
            "limit": 4,
            "chosen": 1,
            "based": 1,
            "knowledge": 1,
            "problem": 3,
            "example": 1,
            "map": 2,
            "romania": 1,
            "city": 3,
            "therefore": 1,
            "valid": 1,
            "studied": 1,
            "discover": 1,
            "reached": 1,
            "action": 1,
            "number": 1,
            "known": 1,
            "diameter": 1,
            "state-space": 1,
            "graph": 1,
            "give": 1,
            "better": 1,
            "lead": 1,
            "efficient": 1,
            "depth-limited": 1,
            "search": 1,
            "know": 1,
            "solved": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para158",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 105,
              "end_char": 112,
              "context": "wledge of the problem. For example, on the map of Romania there are 20 cities. Therefore,\nl\n= 19 is a valid"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para159",
          "content": "Iterative deepening search\nsolves the problem of picking a good value for\nl\nby trying all values: first 0, then 1, then 2, and so on—until either a solution is found, or the depth-limited search returns the\nfailure\nvalue rather than the\ncutoff\nvalue. The algorithm is shown in\nFigure 3.12\n. Iterative deepening combines many of the benefits of depth-first and breadth-first search. Like depth-first search, its memory requirements are modest:\nO(bd\n) when there is a solution, or\nO(bm)\non finite state spaces with no solution. Like breadth-first search, iterative deepening is optimal for problems where all actions have the same cost, and is complete on finite acyclic state spaces, or on any finite state space when we check nodes for cycles all the way up the path.",
          "sentence_count": 5,
          "char_count": 651,
          "prev_para_id": "chap3_para158",
          "next_para_id": "chap3_para160",
          "style_metadata": {
            "para_id": "chap3_para159",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 5
          },
          "terminology": {
            "iterative": 3,
            "deepening": 3,
            "search": 5,
            "solves": 1,
            "problem": 2,
            "picking": 1,
            "good": 1,
            "value": 4,
            "trying": 1,
            "on—until": 1,
            "solution": 3,
            "found": 1,
            "depth-limited": 1,
            "return": 1,
            "failure": 1,
            "cutoff": 1,
            "algorithm": 1,
            "shown": 1,
            "figure": 1,
            "combine": 1,
            "many": 1,
            "benefit": 1,
            "depth-first": 2,
            "breadth-first": 2,
            "memory": 1,
            "requirement": 1,
            "modest": 1,
            "finite": 2,
            "state": 3,
            "space": 3,
            "optimal": 1,
            "action": 1,
            "cost": 1,
            "complete": 1,
            "acyclic": 1,
            "check": 1,
            "node": 1,
            "cycle": 1,
            "way": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para160",
          "content": "×\nFigure 3.12\nIterative deepening and depth-limited tree-like search. Iterative deepening repeatedly applies depth-limited search with increasing limits. It returns one of three different types of values: either a solution node; or\nfailure,\nwhen it has exhausted all nodes and proved there is no solution at any depth; or\ncutoff\n, to mean there might be a solution at a deeper depth than\nl\n. This is a tree-like search algorithm that does not keep track of\nreached\nstates, and thus uses much less memory than best-first search, but runs the risk of visiting the same state multiple times on different paths. Also, if the I\nS\n-C\nYCLE\ncheck does not check\nall\ncycles, then the algorithm may get caught in a loop.",
          "sentence_count": 5,
          "char_count": 603,
          "prev_para_id": "chap3_para159",
          "next_para_id": "chap3_para161",
          "style_metadata": {
            "para_id": "chap3_para160",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "iterative": 2,
            "deepening": 2,
            "depth-limited": 2,
            "tree-like": 2,
            "search": 4,
            "applies": 1,
            "increasing": 1,
            "limit": 1,
            "return": 1,
            "different": 2,
            "type": 1,
            "value": 1,
            "solution": 3,
            "node": 2,
            "failure": 1,
            "exhausted": 1,
            "proved": 1,
            "depth": 2,
            "cutoff": 1,
            "mean": 1,
            "deeper": 1,
            "algorithm": 2,
            "keep": 1,
            "track": 1,
            "reached": 1,
            "state": 2,
            "us": 1,
            "less": 1,
            "memory": 1,
            "best-first": 1,
            "run": 1,
            "risk": 1,
            "visiting": 1,
            "multiple": 1,
            "time": 1,
            "path": 1,
            "ycle": 1,
            "check": 2,
            "cycle": 1,
            "get": 1,
            "caught": 1,
            "loop": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para161",
          "content": "The time complexity is\nO\n(\nb\nd\n) when there is a solution, or\nO\n(\nb\nm\n) when there is none. Each iteration of iterative deepening search generates a new level, in the same way that breadth-first search does, but breadth-first does this by storing all nodes in memory, while iterative-deepening does it by repeating the previous levels, thereby saving memory at the cost of more time.",
          "sentence_count": 2,
          "char_count": 324,
          "prev_para_id": "chap3_para160",
          "next_para_id": "chap3_para162",
          "style_metadata": {
            "para_id": "chap3_para161",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 2
          },
          "terminology": {
            "time": 2,
            "complexity": 1,
            "solution": 1,
            "none": 1,
            "iteration": 1,
            "iterative": 1,
            "deepening": 1,
            "search": 2,
            "generates": 1,
            "new": 1,
            "level": 2,
            "way": 1,
            "breadth-first": 2,
            "storing": 1,
            "node": 1,
            "memory": 2,
            "iterative-deepening": 1,
            "repeating": 1,
            "previous": 1,
            "saving": 1,
            "cost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para162",
          "content": "Figure 3.13\nshows four iterations of iterative-deepening search on a binary search tree, where the solution is found on the fourth iteration.",
          "sentence_count": 1,
          "char_count": 121,
          "prev_para_id": "chap3_para161",
          "next_para_id": "chap3_para163",
          "style_metadata": {
            "para_id": "chap3_para162",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "iteration": 2,
            "iterative-deepening": 1,
            "search": 2,
            "binary": 1,
            "tree": 1,
            "solution": 1,
            "found": 1,
            "fourth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para163",
          "content": "×\nFigure 3.13\nFour iterations of iterative deepening search for goal M on a binary tree, with the depth limit varying from 0 to 3. Note the interior nodes form a single path. The triangle marks the node to expand next; green nodes with dark outlines are on the frontier; the very faint nodes provably can’t be part of a solution with this depth limit.",
          "sentence_count": 3,
          "char_count": 289,
          "prev_para_id": "chap3_para162",
          "next_para_id": "chap3_para164",
          "style_metadata": {
            "para_id": "chap3_para163",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "iteration": 1,
            "iterative": 1,
            "deepening": 1,
            "search": 1,
            "goal": 1,
            "binary": 1,
            "tree": 1,
            "depth": 2,
            "limit": 2,
            "varying": 1,
            "note": 1,
            "interior": 1,
            "node": 3,
            "form": 1,
            "single": 1,
            "path": 1,
            "triangle": 1,
            "mark": 1,
            "expand": 1,
            "next": 1,
            "green": 1,
            "dark": 1,
            "outline": 1,
            "faint": 1,
            "part": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para164",
          "content": "Iterative deepening search may seem wasteful because states near the top of the search tree are re-generated multiple times. But for many state spaces, most of the nodes are in the bottom level, so it does not matter much that the upper levels are repeated. In an iterative deepening search, the nodes on the bottom level (depth\nd\n) are generated once, those on the next-to-bottom level are generated twice, and so on, up to the children of the root, which are generated\nd\ntimes. So the total number of nodes generated in the worst case is\nN\n(IDS) = (\nd\n)\nb\n1\n+(\nd\n−\n1)\nb\n2\n+(\nd\n−\n2)\nb\n3\n⋯\n+\nb\nd\n,\nwhich gives a time complexity of\nO\n(\nb\nd\n)—asymptotically the same as breadth-first search. For example, if\nb\n= 10 and\nd\n= 5, the numbers are\nN\n(IDS) = 50+400+3,000+20,000+100,000 = 123,450\nN\n(BFS) = 10+100+1,000+10,000+100,000 = 111,110,\nIf you are really concerned about the repetition, you can use a hybrid approach that runs\nbreadth-first search until almost all the available memory is consumed, and then runs iterative deepening from all the nodes in the frontier.",
          "sentence_count": 5,
          "char_count": 921,
          "prev_para_id": "chap3_para163",
          "next_para_id": "chap3_para165",
          "style_metadata": {
            "para_id": "chap3_para164",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 46.0,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 230,
            "sentence_count": 5
          },
          "terminology": {
            "iterative": 3,
            "deepening": 3,
            "search": 5,
            "seem": 1,
            "wasteful": 1,
            "state": 2,
            "top": 1,
            "tree": 1,
            "re-generated": 1,
            "multiple": 1,
            "time": 3,
            "many": 1,
            "space": 1,
            "node": 4,
            "bottom": 2,
            "level": 4,
            "much": 1,
            "repeated": 1,
            "depth": 1,
            "generated": 4,
            "next-to-bottom": 1,
            "child": 1,
            "root": 1,
            "total": 1,
            "number": 2,
            "worst": 1,
            "case": 1,
            "id": 2,
            "give": 1,
            "complexity": 1,
            "breadth-first": 2,
            "example": 1,
            "bfs": 1,
            "concerned": 1,
            "repetition": 1,
            "use": 1,
            "hybrid": 1,
            "approach": 1,
            "run": 2,
            "available": 1,
            "memory": 1,
            "consumed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para164",
              "entity_text": "BFS",
              "entity_type": "ORG",
              "start_char": 791,
              "end_char": 794,
              "context": "\n(IDS) = 50+400+3,000+20,000+100,000 = 123,450\nN\n(BFS) = 10+100+1,000+10,000+100,000 = 111,110,\nIf you "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para165",
          "content": "In general, iterative deepening is the preferred uninformed search method when the search state space is larger than can fit in memory and the depth of the solution is not known.",
          "sentence_count": 1,
          "char_count": 148,
          "prev_para_id": "chap3_para164",
          "next_para_id": "chap3_para166",
          "style_metadata": {
            "para_id": "chap3_para165",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 1
          },
          "terminology": {
            "general": 1,
            "iterative": 1,
            "deepening": 1,
            "preferred": 1,
            "uninformed": 1,
            "search": 2,
            "method": 1,
            "state": 1,
            "space": 1,
            "larger": 1,
            "fit": 1,
            "memory": 1,
            "depth": 1,
            "solution": 1,
            "known": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para166",
          "content": "3.4.5\nBidirectional search\nThe algorithms we have covered so far start at an initial state and can reach any one of multiple possible goal states. An alternative approach called\nbidirectional search\nsimultaneously searches forward from the initial state and backwards from the goal state(s), hoping that the two searches will meet. The motivation is that\nb\nd\n/2\n+\nb\nd\n/2\nis much less than\nb\nd\n(e.g., 50,000 times less when\nb = d =\n10).",
          "sentence_count": 3,
          "char_count": 375,
          "prev_para_id": "chap3_para165",
          "next_para_id": "chap3_para167",
          "style_metadata": {
            "para_id": "chap3_para166",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "bidirectional": 2,
            "search": 4,
            "algorithm": 1,
            "covered": 1,
            "start": 1,
            "initial": 2,
            "state": 4,
            "reach": 1,
            "multiple": 1,
            "possible": 1,
            "goal": 2,
            "alternative": 1,
            "approach": 1,
            "called": 1,
            "backwards": 1,
            "hoping": 1,
            "meet": 1,
            "motivation": 1,
            "less": 1,
            "e.g.": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para167",
          "content": "For this to work, we need to keep track of two frontiers and two tables of reached states, and we need to be able to reason backwards: if state\nsʹ\nis a successor of\ns\nin the forward direction, then we need to know that\ns\nis a successor of\nsʹ\nin the backward direction. We have a solution when the two frontiers collide.",
          "sentence_count": 2,
          "char_count": 264,
          "prev_para_id": "chap3_para166",
          "next_para_id": "chap3_para168",
          "style_metadata": {
            "para_id": "chap3_para167",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 2
          },
          "terminology": {
            "work": 1,
            "keep": 1,
            "track": 1,
            "frontier": 2,
            "table": 1,
            "reached": 1,
            "state": 2,
            "need": 2,
            "able": 1,
            "reason": 1,
            "backwards": 1,
            "successor": 2,
            "forward": 1,
            "direction": 2,
            "know": 1,
            "backward": 1,
            "solution": 1,
            "collide": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para168",
          "content": "9\nThere are many different versions of bidirectional search, just as there are many different unidirectional search algorithms. In this section, we describe bidirectional best-first search. Although there are two separate frontiers, the node to be expanded next is always one with a minimum value of the evaluation function, across either frontier. When the evaluation\nfunction is the path cost, we get bidirectional uniform-cost search, and if the cost of the optimal path is\nC\n*, then no node with cost\n>\nC\n*\n2\nwill be expanded. This can result in a considerable speedup.",
          "sentence_count": 5,
          "char_count": 488,
          "prev_para_id": "chap3_para167",
          "next_para_id": "chap3_para169",
          "style_metadata": {
            "para_id": "chap3_para168",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 107,
            "sentence_count": 5
          },
          "terminology": {
            "many": 2,
            "different": 2,
            "version": 1,
            "bidirectional": 3,
            "search": 4,
            "unidirectional": 1,
            "algorithm": 1,
            "section": 1,
            "describe": 1,
            "best-first": 1,
            "separate": 1,
            "frontier": 2,
            "expanded": 2,
            "next": 1,
            "minimum": 1,
            "value": 1,
            "evaluation": 2,
            "function": 2,
            "path": 2,
            "cost": 3,
            "get": 1,
            "uniform-cost": 1,
            "optimal": 1,
            "node": 1,
            "result": 1,
            "considerable": 1,
            "speedup": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para169",
          "content": "The general best-first bidirectional search algorithm is shown in\nFigure 3.14\n. We pass in two versions of the problem and the evaluation function, one in the forward direction (subscript\nF\n) and one in the backward direction (subscript\nB\n). When the evaluation function is the path cost, we know that the first solution found will be an optimal solution, but with different evaluation functions that is not necessarily true. Therefore, we keep track of the best solution found so far, and might have to update that several times before the T\nERMINATED\ntest proves that there is no possible better solution remaining.",
          "sentence_count": 4,
          "char_count": 522,
          "prev_para_id": "chap3_para168",
          "next_para_id": "chap3_para170",
          "style_metadata": {
            "para_id": "chap3_para169",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "general": 1,
            "best-first": 1,
            "bidirectional": 1,
            "search": 1,
            "algorithm": 1,
            "shown": 1,
            "figure": 1,
            "pas": 1,
            "version": 1,
            "problem": 1,
            "evaluation": 3,
            "function": 3,
            "forward": 1,
            "direction": 2,
            "subscript": 2,
            "backward": 1,
            "path": 1,
            "cost": 1,
            "know": 1,
            "first": 1,
            "solution": 4,
            "found": 2,
            "optimal": 1,
            "different": 1,
            "true": 1,
            "keep": 1,
            "track": 1,
            "best": 1,
            "update": 1,
            "several": 1,
            "time": 1,
            "erminated": 1,
            "test": 1,
            "prof": 1,
            "possible": 1,
            "better": 1,
            "remaining": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para169",
              "entity_text": "F\n",
              "entity_type": "PRODUCT",
              "start_char": 188,
              "end_char": 190,
              "context": "function, one in the forward direction (subscript\nF\n) and one in the backward direction (subscript\nB\n)"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para170",
          "content": "×\nFigure 3.14\nBidirectional best-first search keeps two frontiers and two tables of reached states. When a path in one frontier reaches a state that was also reached in the other half of the search, the two paths are joined (by the function J\nOIN\n-N\nODES\n) to form a solution. The first solution we get is not guaranteed to be the best; the function T\nERMINATED\ndetermines when to stop looking for new solutions.",
          "sentence_count": 3,
          "char_count": 345,
          "prev_para_id": "chap3_para169",
          "next_para_id": "chap3_para171",
          "style_metadata": {
            "para_id": "chap3_para170",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "bidirectional": 1,
            "best-first": 1,
            "search": 2,
            "keep": 1,
            "frontier": 2,
            "table": 1,
            "reached": 2,
            "state": 2,
            "reach": 1,
            "half": 1,
            "path": 1,
            "joined": 1,
            "function": 2,
            "oin": 1,
            "ode": 1,
            "form": 1,
            "solution": 3,
            "first": 1,
            "get": 1,
            "guaranteed": 1,
            "best": 1,
            "erminated": 1,
            "determines": 1,
            "stop": 1,
            "looking": 1,
            "new": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para171",
          "content": "3.4.6\nComparing uninformed search algorithms\nFigure 3.15\ncompares uninformed search algorithms in terms of the four evaluation criteria set forth in\nSection 3.3.4\n. This comparison is for tree-like search versions which don’t check for repeated states. For graph searches which do check, the main differences are that depth-first search is complete for finite state spaces, and the space and time complexities are bounded by the size of the state space (the number of vertices and edges, |V | + |\nE\n|).",
          "sentence_count": 3,
          "char_count": 427,
          "prev_para_id": "chap3_para170",
          "next_para_id": "chap3_para172",
          "style_metadata": {
            "para_id": "chap3_para171",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 92,
            "sentence_count": 3
          },
          "terminology": {
            "comparing": 1,
            "uninformed": 2,
            "search": 5,
            "algorithm": 2,
            "figure": 1,
            "compare": 1,
            "term": 1,
            "evaluation": 1,
            "criterion": 1,
            "set": 1,
            "forth": 1,
            "section": 1,
            "comparison": 1,
            "tree-like": 1,
            "version": 1,
            "check": 2,
            "repeated": 1,
            "state": 3,
            "graph": 1,
            "main": 1,
            "difference": 1,
            "depth-first": 1,
            "complete": 1,
            "finite": 1,
            "space": 3,
            "time": 1,
            "complexity": 1,
            "bounded": 1,
            "size": 1,
            "number": 1,
            "vertex": 1,
            "edge": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para171",
              "entity_text": "|V",
              "entity_type": "ORG",
              "start_char": 488,
              "end_char": 490,
              "context": "he state space (the number of vertices and edges, |V | + |\nE\n|)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para172",
          "content": "×\nFigure 3.15\nEvaluation of search algorithms.",
          "sentence_count": 1,
          "char_count": 42,
          "prev_para_id": "chap3_para171",
          "next_para_id": "chap3_para173",
          "style_metadata": {
            "para_id": "chap3_para172",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 8,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "evaluation": 1,
            "search": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para173",
          "content": "b\nis the branching factor;\nm\nis the maximum depth of the search tree;\nd\nis the depth of the shallowest solution, or is\nm\nwhen there is no solution;\nl\nis the depth limit. Superscript caveats are as follows:\n1\ncomplete if\nb\nis finite, and the state space either has a solution or is finite.",
          "sentence_count": 2,
          "char_count": 245,
          "prev_para_id": "chap3_para172",
          "next_para_id": "chap3_para174",
          "style_metadata": {
            "para_id": "chap3_para173",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 2
          },
          "terminology": {
            "branching": 1,
            "factor": 1,
            "maximum": 1,
            "depth": 3,
            "search": 1,
            "tree": 1,
            "shallowest": 1,
            "solution": 3,
            "limit": 1,
            "superscript": 1,
            "caveat": 1,
            "follows": 1,
            "complete": 1,
            "finite": 2,
            "state": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para174",
          "content": "2\ncomplete if all action costs are ≥\nϵ\n> 0;\n3\ncost-optimal if action costs are all identical;\n4\nif both directions are breadth-first or uniform-cost.",
          "sentence_count": 1,
          "char_count": 130,
          "prev_para_id": "chap3_para173",
          "next_para_id": "chap3_para175",
          "style_metadata": {
            "para_id": "chap3_para174",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 1
          },
          "terminology": {
            "complete": 1,
            "action": 2,
            "cost": 2,
            "cost-optimal": 1,
            "identical": 1,
            "direction": 1,
            "breadth-first": 1,
            "uniform-cost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para174",
              "entity_text": "≥",
              "entity_type": "PERSON",
              "start_char": 35,
              "end_char": 36,
              "context": "2\ncomplete if all action costs are ≥\nϵ\n> 0;\n3\ncost-optimal if action costs are all ide"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para175",
          "content": "3.5Informed (Heuristic) Search Strategies\n3.5\nInformed (Heuristic) Search Strategies\nThis section shows how an\ninformed search\nstrategy—one that uses domain-specific hints about the location of goals—can find solutions more efficiently than an uninformed strategy. The hints come in the form of a\nheuristic function\n, denoted\nh\n(\nn\n):\n10\nh(n) =\nestimated cost of the cheapest path from the state at node\nn\nto a goal state.",
          "sentence_count": 2,
          "char_count": 370,
          "prev_para_id": "chap3_para174",
          "next_para_id": "chap3_para176",
          "style_metadata": {
            "para_id": "chap3_para175",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 79,
            "sentence_count": 2
          },
          "terminology": {
            "heuristic": 3,
            "search": 3,
            "strategy": 3,
            "informed": 2,
            "section": 1,
            "show": 1,
            "strategy—one": 1,
            "us": 1,
            "domain-specific": 1,
            "hint": 2,
            "location": 1,
            "goals—can": 1,
            "find": 1,
            "solution": 1,
            "uninformed": 1,
            "come": 1,
            "form": 1,
            "function": 1,
            "denoted": 1,
            "estimated": 1,
            "cost": 1,
            "cheapest": 1,
            "path": 1,
            "state": 2,
            "node": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para175",
              "entity_text": "node\nn",
              "entity_type": "ORG",
              "start_char": 399,
              "end_char": 405,
              "context": "mated cost of the cheapest path from the state at node\nn\nto a goal state."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para176",
          "content": "For example, in route-finding problems, we can estimate the distance from the current state to a goal by computing the straight-line distance on the map between the two points. We study heuristics and where they come from in more detail in\nSection 3.6\n.",
          "sentence_count": 2,
          "char_count": 212,
          "prev_para_id": "chap3_para175",
          "next_para_id": "chap3_para177",
          "style_metadata": {
            "para_id": "chap3_para176",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 2
          },
          "terminology": {
            "example": 1,
            "route-finding": 1,
            "problem": 1,
            "estimate": 1,
            "distance": 2,
            "current": 1,
            "state": 1,
            "goal": 1,
            "computing": 1,
            "straight-line": 1,
            "point": 1,
            "study": 1,
            "heuristic": 1,
            "come": 1,
            "detail": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para177",
          "content": "3.5.1\nGreedy best-first search\nGreedy best-first search\nis a form of best-first search that expands first the node with the lowest\nh\n(\nn\n) value—the node that appears to be closest to the goal—on the grounds that this is likely to lead to a solution quickly. So the evaluation function\nf\n(\nn\n)\n= h\n(\nn\n)\n.",
          "sentence_count": 2,
          "char_count": 261,
          "prev_para_id": "chap3_para176",
          "next_para_id": "chap3_para178",
          "style_metadata": {
            "para_id": "chap3_para177",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 2
          },
          "terminology": {
            "greedy": 2,
            "best-first": 3,
            "search": 3,
            "form": 1,
            "expands": 1,
            "first": 1,
            "lowest": 1,
            "value—the": 1,
            "node": 1,
            "appears": 1,
            "closest": 1,
            "goal—on": 1,
            "ground": 1,
            "likely": 1,
            "lead": 1,
            "solution": 1,
            "evaluation": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para177",
              "entity_text": "Greedy",
              "entity_type": "ORG",
              "start_char": 31,
              "end_char": 37,
              "context": "3.5.1\nGreedy best-first search\nGreedy best-first search\nis a form of best-first search "
            },
            {
              "para_id": "chap3_para177",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 149,
              "end_char": 153,
              "context": " first the node with the lowest\nh\n(\nn\n) value—the node that appears to be closest to the goal—on the gro"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para178",
          "content": "Let us see how this works for route-finding problems in Romania; we use the\nstraight-line\ndistance\nheuristic, which we will call\nh\nSLD\n. If the goal is Bucharest, we need to know the straight-line distances to Bucharest, which are shown in\nFigure 3.16\n. For example,\nh\nSLD\n(\nArad\n) = 366. Notice that the values of\nh\nSLD\ncannot be computed from the problem description itself (that is, the A\nCTIONS\nand R\nESULT\nfunctions). Moreover, it takes a certain amount of world knowledge to know that\nh\nSLD\nis correlated with actual road distances and is, therefore, a useful heuristic.",
          "sentence_count": 5,
          "char_count": 496,
          "prev_para_id": "chap3_para177",
          "next_para_id": "chap3_para179",
          "style_metadata": {
            "para_id": "chap3_para178",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 23.6,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore",
              "moreover"
            ],
            "word_count": 118,
            "sentence_count": 5
          },
          "terminology": {
            "let": 1,
            "see": 1,
            "work": 1,
            "route-finding": 1,
            "problem": 2,
            "romania": 1,
            "straight-line": 2,
            "distance": 3,
            "heuristic": 2,
            "call": 1,
            "sld": 3,
            "goal": 1,
            "bucharest": 2,
            "need": 1,
            "know": 2,
            "shown": 1,
            "figure": 1,
            "example": 1,
            "arad": 1,
            "notice": 1,
            "value": 1,
            "computed": 1,
            "description": 1,
            "ctions": 1,
            "esult": 1,
            "function": 1,
            "take": 1,
            "certain": 1,
            "amount": 1,
            "world": 1,
            "knowledge": 1,
            "correlated": 1,
            "actual": 1,
            "road": 1,
            "useful": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para178",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 56,
              "end_char": 63,
              "context": " see how this works for route-finding problems in Romania; we use the\nstraight-line\ndistance\nheuristic, whi"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 131,
              "end_char": 134,
              "context": "ght-line\ndistance\nheuristic, which we will call\nh\nSLD\n. If the goal is Bucharest, we need to know the s"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 152,
              "end_char": 161,
              "context": "ristic, which we will call\nh\nSLD\n. If the goal is Bucharest, we need to know the straight-line distances to B"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 210,
              "end_char": 219,
              "context": "t, we need to know the straight-line distances to Bucharest, which are shown in\nFigure 3.16\n. For example,\nh\n"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 269,
              "end_char": 272,
              "context": ", which are shown in\nFigure 3.16\n. For example,\nh\nSLD\n(\nArad\n) = 366. Notice that the values of\nh\nSLD\nc"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 275,
              "end_char": 279,
              "context": "h are shown in\nFigure 3.16\n. For example,\nh\nSLD\n(\nArad\n) = 366. Notice that the values of\nh\nSLD\ncannot b"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 317,
              "end_char": 320,
              "context": "h\nSLD\n(\nArad\n) = 366. Notice that the values of\nh\nSLD\ncannot be computed from the problem description i"
            },
            {
              "para_id": "chap3_para178",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 493,
              "end_char": 496,
              "context": " certain amount of world knowledge to know that\nh\nSLD\nis correlated with actual road distances and is, "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para179",
          "content": "Description\nThe binary trees have the root node labeled \"A\". Node \"A\" has two child nodes labeled B and C. Node B has two child nodes labeled D and E. Node C has two child nodes labeled F and G. Node D has two child nodes labeled H and I. Node E has two child nodes labeled J and K. Node F has two child nodes labeled L and M. Node G has two child nodes labeled N and O.",
          "sentence_count": 2,
          "char_count": 292,
          "prev_para_id": "chap3_para178",
          "next_para_id": "chap3_para180",
          "style_metadata": {
            "para_id": "chap3_para179",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 43.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 86,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "binary": 1,
            "tree": 1,
            "root": 1,
            "labeled": 8,
            "child": 7,
            "node": 7,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para179",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 61,
              "end_char": 65,
              "context": "\nThe binary trees have the root node labeled \"A\". Node \"A\" has two child nodes labeled B and C. Node B h"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "C. Node",
              "entity_type": "PERSON",
              "start_char": 104,
              "end_char": 111,
              "context": "d \"A\". Node \"A\" has two child nodes labeled B and C. Node B has two child nodes labeled D and E. Node C has"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "E. Node C",
              "entity_type": "PERSON",
              "start_char": 148,
              "end_char": 157,
              "context": "B and C. Node B has two child nodes labeled D and E. Node C has two child nodes labeled F and G. Node D has t"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 186,
              "end_char": 187,
              "context": "beled D and E. Node C has two child nodes labeled F and G. Node D has two child nodes labeled H and I"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "G. Node",
              "entity_type": "PERSON",
              "start_char": 192,
              "end_char": 199,
              "context": "D and E. Node C has two child nodes labeled F and G. Node D has two child nodes labeled H and I. Node E has"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "H",
              "entity_type": "ORG",
              "start_char": 230,
              "end_char": 231,
              "context": "beled F and G. Node D has two child nodes labeled H and I. Node E has two child nodes labeled J and K"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "I. Node",
              "entity_type": "PERSON",
              "start_char": 236,
              "end_char": 243,
              "context": "F and G. Node D has two child nodes labeled H and I. Node E has two child nodes labeled J and K. Node F has"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "L",
              "entity_type": "PRODUCT",
              "start_char": 318,
              "end_char": 319,
              "context": "beled J and K. Node F has two child nodes labeled L and M. Node G has two child nodes labeled N and O"
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "M. Node G",
              "entity_type": "PERSON",
              "start_char": 324,
              "end_char": 333,
              "context": "J and K. Node F has two child nodes labeled L and M. Node G has two child nodes labeled N and O."
            },
            {
              "para_id": "chap3_para179",
              "entity_text": "N",
              "entity_type": "ORG",
              "start_char": 362,
              "end_char": 363,
              "context": "beled L and M. Node G has two child nodes labeled N and O."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para180",
          "content": "Limit: 0. Two binary trees of level 1.",
          "sentence_count": 2,
          "char_count": 31,
          "prev_para_id": "chap3_para179",
          "next_para_id": "chap3_para181",
          "style_metadata": {
            "para_id": "chap3_para180",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 2
          },
          "terminology": {
            "limit": 1,
            "binary": 1,
            "tree": 1,
            "level": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para181",
          "content": "Binary Tree 1: An arrowhead points to “A”. Node “A” is green-colored.",
          "sentence_count": 2,
          "char_count": 58,
          "prev_para_id": "chap3_para180",
          "next_para_id": "chap3_para182",
          "style_metadata": {
            "para_id": "chap3_para181",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 2
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "arrowhead": 1,
            "point": 1,
            "node": 1,
            "green-colored": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para181",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 43,
              "end_char": 47,
              "context": "Binary Tree 1: An arrowhead points to “A”. Node “A” is green-colored."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para182",
          "content": "Binary Tree 2: Node “A” is faded out.",
          "sentence_count": 1,
          "char_count": 30,
          "prev_para_id": "chap3_para181",
          "next_para_id": "chap3_para183",
          "style_metadata": {
            "para_id": "chap3_para182",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.083,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "node": 1,
            "faded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para182",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 2: Node “A” is faded out."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para183",
          "content": "Limit: 1. Four binary trees of level 2.",
          "sentence_count": 2,
          "char_count": 32,
          "prev_para_id": "chap3_para182",
          "next_para_id": "chap3_para184",
          "style_metadata": {
            "para_id": "chap3_para183",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 2
          },
          "terminology": {
            "limit": 1,
            "binary": 1,
            "tree": 1,
            "level": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para184",
          "content": "Binary Tree 1: Node “A” is lavender-colored. An arrowhead points to “A”. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 3,
          "char_count": 104,
          "prev_para_id": "chap3_para183",
          "next_para_id": "chap3_para185",
          "style_metadata": {
            "para_id": "chap3_para184",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 3
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "node": 1,
            "path": 1,
            "faint": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para185",
          "content": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-colored. An arrowhead points to B. The paths from node “A” are solid lines.",
          "sentence_count": 4,
          "char_count": 119,
          "prev_para_id": "chap3_para184",
          "next_para_id": "chap3_para186",
          "style_metadata": {
            "para_id": "chap3_para185",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 1,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 1,
            "solid": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para185",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para186",
          "content": "Binary Tree 3: Node “A” is lavender-colored. Node C is green-colored. The path between nodes “A” and C is a solid line. The path from “A” to B and node B are faded out.",
          "sentence_count": 4,
          "char_count": 135,
          "prev_para_id": "chap3_para185",
          "next_para_id": "chap3_para187",
          "style_metadata": {
            "para_id": "chap3_para186",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "path": 2,
            "solid": 1,
            "line": 1,
            "faded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para186",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 3: Node “A” is lavender-colored. Node C is green-colored."
            },
            {
              "para_id": "chap3_para186",
              "entity_text": "Node C",
              "entity_type": "PERSON",
              "start_char": 45,
              "end_char": 51,
              "context": "Binary Tree 3: Node “A” is lavender-colored. Node C is green-colored. The path between nodes “A” and "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para187",
          "content": "Binary Tree 4: All nodes and paths are faded out.",
          "sentence_count": 1,
          "char_count": 40,
          "prev_para_id": "chap3_para186",
          "next_para_id": "chap3_para188",
          "style_metadata": {
            "para_id": "chap3_para187",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "node": 1,
            "path": 1,
            "faded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para188",
          "content": "Limit: 2. Eight binary trees of level 2.",
          "sentence_count": 2,
          "char_count": 33,
          "prev_para_id": "chap3_para187",
          "next_para_id": "chap3_para189",
          "style_metadata": {
            "para_id": "chap3_para188",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 2
          },
          "terminology": {
            "limit": 1,
            "binary": 1,
            "tree": 1,
            "level": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para189",
          "content": "Binary Tree 1: Node “A” is lavender-colored. An arrowhead points to “A”. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 3,
          "char_count": 104,
          "prev_para_id": "chap3_para188",
          "next_para_id": "chap3_para190",
          "style_metadata": {
            "para_id": "chap3_para189",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 3
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "node": 1,
            "path": 1,
            "faint": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para190",
          "content": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-colored. An arrowhead points to B. The paths from node “A” are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 162,
          "prev_para_id": "chap3_para189",
          "next_para_id": "chap3_para191",
          "style_metadata": {
            "para_id": "chap3_para190",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para190",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para191",
          "content": "Binary Tree 3: Nodes “A” and B are lavender-colored. Nodes C, D, and E are green-colored. An arrowhead points to D. The paths from “A” and B are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 171,
          "prev_para_id": "chap3_para190",
          "next_para_id": "chap3_para192",
          "style_metadata": {
            "para_id": "chap3_para191",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para192",
          "content": "Binary Tree 4: Nodes “A” and B are lavender-colored. Nodes C and E are green-colored. An arrowhead points to E. The paths from “A” are solid lines. The path between B and E is a solid line. The path from B to D and node D are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 6,
          "char_count": 231,
          "prev_para_id": "chap3_para191",
          "next_para_id": "chap3_para193",
          "style_metadata": {
            "para_id": "chap3_para192",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 6
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 2,
            "line": 3,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para193",
          "content": "Binary Tree 5: Node “A” is lavender-colored. Node C is green-colored. An arrowhead points to C. The path between “A” and C is a solid line. The path from “A” to B, node B, and all child nodes of B are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 212,
          "prev_para_id": "chap3_para192",
          "next_para_id": "chap3_para194",
          "style_metadata": {
            "para_id": "chap3_para193",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 4,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 1,
            "line": 2,
            "child": 1,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para193",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 5: Node “A” is lavender-colored. Node C is green-colored."
            },
            {
              "para_id": "chap3_para193",
              "entity_text": "Node C",
              "entity_type": "PERSON",
              "start_char": 45,
              "end_char": 51,
              "context": "Binary Tree 5: Node “A” is lavender-colored. Node C is green-colored. An arrowhead points to C. The p"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para194",
          "content": "Binary Tree 6: Nodes “A” and C are lavender-colored. Nodes F and G are green-colored. An arrowhead points to F. The path between “A” and C is a solid line. The paths from C are solid lines.",
          "sentence_count": 4,
          "char_count": 153,
          "prev_para_id": "chap3_para193",
          "next_para_id": "chap3_para195",
          "style_metadata": {
            "para_id": "chap3_para194",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 1,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para194",
              "entity_text": "Nodes F and G",
              "entity_type": "PRODUCT",
              "start_char": 53,
              "end_char": 66,
              "context": "ary Tree 6: Nodes “A” and C are lavender-colored. Nodes F and G are green-colored. An arrowhead points to F. The "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para195",
          "content": "Binary Tree 7: Nodes “A” and C are lavender-colored. Node G is green-colored. The path between “A” and C is a solid line. The path between C and G is a solid line. The path from C to E and node E are faded out.",
          "sentence_count": 5,
          "char_count": 166,
          "prev_para_id": "chap3_para194",
          "next_para_id": "chap3_para196",
          "style_metadata": {
            "para_id": "chap3_para195",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "path": 3,
            "solid": 2,
            "line": 2,
            "faded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para195",
              "entity_text": "Node G",
              "entity_type": "PERSON",
              "start_char": 53,
              "end_char": 59,
              "context": "ary Tree 7: Nodes “A” and C are lavender-colored. Node G is green-colored. The path between “A” and C is a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para196",
          "content": "Binary Tree 8: All nodes and paths are faded out.",
          "sentence_count": 1,
          "char_count": 40,
          "prev_para_id": "chap3_para195",
          "next_para_id": "chap3_para197",
          "style_metadata": {
            "para_id": "chap3_para196",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "node": 1,
            "path": 1,
            "faded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para197",
          "content": "Limit: 3. Twelve binary trees of level 3.",
          "sentence_count": 2,
          "char_count": 34,
          "prev_para_id": "chap3_para196",
          "next_para_id": "chap3_para198",
          "style_metadata": {
            "para_id": "chap3_para197",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 2
          },
          "terminology": {
            "limit": 1,
            "twelve": 1,
            "binary": 1,
            "tree": 1,
            "level": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para198",
          "content": "Binary Tree 1: Node “A” is green-colored. An arrowhead points to “A”. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 3,
          "char_count": 101,
          "prev_para_id": "chap3_para197",
          "next_para_id": "chap3_para199",
          "style_metadata": {
            "para_id": "chap3_para198",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 3
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "node": 1,
            "path": 1,
            "faint": 1,
            "dashed": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para199",
          "content": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-colored. An arrowhead points to B. The paths from node “A” are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 162,
          "prev_para_id": "chap3_para198",
          "next_para_id": "chap3_para200",
          "style_metadata": {
            "para_id": "chap3_para199",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para199",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 2: Node “A” is lavender-colored. Nodes B and C are green-"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para200",
          "content": "Binary Tree 3: Nodes “A” and B are lavender-colored. Nodes C, D, and E are green-colored. An arrowhead points to D. The paths from nodes “A” and B are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 176,
          "prev_para_id": "chap3_para199",
          "next_para_id": "chap3_para201",
          "style_metadata": {
            "para_id": "chap3_para200",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para201",
          "content": "Binary Tree 4: Nodes “A”, B, and D are lavender-colored. Nodes C, E, H, and I are green-colored. An arrowhead points to H. The paths from “A”, B, and D are solid lines. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 179,
          "prev_para_id": "chap3_para200",
          "next_para_id": "chap3_para202",
          "style_metadata": {
            "para_id": "chap3_para201",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 1,
            "line": 2,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para202",
          "content": "Binary Tree 5: Nodes “A”, B, and D are lavender-colored. Nodes C, E, and I are green-colored. An arrowhead points to I. The paths from “A” and B are solid lines. The path between D and I is a solid line. The path from D to H and node H are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 241,
          "prev_para_id": "chap3_para201",
          "next_para_id": "chap3_para203",
          "style_metadata": {
            "para_id": "chap3_para202",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.14,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 7
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 2,
            "line": 3,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para202",
              "entity_text": "I.",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 119,
              "context": ", and I are green-colored. An arrowhead points to I. The paths from “A” and B are solid lines. The pat"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para203",
          "content": "Binary Tree 6: Nodes “A” and B are lavender-colored. Nodes E and C are green-colored. An arrowhead points to E. The paths from “A” are solid lines. The path between B and E is a solid line. The path from B to D, node D, and the child nodes of D are all faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 6,
          "char_count": 252,
          "prev_para_id": "chap3_para202",
          "next_para_id": "chap3_para204",
          "style_metadata": {
            "para_id": "chap3_para203",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 6
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 4,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 2,
            "line": 3,
            "child": 1,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para204",
          "content": "Binary Tree 7: Nodes “A”, B, and E are lavender-colored. Nodes C, J, and K are green-colored. An arrowhead points to J. The paths from “A” and E are solid lines. The path between B and E is a solid line. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 6,
          "char_count": 206,
          "prev_para_id": "chap3_para203",
          "next_para_id": "chap3_para205",
          "style_metadata": {
            "para_id": "chap3_para204",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 6
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 3,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para204",
              "entity_text": "J. The",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 123,
              "context": ", and K are green-colored. An arrowhead points to J. The paths from “A” and E are solid lines. The path be"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para205",
          "content": "Binary Tree 8: Nodes “A”, B, and E are lavender-colored. Nodes C and K are green-colored. An arrowhead points to K. The paths from “A” are solid lines. The path between B and E is a solid line. The path between K and E is a solid line. The path from E to J and node J are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 266,
          "prev_para_id": "chap3_para204",
          "next_para_id": "chap3_para206",
          "style_metadata": {
            "para_id": "chap3_para205",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 7
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 4,
            "solid": 3,
            "line": 4,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para206",
          "content": "Binary Tree 9: Node “A” is lavender-colored and node C is green-colored. An arrowhead points to C. The path between “A” and C is a solid line. The path from “A” to B, node B, and all child nodes of B are faded. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 4,
          "char_count": 211,
          "prev_para_id": "chap3_para205",
          "next_para_id": "chap3_para207",
          "style_metadata": {
            "para_id": "chap3_para206",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 4
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 4,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 3,
            "solid": 1,
            "line": 2,
            "child": 1,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para206",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 15,
              "end_char": 19,
              "context": "Binary Tree 9: Node “A” is lavender-colored and node C is green-color"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para207",
          "content": "Binary Tree 10: Nodes “A” and C are lavender-colored. Nodes F and G are green-colored. An arrowhead points to F. The paths from C are solid lines. The path between “A” and C is a solid line. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 197,
          "prev_para_id": "chap3_para206",
          "next_para_id": "chap3_para208",
          "style_metadata": {
            "para_id": "chap3_para207",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 3,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para207",
              "entity_text": "Nodes F and G",
              "entity_type": "PRODUCT",
              "start_char": 54,
              "end_char": 67,
              "context": "ry Tree 10: Nodes “A” and C are lavender-colored. Nodes F and G are green-colored. An arrowhead points to F. The "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para208",
          "content": "Binary Tree 11: Nodes “A”, C, and F are lavender-colored. Nodes G, L, and M are green-colored. An arrowhead points to L. The paths from C and F are solid lines. The path between “A” and C is a solid line. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 5,
          "char_count": 207,
          "prev_para_id": "chap3_para207",
          "next_para_id": "chap3_para209",
          "style_metadata": {
            "para_id": "chap3_para208",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 5
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 2,
            "solid": 2,
            "line": 3,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para208",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 34,
              "end_char": 35,
              "context": "Binary Tree 11: Nodes “A”, C, and F are lavender-colored. Nodes G, L, and M are green"
            },
            {
              "para_id": "chap3_para208",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 142,
              "end_char": 143,
              "context": "d. An arrowhead points to L. The paths from C and F are solid lines. The path between “A” and C is a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para209",
          "content": "Binary Tree 12: Nodes “A”, C, and F are lavender-colored. Nodes G and M are green-colored. An arrowhead points to M. The paths from C are solid lines. The path between “A” and C is a solid line. The path between F and M is a solid line. The path from F to L and node L are faded out. All other nodes and paths are in faint dashed lines.",
          "sentence_count": 7,
          "char_count": 267,
          "prev_para_id": "chap3_para208",
          "next_para_id": "chap3_para210",
          "style_metadata": {
            "para_id": "chap3_para209",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 7
          },
          "terminology": {
            "binary": 1,
            "tree": 1,
            "lavender-colored": 1,
            "node": 3,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "path": 4,
            "solid": 3,
            "line": 4,
            "faded": 1,
            "dashed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para209",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 34,
              "end_char": 35,
              "context": "Binary Tree 12: Nodes “A”, C, and F are lavender-colored. Nodes G and M are green-col"
            },
            {
              "para_id": "chap3_para209",
              "entity_text": "F and M",
              "entity_type": "PRODUCT",
              "start_char": 212,
              "end_char": 219,
              "context": "tween “A” and C is a solid line. The path between F and M is a solid line. The path from F to L and node L "
            },
            {
              "para_id": "chap3_para209",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 251,
              "end_char": 252,
              "context": "th between F and M is a solid line. The path from F to L and node L are faded out. All other nodes an"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para210",
          "content": "×\nFigure 3.16\nValues of\nh\nSLD\n—straight-line distances to Bucharest.",
          "sentence_count": 1,
          "char_count": 63,
          "prev_para_id": "chap3_para209",
          "next_para_id": "chap3_para211",
          "style_metadata": {
            "para_id": "chap3_para210",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "value": 1,
            "sld": 1,
            "—straight-line": 1,
            "distance": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para210",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 29,
              "context": "×\nFigure 3.16\nValues of\nh\nSLD\n—straight-line distances to Bucharest."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para211",
          "content": "Figure 3.17\nshows the progress of a greedy best-first search using\nh\nSLD\nto find a path from Arad to Bucharest. The first node to be expanded from Arad will be Sibiu because the heuristic says it is closer to Bucharest than is either Zerind or Timisoara. The next node to be expanded will be Fagaras because it is now closest according to the heuristic. Fagaras in turn generates Bucharest, which is the goal. For this particular problem, greedy best-first search using\nh\nSLD\nfinds a solution without ever expanding a node that is not on the solution path. The solution it found does not have optimal cost, however: the path via Sibiu and Fagaras to Bucharest is 32 miles longer than the path through Rimnicu Vilcea and Pitesti. This is why the algorithm is called “greedy”—on each iteration it tries to get as close to a goal as it can, but greediness can lead to worse results than being careful.",
          "sentence_count": 7,
          "char_count": 745,
          "prev_para_id": "chap3_para210",
          "next_para_id": "chap3_para212",
          "style_metadata": {
            "para_id": "chap3_para211",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 25.14,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 176,
            "sentence_count": 7
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "progress": 1,
            "greedy": 3,
            "best-first": 2,
            "search": 2,
            "using": 2,
            "sld": 2,
            "find": 2,
            "path": 4,
            "arad": 2,
            "bucharest": 4,
            "first": 1,
            "node": 3,
            "expanded": 2,
            "sibiu": 2,
            "heuristic": 2,
            "say": 1,
            "closer": 1,
            "zerind": 1,
            "timisoara": 1,
            "next": 1,
            "closest": 1,
            "according": 1,
            "fagaras": 2,
            "turn": 1,
            "generates": 1,
            "goal": 2,
            "particular": 1,
            "problem": 1,
            "solution": 3,
            "expanding": 1,
            "found": 1,
            "optimal": 1,
            "cost": 1,
            "mile": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "pitesti": 1,
            "algorithm": 1,
            "called": 1,
            "—on": 1,
            "iteration": 1,
            "try": 1,
            "get": 1,
            "close": 1,
            "greediness": 1,
            "lead": 1,
            "worse": 1,
            "result": 1,
            "careful": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para211",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 69,
              "end_char": 72,
              "context": "he progress of a greedy best-first search using\nh\nSLD\nto find a path from Arad to Bucharest. The first "
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 93,
              "end_char": 97,
              "context": "best-first search using\nh\nSLD\nto find a path from Arad to Bucharest. The first node to be expanded from "
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 147,
              "end_char": 151,
              "context": " to Bucharest. The first node to be expanded from Arad will be Sibiu because the heuristic says it is cl"
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 160,
              "end_char": 165,
              "context": ". The first node to be expanded from Arad will be Sibiu because the heuristic says it is closer to Buchar"
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 234,
              "end_char": 240,
              "context": "tic says it is closer to Bucharest than is either Zerind or Timisoara. The next node to be expanded will b"
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 244,
              "end_char": 253,
              "context": "t is closer to Bucharest than is either Zerind or Timisoara. The next node to be expanded will be Fagaras bec"
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 380,
              "end_char": 389,
              "context": "rding to the heuristic. Fagaras in turn generates Bucharest, which is the goal. For this particular problem, "
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 472,
              "end_char": 475,
              "context": "ticular problem, greedy best-first search using\nh\nSLD\nfinds a solution without ever expanding a node th"
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 518,
              "end_char": 522,
              "context": "g\nh\nSLD\nfinds a solution without ever expanding a node that is not on the solution path. The solution it"
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 629,
              "end_char": 634,
              "context": "does not have optimal cost, however: the path via Sibiu and Fagaras to Bucharest is 32 miles longer than "
            },
            {
              "para_id": "chap3_para211",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 650,
              "end_char": 659,
              "context": " cost, however: the path via Sibiu and Fagaras to Bucharest is 32 miles longer than the path through Rimnicu "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para212",
          "content": "Description\nArad, 366. Bucharest, 0, Craiova, 160. Drobeta, 242. Eforie, 161. Fagaras, 176. Giurgiu, 77. Hirsova, 151. Iasi, 226. Lugoj, 244. Mehadia, 241. Neamt, 234. Oradea, 380. Pitesti, 100. Rimnicu Vilcea, 193. Sibiu, 253. Timisoara, 329. Urziceni, 80. Vaslui, 199. Zerind, 374.",
          "sentence_count": 19,
          "char_count": 243,
          "prev_para_id": "chap3_para211",
          "next_para_id": "chap3_para213",
          "style_metadata": {
            "para_id": "chap3_para212",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 3.37,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 19
          },
          "terminology": {
            "description": 1,
            "arad": 1,
            "bucharest": 1,
            "craiova": 1,
            "drobeta": 1,
            "eforie": 1,
            "fagaras": 1,
            "giurgiu": 1,
            "hirsova": 1,
            "iasi": 1,
            "lugoj": 1,
            "mehadia": 1,
            "neamt": 1,
            "oradea": 1,
            "pitesti": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "sibiu": 1,
            "timisoara": 1,
            "urziceni": 1,
            "vaslui": 1,
            "zerind": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para212",
              "entity_text": "Description\nArad",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 16,
              "context": "Description\nArad, 366. Bucharest, 0, Craiova, 160. Drobeta, 242. E"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 23,
              "end_char": 32,
              "context": "Description\nArad, 366. Bucharest, 0, Craiova, 160. Drobeta, 242. Eforie, 161. Faga"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Craiova",
              "entity_type": "GPE",
              "start_char": 37,
              "end_char": 44,
              "context": "Description\nArad, 366. Bucharest, 0, Craiova, 160. Drobeta, 242. Eforie, 161. Fagaras, 176. Gi"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Drobeta",
              "entity_type": "PERSON",
              "start_char": 51,
              "end_char": 58,
              "context": "escription\nArad, 366. Bucharest, 0, Craiova, 160. Drobeta, 242. Eforie, 161. Fagaras, 176. Giurgiu, 77. Hir"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Hirsova",
              "entity_type": "ORG",
              "start_char": 105,
              "end_char": 112,
              "context": "eta, 242. Eforie, 161. Fagaras, 176. Giurgiu, 77. Hirsova, 151. Iasi, 226. Lugoj, 244. Mehadia, 241. Neamt,"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 130,
              "end_char": 135,
              "context": "garas, 176. Giurgiu, 77. Hirsova, 151. Iasi, 226. Lugoj, 244. Mehadia, 241. Neamt, 234. Oradea, 380. Pite"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Mehadia",
              "entity_type": "GPE",
              "start_char": 142,
              "end_char": 149,
              "context": "Giurgiu, 77. Hirsova, 151. Iasi, 226. Lugoj, 244. Mehadia, 241. Neamt, 234. Oradea, 380. Pitesti, 100. Rimn"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Oradea",
              "entity_type": "ORG",
              "start_char": 168,
              "end_char": 174,
              "context": " Iasi, 226. Lugoj, 244. Mehadia, 241. Neamt, 234. Oradea, 380. Pitesti, 100. Rimnicu Vilcea, 193. Sibiu, 2"
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 216,
              "end_char": 221,
              "context": ". Oradea, 380. Pitesti, 100. Rimnicu Vilcea, 193. Sibiu, 253. Timisoara, 329. Urziceni, 80. Vaslui, 199. "
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 228,
              "end_char": 237,
              "context": "0. Pitesti, 100. Rimnicu Vilcea, 193. Sibiu, 253. Timisoara, 329. Urziceni, 80. Vaslui, 199. Zerind, 374."
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Urziceni",
              "entity_type": "ORG",
              "start_char": 244,
              "end_char": 252,
              "context": " Rimnicu Vilcea, 193. Sibiu, 253. Timisoara, 329. Urziceni, 80. Vaslui, 199. Zerind, 374."
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Vaslui",
              "entity_type": "PERSON",
              "start_char": 258,
              "end_char": 264,
              "context": "a, 193. Sibiu, 253. Timisoara, 329. Urziceni, 80. Vaslui, 199. Zerind, 374."
            },
            {
              "para_id": "chap3_para212",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 271,
              "end_char": 277,
              "context": ", 253. Timisoara, 329. Urziceni, 80. Vaslui, 199. Zerind, 374."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para213",
          "content": "×\nFigure 3.17\nStages in a greedy best-first tree-like search for Bucharest with the straight-line distance heuristic\nh\nSLD\n. Nodes are labeled with their\nh\n-values.",
          "sentence_count": 2,
          "char_count": 145,
          "prev_para_id": "chap3_para212",
          "next_para_id": "chap3_para214",
          "style_metadata": {
            "para_id": "chap3_para213",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "stage": 1,
            "greedy": 1,
            "best-first": 1,
            "tree-like": 1,
            "search": 1,
            "bucharest": 1,
            "straight-line": 1,
            "distance": 1,
            "heuristic": 1,
            "sld": 1,
            "node": 1,
            "labeled": 1,
            "-values": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para213",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 119,
              "end_char": 122,
              "context": "arest with the straight-line distance heuristic\nh\nSLD\n. Nodes are labeled with their\nh\n-values."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para214",
          "content": "Greedy best-first graph search is complete in finite state spaces, but not in infinite ones. The worst-case time and space complexity is\nO\n(|\nV\n|). With a good heuristic function, however, the complexity can be reduced substantially, on certain problems reaching\nO\n(\nbm\n)\n.",
          "sentence_count": 3,
          "char_count": 236,
          "prev_para_id": "chap3_para213",
          "next_para_id": "chap3_para215",
          "style_metadata": {
            "para_id": "chap3_para214",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 18.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 55,
            "sentence_count": 3
          },
          "terminology": {
            "greedy": 1,
            "best-first": 1,
            "graph": 1,
            "search": 1,
            "complete": 1,
            "finite": 1,
            "state": 1,
            "space": 2,
            "infinite": 1,
            "one": 1,
            "worst-case": 1,
            "time": 1,
            "complexity": 2,
            "good": 1,
            "heuristic": 1,
            "function": 1,
            "reduced": 1,
            "certain": 1,
            "problem": 1,
            "reaching": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para215",
          "content": "3.5.2\nA* search\nThe most common informed search algorithm is\nA\n*\nsearch\n(pronounced “A-star search”), a best-first search that uses the evaluation function\nf\n(\nn\n) =\ng\n(\nn\n) +\nh\n(\nn\n)\nwhere\ng(n)\nis the path cost from the initial state to node\nn\n, and\nh\n(\nn\n) is the\nestimated\ncost of the shortest path from\nn\nto a goal state, so we have\nf\n(\nn\n) = estimated cost of the best path that continues from\nn\nto a goal\n.",
          "sentence_count": 1,
          "char_count": 372,
          "prev_para_id": "chap3_para214",
          "next_para_id": "chap3_para216",
          "style_metadata": {
            "para_id": "chap3_para215",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 103.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 1
          },
          "terminology": {
            "search": 5,
            "common": 1,
            "informed": 1,
            "algorithm": 1,
            "pronounced": 1,
            "a-star": 1,
            "best-first": 1,
            "us": 1,
            "evaluation": 1,
            "function": 1,
            "path": 3,
            "cost": 3,
            "initial": 1,
            "state": 2,
            "node": 1,
            "estimated": 2,
            "shortest": 1,
            "goal": 2,
            "best": 1,
            "continues": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para215",
              "entity_text": "g(n",
              "entity_type": "ORG",
              "start_char": 190,
              "end_char": 193,
              "context": "uation function\nf\n(\nn\n) =\ng\n(\nn\n) +\nh\n(\nn\n)\nwhere\ng(n)\nis the path cost from the initial state to node\n"
            },
            {
              "para_id": "chap3_para215",
              "entity_text": "node\nn\n",
              "entity_type": "ORG",
              "start_char": 238,
              "end_char": 245,
              "context": "e\ng(n)\nis the path cost from the initial state to node\nn\n, and\nh\n(\nn\n) is the\nestimated\ncost of the shortes"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para216",
          "content": "In\nFigure 3.18\n, we show the progress of an A* search with the goal of reaching Bucharest. The values of\ng\nare computed from the action costs in\nFigure 3.1\n, and the values of\nh\nSLD\nare given in\nFigure 3.16\n. Notice that Bucharest first appears on the frontier at step (e), but it is not selected for expansion (and thus not detected as a solution) because at\nf\n= 450 it is not the lowest-cost node on the frontier—that would be Pitesti, at\nf =\n417. Another way to say this is that there\nmight\nbe a solution through Pitesti whose cost is as low as 417, so the algorithm will not settle for a solution that costs 450. At step (f), a different path to Bucharest is now the lowest-cost node, at\nf =\n418, so it is selected and detected as the optimal solution.",
          "sentence_count": 5,
          "char_count": 626,
          "prev_para_id": "chap3_para215",
          "next_para_id": "chap3_para217",
          "style_metadata": {
            "para_id": "chap3_para216",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 165,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 3,
            "show": 1,
            "progress": 1,
            "search": 1,
            "goal": 1,
            "reaching": 1,
            "bucharest": 3,
            "value": 2,
            "computed": 1,
            "action": 1,
            "cost": 3,
            "sld": 1,
            "given": 1,
            "notice": 1,
            "appears": 1,
            "frontier": 1,
            "step": 2,
            "selected": 2,
            "expansion": 1,
            "detected": 2,
            "solution": 4,
            "lowest-cost": 2,
            "node": 2,
            "pitesti": 2,
            "way": 1,
            "say": 1,
            "low": 1,
            "settle": 1,
            "different": 1,
            "path": 1,
            "optimal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para216",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 178,
              "end_char": 181,
              "context": " action costs in\nFigure 3.1\n, and the values of\nh\nSLD\nare given in\nFigure 3.16\n. Notice that Bucharest "
            },
            {
              "para_id": "chap3_para216",
              "entity_text": "Pitesti",
              "entity_type": "ORG",
              "start_char": 516,
              "end_char": 523,
              "context": "ay this is that there\nmight\nbe a solution through Pitesti whose cost is as low as 417, so the algorithm wil"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para217",
          "content": "Description\nIn all four parts, a node labeled Arad is shown.",
          "sentence_count": 1,
          "char_count": 51,
          "prev_para_id": "chap3_para216",
          "next_para_id": "chap3_para218",
          "style_metadata": {
            "para_id": "chap3_para217",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "labeled": 1,
            "arad": 1,
            "shown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para217",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 33,
              "end_char": 37,
              "context": "Description\nIn all four parts, a node labeled Arad is shown."
            },
            {
              "para_id": "chap3_para217",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 46,
              "end_char": 50,
              "context": "Description\nIn all four parts, a node labeled Arad is shown."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para218",
          "content": "Part (“A”): The initial state. The Arad node is green-colored. An arrowhead points to Arad and 366 is marked next to the node.",
          "sentence_count": 3,
          "char_count": 104,
          "prev_para_id": "chap3_para217",
          "next_para_id": "chap3_para219",
          "style_metadata": {
            "para_id": "chap3_para218",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.33,
            "passive_voice_ratio": 0.032,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "initial": 1,
            "state": 1,
            "arad": 2,
            "node": 2,
            "green-colored": 1,
            "arrowhead": 1,
            "point": 1,
            "marked": 1,
            "next": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para218",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 35,
              "end_char": 39,
              "context": "Part (“A”): The initial state. The Arad node is green-colored. An arrowhead points to Ara"
            },
            {
              "para_id": "chap3_para218",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 86,
              "end_char": 90,
              "context": "rad node is green-colored. An arrowhead points to Arad and 366 is marked next to the node."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para219",
          "content": "Part (b): After expanding Arad. The Arad node is lavender-colored and is connected to three green-colored nodes labeled Sibiu 253, Timisoara 329, and Zerind 374. An arrowhead points to Sibiu.",
          "sentence_count": 3,
          "char_count": 162,
          "prev_para_id": "chap3_para218",
          "next_para_id": "chap3_para220",
          "style_metadata": {
            "para_id": "chap3_para219",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.33,
            "passive_voice_ratio": 0.027,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "arad": 2,
            "node": 2,
            "lavender-colored": 1,
            "connected": 1,
            "green-colored": 1,
            "labeled": 1,
            "sibiu": 2,
            "timisoara": 1,
            "zerind": 1,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para219",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 26,
              "end_char": 30,
              "context": "Part (b): After expanding Arad. The Arad node is lavender-colored and is connect"
            },
            {
              "para_id": "chap3_para219",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 40,
              "context": "Part (b): After expanding Arad. The Arad node is lavender-colored and is connected to thre"
            },
            {
              "para_id": "chap3_para219",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 120,
              "end_char": 125,
              "context": "is connected to three green-colored nodes labeled Sibiu 253, Timisoara 329, and Zerind 374. An arrowhead "
            },
            {
              "para_id": "chap3_para219",
              "entity_text": "Timisoara 329",
              "entity_type": "PERSON",
              "start_char": 131,
              "end_char": 144,
              "context": "d to three green-colored nodes labeled Sibiu 253, Timisoara 329, and Zerind 374. An arrowhead points to Sibiu."
            },
            {
              "para_id": "chap3_para219",
              "entity_text": "Zerind 374",
              "entity_type": "PERSON",
              "start_char": 150,
              "end_char": 160,
              "context": "lored nodes labeled Sibiu 253, Timisoara 329, and Zerind 374. An arrowhead points to Sibiu."
            },
            {
              "para_id": "chap3_para219",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 185,
              "end_char": 190,
              "context": "soara 329, and Zerind 374. An arrowhead points to Sibiu."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para220",
          "content": "Part (c): After expanding Sibiu. The Arad node is lavender-colored and is connected to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while Timisoara and Zerind are green-colored. Sibiu is connected to four green-colored nodes labeled Arad 366, Fagaras 177, Oradea 380, and Rimnicu Vilcea 193. An arrowhead points to Fagaras.",
          "sentence_count": 5,
          "char_count": 308,
          "prev_para_id": "chap3_para219",
          "next_para_id": "chap3_para221",
          "style_metadata": {
            "para_id": "chap3_para220",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.2,
            "passive_voice_ratio": 0.03,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 5
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "sibiu": 4,
            "arad": 2,
            "node": 3,
            "lavender-colored": 2,
            "connected": 2,
            "labeled": 2,
            "timisoara": 2,
            "zerind": 1,
            "green-colored": 2,
            "fagaras": 2,
            "oradea": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para220",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 26,
              "end_char": 31,
              "context": "Part (c): After expanding Sibiu. The Arad node is lavender-colored and is connect"
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 37,
              "end_char": 41,
              "context": "Part (c): After expanding Sibiu. The Arad node is lavender-colored and is connected to thre"
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 107,
              "end_char": 112,
              "context": "r-colored and is connected to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender"
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Timisoara 329",
              "entity_type": "PERSON",
              "start_char": 114,
              "end_char": 127,
              "context": "ed and is connected to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while "
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Zerind 374",
              "entity_type": "PERSON",
              "start_char": 133,
              "end_char": 143,
              "context": " to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while Timisoara and Ze"
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 145,
              "end_char": 150,
              "context": "des labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while Timisoara and Zerind ar"
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 177,
              "end_char": 186,
              "context": ", and Zerind 374. Sibiu is lavender-colored while Timisoara and Zerind are green-colored. Sibiu is connected "
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 191,
              "end_char": 197,
              "context": "74. Sibiu is lavender-colored while Timisoara and Zerind are green-colored. Sibiu is connected to four gre"
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 217,
              "end_char": 222,
              "context": "red while Timisoara and Zerind are green-colored. Sibiu is connected to four green-colored nodes labeled "
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Arad 366",
              "entity_type": "PERSON",
              "start_char": 272,
              "end_char": 280,
              "context": " is connected to four green-colored nodes labeled Arad 366, Fagaras 177, Oradea 380, and Rimnicu Vilcea 193."
            },
            {
              "para_id": "chap3_para220",
              "entity_text": "Oradea 380",
              "entity_type": "ORG",
              "start_char": 295,
              "end_char": 305,
              "context": "reen-colored nodes labeled Arad 366, Fagaras 177, Oradea 380, and Rimnicu Vilcea 193. An arrowhead points to F"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para221",
          "content": "Part (d): After expanding Fagaras. The Arad node is lavender-colored and is connected to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while Timisoara and Zerind are green-colored. Sibiu is connected to four nodes labeled Arad 366, Fagaras, Oradea 380, and Rimnicu Vilcea 193. Of these four, Fagaras is lavender-colored while the other three are green-colored. Fagaras is connected to two green-colored nodes labeled Sibiu 253 and Bucharest 0. An arrowhead points to Bucharest.",
          "sentence_count": 7,
          "char_count": 438,
          "prev_para_id": "chap3_para220",
          "next_para_id": "chap3_para222",
          "style_metadata": {
            "para_id": "chap3_para221",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.033,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 7
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "fagaras": 4,
            "arad": 2,
            "node": 4,
            "lavender-colored": 3,
            "connected": 3,
            "labeled": 3,
            "sibiu": 4,
            "timisoara": 2,
            "zerind": 1,
            "green-colored": 3,
            "oradea": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "bucharest": 2,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para221",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 39,
              "end_char": 43,
              "context": "Part (d): After expanding Fagaras. The Arad node is lavender-colored and is connected to thre"
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 109,
              "end_char": 114,
              "context": "r-colored and is connected to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender"
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Timisoara 329",
              "entity_type": "PERSON",
              "start_char": 116,
              "end_char": 129,
              "context": "ed and is connected to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while "
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Zerind 374",
              "entity_type": "PERSON",
              "start_char": 135,
              "end_char": 145,
              "context": " to three nodes labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while Timisoara and Ze"
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 147,
              "end_char": 152,
              "context": "des labeled Sibiu, Timisoara 329, and Zerind 374. Sibiu is lavender-colored while Timisoara and Zerind ar"
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 179,
              "end_char": 188,
              "context": ", and Zerind 374. Sibiu is lavender-colored while Timisoara and Zerind are green-colored. Sibiu is connected "
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 193,
              "end_char": 199,
              "context": "74. Sibiu is lavender-colored while Timisoara and Zerind are green-colored. Sibiu is connected to four nod"
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 219,
              "end_char": 224,
              "context": "red while Timisoara and Zerind are green-colored. Sibiu is connected to four nodes labeled Arad 366, Faga"
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Arad 366",
              "entity_type": "PERSON",
              "start_char": 260,
              "end_char": 268,
              "context": "colored. Sibiu is connected to four nodes labeled Arad 366, Fagaras, Oradea 380, and Rimnicu Vilcea 193. Of "
            },
            {
              "para_id": "chap3_para221",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 455,
              "end_char": 460,
              "context": "s is connected to two green-colored nodes labeled Sibiu 253 and Bucharest 0. An arrowhead points to Bucha"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para222",
          "content": "×\nFigure 3.18\nStages in an A* search for Bucharest. Nodes are labeled with\nf = g + h.",
          "sentence_count": 2,
          "char_count": 70,
          "prev_para_id": "chap3_para221",
          "next_para_id": "chap3_para223",
          "style_metadata": {
            "para_id": "chap3_para222",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "stage": 1,
            "search": 1,
            "bucharest": 1,
            "node": 1,
            "labeled": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para222",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 41,
              "end_char": 50,
              "context": "×\nFigure 3.18\nStages in an A* search for Bucharest. Nodes are labeled with\nf = g + h."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para223",
          "content": "The\nh\nvalues are the straight-line distances to Bucharest taken from\nFigure 3.16\n.",
          "sentence_count": 1,
          "char_count": 73,
          "prev_para_id": "chap3_para222",
          "next_para_id": "chap3_para224",
          "style_metadata": {
            "para_id": "chap3_para223",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "value": 1,
            "straight-line": 1,
            "distance": 1,
            "bucharest": 1,
            "taken": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para224",
          "content": "A* search is complete.",
          "sentence_count": 1,
          "char_count": 19,
          "prev_para_id": "chap3_para223",
          "next_para_id": "chap3_para225",
          "style_metadata": {
            "para_id": "chap3_para224",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 6,
            "sentence_count": 1
          },
          "terminology": {
            "search": 1,
            "complete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para225",
          "content": "11\nWhether A* is cost-optimal depends on certain properties of the heuristic. A key property is\nadmissibility\n: an\nadmissible heuristic\nis one that\nnever overestimates\nthe cost to reach a goal. (An admissible heuristic is therefore\noptimistic.)\nWith\nan admissible heuristic, A* is cost-optimal, which we can show with a proof by contradiction. Suppose the optimal path has cost\nC\n*, but the algorithm returns a path with cost\nC > C\n*. Then there must be some node\nn\nwhich is on the optimal path and is unexpanded (because if all the nodes on the optimal path had been expanded, then we would have returned that optimal solution). So then, using the notation\ng\n*(\nn\n) to mean the cost of the optimal path from the start to\nn\n, and\nh*\n(\nn\n) to mean the cost of the optimal path from\nn\nto the nearest goal, we have:\nf\n(\nn\n) >\nC\n*\n(otherwise\nn\nwould have been expanded)\nf\n(\nn\n) =\ng\n(\nn\n) +\nh\n(\nn\n) (by definition)\nf\n(\nn\n) =\ng\n*\n(\nn\n) +\nh\n(\nn\n) (because\nn\nis on an optimal path)\nf\n(\nn\n)\n≤\ng\n*\n(\nn\n) +\nh\n*\n(\nn\n) (because of admissibility,\nh\n(\nn\n)\n≤\nh\n*\n(\nn\n))\nf\n(\nn\n)\n≤\nC\n*\n(by definition,\nC\n*\n=\ng\n*\n(\nn\n) +\nh\n*\n(\nn\n))\nThe first and last lines form a contradiction, so the supposition that the algorithm could return a suboptimal path must be wrong—it must be that A* returns only cost-optimal paths.",
          "sentence_count": 7,
          "char_count": 1140,
          "prev_para_id": "chap3_para224",
          "next_para_id": "chap3_para226",
          "style_metadata": {
            "para_id": "chap3_para225",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 46.14,
            "passive_voice_ratio": 0.003,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 323,
            "sentence_count": 7
          },
          "terminology": {
            "cost-optimal": 3,
            "depends": 1,
            "certain": 1,
            "property": 2,
            "heuristic": 4,
            "key": 1,
            "admissibility": 2,
            "admissible": 3,
            "overestimate": 1,
            "cost": 5,
            "reach": 1,
            "goal": 2,
            "optimistic": 1,
            "show": 1,
            "proof": 1,
            "contradiction": 2,
            "suppose": 1,
            "optimal": 7,
            "path": 9,
            "algorithm": 2,
            "return": 3,
            "node": 2,
            "unexpanded": 1,
            "expanded": 2,
            "returned": 1,
            "solution": 1,
            "using": 1,
            "notation": 1,
            "mean": 2,
            "start": 1,
            "nearest": 1,
            "definition": 2,
            "last": 1,
            "line": 1,
            "supposition": 1,
            "suboptimal": 1,
            "wrong—it": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para226",
          "content": "A slightly stronger property is called\nconsistency\n. A heuristic\nh\n(\nn\n) is consistent if, for every node\nn\nand every successor\nnʹ\nof\nn\ngenerated by an action\na,\nwe have:\nh\n(\nn\n)\n≤\nc\n(\nn\n,\na\n,\nn\n′\n)\n+\nh\n(\nn\n′\n)\n.",
          "sentence_count": 2,
          "char_count": 193,
          "prev_para_id": "chap3_para225",
          "next_para_id": "chap3_para227",
          "style_metadata": {
            "para_id": "chap3_para226",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "stronger": 1,
            "property": 1,
            "called": 1,
            "consistency": 1,
            "heuristic": 1,
            "consistent": 1,
            "node": 1,
            "successor": 1,
            "generated": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para227",
          "content": "This is a form of the\ntriangle inequality\n, which stipulates that a side of a triangle cannot be longer than the sum of the other two sides (see\nFigure 3.19\n). An example of a consistent heuristic is the straight-line distance\nh\nSLD\nthat we used in getting to Bucharest.",
          "sentence_count": 2,
          "char_count": 227,
          "prev_para_id": "chap3_para226",
          "next_para_id": "chap3_para228",
          "style_metadata": {
            "para_id": "chap3_para227",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 2
          },
          "terminology": {
            "form": 1,
            "triangle": 2,
            "inequality": 1,
            "stipulates": 1,
            "side": 2,
            "sum": 1,
            "see": 1,
            "figure": 1,
            "example": 1,
            "consistent": 1,
            "heuristic": 1,
            "straight-line": 1,
            "distance": 1,
            "sld": 1,
            "used": 1,
            "getting": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para227",
              "entity_text": "SLD",
              "entity_type": "ORG",
              "start_char": 229,
              "end_char": 232,
              "context": "sistent heuristic is the straight-line distance\nh\nSLD\nthat we used in getting to Bucharest."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para228",
          "content": "Description\nPart (“A”): The initial state. A green-colored node is labeled Arad 366 equals 0 plus 366. An arrowhead points to Arad.",
          "sentence_count": 3,
          "char_count": 111,
          "prev_para_id": "chap3_para227",
          "next_para_id": "chap3_para229",
          "style_metadata": {
            "para_id": "chap3_para228",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.67,
            "passive_voice_ratio": 0.034,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 3
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "initial": 1,
            "state": 1,
            "green-colored": 1,
            "node": 1,
            "labeled": 1,
            "arad": 2,
            "equal": 1,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para228",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 59,
              "end_char": 63,
              "context": "on\nPart (“A”): The initial state. A green-colored node is labeled Arad 366 equals 0 plus 366. An arrowhe"
            },
            {
              "para_id": "chap3_para228",
              "entity_text": "Arad 366",
              "entity_type": "PERSON",
              "start_char": 75,
              "end_char": 83,
              "context": "he initial state. A green-colored node is labeled Arad 366 equals 0 plus 366. An arrowhead points to Arad."
            },
            {
              "para_id": "chap3_para228",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 126,
              "end_char": 130,
              "context": "rad 366 equals 0 plus 366. An arrowhead points to Arad."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para229",
          "content": "Part (b): After expanding Arad. The Arad node is now lavender-colored and is connected to three green-colored nodes labeled Sibiu 393 equals 140 plus 253, Timisoara 447 equals 118 plus 329, and Zerind 449 equals 75 plus 374. An arrowhead points to Sibiu.",
          "sentence_count": 3,
          "char_count": 212,
          "prev_para_id": "chap3_para228",
          "next_para_id": "chap3_para230",
          "style_metadata": {
            "para_id": "chap3_para229",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.67,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "arad": 2,
            "node": 2,
            "lavender-colored": 1,
            "connected": 1,
            "green-colored": 1,
            "labeled": 1,
            "sibiu": 2,
            "equal": 3,
            "timisoara": 1,
            "zerind": 1,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para229",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 26,
              "end_char": 30,
              "context": "Part (b): After expanding Arad. The Arad node is now lavender-colored and is con"
            },
            {
              "para_id": "chap3_para229",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 40,
              "context": "Part (b): After expanding Arad. The Arad node is now lavender-colored and is connected to "
            },
            {
              "para_id": "chap3_para229",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 124,
              "end_char": 129,
              "context": "is connected to three green-colored nodes labeled Sibiu 393 equals 140 plus 253, Timisoara 447 equals 118"
            },
            {
              "para_id": "chap3_para229",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 155,
              "end_char": 164,
              "context": "ored nodes labeled Sibiu 393 equals 140 plus 253, Timisoara 447 equals 118 plus 329, and Zerind 449 equals 75"
            },
            {
              "para_id": "chap3_para229",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 194,
              "end_char": 200,
              "context": " plus 253, Timisoara 447 equals 118 plus 329, and Zerind 449 equals 75 plus 374. An arrowhead points to Si"
            },
            {
              "para_id": "chap3_para229",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 248,
              "end_char": 253,
              "context": "nd 449 equals 75 plus 374. An arrowhead points to Sibiu."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para230",
          "content": "Part (c): After expanding Sibiu. The Sibiu node is now lavender-colored and is connected to four green-colored nodes labeled Arad 646 equals 280 plus 366, Fagaras 415 equals 239 plus 176, Oradea 671 equals 291 plus 380, and Rimnicu Vilcea 413 equals 220 plus 193. An arrowhead points to Rimnicu Vilcea.",
          "sentence_count": 3,
          "char_count": 252,
          "prev_para_id": "chap3_para229",
          "next_para_id": "chap3_para231",
          "style_metadata": {
            "para_id": "chap3_para230",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "sibiu": 2,
            "node": 2,
            "lavender-colored": 1,
            "connected": 1,
            "green-colored": 1,
            "labeled": 1,
            "arad": 1,
            "equal": 4,
            "fagaras": 1,
            "oradea": 1,
            "rimnicu": 2,
            "vilcea": 2,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para230",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 26,
              "end_char": 31,
              "context": "Part (c): After expanding Sibiu. The Sibiu node is now lavender-colored and is co"
            },
            {
              "para_id": "chap3_para230",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 37,
              "end_char": 42,
              "context": "Part (c): After expanding Sibiu. The Sibiu node is now lavender-colored and is connected to "
            },
            {
              "para_id": "chap3_para230",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 43,
              "end_char": 47,
              "context": "Part (c): After expanding Sibiu. The Sibiu node is now lavender-colored and is connected to four "
            },
            {
              "para_id": "chap3_para230",
              "entity_text": "Oradea 671",
              "entity_type": "ORG",
              "start_char": 188,
              "end_char": 198,
              "context": "ls 280 plus 366, Fagaras 415 equals 239 plus 176, Oradea 671 equals 291 plus 380, and Rimnicu Vilcea 413 equal"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para231",
          "content": "Part (d): After expanding Rimnicu Vilcea. The Rimnicu Vilcea node is now lavender-colored and is connected to three green-colored nodes labeled Craiova 526 equals 366 plus 160, Pitesti 417 equals 317 plus 100, and Sibiu 553 equals 300 plus 253. An arrowhead points to Fagaras.",
          "sentence_count": 3,
          "char_count": 232,
          "prev_para_id": "chap3_para230",
          "next_para_id": "chap3_para232",
          "style_metadata": {
            "para_id": "chap3_para231",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.33,
            "passive_voice_ratio": 0.019,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "rimnicu": 2,
            "vilcea": 2,
            "node": 2,
            "lavender-colored": 1,
            "connected": 1,
            "green-colored": 1,
            "labeled": 1,
            "craiova": 1,
            "equal": 3,
            "pitesti": 1,
            "sibiu": 1,
            "arrowhead": 1,
            "point": 1,
            "fagaras": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para231",
              "entity_text": "Craiova 526",
              "entity_type": "PRODUCT",
              "start_char": 144,
              "end_char": 155,
              "context": "is connected to three green-colored nodes labeled Craiova 526 equals 366 plus 160, Pitesti 417 equals 317 plus "
            },
            {
              "para_id": "chap3_para231",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 214,
              "end_char": 219,
              "context": "66 plus 160, Pitesti 417 equals 317 plus 100, and Sibiu 553 equals 300 plus 253. An arrowhead points to F"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para232",
          "content": "Part (e): After expanding Fagaras. The Fagaras node under the Sibiu node is now lavender-colored and is connected to two green-colored nodes labeled Sibiu 591 equals 338 plus 253 and Bucharest 450 equals 450 plus 0. An arrowhead points to Pitesti under Rimnicu Vilcea.",
          "sentence_count": 3,
          "char_count": 225,
          "prev_para_id": "chap3_para231",
          "next_para_id": "chap3_para233",
          "style_metadata": {
            "para_id": "chap3_para232",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.33,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "fagaras": 2,
            "node": 2,
            "sibiu": 2,
            "lavender-colored": 1,
            "connected": 1,
            "green-colored": 1,
            "labeled": 1,
            "equal": 2,
            "bucharest": 1,
            "arrowhead": 1,
            "point": 1,
            "pitesti": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para232",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 62,
              "end_char": 67,
              "context": "ter expanding Fagaras. The Fagaras node under the Sibiu node is now lavender-colored and is connected to "
            },
            {
              "para_id": "chap3_para232",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 68,
              "end_char": 72,
              "context": "panding Fagaras. The Fagaras node under the Sibiu node is now lavender-colored and is connected to two g"
            },
            {
              "para_id": "chap3_para232",
              "entity_text": "Sibiu 591",
              "entity_type": "ORG",
              "start_char": 149,
              "end_char": 158,
              "context": "d is connected to two green-colored nodes labeled Sibiu 591 equals 338 plus 253 and Bucharest 450 equals 450 "
            },
            {
              "para_id": "chap3_para232",
              "entity_text": "Bucharest 450",
              "entity_type": "ORG",
              "start_char": 183,
              "end_char": 196,
              "context": "d nodes labeled Sibiu 591 equals 338 plus 253 and Bucharest 450 equals 450 plus 0. An arrowhead points to Pitesti"
            },
            {
              "para_id": "chap3_para232",
              "entity_text": "Pitesti under Rimnicu Vilcea",
              "entity_type": "ORG",
              "start_char": 239,
              "end_char": 267,
              "context": "est 450 equals 450 plus 0. An arrowhead points to Pitesti under Rimnicu Vilcea."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para233",
          "content": "Part (f): After expanding Pitesti. The node Pitesti is now lavender-colored and is connected to three green-colored nodes labeled Bucharest 418 equals 418 plus 0, Craiova 615 equals 455 plus 160, and Rimnicu Vilcea 607 equals 414 plus 193. An arrowhead points to Bucharest under the Pitesti node.",
          "sentence_count": 3,
          "char_count": 249,
          "prev_para_id": "chap3_para232",
          "next_para_id": "chap3_para234",
          "style_metadata": {
            "para_id": "chap3_para233",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.33,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "expanding": 1,
            "pitesti": 3,
            "node": 3,
            "lavender-colored": 1,
            "connected": 1,
            "green-colored": 1,
            "labeled": 1,
            "bucharest": 2,
            "equal": 3,
            "craiova": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "arrowhead": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para233",
              "entity_text": "Pitesti",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 33,
              "context": "Part (f): After expanding Pitesti. The node Pitesti is now lavender-colored and is "
            },
            {
              "para_id": "chap3_para233",
              "entity_text": "Craiova 615",
              "entity_type": "ORG",
              "start_char": 163,
              "end_char": 174,
              "context": "ed nodes labeled Bucharest 418 equals 418 plus 0, Craiova 615 equals 455 plus 160, and Rimnicu Vilcea 607 equal"
            },
            {
              "para_id": "chap3_para233",
              "entity_text": "Bucharest",
              "entity_type": "ORG",
              "start_char": 263,
              "end_char": 272,
              "context": "a 607 equals 414 plus 193. An arrowhead points to Bucharest under the Pitesti node."
            },
            {
              "para_id": "chap3_para233",
              "entity_text": "Pitesti",
              "entity_type": "PRODUCT",
              "start_char": 283,
              "end_char": 290,
              "context": "s 193. An arrowhead points to Bucharest under the Pitesti node."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para234",
          "content": "×\nFigure 3.19\nTriangle inequality: If the heuristic\nh\nis\nconsistent\n, then the single number\nh\n(\nn\n) will be less than the sum of the cost\nc\n(\nn, a, aʹ\n) of the action from\nn\nto\nnʹ\nplus the heuristic estimate\nh\n(\nnʹ\n).",
          "sentence_count": 1,
          "char_count": 191,
          "prev_para_id": "chap3_para233",
          "next_para_id": "chap3_para235",
          "style_metadata": {
            "para_id": "chap3_para234",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 54.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "triangle": 1,
            "inequality": 1,
            "heuristic": 2,
            "consistent": 1,
            "single": 1,
            "number": 1,
            "sum": 1,
            "cost": 1,
            "action": 1,
            "estimate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para234",
              "entity_text": "Triangle",
              "entity_type": "ORG",
              "start_char": 14,
              "end_char": 22,
              "context": "×\nFigure 3.19\nTriangle inequality: If the heuristic\nh\nis\nconsistent\n, th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para235",
          "content": "Every consistent heuristic is admissible (but not vice versa), so with a consistent heuristic, A* is cost-optimal. In addition, with a consistent heuristic, the first time we reach a state it will be on an optimal path, so we never have to re-add a state to the frontier, and never have to change an entry in\nreached.",
          "sentence_count": 2,
          "char_count": 262,
          "prev_para_id": "chap3_para234",
          "next_para_id": "chap3_para236",
          "style_metadata": {
            "para_id": "chap3_para235",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 2
          },
          "terminology": {
            "consistent": 3,
            "heuristic": 3,
            "admissible": 1,
            "vice": 1,
            "versa": 1,
            "cost-optimal": 1,
            "addition": 1,
            "first": 1,
            "time": 1,
            "reach": 1,
            "state": 2,
            "optimal": 1,
            "path": 1,
            "re-add": 1,
            "frontier": 1,
            "change": 1,
            "entry": 1,
            "reached": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para236",
          "content": "But with an inconsistent heuristic, we may end up with multiple paths reaching the same state, and if each new path has a lower path cost than the previous one, then we will end up with multiple nodes for that state in the frontier, costing us both time and space. Because of that, some implementations of A* take care to only enter a state into the frontier once, and if a better path to the state is found, all the successors of the state are updated (which requires that nodes have child pointers as well as parent pointers). These complications have led many implementers to avoid inconsistent heuristics, but Felner\net al.",
          "sentence_count": 3,
          "char_count": 517,
          "prev_para_id": "chap3_para235",
          "next_para_id": "chap3_para237",
          "style_metadata": {
            "para_id": "chap3_para236",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 126,
            "sentence_count": 3
          },
          "terminology": {
            "inconsistent": 2,
            "heuristic": 2,
            "end": 2,
            "multiple": 2,
            "path": 4,
            "reaching": 1,
            "state": 5,
            "new": 1,
            "cost": 1,
            "previous": 1,
            "node": 2,
            "frontier": 2,
            "costing": 1,
            "time": 1,
            "space": 1,
            "implementation": 1,
            "take": 1,
            "care": 1,
            "enter": 1,
            "found": 1,
            "successor": 1,
            "updated": 1,
            "requires": 1,
            "child": 1,
            "pointer": 2,
            "parent": 1,
            "complication": 1,
            "led": 1,
            "many": 1,
            "implementers": 1,
            "avoid": 1,
            "felner": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para236",
              "entity_text": "Felner",
              "entity_type": "PERSON",
              "start_char": 614,
              "end_char": 620,
              "context": "mplementers to avoid inconsistent heuristics, but Felner\net al."
            },
            {
              "para_id": "chap3_para236",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 624,
              "end_char": 626,
              "context": "s to avoid inconsistent heuristics, but Felner\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para237",
          "content": "(2011) argues that the worst effects rarely happen in practice, and one shouldn’t be afraid of inconsistent heuristics.",
          "sentence_count": 1,
          "char_count": 102,
          "prev_para_id": "chap3_para236",
          "next_para_id": "chap3_para238",
          "style_metadata": {
            "para_id": "chap3_para237",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "argues": 1,
            "worst": 1,
            "effect": 1,
            "happen": 1,
            "practice": 1,
            "afraid": 1,
            "inconsistent": 1,
            "heuristic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para238",
          "content": "With an inadmissible heuristic, A* may or may not be cost-optimal. Here are two cases where it is: First, if there is even one cost-optimal path on which\nh\n(\nn\n) is admissible for all nodes\nn\non the path, then that path will be found, no matter what the heuristic says for states off the path. Second, if the optimal solution has cost\nC\n*, and the second-best has cost\nC\n2\n, and if\nh\n(\nn\n) overestimates some costs, but never by more than\nC\n2\n–\nC\n*, then A* is guaranteed to return cost-optimal solutions.",
          "sentence_count": 3,
          "char_count": 424,
          "prev_para_id": "chap3_para237",
          "next_para_id": "chap3_para239",
          "style_metadata": {
            "para_id": "chap3_para238",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.67,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 116,
            "sentence_count": 3
          },
          "terminology": {
            "inadmissible": 1,
            "heuristic": 2,
            "cost-optimal": 3,
            "case": 1,
            "path": 3,
            "admissible": 1,
            "node": 1,
            "found": 1,
            "say": 1,
            "state": 1,
            "second": 1,
            "optimal": 1,
            "solution": 2,
            "cost": 3,
            "second-best": 1,
            "overestimate": 1,
            "guaranteed": 1,
            "return": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para239",
          "content": "3.5.3\nSearch contours\nA useful way to visualize a search is to draw\ncontours\nin the state space, just like the contours in a topographic map.",
          "sentence_count": 1,
          "char_count": 120,
          "prev_para_id": "chap3_para238",
          "next_para_id": "chap3_para240",
          "style_metadata": {
            "para_id": "chap3_para239",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "search": 2,
            "contour": 3,
            "useful": 1,
            "way": 1,
            "draw": 1,
            "state": 1,
            "space": 1,
            "topographic": 1,
            "map": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para240",
          "content": "Figure 3.20\nshows an example. Inside the contour labeled 400, all nodes have\nf\n(\nn\n) =\ng\n(\nn\n) +\nh\n(\nn\n) ≤ 400, and so on. Then, because A* expands the frontier node of lowest\nf\n-cost, we can see that an A* search fans out from the start node, adding nodes in concentric bands of increasing\nf\n-cost.",
          "sentence_count": 3,
          "char_count": 252,
          "prev_para_id": "chap3_para239",
          "next_para_id": "chap3_para241",
          "style_metadata": {
            "para_id": "chap3_para240",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "example": 1,
            "contour": 1,
            "labeled": 1,
            "node": 2,
            "expands": 1,
            "lowest": 1,
            "-cost": 2,
            "see": 1,
            "search": 1,
            "fan": 1,
            "start": 1,
            "adding": 1,
            "concentric": 1,
            "band": 1,
            "increasing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para240",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 238,
              "end_char": 242,
              "context": "can see that an A* search fans out from the start node, adding nodes in concentric bands of increasing\nf"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para241",
          "content": "Description\nThree circles are labeled n, n prime, and G subscript n prime. An arrow from n to G subscript n prime is labeled h (n). An arrow from n prime to G subscript n prime is labeled h (n prime). An arrow from n to n prime is labeled c (n, “A”, n prime).",
          "sentence_count": 4,
          "char_count": 206,
          "prev_para_id": "chap3_para240",
          "next_para_id": "chap3_para242",
          "style_metadata": {
            "para_id": "chap3_para241",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.75,
            "passive_voice_ratio": 0.042,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 71,
            "sentence_count": 4
          },
          "terminology": {
            "description": 1,
            "circle": 1,
            "labeled": 4,
            "prime": 8,
            "subscript": 3,
            "arrow": 3,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para242",
          "content": "×\nFigure 3.20\nMap of Romania showing contours at\nf =\n380,\nf =\n400, and\nf =\n420, with Arad as the start state. Nodes inside a given contour have\nf\n=\ng + h\ncosts less than or equal to the contour value.",
          "sentence_count": 2,
          "char_count": 168,
          "prev_para_id": "chap3_para241",
          "next_para_id": "chap3_para243",
          "style_metadata": {
            "para_id": "chap3_para242",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "map": 1,
            "romania": 1,
            "showing": 1,
            "contour": 3,
            "arad": 1,
            "start": 1,
            "state": 1,
            "node": 1,
            "given": 1,
            "cost": 1,
            "equal": 1,
            "value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para242",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 21,
              "end_char": 28,
              "context": "×\nFigure 3.20\nMap of Romania showing contours at\nf =\n380,\nf =\n400, and\nf =\n420"
            },
            {
              "para_id": "chap3_para242",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 85,
              "end_char": 89,
              "context": "g contours at\nf =\n380,\nf =\n400, and\nf =\n420, with Arad as the start state. Nodes inside a given contour "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para243",
          "content": "With uniform-cost search, we also have contours, but of\ng\n-cost, not\ng\n+\nh\n. The contours with uniform-cost search will be “circular” around the start state, spreading out equally in all directions with no preference towards the goal. With A* search using a good heuristic, the\ng\n+\nh\nbands will stretch toward a goal state (as in\nFigure 3.20\n) and become more narrowly focused around an optimal path.",
          "sentence_count": 3,
          "char_count": 341,
          "prev_para_id": "chap3_para242",
          "next_para_id": "chap3_para244",
          "style_metadata": {
            "para_id": "chap3_para243",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 3
          },
          "terminology": {
            "uniform-cost": 2,
            "search": 3,
            "contour": 2,
            "-cost": 1,
            "circular": 1,
            "start": 1,
            "state": 2,
            "spreading": 1,
            "direction": 1,
            "preference": 1,
            "towards": 1,
            "goal": 2,
            "using": 1,
            "good": 1,
            "heuristic": 1,
            "band": 1,
            "stretch": 1,
            "figure": 1,
            "become": 1,
            "focused": 1,
            "optimal": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para244",
          "content": "It should be clear that as you extend a path, the\ng\ncosts are\nmonotonic\n: the path cost always increases as you go along a path, because action costs are always positive.",
          "sentence_count": 1,
          "char_count": 142,
          "prev_para_id": "chap3_para243",
          "next_para_id": "chap3_para245",
          "style_metadata": {
            "para_id": "chap3_para244",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 1
          },
          "terminology": {
            "clear": 1,
            "extend": 1,
            "path": 3,
            "cost": 3,
            "monotonic": 1,
            "increase": 1,
            "along": 1,
            "action": 1,
            "positive": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para245",
          "content": "12\nTherefore you get concentric contour lines that don’t cross each other, and if you choose to draw the lines fine enough, you can put a line between any two nodes on any path.",
          "sentence_count": 1,
          "char_count": 145,
          "prev_para_id": "chap3_para244",
          "next_para_id": "chap3_para246",
          "style_metadata": {
            "para_id": "chap3_para245",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 39,
            "sentence_count": 1
          },
          "terminology": {
            "get": 1,
            "concentric": 1,
            "contour": 1,
            "line": 3,
            "cross": 1,
            "choose": 1,
            "draw": 1,
            "fine": 1,
            "put": 1,
            "node": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para246",
          "content": "But it is not obvious whether the\nf\n=\ng\n+\nh\ncost will monotonically increase. As you extend a path from\nn\nto\nnʹ\n, the cost goes from\ng\n(\nn\n) +\nh\n(\nn\n) to\ng\n(\nn\n) +\nc\n(\nn\n,\na,\nn'\n) +\nh\n(\nn'\n). Canceling out the\ng\n(\nn\n) term, we see that the path’s cost will be monotonically increasing if and only if\nh\n(\nn\n) ≤\nc\n(\nn\n, a\n, n')\n+\nh\n(\nn'\n); in other words if and only if the heuristic is consistent.",
          "sentence_count": 3,
          "char_count": 341,
          "prev_para_id": "chap3_para245",
          "next_para_id": "chap3_para247",
          "style_metadata": {
            "para_id": "chap3_para246",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 120,
            "sentence_count": 3
          },
          "terminology": {
            "obvious": 1,
            "cost": 3,
            "increase": 1,
            "extend": 1,
            "path": 2,
            "go": 1,
            "canceling": 1,
            "term": 1,
            "see": 1,
            "increasing": 1,
            "word": 1,
            "heuristic": 1,
            "consistent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para247",
          "content": "13\nBut note that a path might contribute several nodes in a row with the same\ng\n(\nn\n) +\nh\n(\nn\n) score; this will happen whenever the decrease in\nh\nis exactly equal to the action cost just taken (for example, in a grid problem, when\nn\nis in the same row as the goal and you take a step towards the goal,\ng\nis increased by 1 and\nh\nis decreased by 1). If\nC\n* is the cost of the optimal solution path, then we can say the following:\n•\nA* expands all nodes that can be reached from the initial state on a path where every node on the path has\nf\n(\nn\n) <\nC\n*. We say these are\nsurely expanded nodes\n.",
          "sentence_count": 3,
          "char_count": 490,
          "prev_para_id": "chap3_para246",
          "next_para_id": "chap3_para248",
          "style_metadata": {
            "para_id": "chap3_para247",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 48.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 144,
            "sentence_count": 3
          },
          "terminology": {
            "note": 1,
            "path": 4,
            "contribute": 1,
            "several": 1,
            "node": 4,
            "row": 2,
            "happen": 1,
            "decrease": 1,
            "equal": 1,
            "action": 1,
            "cost": 2,
            "taken": 1,
            "example": 1,
            "grid": 1,
            "problem": 1,
            "goal": 2,
            "take": 1,
            "step": 1,
            "towards": 1,
            "increased": 1,
            "decreased": 1,
            "optimal": 1,
            "solution": 1,
            "say": 2,
            "following": 1,
            "expands": 1,
            "reached": 1,
            "initial": 1,
            "state": 1,
            "expanded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para248",
          "content": "•\nA* might then expand some of the nodes right on the “goal contour” (where\nf\n(\nn\n) =\nC\n*) before selecting a goal node.",
          "sentence_count": 1,
          "char_count": 101,
          "prev_para_id": "chap3_para247",
          "next_para_id": "chap3_para249",
          "style_metadata": {
            "para_id": "chap3_para248",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 1
          },
          "terminology": {
            "expand": 1,
            "node": 2,
            "right": 1,
            "goal": 2,
            "contour": 1,
            "selecting": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para249",
          "content": "•\nA* expands no nodes with\nf\n(\nn\n) >\nC\n*.",
          "sentence_count": 1,
          "char_count": 36,
          "prev_para_id": "chap3_para248",
          "next_para_id": "chap3_para250",
          "style_metadata": {
            "para_id": "chap3_para249",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "expands": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para250",
          "content": "We say that A* with a consistent heuristic is\noptimally efficient\nin the sense that any algorithm that extends search paths from the initial state, and uses the same heuristic information, must expand all nodes that are surely expanded by A\n*\n(because any one of them could have been part of an optimal solution). Among the nodes with\nf\n(\nn\n) =\nC\n*, one algorithm could get lucky and choose the optimal one first while another algorithm is unlucky; we don’t consider this difference in defining optimal efficiency.",
          "sentence_count": 2,
          "char_count": 434,
          "prev_para_id": "chap3_para249",
          "next_para_id": "chap3_para251",
          "style_metadata": {
            "para_id": "chap3_para250",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 51.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 102,
            "sentence_count": 2
          },
          "terminology": {
            "say": 1,
            "consistent": 1,
            "heuristic": 2,
            "efficient": 1,
            "sense": 1,
            "algorithm": 3,
            "extends": 1,
            "search": 1,
            "path": 1,
            "initial": 1,
            "state": 1,
            "us": 1,
            "information": 1,
            "expand": 1,
            "node": 2,
            "expanded": 1,
            "part": 1,
            "optimal": 2,
            "solution": 1,
            "get": 1,
            "lucky": 1,
            "choose": 1,
            "first": 1,
            "unlucky": 1,
            "consider": 1,
            "difference": 1,
            "defining": 1,
            "efficiency": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para251",
          "content": "A\n*\nis efficient because it\nprunes\naway search tree nodes that are not necessary for finding an optimal solution. In\nFigure 3.18(b)\nwe see that Timisoara has\nf\n= 447 and Zerind has\nf\n= 449. Even though they are children of the root and would be among the first nodes expanded by uniform-cost or breadth-first search, they are never expanded by A\n*\nsearch because the solution with\nf\n= 418 is found first. The concept of pruning—eliminating possibilities from consideration without having to examine them—is important for many areas of AI.",
          "sentence_count": 4,
          "char_count": 459,
          "prev_para_id": "chap3_para250",
          "next_para_id": "chap3_para252",
          "style_metadata": {
            "para_id": "chap3_para251",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 101,
            "sentence_count": 4
          },
          "terminology": {
            "efficient": 1,
            "prune": 1,
            "search": 3,
            "tree": 1,
            "node": 2,
            "necessary": 1,
            "finding": 1,
            "optimal": 1,
            "solution": 2,
            "figure": 1,
            "see": 1,
            "timisoara": 1,
            "zerind": 1,
            "child": 1,
            "root": 1,
            "first": 1,
            "expanded": 2,
            "uniform-cost": 1,
            "breadth-first": 1,
            "found": 1,
            "concept": 1,
            "pruning—eliminating": 1,
            "possibility": 1,
            "consideration": 1,
            "examine": 1,
            "them—is": 1,
            "important": 1,
            "many": 1,
            "area": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para251",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 144,
              "end_char": 153,
              "context": "n optimal solution. In\nFigure 3.18(b)\nwe see that Timisoara has\nf\n= 447 and Zerind has\nf\n= 449. Even though t"
            },
            {
              "para_id": "chap3_para251",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 170,
              "end_char": 176,
              "context": "ure 3.18(b)\nwe see that Timisoara has\nf\n= 447 and Zerind has\nf\n= 449. Even though they are children of the"
            },
            {
              "para_id": "chap3_para251",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 535,
              "end_char": 537,
              "context": "ng to examine them—is important for many areas of AI."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para252",
          "content": "That A\n*\nsearch is complete, cost-optimal, and optimally efficient among all such algorithms is rather satisfying. Unfortunately, it does not mean that A* is the answer to all our searching needs. The catch is that for many problems, the number of nodes expanded can be exponential in the length of the solution. For example, consider a version of the vacuum world with a super-powerful vacuum that can clean up any one square at a cost of 1 unit, without even having to visit the square; in that scenario, squares can be cleaned in any order. With\nN\ninitially dirty squares, there are 2\nN\nstates where some subset has been cleaned; all of those states are on an optimal solution path, and hence satisfy\nf\n(\nn\n) <\nC\n*, so all of them would be visited by A\n*\n.",
          "sentence_count": 5,
          "char_count": 631,
          "prev_para_id": "chap3_para251",
          "next_para_id": "chap3_para253",
          "style_metadata": {
            "para_id": "chap3_para252",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 160,
            "sentence_count": 5
          },
          "terminology": {
            "search": 1,
            "complete": 1,
            "cost-optimal": 1,
            "efficient": 1,
            "algorithm": 1,
            "satisfying": 1,
            "mean": 1,
            "answer": 1,
            "searching": 1,
            "need": 1,
            "catch": 1,
            "many": 1,
            "problem": 1,
            "number": 1,
            "node": 1,
            "expanded": 1,
            "exponential": 1,
            "length": 1,
            "solution": 2,
            "example": 1,
            "consider": 1,
            "version": 1,
            "vacuum": 2,
            "world": 1,
            "super-powerful": 1,
            "clean": 1,
            "square": 4,
            "cost": 1,
            "unit": 1,
            "visit": 1,
            "scenario": 1,
            "cleaned": 2,
            "order": 1,
            "dirty": 1,
            "state": 2,
            "subset": 1,
            "optimal": 1,
            "path": 1,
            "hence": 1,
            "satisfy": 1,
            "visited": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para253",
          "content": "3.5.4\nSatisficing search: Inadmissible heuristics and weighted A*\nA\n*\nsearch has many good qualities, but it expands a lot of nodes. We can explore fewer nodes (taking less time and space) if we are willing to accept solutions that are suboptimal, but are “good enough”—what we call\nsatisficing\nsolutions. If we allow A* search to use an\ninadmissible heuristic\n—one that may overestimate—then we risk missing the optimal solution, but the heuristic can potentially be more accurate, thereby reducing the number of\nnodes expanded. For example, road engineers know the concept of a\ndetour index,\nwhich is a multiplier applied to the straight-line distance to account for the typical curvature of roads. A detour index of 1.3 means that if two cities are 10 miles apart in straight-line distance, a good estimate of the best path between them is 13 miles. For most localities, the detour index ranges between 1.2 and 1.6.",
          "sentence_count": 6,
          "char_count": 777,
          "prev_para_id": "chap3_para252",
          "next_para_id": "chap3_para254",
          "style_metadata": {
            "para_id": "chap3_para253",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 175,
            "sentence_count": 6
          },
          "terminology": {
            "satisficing": 2,
            "search": 2,
            "inadmissible": 2,
            "heuristic": 3,
            "weighted": 1,
            "many": 1,
            "good": 3,
            "quality": 1,
            "expands": 1,
            "lot": 1,
            "node": 3,
            "explore": 1,
            "fewer": 1,
            "taking": 1,
            "less": 1,
            "time": 1,
            "space": 1,
            "willing": 1,
            "accept": 1,
            "solution": 3,
            "suboptimal": 1,
            "call": 1,
            "allow": 1,
            "use": 1,
            "—one": 1,
            "overestimate—then": 1,
            "risk": 1,
            "missing": 1,
            "optimal": 1,
            "accurate": 1,
            "thereby": 1,
            "reducing": 1,
            "number": 1,
            "expanded": 1,
            "example": 1,
            "road": 2,
            "engineer": 1,
            "know": 1,
            "detour": 3,
            "index": 3,
            "applied": 1,
            "straight-line": 2,
            "distance": 2,
            "account": 1,
            "typical": 1,
            "curvature": 1,
            "mean": 1,
            "city": 1,
            "mile": 2,
            "estimate": 1,
            "best": 1,
            "path": 1,
            "locality": 1,
            "range": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para254",
          "content": "We can apply this idea to any problem, not just ones involving roads, with an approach called\nweighted A\n*\nsearch\nwhere we weight the heuristic value more heavily, giving us the evaluation function\nf\n(\nn\n)\n=\ng\n(\nn\n) +\nW\n×\nh\n(\nn\n), for some\nW\n> 1.",
          "sentence_count": 1,
          "char_count": 213,
          "prev_para_id": "chap3_para253",
          "next_para_id": "chap3_para255",
          "style_metadata": {
            "para_id": "chap3_para254",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 60.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 60,
            "sentence_count": 1
          },
          "terminology": {
            "idea": 1,
            "problem": 1,
            "one": 1,
            "involving": 1,
            "road": 1,
            "approach": 1,
            "called": 1,
            "weighted": 1,
            "search": 1,
            "weight": 1,
            "heuristic": 1,
            "value": 1,
            "giving": 1,
            "evaluation": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para255",
          "content": "Figure 3.21\nshows a search problem on a grid world. In (a), an A* search finds the optimal solution, but has to explore a large portion of the state space to find it. In (b), a weighted A* search finds a solution that is slightly costlier, but the search time is much faster. We see that the weighted search focuses the contour of reached states towards a goal. That means that fewer states are explored, but if the optimal path ever strays outside of the weighted search’s contour (as it does in this case), then the optimal path will not be found. In general, if the optimal solution costs\nC\n*, a weighted A* search will find a solution that costs somewhere between\nC\n* and\nW\n×\nC\n*; but in practice we usually get results much closer to\nC\n* than\nW\n×\nC\n*.",
          "sentence_count": 6,
          "char_count": 625,
          "prev_para_id": "chap3_para254",
          "next_para_id": "chap3_para256",
          "style_metadata": {
            "para_id": "chap3_para255",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 173,
            "sentence_count": 6
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "search": 7,
            "problem": 1,
            "grid": 1,
            "world": 1,
            "find": 4,
            "optimal": 4,
            "solution": 4,
            "large": 1,
            "portion": 1,
            "state": 3,
            "space": 1,
            "weighted": 4,
            "costlier": 1,
            "time": 1,
            "much": 1,
            "see": 1,
            "focus": 1,
            "contour": 2,
            "reached": 1,
            "towards": 1,
            "goal": 1,
            "mean": 1,
            "fewer": 1,
            "explored": 1,
            "path": 2,
            "stray": 1,
            "case": 1,
            "found": 1,
            "general": 1,
            "cost": 2,
            "practice": 1,
            "get": 1,
            "result": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para256",
          "content": "Description\nThe cities of Romania as shown as nodes and each node is labeled with the respective city’s starting letter. The contour labeled 380 encloses node “A”. The contour labeled 400 encloses “A” and S. The contour labeled 420 encloses “A”, S, R, F, P, and B. The remaining cities are outside all contours shown.",
          "sentence_count": 4,
          "char_count": 264,
          "prev_para_id": "chap3_para255",
          "next_para_id": "chap3_para257",
          "style_metadata": {
            "para_id": "chap3_para256",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.75,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 71,
            "sentence_count": 4
          },
          "terminology": {
            "description": 1,
            "city": 3,
            "romania": 1,
            "shown": 2,
            "node": 1,
            "labeled": 4,
            "respective": 1,
            "starting": 1,
            "letter": 1,
            "contour": 4,
            "encloses": 3,
            "remaining": 1,
            "outside": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para256",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 26,
              "end_char": 33,
              "context": "Description\nThe cities of Romania as shown as nodes and each node is labeled with t"
            },
            {
              "para_id": "chap3_para256",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 252,
              "end_char": 253,
              "context": "nd S. The contour labeled 420 encloses “A”, S, R, F, P, and B. The remaining cities are outside all c"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para257",
          "content": "×\nFigure 3.21\nTwo searches on the same grid: (a) an A* search and (b) a weighted A* search with weight\nW =\n2. The gray bars are obstacles, the purple line is the path from the green start to red goal, and the small dots are states that were reached by each search. On this particular problem, weighted A* explores 7 times fewer states and finds a path that is 5% more costly.",
          "sentence_count": 3,
          "char_count": 306,
          "prev_para_id": "chap3_para256",
          "next_para_id": "chap3_para258",
          "style_metadata": {
            "para_id": "chap3_para257",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "search": 4,
            "grid": 1,
            "weighted": 2,
            "weight": 1,
            "gray": 1,
            "bar": 1,
            "obstacle": 1,
            "purple": 1,
            "line": 1,
            "path": 2,
            "green": 1,
            "start": 1,
            "red": 1,
            "goal": 1,
            "small": 1,
            "dot": 1,
            "state": 2,
            "reached": 1,
            "particular": 1,
            "problem": 1,
            "explores": 1,
            "time": 1,
            "fewer": 1,
            "find": 1,
            "costly": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para258",
          "content": "We have considered searches that evaluate states by combining\ng\nand\nh\nin various ways; weighted A* can be seen as a generalization of the others:\nA\n*\nsearch:\nUniform-cost search:\nGreedy best-first search:\nWeighted A\n*\nsearch:\ng\n(\nn\n) +\nh\n(\nn\n)\ng\n(\nn\n)\nh\n(\nn\n)\ng\n(\nn\n) +\nW\n×\nh\n(\nn\n)\n(\nW\n= 1)\n(\nW\n= 0)\n(\nW\n=\n∞\n)\n(1 <\nW\n<\n∞\n)\nYou could call weighted A* “somewhat-greedy search”: like greedy best-first search, it focuses the search towards a goal; on the other hand, it won’t ignore the path cost completely, and will suspend a path that is making little progress at great cost.",
          "sentence_count": 1,
          "char_count": 513,
          "prev_para_id": "chap3_para257",
          "next_para_id": "chap3_para259",
          "style_metadata": {
            "para_id": "chap3_para258",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 148.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 148,
            "sentence_count": 1
          },
          "terminology": {
            "considered": 1,
            "search": 8,
            "evaluate": 1,
            "state": 1,
            "combining": 1,
            "various": 1,
            "way": 1,
            "weighted": 3,
            "seen": 1,
            "generalization": 1,
            "others": 1,
            "uniform-cost": 1,
            "greedy": 2,
            "best-first": 2,
            "call": 1,
            "somewhat-greedy": 1,
            "focus": 1,
            "towards": 1,
            "goal": 1,
            "hand": 1,
            "path": 2,
            "cost": 2,
            "suspend": 1,
            "making": 1,
            "little": 1,
            "progress": 1,
            "great": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para259",
          "content": "There are a variety of suboptimal search algorithms, which can be characterized by the criteria for what counts as “good enough.” In\nbounded suboptimal search\n, we look for a solution that is guaranteed to be within a constant factor\nW\nof the optimal cost. Weighted A* provides this guarantee. In\nbounded-cost search\n, we look for a solution whose cost is less than some constant\nC\n. And in\nunbounded-cost search\n, we accept a solution of any cost, as long as we can find it quickly.",
          "sentence_count": 4,
          "char_count": 406,
          "prev_para_id": "chap3_para258",
          "next_para_id": "chap3_para260",
          "style_metadata": {
            "para_id": "chap3_para259",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 4
          },
          "terminology": {
            "variety": 1,
            "suboptimal": 2,
            "search": 4,
            "algorithm": 1,
            "characterized": 1,
            "criterion": 1,
            "count": 1,
            "good": 1,
            "enough.": 1,
            "bounded": 1,
            "look": 2,
            "solution": 3,
            "guaranteed": 1,
            "constant": 2,
            "factor": 1,
            "optimal": 1,
            "cost": 3,
            "weighted": 1,
            "provides": 1,
            "guarantee": 1,
            "bounded-cost": 1,
            "less": 1,
            "unbounded-cost": 1,
            "long": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para260",
          "content": "An example of an unbounded-cost search algorithm is\nspeedy search\n, which is a version of greedy best-first search that uses as a heuristic the estimated number of actions required to reach a goal, regardless of the cost of those actions. Thus, for problems where all actions have the same cost it is the same as greedy best-first search, but when actions have different costs, it tends to lead the search to find a solution quickly, even if it might have a high cost.",
          "sentence_count": 2,
          "char_count": 387,
          "prev_para_id": "chap3_para259",
          "next_para_id": "chap3_para261",
          "style_metadata": {
            "para_id": "chap3_para260",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 2
          },
          "terminology": {
            "example": 1,
            "unbounded-cost": 1,
            "search": 5,
            "algorithm": 1,
            "speedy": 1,
            "version": 1,
            "greedy": 2,
            "best-first": 2,
            "us": 1,
            "heuristic": 1,
            "estimated": 1,
            "number": 1,
            "action": 4,
            "required": 1,
            "reach": 1,
            "goal": 1,
            "cost": 4,
            "problem": 1,
            "different": 1,
            "tends": 1,
            "lead": 1,
            "find": 1,
            "solution": 1,
            "high": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para261",
          "content": "3.5.5\nMemory-bounded search\nThe main issue with A* is its use of memory. In this section we’ll cover some implementation tricks that save space, and then some entirely new algorithms that take better advantage of the available space.",
          "sentence_count": 2,
          "char_count": 198,
          "prev_para_id": "chap3_para260",
          "next_para_id": "chap3_para262",
          "style_metadata": {
            "para_id": "chap3_para261",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "memory-bounded": 1,
            "search": 1,
            "main": 1,
            "issue": 1,
            "use": 1,
            "memory": 1,
            "section": 1,
            "cover": 1,
            "implementation": 1,
            "trick": 1,
            "save": 1,
            "space": 2,
            "new": 1,
            "algorithm": 1,
            "take": 1,
            "better": 1,
            "advantage": 1,
            "available": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para262",
          "content": "Memory is split between the\nfrontier\nand the\nreached\nstates. In our implementation of best-first search, a state that is on the frontier is stored in two places: as a node in the frontier (so we can decide what to expand next) and as an entry in the table of reached states (so we know if we have visited the state before). For many problems (such as exploring a grid), this duplication is not a concern, because the size of\nfrontier\nis much smaller than\nreached\n, so duplicating the states in the frontier requires a comparatively trivial amount of memory. But some implementations keep a state in only one of the two places, saving a bit of space at the cost of complicating (and perhaps slowing down) the algorithm.",
          "sentence_count": 4,
          "char_count": 597,
          "prev_para_id": "chap3_para261",
          "next_para_id": "chap3_para263",
          "style_metadata": {
            "para_id": "chap3_para262",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.75,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 147,
            "sentence_count": 4
          },
          "terminology": {
            "memory": 2,
            "split": 1,
            "reached": 3,
            "state": 6,
            "implementation": 2,
            "best-first": 1,
            "search": 1,
            "frontier": 1,
            "stored": 1,
            "place": 2,
            "decide": 1,
            "expand": 1,
            "next": 1,
            "entry": 1,
            "table": 1,
            "know": 1,
            "visited": 1,
            "many": 1,
            "problem": 1,
            "exploring": 1,
            "grid": 1,
            "duplication": 1,
            "concern": 1,
            "size": 1,
            "much": 1,
            "smaller": 1,
            "duplicating": 1,
            "requires": 1,
            "trivial": 1,
            "amount": 1,
            "keep": 1,
            "saving": 1,
            "bit": 1,
            "space": 1,
            "cost": 1,
            "complicating": 1,
            "slowing": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para263",
          "content": "Another possibility is to remove states from\nreached\nwhen we can prove that they are no longer needed. For some problems, we can use the separation property (\nFigure 3.6\non\npage 90\n), along with the prohibition of U-turn actions, to ensure that all actions either move outwards from the frontier or onto another frontier state. In that case, we need only check the frontier for redundant paths, and we can eliminate the\nreached\ntable.",
          "sentence_count": 3,
          "char_count": 367,
          "prev_para_id": "chap3_para262",
          "next_para_id": "chap3_para264",
          "style_metadata": {
            "para_id": "chap3_para263",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 3
          },
          "terminology": {
            "possibility": 1,
            "remove": 1,
            "state": 2,
            "reached": 2,
            "needed": 1,
            "problem": 1,
            "use": 1,
            "separation": 1,
            "property": 1,
            "figure": 1,
            "page": 1,
            "prohibition": 1,
            "u-turn": 1,
            "action": 2,
            "ensure": 1,
            "move": 1,
            "outwards": 1,
            "frontier": 2,
            "case": 1,
            "check": 1,
            "redundant": 1,
            "path": 1,
            "eliminate": 1,
            "table": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para264",
          "content": "For other problems, we can keep\nreference counts\nof the number of times a state has been reached, and remove it from the\nreached\ntable when there are no more ways to reach the state. For example, on a grid world where each state can be reached only from its four neighbors, once we have reached a state four times, we can remove it from the table.",
          "sentence_count": 2,
          "char_count": 285,
          "prev_para_id": "chap3_para263",
          "next_para_id": "chap3_para265",
          "style_metadata": {
            "para_id": "chap3_para264",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 2
          },
          "terminology": {
            "problem": 1,
            "keep": 1,
            "reference": 1,
            "count": 1,
            "number": 1,
            "time": 2,
            "state": 4,
            "reached": 4,
            "remove": 2,
            "table": 2,
            "way": 1,
            "reach": 1,
            "example": 1,
            "grid": 1,
            "world": 1,
            "neighbor": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para265",
          "content": "Now let’s consider new algorithms that are designed to conserve memory usage.",
          "sentence_count": 1,
          "char_count": 66,
          "prev_para_id": "chap3_para264",
          "next_para_id": "chap3_para266",
          "style_metadata": {
            "para_id": "chap3_para265",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "let": 1,
            "consider": 1,
            "new": 1,
            "algorithm": 1,
            "designed": 1,
            "conserve": 1,
            "memory": 1,
            "usage": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para266",
          "content": "Beam search\nlimits the size of the frontier. The easiest approach is to keep only the\nk\nnodes with the best\nf\n-scores, discarding any other expanded nodes. This of course makes the search incomplete and suboptimal, but we can choose\nk\nto make good use of available memory, and the algorithm executes fast because it expands fewer nodes. For many problems it can find good near-optimal solutions. You can think of uniform-cost or A* search as spreading out everywhere in concentric contours, and think of beam search as exploring only a focused portion of those contours, the portion that contains the\nk\nbest candidates.",
          "sentence_count": 5,
          "char_count": 524,
          "prev_para_id": "chap3_para265",
          "next_para_id": "chap3_para267",
          "style_metadata": {
            "para_id": "chap3_para266",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 116,
            "sentence_count": 5
          },
          "terminology": {
            "beam": 1,
            "search": 4,
            "limit": 1,
            "size": 1,
            "frontier": 1,
            "easiest": 1,
            "approach": 1,
            "keep": 1,
            "node": 3,
            "best": 1,
            "-scores": 1,
            "discarding": 1,
            "expanded": 1,
            "course": 1,
            "make": 2,
            "incomplete": 1,
            "suboptimal": 1,
            "choose": 1,
            "good": 2,
            "use": 1,
            "available": 1,
            "memory": 1,
            "algorithm": 1,
            "executes": 1,
            "fast": 1,
            "expands": 1,
            "fewer": 1,
            "many": 1,
            "problem": 1,
            "find": 1,
            "near-optimal": 1,
            "solution": 1,
            "think": 2,
            "uniform-cost": 1,
            "spreading": 1,
            "concentric": 1,
            "contour": 2,
            "exploring": 1,
            "focused": 1,
            "portion": 2,
            "contains": 1,
            "candidate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para266",
              "entity_text": "Beam",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 4,
              "context": "Beam search\nlimits the size of the frontier. The easie"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para267",
          "content": "An alternative version of beam search doesn’t keep a strict limit on the size of the frontier but instead keeps every node whose\nf\n-score is within δ of the best\nf\n-score. That way, when there are a few strong-scoring nodes only a few will be kept, but if there are no strong nodes then more will be kept until a strong one emerges.",
          "sentence_count": 2,
          "char_count": 272,
          "prev_para_id": "chap3_para266",
          "next_para_id": "chap3_para268",
          "style_metadata": {
            "para_id": "chap3_para267",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 71,
            "sentence_count": 2
          },
          "terminology": {
            "alternative": 1,
            "version": 1,
            "beam": 1,
            "search": 1,
            "keep": 2,
            "strict": 1,
            "limit": 1,
            "size": 1,
            "frontier": 1,
            "node": 3,
            "-score": 2,
            "best": 1,
            "way": 1,
            "strong-scoring": 1,
            "kept": 2,
            "strong": 2,
            "emerges": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para268",
          "content": "Iterative-deepening A\n*\nsearch\n(IDA*) is to A* what iterative-deepening search is to depth-first: IDA* gives us the benefits of A* without the requirement to keep all reached states in memory, at a cost of visiting some states multiple times. It is a very important and commonly used algorithm for problems that do not fit in memory.",
          "sentence_count": 2,
          "char_count": 280,
          "prev_para_id": "chap3_para267",
          "next_para_id": "chap3_para269",
          "style_metadata": {
            "para_id": "chap3_para268",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 2
          },
          "terminology": {
            "iterative-deepening": 2,
            "search": 2,
            "ida": 2,
            "depth-first": 1,
            "give": 1,
            "benefit": 1,
            "requirement": 1,
            "keep": 1,
            "reached": 1,
            "state": 2,
            "memory": 2,
            "cost": 1,
            "visiting": 1,
            "multiple": 1,
            "time": 1,
            "important": 1,
            "used": 1,
            "algorithm": 1,
            "problem": 1,
            "fit": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para268",
              "entity_text": "IDA",
              "entity_type": "PERSON",
              "start_char": 32,
              "end_char": 35,
              "context": "Iterative-deepening A\n*\nsearch\n(IDA*) is to A* what iterative-deepening search is to "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para269",
          "content": "In standard iterative deepening the cutoff is the depth, which is increased by one each iteration. In IDA* the cutoff is the\nf\n-cost (\ng\n+\nh\n); at each iteration, the cutoff value is the smallest\nf\n-cost of any node that exceeded the cutoff on the previous iteration. In other words, each iteration exhaustively searches an\nf\n-contour, finds a node just beyond that contour, and uses that node’s\nf\n-cost as the next contour. For problems like the 8-puzzle where each path’s\nf\n-cost is an integer, this works very well, resulting in steady progress towards the goal each iteration. If the optimal solution has cost\nC\n*, then there can be no more than\nC\n* iterations (for example, no more than 31 iterations on the hardest 8-puzzle problems). But for a problem where every node has a different\nf\n-cost, each new contour might contain only one new node, and the number of iterations could be equal to the number of states.",
          "sentence_count": 6,
          "char_count": 772,
          "prev_para_id": "chap3_para268",
          "next_para_id": "chap3_para270",
          "style_metadata": {
            "para_id": "chap3_para269",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.17,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 193,
            "sentence_count": 6
          },
          "terminology": {
            "standard": 1,
            "iterative": 1,
            "deepening": 1,
            "cutoff": 3,
            "depth": 1,
            "increased": 1,
            "iteration": 8,
            "ida": 1,
            "value": 1,
            "smallest": 1,
            "-cost": 3,
            "node": 5,
            "exceeded": 1,
            "previous": 1,
            "word": 1,
            "search": 1,
            "-contour": 1,
            "find": 1,
            "contour": 3,
            "us": 1,
            "next": 1,
            "problem": 3,
            "8-puzzle": 2,
            "path": 1,
            "integer": 1,
            "work": 1,
            "resulting": 1,
            "steady": 1,
            "progress": 1,
            "towards": 1,
            "goal": 1,
            "optimal": 1,
            "solution": 1,
            "cost": 1,
            "example": 1,
            "hardest": 1,
            "different": 1,
            "new": 2,
            "contain": 1,
            "number": 2,
            "equal": 1,
            "state": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para269",
              "entity_text": "IDA",
              "entity_type": "PERSON",
              "start_char": 102,
              "end_char": 105,
              "context": "pth, which is increased by one each iteration. In IDA* the cutoff is the\nf\n-cost (\ng\n+\nh\n); at each ite"
            },
            {
              "para_id": "chap3_para269",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 344,
              "end_char": 348,
              "context": "tion exhaustively searches an\nf\n-contour, finds a node just beyond that contour, and uses that node’s\nf\n"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para270",
          "content": "Recursive best-first search\n(RBFS) (\nFigure 3.22\n) attempts to mimic the operation of standard best-first search, but using only linear space. RBFS resembles a recursive depth-first search, but rather than continuing indefinitely down the current path, it uses the\nf-limit\nvariable to keep track of the\nf\n-value of the best\nalternative\npath available from any ancestor of the current node. If the current node exceeds this limit, the recursion unwinds back to the alternative path. As the recursion unwinds, RBFS replaces the\nf\n-value of each node along the path with a\nbacked-up value\n—the best\nf\n-value of its children. In this way, RBFS remembers the\nf\n-value of the best leaf in the forgotten subtree and can therefore decide whether it’s worth reexpanding the subtree at some later time.",
          "sentence_count": 5,
          "char_count": 677,
          "prev_para_id": "chap3_para269",
          "next_para_id": "chap3_para271",
          "style_metadata": {
            "para_id": "chap3_para270",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 29.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 148,
            "sentence_count": 5
          },
          "terminology": {
            "recursive": 2,
            "best-first": 2,
            "search": 3,
            "rbfs": 4,
            "figure": 1,
            "attempt": 1,
            "mimic": 1,
            "operation": 1,
            "standard": 1,
            "using": 1,
            "linear": 1,
            "space": 1,
            "resembles": 1,
            "depth-first": 1,
            "continuing": 1,
            "current": 3,
            "path": 4,
            "us": 1,
            "f-limit": 1,
            "variable": 1,
            "keep": 1,
            "track": 1,
            "-value": 4,
            "alternative": 2,
            "available": 1,
            "ancestor": 1,
            "node": 2,
            "exceeds": 1,
            "limit": 1,
            "recursion": 2,
            "unwinds": 2,
            "replaces": 1,
            "backed-up": 1,
            "value": 1,
            "—the": 1,
            "best": 2,
            "child": 1,
            "way": 1,
            "remembers": 1,
            "leaf": 1,
            "forgotten": 1,
            "subtree": 2,
            "worth": 1,
            "reexpanding": 1,
            "later": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para270",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 635,
              "end_char": 639,
              "context": "\n—the best\nf\n-value of its children. In this way, RBFS remembers the\nf\n-value of the best leaf in the fo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para271",
          "content": "Figure 3.23\nshows how RBFS reaches Bucharest.",
          "sentence_count": 1,
          "char_count": 40,
          "prev_para_id": "chap3_para270",
          "next_para_id": "chap3_para272",
          "style_metadata": {
            "para_id": "chap3_para271",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 8,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "rbfs": 1,
            "reach": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para271",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 22,
              "end_char": 26,
              "context": "Figure 3.23\nshows how RBFS reaches Bucharest."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para272",
          "content": "Description\nIn both parts, equidistant small dots are shown across the entire grid. A maze of multiple gray bars is shown scattered throughout the grid. A green dot is shown toward the left end of the grid and a red dot toward the right end of the grid. A purple line starts from the green, moves through the grid, and ends at the red dot. The purple line doesn’t cross or pass through any gray bars, rather, it moves above, below, or between two gray bars.",
          "sentence_count": 5,
          "char_count": 373,
          "prev_para_id": "chap3_para271",
          "next_para_id": "chap3_para273",
          "style_metadata": {
            "para_id": "chap3_para272",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 100,
            "sentence_count": 5
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "equidistant": 1,
            "small": 1,
            "dot": 4,
            "shown": 3,
            "entire": 1,
            "grid": 5,
            "maze": 1,
            "multiple": 1,
            "gray": 3,
            "bar": 3,
            "scattered": 1,
            "green": 2,
            "left": 1,
            "end": 3,
            "red": 2,
            "right": 1,
            "purple": 2,
            "line": 2,
            "start": 1,
            "move": 2,
            "cross": 1,
            "pas": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para273",
          "content": "Part (“A”): The purple line takes a path that almost resembles a curve that opens upward. The purple line stays mostly below the bulk of the gray bars, without navigating much through the maze of the gray bars.",
          "sentence_count": 2,
          "char_count": 173,
          "prev_para_id": "chap3_para272",
          "next_para_id": "chap3_para274",
          "style_metadata": {
            "para_id": "chap3_para273",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "part": 1,
            "purple": 2,
            "line": 2,
            "take": 1,
            "path": 1,
            "resembles": 1,
            "curve": 1,
            "open": 1,
            "upward": 1,
            "stay": 1,
            "bulk": 1,
            "gray": 2,
            "bar": 2,
            "navigating": 1,
            "much": 1,
            "maze": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para274",
          "content": "Part (b): The purple line moves in an irregular path. The purple line navigates through the maze of the gray bars, through the bulk.",
          "sentence_count": 2,
          "char_count": 109,
          "prev_para_id": "chap3_para273",
          "next_para_id": "chap3_para275",
          "style_metadata": {
            "para_id": "chap3_para274",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 2
          },
          "terminology": {
            "part": 1,
            "purple": 2,
            "line": 2,
            "move": 1,
            "irregular": 1,
            "path": 1,
            "navigates": 1,
            "maze": 1,
            "gray": 1,
            "bar": 1,
            "bulk": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para275",
          "content": "×\nFigure 3.22\nThe algorithm for recursive best-first search.",
          "sentence_count": 1,
          "char_count": 54,
          "prev_para_id": "chap3_para274",
          "next_para_id": "chap3_para276",
          "style_metadata": {
            "para_id": "chap3_para275",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "algorithm": 1,
            "recursive": 1,
            "best-first": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para276",
          "content": "RBFS is somewhat more efficient than IDA*, but still suffers from excessive node regeneration. In the example in\nFigure 3.23\n, RBFS follows the path via Rimnicu Vilcea, then\n“changes its mind” and tries Fagaras, and then changes its mind back again. These mind changes occur because every time the current best path is extended, its\nf\n-value is likely to increase—\nh\nis usually less optimistic for nodes closer to a goal. When this happens, the second-best path might become the best path, so the search has to backtrack to follow it. Each mind change corresponds to an iteration of IDA* and could require many reexpansions of forgotten nodes to recreate the best path and extend it one more node.",
          "sentence_count": 5,
          "char_count": 584,
          "prev_para_id": "chap3_para275",
          "next_para_id": "chap3_para277",
          "style_metadata": {
            "para_id": "chap3_para276",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.2,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 5
          },
          "terminology": {
            "rbfs": 2,
            "efficient": 1,
            "ida": 2,
            "suffers": 1,
            "excessive": 1,
            "node": 4,
            "regeneration": 1,
            "example": 1,
            "figure": 1,
            "follows": 1,
            "path": 5,
            "rimnicu": 1,
            "vilcea": 1,
            "change": 4,
            "mind": 4,
            "try": 1,
            "fagaras": 1,
            "occur": 1,
            "time": 1,
            "current": 1,
            "best": 3,
            "extended": 1,
            "likely": 1,
            "increase—": 1,
            "optimistic": 1,
            "closer": 1,
            "goal": 1,
            "happens": 1,
            "second-best": 1,
            "become": 1,
            "search": 1,
            "backtrack": 1,
            "follow": 1,
            "corresponds": 1,
            "iteration": 1,
            "require": 1,
            "many": 1,
            "reexpansions": 1,
            "forgotten": 1,
            "recreate": 1,
            "extend": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para276",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 4,
              "context": "RBFS is somewhat more efficient than IDA*, but still s"
            },
            {
              "para_id": "chap3_para276",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 127,
              "end_char": 131,
              "context": "ode regeneration. In the example in\nFigure 3.23\n, RBFS follows the path via Rimnicu Vilcea, then\n“change"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para277",
          "content": "Description\nPart (“A”): After expanding Pitesti, Sibiu, and Rimnicu Vilcea. A node labeled Arad 366 is connected to three nodes labeled Sibiu 393, Timisoara 447, and Zerind 449. Timisoara and Zerind are green-colored. A small box above Arad reads infinity. Sibiu is connected to four nodes labeled Arad 646, Fagaras 415, Oradea 671, and Rimnicu Vilcea 413. A small box each above Sibiu and Rimnicu Vilcea read 447 and 415, respectively. Arad, Sibiu, and Rimnicu Vilcea are lavender-colored. The other three nodes under Sibiu are green-colored. Rimnicu Vilcea is connected to three green-colored nodes, Craiova 526, Pitesti 417, and Sibiu 553.",
          "sentence_count": 9,
          "char_count": 543,
          "prev_para_id": "chap3_para276",
          "next_para_id": "chap3_para278",
          "style_metadata": {
            "para_id": "chap3_para277",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.024,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 126,
            "sentence_count": 9
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "expanding": 1,
            "pitesti": 2,
            "sibiu": 7,
            "rimnicu": 5,
            "vilcea": 4,
            "node": 5,
            "labeled": 3,
            "connected": 3,
            "timisoara": 2,
            "zerind": 1,
            "green-colored": 3,
            "small": 2,
            "box": 2,
            "arad": 3,
            "read": 2,
            "infinity": 1,
            "fagaras": 1,
            "oradea": 1,
            "lavender-colored": 1,
            "craiova": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para277",
              "entity_text": "Pitesti",
              "entity_type": "ORG",
              "start_char": 40,
              "end_char": 47,
              "context": "Description\nPart (“A”): After expanding Pitesti, Sibiu, and Rimnicu Vilcea. A node labeled Arad 3"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 49,
              "end_char": 54,
              "context": "Description\nPart (“A”): After expanding Pitesti, Sibiu, and Rimnicu Vilcea. A node labeled Arad 366 is c"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 78,
              "end_char": 82,
              "context": "r expanding Pitesti, Sibiu, and Rimnicu Vilcea. A node labeled Arad 366 is connected to three nodes labe"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Arad 366",
              "entity_type": "PERSON",
              "start_char": 91,
              "end_char": 99,
              "context": "itesti, Sibiu, and Rimnicu Vilcea. A node labeled Arad 366 is connected to three nodes labeled Sibiu 393, Ti"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 136,
              "end_char": 141,
              "context": "eled Arad 366 is connected to three nodes labeled Sibiu 393, Timisoara 447, and Zerind 449. Timisoara and"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Timisoara 447",
              "entity_type": "PERSON",
              "start_char": 147,
              "end_char": 160,
              "context": "66 is connected to three nodes labeled Sibiu 393, Timisoara 447, and Zerind 449. Timisoara and Zerind are green-c"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 166,
              "end_char": 172,
              "context": "three nodes labeled Sibiu 393, Timisoara 447, and Zerind 449. Timisoara and Zerind are green-colored. A sm"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 178,
              "end_char": 187,
              "context": "labeled Sibiu 393, Timisoara 447, and Zerind 449. Timisoara and Zerind are green-colored. A small box above A"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Zerind",
              "entity_type": "PERSON",
              "start_char": 192,
              "end_char": 198,
              "context": "393, Timisoara 447, and Zerind 449. Timisoara and Zerind are green-colored. A small box above Arad reads i"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 236,
              "end_char": 240,
              "context": "a and Zerind are green-colored. A small box above Arad reads infinity. Sibiu is connected to four nodes "
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 257,
              "end_char": 262,
              "context": "n-colored. A small box above Arad reads infinity. Sibiu is connected to four nodes labeled Arad 646, Faga"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Oradea 671",
              "entity_type": "ORG",
              "start_char": 321,
              "end_char": 331,
              "context": "cted to four nodes labeled Arad 646, Fagaras 415, Oradea 671, and Rimnicu Vilcea 413. A small box each above S"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 380,
              "end_char": 385,
              "context": "1, and Rimnicu Vilcea 413. A small box each above Sibiu and Rimnicu Vilcea read 447 and 415, respectively"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 437,
              "end_char": 441,
              "context": "nd Rimnicu Vilcea read 447 and 415, respectively. Arad, Sibiu, and Rimnicu Vilcea are lavender-colored. "
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 443,
              "end_char": 448,
              "context": "nicu Vilcea read 447 and 415, respectively. Arad, Sibiu, and Rimnicu Vilcea are lavender-colored. The oth"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 519,
              "end_char": 524,
              "context": "are lavender-colored. The other three nodes under Sibiu are green-colored. Rimnicu Vilcea is connected to"
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Craiova 526",
              "entity_type": "PERSON",
              "start_char": 602,
              "end_char": 613,
              "context": "Vilcea is connected to three green-colored nodes, Craiova 526, Pitesti 417, and Sibiu 553."
            },
            {
              "para_id": "chap3_para277",
              "entity_text": "Sibiu 553",
              "entity_type": "PERSON",
              "start_char": 632,
              "end_char": 641,
              "context": "reen-colored nodes, Craiova 526, Pitesti 417, and Sibiu 553."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para278",
          "content": "Part (b): After unwinding back to Sibiu and expanding Fagaras. Rimnicu Vilcea is now green-colored, the small box above it is removed, and the node’s previous label of 413 is struck off to read the new value of 417. Fagaras is now lavender-colored and has a small box above it that reads 417. Fagaras is connected to two green-colored nodes labeled Sibiu 591 and Bucharest 450.",
          "sentence_count": 4,
          "char_count": 312,
          "prev_para_id": "chap3_para277",
          "next_para_id": "chap3_para279",
          "style_metadata": {
            "para_id": "chap3_para278",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.75,
            "passive_voice_ratio": 0.027,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 4
          },
          "terminology": {
            "part": 1,
            "unwinding": 1,
            "sibiu": 2,
            "expanding": 1,
            "fagaras": 3,
            "rimnicu": 1,
            "vilcea": 1,
            "green-colored": 2,
            "small": 2,
            "box": 2,
            "removed": 1,
            "previous": 1,
            "label": 1,
            "struck": 1,
            "read": 2,
            "new": 1,
            "value": 1,
            "lavender-colored": 1,
            "connected": 1,
            "node": 1,
            "labeled": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para278",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 34,
              "end_char": 39,
              "context": "Part (b): After unwinding back to Sibiu and expanding Fagaras. Rimnicu Vilcea is now gree"
            },
            {
              "para_id": "chap3_para278",
              "entity_text": "Sibiu",
              "entity_type": "PERSON",
              "start_char": 349,
              "end_char": 354,
              "context": "s is connected to two green-colored nodes labeled Sibiu 591 and Bucharest 450."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para279",
          "content": "Part (c): After switching back to Rimnicu Vilcea and expanding Pitesti. Fagaras is now back to being green-colored, the small box above it is removed, and the node’s previous label of 415 is struck off to read the new value of 450. Rimnicu Vilcea is back to being lavender-colored and has a small box above it that reads 447. Rimnicu Vilcea is connected to three nodes labeled Craiova 526, Pitesti 417, and Sibiu 553. Pitesti is lavender-colored and has a small box above it that reads 447. The other two nodes under Rimnicu Vilcea are green-colored. Pitesti is connected to three green-colored nodes Bucharest 418, Craiova 615, and Rimnicu Vilcea 607.",
          "sentence_count": 7,
          "char_count": 542,
          "prev_para_id": "chap3_para278",
          "next_para_id": "chap3_para280",
          "style_metadata": {
            "para_id": "chap3_para279",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.86,
            "passive_voice_ratio": 0.024,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 125,
            "sentence_count": 7
          },
          "terminology": {
            "part": 1,
            "switching": 1,
            "rimnicu": 5,
            "vilcea": 5,
            "expanding": 1,
            "pitesti": 4,
            "fagaras": 1,
            "green-colored": 3,
            "small": 3,
            "box": 3,
            "removed": 1,
            "previous": 1,
            "label": 1,
            "struck": 1,
            "read": 3,
            "new": 1,
            "value": 1,
            "lavender-colored": 2,
            "connected": 2,
            "node": 3,
            "labeled": 1,
            "craiova": 2,
            "sibiu": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para279",
              "entity_text": "Pitesti",
              "entity_type": "PRODUCT",
              "start_char": 63,
              "end_char": 70,
              "context": "er switching back to Rimnicu Vilcea and expanding Pitesti. Fagaras is now back to being green-colored, the "
            },
            {
              "para_id": "chap3_para279",
              "entity_text": "Sibiu 553",
              "entity_type": "PERSON",
              "start_char": 407,
              "end_char": 416,
              "context": "three nodes labeled Craiova 526, Pitesti 417, and Sibiu 553. Pitesti is lavender-colored and has a small box "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para280",
          "content": "×\nFigure 3.23\nStages in an RBFS search for the shortest route to Bucharest. The\nf-limit\nvalue for each recursive call is shown on top of each current node, and every node is labeled with its\nf\n-cost. (a) The path via Rimnicu Vilcea is followed until the current best leaf (Pitesti) has a value that is worse than the best alternative path (Fagaras). (b) The recursion unwinds and the best leaf value of the forgotten subtree (417) is backed up to Rimnicu Vilcea; then Fagaras is expanded, revealing a best leaf value of 450. (c) The recursion unwinds and the best leaf value of the forgotten subtree (450) is backed up to Fagaras; then Rimnicu Vilcea is expanded. This time, because the best alternative path (through Timisoara) costs at least 447, the expansion continues to Bucharest.",
          "sentence_count": 6,
          "char_count": 656,
          "prev_para_id": "chap3_para279",
          "next_para_id": "chap3_para281",
          "style_metadata": {
            "para_id": "chap3_para280",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 165,
            "sentence_count": 6
          },
          "terminology": {
            "figure": 1,
            "stage": 1,
            "rbfs": 1,
            "search": 1,
            "shortest": 1,
            "route": 1,
            "f-limit": 1,
            "value": 5,
            "recursive": 1,
            "call": 1,
            "shown": 1,
            "top": 1,
            "current": 2,
            "node": 2,
            "labeled": 1,
            "-cost": 1,
            "path": 3,
            "rimnicu": 3,
            "vilcea": 3,
            "followed": 1,
            "best": 4,
            "leaf": 4,
            "pitesti": 1,
            "worse": 1,
            "alternative": 2,
            "fagaras": 3,
            "recursion": 2,
            "unwinds": 2,
            "forgotten": 2,
            "subtree": 2,
            "backed": 2,
            "expanded": 2,
            "revealing": 1,
            "time": 1,
            "timisoara": 1,
            "cost": 1,
            "least": 1,
            "expansion": 1,
            "continues": 1,
            "bucharest": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para280",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 27,
              "end_char": 31,
              "context": "×\nFigure 3.23\nStages in an RBFS search for the shortest route to Bucharest. The\nf"
            },
            {
              "para_id": "chap3_para280",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 150,
              "end_char": 154,
              "context": "ch recursive call is shown on top of each current node, and every node is labeled with its\nf\n-cost. (a) "
            },
            {
              "para_id": "chap3_para280",
              "entity_text": "Timisoara",
              "entity_type": "PERSON",
              "start_char": 718,
              "end_char": 727,
              "context": " time, because the best alternative path (through Timisoara) costs at least 447, the expansion continues to B"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para281",
          "content": "RBFS is optimal if the heuristic function\nh(n)\nis admissible. Its space complexity is linear in the depth of the deepest optimal solution, but its time complexity is rather difficult to characterize: it depends both on the accuracy of the heuristic function and on how often the best path changes as nodes are expanded. It expands nodes in order of increasing\nf\n-score, even if\nf\nis nonmonotonic.",
          "sentence_count": 3,
          "char_count": 335,
          "prev_para_id": "chap3_para280",
          "next_para_id": "chap3_para282",
          "style_metadata": {
            "para_id": "chap3_para281",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 3
          },
          "terminology": {
            "rbfs": 1,
            "optimal": 2,
            "heuristic": 2,
            "function": 2,
            "admissible": 1,
            "space": 1,
            "complexity": 2,
            "linear": 1,
            "depth": 1,
            "deepest": 1,
            "solution": 1,
            "time": 1,
            "difficult": 1,
            "characterize": 1,
            "depends": 1,
            "accuracy": 1,
            "best": 1,
            "path": 1,
            "change": 1,
            "node": 2,
            "expanded": 1,
            "expands": 1,
            "order": 1,
            "increasing": 1,
            "nonmonotonic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para281",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 4,
              "context": "RBFS is optimal if the heuristic function\nh(n)\nis admi"
            },
            {
              "para_id": "chap3_para281",
              "entity_text": "h(n",
              "entity_type": "PERSON",
              "start_char": 42,
              "end_char": 45,
              "context": "RBFS is optimal if the heuristic function\nh(n)\nis admissible. Its space complexity is linear in"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para282",
          "content": "IDA* and RBFS suffer from using\ntoo little\nmemory. Between iterations, IDA* retains only a single number: the current\nf\n-cost limit. RBFS retains more information in memory, but it uses only linear space: even if more memory were available, RBFS has no way to make use of it. Because they forget most of what they have done, both algorithms may end up reexploring the same states many times over.",
          "sentence_count": 4,
          "char_count": 331,
          "prev_para_id": "chap3_para281",
          "next_para_id": "chap3_para283",
          "style_metadata": {
            "para_id": "chap3_para282",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 4
          },
          "terminology": {
            "ida": 2,
            "rbfs": 3,
            "suffer": 1,
            "using": 1,
            "little": 1,
            "memory": 2,
            "iteration": 1,
            "retains": 2,
            "single": 1,
            "number": 1,
            "current": 1,
            "-cost": 1,
            "limit": 1,
            "information": 1,
            "us": 1,
            "linear": 1,
            "space": 1,
            "available": 1,
            "way": 1,
            "make": 1,
            "use": 1,
            "forget": 1,
            "done": 1,
            "algorithm": 1,
            "end": 1,
            "reexploring": 1,
            "state": 1,
            "many": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para282",
              "entity_text": "IDA",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 3,
              "context": "IDA* and RBFS suffer from using\ntoo little\nmemory. Be"
            },
            {
              "para_id": "chap3_para282",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 9,
              "end_char": 13,
              "context": "IDA* and RBFS suffer from using\ntoo little\nmemory. Between iter"
            },
            {
              "para_id": "chap3_para282",
              "entity_text": "IDA",
              "entity_type": "PERSON",
              "start_char": 71,
              "end_char": 74,
              "context": "from using\ntoo little\nmemory. Between iterations, IDA* retains only a single number: the current\nf\n-cos"
            },
            {
              "para_id": "chap3_para282",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 241,
              "end_char": 245,
              "context": "linear space: even if more memory were available, RBFS has no way to make use of it. Because they forget"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para283",
          "content": "It seems sensible, therefore, to determine how much memory we have available, and allow an algorithm to use all of it. Two algorithms that do this are\nMA\n* (memory-bounded A*) and\nSMA\n* (simplified MA*). SMA* is—well—simpler, so we will describe it. SMA* proceeds just like A*, expanding the best leaf until memory is full. At this point, it cannot add a new node to the search tree without dropping an old one. SMA* always drops the\nworst\nleaf node—the one with the highest\nf\n-value. Like RBFS, SMA* then backs up the value of the forgotten node to its parent. In this way, the ancestor of a forgotten subtree knows the quality of the best path in that subtree. With this information, SMA* regenerates the subtree only when all other paths have been shown to look worse than the path it has forgotten. Another way of saying this is that if all the descendants of a node\nn\nare forgotten, then we will not know which way to go from\nn\n, but we will still have an idea of how worthwhile it is to go anywhere from\nn\n.",
          "sentence_count": 10,
          "char_count": 836,
          "prev_para_id": "chap3_para282",
          "next_para_id": "chap3_para284",
          "style_metadata": {
            "para_id": "chap3_para283",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 22.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 224,
            "sentence_count": 10
          },
          "terminology": {
            "seems": 1,
            "sensible": 1,
            "determine": 1,
            "much": 1,
            "memory": 2,
            "available": 1,
            "allow": 1,
            "algorithm": 2,
            "use": 1,
            "memory-bounded": 1,
            "sma": 6,
            "simplified": 1,
            "is—well—simpler": 1,
            "describe": 1,
            "proceeds": 1,
            "expanding": 1,
            "best": 2,
            "leaf": 2,
            "full": 1,
            "point": 1,
            "add": 1,
            "new": 1,
            "node": 2,
            "search": 1,
            "tree": 1,
            "dropping": 1,
            "old": 1,
            "drop": 1,
            "worst": 1,
            "highest": 1,
            "-value": 1,
            "rbfs": 1,
            "back": 1,
            "value": 1,
            "forgotten": 4,
            "parent": 1,
            "way": 3,
            "ancestor": 1,
            "subtree": 3,
            "know": 2,
            "quality": 1,
            "path": 3,
            "information": 1,
            "regenerates": 1,
            "shown": 1,
            "look": 1,
            "worse": 1,
            "saying": 1,
            "descendant": 1,
            "idea": 1,
            "worthwhile": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para283",
              "entity_text": "MA",
              "entity_type": "PERSON",
              "start_char": 151,
              "end_char": 153,
              "context": "to use all of it. Two algorithms that do this are\nMA\n* (memory-bounded A*) and\nSMA\n* (simplified MA*)."
            },
            {
              "para_id": "chap3_para283",
              "entity_text": "MA*",
              "entity_type": "PERSON",
              "start_char": 198,
              "end_char": 201,
              "context": "re\nMA\n* (memory-bounded A*) and\nSMA\n* (simplified MA*). SMA* is—well—simpler, so we will describe it. S"
            },
            {
              "para_id": "chap3_para283",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 250,
              "end_char": 253,
              "context": "*). SMA* is—well—simpler, so we will describe it. SMA* proceeds just like A*, expanding the best leaf u"
            },
            {
              "para_id": "chap3_para283",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 490,
              "end_char": 494,
              "context": "leaf node—the one with the highest\nf\n-value. Like RBFS, SMA* then backs up the value of the forgotten no"
            },
            {
              "para_id": "chap3_para283",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 496,
              "end_char": 499,
              "context": "ode—the one with the highest\nf\n-value. Like RBFS, SMA* then backs up the value of the forgotten node to"
            },
            {
              "para_id": "chap3_para283",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 686,
              "end_char": 689,
              "context": "best path in that subtree. With this information, SMA* regenerates the subtree only when all other path"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para284",
          "content": "The complete algorithm is described in the online code repository accompanying this book. There is one subtlety worth mentioning. We said that SMA\n*\nexpands the best leaf and deletes the worst leaf. What if\nall\nthe leaf nodes have the same\nf\n-value? To avoid selecting the same node for deletion and expansion, SMA* expands the\nnewest\nbest leaf and deletes the\noldest\nworst leaf. These coincide when there is only one leaf, but in that case, the current search tree must be a single path from root to leaf that fills all of memory. If the leaf is not a goal node, then\neven if it is on an optimal solution path,\nthat solution is not reachable with the available memory. Therefore, the node can be discarded exactly as if it had no successors.",
          "sentence_count": 8,
          "char_count": 619,
          "prev_para_id": "chap3_para283",
          "next_para_id": "chap3_para285",
          "style_metadata": {
            "para_id": "chap3_para284",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 18.88,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 151,
            "sentence_count": 8
          },
          "terminology": {
            "complete": 1,
            "algorithm": 1,
            "described": 1,
            "online": 1,
            "code": 1,
            "repository": 1,
            "accompanying": 1,
            "book": 1,
            "subtlety": 1,
            "worth": 1,
            "mentioning": 1,
            "said": 1,
            "sma": 2,
            "expands": 2,
            "best": 2,
            "leaf": 8,
            "deletes": 2,
            "worst": 2,
            "-value": 1,
            "avoid": 1,
            "selecting": 1,
            "node": 1,
            "deletion": 1,
            "expansion": 1,
            "newest": 1,
            "oldest": 1,
            "coincide": 1,
            "case": 1,
            "current": 1,
            "search": 1,
            "tree": 1,
            "single": 1,
            "path": 2,
            "root": 1,
            "fill": 1,
            "memory": 2,
            "goal": 1,
            "optimal": 1,
            "solution": 2,
            "reachable": 1,
            "available": 1,
            "discarded": 1,
            "successor": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para284",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 143,
              "end_char": 146,
              "context": "re is one subtlety worth mentioning. We said that SMA\n*\nexpands the best leaf and deletes the worst lea"
            },
            {
              "para_id": "chap3_para284",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 311,
              "end_char": 314,
              "context": "lecting the same node for deletion and expansion, SMA* expands the\nnewest\nbest leaf and deletes the\nold"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para285",
          "content": "SMA\n*\nis complete if there is any reachable solution—that is, if\nd\n, the depth of the shallowest goal node, is less than the memory size (expressed in nodes). It is optimal if any optimal solution is reachable; otherwise, it returns the best reachable solution. In practical terms, SMA\n*\nis a fairly robust choice for finding optimal solutions, particularly when the state space is a graph, action costs are not uniform, and node generation is expensive compared to the overhead of maintaining the frontier and the reached set.",
          "sentence_count": 3,
          "char_count": 444,
          "prev_para_id": "chap3_para284",
          "next_para_id": "chap3_para286",
          "style_metadata": {
            "para_id": "chap3_para285",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 3
          },
          "terminology": {
            "sma": 2,
            "complete": 1,
            "reachable": 3,
            "depth": 1,
            "shallowest": 1,
            "goal": 1,
            "node": 3,
            "less": 1,
            "memory": 1,
            "size": 1,
            "expressed": 1,
            "optimal": 3,
            "solution": 3,
            "return": 1,
            "best": 1,
            "practical": 1,
            "term": 1,
            "robust": 1,
            "choice": 1,
            "finding": 1,
            "state": 1,
            "space": 1,
            "graph": 1,
            "action": 1,
            "cost": 1,
            "uniform": 1,
            "generation": 1,
            "expensive": 1,
            "compared": 1,
            "overhead": 1,
            "maintaining": 1,
            "frontier": 1,
            "reached": 1,
            "set": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para285",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 3,
              "context": "SMA\n*\nis complete if there is any reachable solution—"
            },
            {
              "para_id": "chap3_para285",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 102,
              "end_char": 106,
              "context": "—that is, if\nd\n, the depth of the shallowest goal node, is less than the memory size (expressed in nodes"
            },
            {
              "para_id": "chap3_para285",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 282,
              "end_char": 285,
              "context": " the best reachable solution. In practical terms, SMA\n*\nis a fairly robust choice for finding optimal s"
            },
            {
              "para_id": "chap3_para285",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 425,
              "end_char": 429,
              "context": "ace is a graph, action costs are not uniform, and node generation is expensive compared to the overhead "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para286",
          "content": "On very hard problems, however, it will often be the case that SMA* is forced to switch back and forth continually among many candidate solution paths, only a small subset of which can fit in memory. (This resembles the problem of\nthrashing\nin disk paging systems.) Then the extra time required for repeated regeneration of the same nodes means that problems that would be practically solvable by A*, given unlimited memory, become intractable for SMA*. That is to say,\nmemory limitations can make a problem intractable from the point of view of computation time.",
          "sentence_count": 4,
          "char_count": 473,
          "prev_para_id": "chap3_para285",
          "next_para_id": "chap3_para287",
          "style_metadata": {
            "para_id": "chap3_para286",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 27.25,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 109,
            "sentence_count": 4
          },
          "terminology": {
            "hard": 1,
            "problem": 4,
            "case": 1,
            "forced": 1,
            "switch": 1,
            "forth": 1,
            "many": 1,
            "candidate": 1,
            "solution": 1,
            "path": 1,
            "small": 1,
            "subset": 1,
            "fit": 1,
            "memory": 3,
            "resembles": 1,
            "thrashing": 1,
            "disk": 1,
            "paging": 1,
            "system": 1,
            "extra": 1,
            "time": 2,
            "required": 1,
            "repeated": 1,
            "regeneration": 1,
            "node": 1,
            "mean": 1,
            "solvable": 1,
            "given": 1,
            "unlimited": 1,
            "become": 1,
            "intractable": 2,
            "sma": 1,
            "say": 1,
            "limitation": 1,
            "make": 1,
            "point": 1,
            "view": 1,
            "computation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para286",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 63,
              "end_char": 66,
              "context": "problems, however, it will often be the case that SMA* is forced to switch back and forth continually a"
            },
            {
              "para_id": "chap3_para286",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 448,
              "end_char": 451,
              "context": "*, given unlimited memory, become intractable for SMA*. That is to say,\nmemory limitations can make a p"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para287",
          "content": "Although no current theory explains the tradeoff between time and memory, it seems that this is an inescapable problem. The only way out is to drop the optimality requirement.",
          "sentence_count": 2,
          "char_count": 147,
          "prev_para_id": "chap3_para286",
          "next_para_id": "chap3_para288",
          "style_metadata": {
            "para_id": "chap3_para287",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 2
          },
          "terminology": {
            "current": 1,
            "theory": 1,
            "explains": 1,
            "tradeoff": 1,
            "time": 1,
            "memory": 1,
            "seems": 1,
            "inescapable": 1,
            "problem": 1,
            "way": 1,
            "drop": 1,
            "optimality": 1,
            "requirement": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para288",
          "content": "3.5.6\nBidirectional heuristic search\nWith unidirectional best-first search, we saw that using\nf(n)\n=\ng(n)\n+\nh\n(\nn\n) as the evaluation function gives us an A* search that is guaranteed to find optimal-cost solutions (assuming an admissible\nh\n) while being optimally efficient in the number of nodes expanded.",
          "sentence_count": 1,
          "char_count": 269,
          "prev_para_id": "chap3_para287",
          "next_para_id": "chap3_para289",
          "style_metadata": {
            "para_id": "chap3_para288",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 61.0,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 1
          },
          "terminology": {
            "bidirectional": 1,
            "heuristic": 1,
            "search": 3,
            "unidirectional": 1,
            "best-first": 1,
            "saw": 1,
            "using": 1,
            "evaluation": 1,
            "function": 1,
            "give": 1,
            "guaranteed": 1,
            "find": 1,
            "optimal-cost": 1,
            "solution": 1,
            "assuming": 1,
            "admissible": 1,
            "efficient": 1,
            "number": 1,
            "node": 1,
            "expanded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para288",
              "entity_text": "f(n",
              "entity_type": "GPE",
              "start_char": 94,
              "end_char": 97,
              "context": "idirectional best-first search, we saw that using\nf(n)\n=\ng(n)\n+\nh\n(\nn\n) as the evaluation function give"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para289",
          "content": "With bidirectional best-first search we could also try using\nf\n(\nn\n) =\ng\n(\nn\n) +\nh\n(\nn\n), but unfortunately there is no guarantee that this would lead to an optimal-cost solution, nor that it would be optimally efficient, even with an admissible heuristic. With bidirectional search, it turns out that it is not individual nodes but rather\npairs\nof nodes (one from each frontier) that can be proved to be surely expanded, so any proof of efficiency will have to consider pairs of nodes (Eckerle\net al.,\n2017).",
          "sentence_count": 2,
          "char_count": 432,
          "prev_para_id": "chap3_para288",
          "next_para_id": "chap3_para290",
          "style_metadata": {
            "para_id": "chap3_para289",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 53.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 2
          },
          "terminology": {
            "bidirectional": 2,
            "best-first": 1,
            "search": 2,
            "try": 1,
            "using": 1,
            "unfortunately": 1,
            "guarantee": 1,
            "lead": 1,
            "optimal-cost": 1,
            "solution": 1,
            "efficient": 1,
            "admissible": 1,
            "heuristic": 1,
            "turn": 1,
            "individual": 1,
            "pair": 2,
            "frontier": 1,
            "proved": 1,
            "expanded": 1,
            "proof": 1,
            "efficiency": 1,
            "consider": 1,
            "eckerle": 1,
            "al.": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para289",
              "entity_text": "Eckerle",
              "entity_type": "GPE",
              "start_char": 487,
              "end_char": 494,
              "context": " efficiency will have to consider pairs of nodes (Eckerle\net al.,\n2017)."
            },
            {
              "para_id": "chap3_para289",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 498,
              "end_char": 501,
              "context": " will have to consider pairs of nodes (Eckerle\net al.,\n2017)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para290",
          "content": "We’ll start with some new notation. We use\nf\nF\n(\nn\n) =\ng\nF\n(\nn\n)+\nh\nF\n(\nn\n) for nodes going in the forward direction (with the initial state as root) and\nf\nB\n(\nn\n) =\ng\nB\n(\nn\n) +\nh\nB\n(\nn\n) for nodes in the backward direction (with a goal state as root). Although both forward and backward searches are solving the same problem, they have different evaluation functions because, for example, the heuristics are different depending on whether you are striving for the goal or for the initial state. We’ll assume admissible heuristics.",
          "sentence_count": 4,
          "char_count": 454,
          "prev_para_id": "chap3_para289",
          "next_para_id": "chap3_para291",
          "style_metadata": {
            "para_id": "chap3_para290",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 124,
            "sentence_count": 4
          },
          "terminology": {
            "start": 1,
            "new": 1,
            "notation": 1,
            "use": 1,
            "node": 2,
            "going": 1,
            "forward": 1,
            "direction": 2,
            "initial": 2,
            "state": 3,
            "root": 2,
            "backward": 2,
            "goal": 2,
            "search": 1,
            "solving": 1,
            "problem": 1,
            "different": 2,
            "evaluation": 1,
            "function": 1,
            "example": 1,
            "heuristic": 2,
            "depending": 1,
            "striving": 1,
            "assume": 1,
            "admissible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para290",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 45,
              "end_char": 46,
              "context": "We’ll start with some new notation. We use\nf\nF\n(\nn\n) =\ng\nF\n(\nn\n)+\nh\nF\n(\nn\n) for nodes going in t"
            },
            {
              "para_id": "chap3_para290",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 68,
              "end_char": 69,
              "context": "ome new notation. We use\nf\nF\n(\nn\n) =\ng\nF\n(\nn\n)+\nh\nF\n(\nn\n) for nodes going in the forward direction (w"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para291",
          "content": "Consider a forward path from the initial state to a node\nm\nand a backward path from the goal to a node\nn\n. We can define a lower bound on the cost of a solution that follows the path from the initial state to\nm\n, then somehow gets to\nn\n, then follows the path to the goal as\nl\nb\n(\nm\n,\nn\n) = max (\ng\nF\n(\nm\n) +\ng\nB\n(\nn\n),\nf\nF\n(\nm\n),\nf\nB\n(\nn\n))\nIn other words, the cost of such a path must be at least as large as the sum of the path costs of the two parts (because the remaining connection between them must have nonnegative cost), and the cost must also be at least as much as the estimated\nf\ncost of either part (because the heuristic estimates are optimistic). Given that, the theorem is that for any pair of nodes\nm\n,\nn\nwith\nlb(m, n)\nless than the optimal cost\nC\n*, we must expand either\nm\nor\nn\n, because the path that goes through both of them is a potential optimal solution. The difficulty is that we don’t know for sure which node is best to expand, and therefore no bidirectional search algorithm can be guaranteed to be optimally efficient—any algorithm might expand up to twice the minimum number of nodes if it always chooses the wrong member of a pair to expand first. Some bidirectional heuristic search algorithms explicitly manage a queue of (\nm\n,\nn\n) pairs, but we will stick with bidirectional best-first search (\nFigure 3.14\n), which has two frontier priority queues, and give it an evaluation function that mimics the\nlb\ncriteria:\nf\n2\n(\nn\n) = max (2\ng\n(\nn\n),\ng\n(\nn\n) +\nh\n(\nn\n))\nThe node to expand next will be the one that minimizes this\nf\n2\nvalue; the node can come from either frontier. This\nf\n2\nfunction guarantees that we will never expand a node (from either frontier) with\ng\n(\nn\n) >\nC\n*\n2\n. We say the two halves of the search “meet in the middle” in the sense that when the two frontiers touch, no node inside of either frontier has a path cost greater than the bound\nC\n*\n2\n.",
          "sentence_count": 7,
          "char_count": 1601,
          "prev_para_id": "chap3_para290",
          "next_para_id": "chap3_para292",
          "style_metadata": {
            "para_id": "chap3_para291",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 62.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 437,
            "sentence_count": 7
          },
          "terminology": {
            "consider": 1,
            "forward": 1,
            "path": 8,
            "initial": 2,
            "state": 2,
            "node": 8,
            "backward": 1,
            "goal": 2,
            "define": 1,
            "bound": 2,
            "cost": 8,
            "solution": 2,
            "follows": 2,
            "somehow": 1,
            "get": 1,
            "max": 2,
            "word": 1,
            "least": 2,
            "large": 1,
            "sum": 1,
            "part": 2,
            "remaining": 1,
            "connection": 1,
            "nonnegative": 1,
            "estimated": 1,
            "heuristic": 2,
            "estimate": 1,
            "optimistic": 1,
            "given": 1,
            "theorem": 1,
            "pair": 3,
            "optimal": 2,
            "expand": 6,
            "go": 1,
            "potential": 1,
            "difficulty": 1,
            "know": 1,
            "sure": 1,
            "best": 1,
            "bidirectional": 3,
            "search": 4,
            "algorithm": 3,
            "guaranteed": 1,
            "efficient—any": 1,
            "minimum": 1,
            "number": 1,
            "chooses": 1,
            "wrong": 1,
            "member": 1,
            "first": 1,
            "manage": 1,
            "queue": 2,
            "stick": 1,
            "best-first": 1,
            "figure": 1,
            "frontier": 5,
            "priority": 1,
            "give": 1,
            "evaluation": 1,
            "function": 2,
            "mimic": 1,
            "criterion": 1,
            "minimizes": 1,
            "value": 1,
            "come": 1,
            "guarantee": 1,
            "say": 1,
            "half": 1,
            "meet": 1,
            "middle": 1,
            "sense": 1,
            "touch": 1,
            "greater": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para291",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 52,
              "end_char": 56,
              "context": "nsider a forward path from the initial state to a node\nm\nand a backward path from the goal to a node\nn\n."
            },
            {
              "para_id": "chap3_para291",
              "entity_text": "max",
              "entity_type": "PERSON",
              "start_char": 291,
              "end_char": 294,
              "context": "n follows the path to the goal as\nl\nb\n(\nm\n,\nn\n) = max (\ng\nF\n(\nm\n) +\ng\nB\n(\nn\n),\nf\nF\n(\nm\n),\nf\nB\n(\nn\n))\nIn"
            },
            {
              "para_id": "chap3_para291",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 322,
              "end_char": 323,
              "context": "as\nl\nb\n(\nm\n,\nn\n) = max (\ng\nF\n(\nm\n) +\ng\nB\n(\nn\n),\nf\nF\n(\nm\n),\nf\nB\n(\nn\n))\nIn other words, the cost of suc"
            },
            {
              "para_id": "chap3_para291",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 932,
              "end_char": 936,
              "context": "e difficulty is that we don’t know for sure which node is best to expand, and therefore no bidirectional"
            },
            {
              "para_id": "chap3_para291",
              "entity_text": "max",
              "entity_type": "PERSON",
              "start_char": 1461,
              "end_char": 1464,
              "context": "function that mimics the\nlb\ncriteria:\nf\n2\n(\nn\n) = max (2\ng\n(\nn\n),\ng\n(\nn\n) +\nh\n(\nn\n))\nThe node to expand"
            },
            {
              "para_id": "chap3_para291",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 1571,
              "end_char": 1575,
              "context": "ill be the one that minimizes this\nf\n2\nvalue; the node can come from either frontier. This\nf\n2\nfunction "
            },
            {
              "para_id": "chap3_para291",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 1664,
              "end_char": 1668,
              "context": "2\nfunction guarantees that we will never expand a node (from either frontier) with\ng\n(\nn\n) >\nC\n*\n2\n. We "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para292",
          "content": "Figure 3.24\nworks through an example bidirectional search.",
          "sentence_count": 1,
          "char_count": 52,
          "prev_para_id": "chap3_para291",
          "next_para_id": "chap3_para293",
          "style_metadata": {
            "para_id": "chap3_para292",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "work": 1,
            "example": 1,
            "bidirectional": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para293",
          "content": "Description\nThere are four circles in each of the two rows where the circles represent nodes. The four circles in the first row are Start, “A”, F, and Goal. The four circles in the second row are C, B, D, and E. A solid arrow from Start to “A” is labeled 4. For circle “A”, f equals 9 equals 4 plus 5 and f subscript 2 equals 10. Another solid arrow from Start to B is labeled 6. For B, f equals 8 equals 6 plus 2 and f subscript 2 equals 12. A dashed arrow from B to C is labeled 1. For C, f equals 8 equals 7 plus 1 and f subscript 2 equals 14. Another dashed arrow from B to D is labeled 1. For D, f equals 9 equals 7 plus 2 and f subscript 2 equals 14. A dashed arrow from D to E is labeled 1. For E, f equals 9 equals 8 plus 1 and f subscript 2 equals 16. An arrow from Goal to F is labeled 4. For node F, function f equals 10 equals 6 plus 4 and f subscript 2 equals 10. A dashed double-headed arrow from node F to “A” is labeled 2.",
          "sentence_count": 15,
          "char_count": 734,
          "prev_para_id": "chap3_para292",
          "next_para_id": "chap3_para294",
          "style_metadata": {
            "para_id": "chap3_para293",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.27,
            "passive_voice_ratio": 0.031,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 229,
            "sentence_count": 15
          },
          "terminology": {
            "description": 1,
            "circle": 5,
            "row": 3,
            "represent": 1,
            "start": 3,
            "goal": 2,
            "second": 1,
            "solid": 2,
            "arrow": 7,
            "labeled": 7,
            "equal": 18,
            "subscript": 6,
            "dashed": 4,
            "node": 2,
            "function": 1,
            "double-headed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para293",
              "entity_text": "Start",
              "entity_type": "PRODUCT",
              "start_char": 132,
              "end_char": 137,
              "context": "sent nodes. The four circles in the first row are Start, “A”, F, and Goal. The four circles in the second"
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 144,
              "end_char": 145,
              "context": "The four circles in the first row are Start, “A”, F, and Goal. The four circles in the second row are"
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "Goal",
              "entity_type": "PERSON",
              "start_char": 151,
              "end_char": 155,
              "context": "r circles in the first row are Start, “A”, F, and Goal. The four circles in the second row are C, B, D, "
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "Start",
              "entity_type": "PRODUCT",
              "start_char": 231,
              "end_char": 236,
              "context": "second row are C, B, D, and E. A solid arrow from Start to “A” is labeled 4. For circle “A”, f equals 9 e"
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "Start",
              "entity_type": "ORG",
              "start_char": 355,
              "end_char": 360,
              "context": "f subscript 2 equals 10. Another solid arrow from Start to B is labeled 6. For B, f equals 8 equals 6 plu"
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "Goal",
              "entity_type": "PERSON",
              "start_char": 775,
              "end_char": 779,
              "context": "plus 1 and f subscript 2 equals 16. An arrow from Goal to F is labeled 4. For node F, function f equals "
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 783,
              "end_char": 784,
              "context": "nd f subscript 2 equals 16. An arrow from Goal to F is labeled 4. For node F, function f equals 10 eq"
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 808,
              "end_char": 809,
              "context": "6. An arrow from Goal to F is labeled 4. For node F, function f equals 10 equals 6 plus 4 and f subsc"
            },
            {
              "para_id": "chap3_para293",
              "entity_text": "node F",
              "entity_type": "PRODUCT",
              "start_char": 911,
              "end_char": 917,
              "context": "pt 2 equals 10. A dashed double-headed arrow from node F to “A” is labeled 2."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para294",
          "content": "×\nFigure 3.24\nBidirectional search maintains two frontiers: on the left, nodes A and B are successors of Start; on the right, node F is an inverse successor of Goal. Each node is labeled with\nf = g + h\nvalues and the\nf\n2\n= max(2\ng\n,\ng + h\n) value. (The\ng\nvalues are the sum of the action costs as shown on each arrow; the\nh\nvalues are arbitrary and cannot be derived from anything in the figure.) The optimal solution, Start-A-F-Goal, has cost\nC\n* = 4 + 2 + 4 = 10, so that means that a meet-in-the-middle bidirectional algorithm should not expand any node with\ng\n>\nC\n*\n2\n= 5; and indeed the next node to be expanded would be A or F (each with\ng\n=4), leading us to an optimal solution. If we expanded the node with lowest\nf\ncost first, then B and C would come next, and D and E would be tied with A, but they all have\ng\n>\nC\n*\n2\nand thus are never expanded when\nf\n2\nis the evaluation function.",
          "sentence_count": 5,
          "char_count": 739,
          "prev_para_id": "chap3_para293",
          "next_para_id": "chap3_para295",
          "style_metadata": {
            "para_id": "chap3_para294",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 43.0,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 215,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 2,
            "bidirectional": 2,
            "search": 1,
            "maintains": 1,
            "frontier": 1,
            "left": 1,
            "node": 4,
            "successor": 2,
            "start": 1,
            "right": 1,
            "inverse": 1,
            "goal": 1,
            "labeled": 1,
            "value": 4,
            "max": 1,
            "sum": 1,
            "action": 1,
            "cost": 3,
            "shown": 1,
            "arrow": 1,
            "arbitrary": 1,
            "derived": 1,
            "anything": 1,
            "optimal": 2,
            "solution": 2,
            "start-a-f-goal": 1,
            "mean": 1,
            "meet-in-the-middle": 1,
            "algorithm": 1,
            "expand": 1,
            "next": 1,
            "expanded": 3,
            "leading": 1,
            "lowest": 1,
            "come": 1,
            "tied": 1,
            "evaluation": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para294",
              "entity_text": "Start",
              "entity_type": "PRODUCT",
              "start_char": 105,
              "end_char": 110,
              "context": "ers: on the left, nodes A and B are successors of Start; on the right, node F is an inverse successor of "
            },
            {
              "para_id": "chap3_para294",
              "entity_text": "node F",
              "entity_type": "PERSON",
              "start_char": 126,
              "end_char": 132,
              "context": "es A and B are successors of Start; on the right, node F is an inverse successor of Goal. Each node is lab"
            },
            {
              "para_id": "chap3_para294",
              "entity_text": "Goal",
              "entity_type": "PERSON",
              "start_char": 160,
              "end_char": 164,
              "context": "; on the right, node F is an inverse successor of Goal. Each node is labeled with\nf = g + h\nvalues and t"
            },
            {
              "para_id": "chap3_para294",
              "entity_text": "Start-A-F-Goal",
              "entity_type": "ORG",
              "start_char": 419,
              "end_char": 433,
              "context": "om anything in the figure.) The optimal solution, Start-A-F-Goal, has cost\nC\n* = 4 + 2 + 4 = 10, so that means tha"
            },
            {
              "para_id": "chap3_para294",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 631,
              "end_char": 632,
              "context": "indeed the next node to be expanded would be A or F (each with\ng\n=4), leading us to an optimal soluti"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para295",
          "content": "We have described an approach where the\nh\nF\nheuristic estimates the distance to the goal (or, when the problem has multiple goal states, the distance to the closest goal) and\nh\nB\nestimates the distance to the start. This is called a\nfront-to-end\nsearch. An alternative, called\nfront-to-front\nsearch, attempts to estimate the distance to the other frontier. Clearly, if a frontier has millions of nodes, it would be inefficient to apply the heuristic function to every\none of them and take the minimum. But it can work to sample a few nodes from the frontier. In certain specific problem domains it is possible to\nsummarize\nthe frontier—for example, in a grid search problem, we can incrementally compute a bounding box of the frontier, and use as a heuristic the distance to the bounding box.",
          "sentence_count": 6,
          "char_count": 670,
          "prev_para_id": "chap3_para294",
          "next_para_id": "chap3_para296",
          "style_metadata": {
            "para_id": "chap3_para295",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 153,
            "sentence_count": 6
          },
          "terminology": {
            "described": 1,
            "approach": 1,
            "heuristic": 3,
            "estimate": 3,
            "distance": 5,
            "goal": 3,
            "problem": 3,
            "multiple": 1,
            "state": 1,
            "closest": 1,
            "called": 2,
            "front-to-end": 1,
            "search": 3,
            "alternative": 1,
            "front-to-front": 1,
            "attempt": 1,
            "frontier": 4,
            "million": 1,
            "node": 2,
            "inefficient": 1,
            "apply": 1,
            "function": 1,
            "take": 1,
            "minimum": 1,
            "work": 1,
            "sample": 1,
            "certain": 1,
            "specific": 1,
            "domain": 1,
            "possible": 1,
            "summarize": 1,
            "frontier—for": 1,
            "example": 1,
            "grid": 1,
            "compute": 1,
            "bounding": 2,
            "box": 2,
            "use": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para295",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 42,
              "end_char": 43,
              "context": "We have described an approach where the\nh\nF\nheuristic estimates the distance to the goal (or,"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para296",
          "content": "Bidirectional search is sometimes more efficient than unidirectional search, sometimes not. In general, if we have a very good heuristic, then A* search produces search contours that are focused on the goal, and adding bidirectional search does not help much. With an average heuristic, bidirectional search that meets in the middle tends to expand fewer nodes and is preferred. In the worst case of a poor heuristic, the search is no longer focused on the goal, and bidirectional search has the same asymptotic complexity as A*. Bidirectional search with the\nf\n2\nevaluation function and an admissible heuristic\nh\nis complete and optimal.",
          "sentence_count": 5,
          "char_count": 541,
          "prev_para_id": "chap3_para295",
          "next_para_id": "chap3_para297",
          "style_metadata": {
            "para_id": "chap3_para296",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.4,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 117,
            "sentence_count": 5
          },
          "terminology": {
            "bidirectional": 5,
            "search": 9,
            "efficient": 1,
            "unidirectional": 1,
            "general": 1,
            "good": 1,
            "heuristic": 4,
            "produce": 1,
            "contour": 1,
            "focused": 2,
            "goal": 2,
            "adding": 1,
            "help": 1,
            "much": 1,
            "average": 1,
            "meet": 1,
            "middle": 1,
            "tends": 1,
            "expand": 1,
            "fewer": 1,
            "node": 1,
            "preferred": 1,
            "worst": 1,
            "case": 1,
            "poor": 1,
            "asymptotic": 1,
            "complexity": 1,
            "evaluation": 1,
            "function": 1,
            "admissible": 1,
            "complete": 1,
            "optimal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para297",
          "content": "3.6Heuristic Functions\n3.6\nHeuristic Functions\nIn this section, we look at how the accuracy of a heuristic affects search performance, and also consider how heuristics can be invented. As our main example we’ll return to the 8-puzzle. As mentioned in\nSection 3.2\n, the object of the puzzle is to slide the tiles horizontally or vertically into the empty space until the configuration matches the goal configuration (\nFigure 3.25\n).",
          "sentence_count": 3,
          "char_count": 368,
          "prev_para_id": "chap3_para296",
          "next_para_id": "chap3_para298",
          "style_metadata": {
            "para_id": "chap3_para297",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "3.6heuristic": 1,
            "function": 2,
            "heuristic": 3,
            "section": 2,
            "look": 1,
            "accuracy": 1,
            "affect": 1,
            "search": 1,
            "performance": 1,
            "consider": 1,
            "invented": 1,
            "main": 1,
            "example": 1,
            "return": 1,
            "8-puzzle": 1,
            "mentioned": 1,
            "object": 1,
            "puzzle": 1,
            "slide": 1,
            "tile": 1,
            "empty": 1,
            "space": 1,
            "configuration": 2,
            "match": 1,
            "goal": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para297",
              "entity_text": "Heuristic Functions",
              "entity_type": "ORG",
              "start_char": 27,
              "end_char": 46,
              "context": "3.6Heuristic Functions\n3.6\nHeuristic Functions\nIn this section, we look at how the accuracy of a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para298",
          "content": "Description\nA square labeled Start state has three rows and three columns. Row 1: Column 1, 7. Column 2, 2. Column 3, 4. Row 2: Column 1, 5. Column 2, blank. Column 3, 6. Row 3: Column 1, 8. Column 2, 3. Column 3, 1. Another square labeled Goal state has three rows and three columns. Row 1: Column 1, blank. Column 2, 1. Column 3, 2. Row 2: Column 1, 3. Column 2, 4. Column 3, 5. Row 3: Column 1, 6. Column 2, 7. Column 3, 8.",
          "sentence_count": 20,
          "char_count": 339,
          "prev_para_id": "chap3_para297",
          "next_para_id": "chap3_para299",
          "style_metadata": {
            "para_id": "chap3_para298",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.9,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 118,
            "sentence_count": 20
          },
          "terminology": {
            "description": 1,
            "square": 2,
            "labeled": 2,
            "start": 1,
            "state": 2,
            "row": 8,
            "column": 20,
            "blank": 2,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para298",
              "entity_text": "Start",
              "entity_type": "PRODUCT",
              "start_char": 29,
              "end_char": 34,
              "context": "Description\nA square labeled Start state has three rows and three columns. Row 1: Co"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para299",
          "content": "×\nFigure 3.25\nA typical instance of the 8-puzzle. The shortest solution is 26 actions long.",
          "sentence_count": 2,
          "char_count": 78,
          "prev_para_id": "chap3_para298",
          "next_para_id": "chap3_para300",
          "style_metadata": {
            "para_id": "chap3_para299",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "typical": 1,
            "instance": 1,
            "8-puzzle": 1,
            "shortest": 1,
            "solution": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para300",
          "content": "There are 9!/2 = 181,400 reachable states in an 8-puzzle, so a search could easily keep them all in memory. But for the 15-puzzle, there are 16!/2 states—over 10 trillion—so to search that space we will need the help of a good admissible heuristic function. There is a long history of such heuristics for the 15-puzzle; here are two commonly used candidates:\n•\nh\n1\n= the number of misplaced tiles (blank not included). For\nFigure 3.25\n, all eight tiles are out of position, so the start state has\nh\n1\n= 8.",
          "sentence_count": 4,
          "char_count": 421,
          "prev_para_id": "chap3_para299",
          "next_para_id": "chap3_para301",
          "style_metadata": {
            "para_id": "chap3_para300",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 109,
            "sentence_count": 4
          },
          "terminology": {
            "reachable": 1,
            "state": 2,
            "8-puzzle": 1,
            "search": 2,
            "keep": 1,
            "memory": 1,
            "15-puzzle": 2,
            "states—over": 1,
            "trillion—so": 1,
            "space": 1,
            "need": 1,
            "help": 1,
            "good": 1,
            "admissible": 1,
            "heuristic": 2,
            "function": 1,
            "history": 1,
            "used": 1,
            "candidate": 1,
            "number": 1,
            "misplaced": 1,
            "tile": 2,
            "blank": 1,
            "included": 1,
            "figure": 1,
            "position": 1,
            "start": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para301",
          "content": "h\n1\nis an admissible heuristic because any tile that is out of place will require at least one move to get it to the right place.",
          "sentence_count": 1,
          "char_count": 105,
          "prev_para_id": "chap3_para300",
          "next_para_id": "chap3_para302",
          "style_metadata": {
            "para_id": "chap3_para301",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "admissible": 1,
            "heuristic": 1,
            "tile": 1,
            "place": 2,
            "require": 1,
            "least": 1,
            "move": 1,
            "get": 1,
            "right": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para302",
          "content": "•\nh\n2\n=\nthe sum of the distances of the tiles from their goal positions. Because tiles cannot move along diagonals, the distance is the sum of the horizontal and vertical distances—sometimes called the\ncity-block distance\nor\nManhattan distance\n.",
          "sentence_count": 2,
          "char_count": 213,
          "prev_para_id": "chap3_para301",
          "next_para_id": "chap3_para303",
          "style_metadata": {
            "para_id": "chap3_para302",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "sum": 2,
            "distance": 4,
            "tile": 2,
            "goal": 1,
            "position": 1,
            "move": 1,
            "diagonal": 1,
            "horizontal": 1,
            "vertical": 1,
            "distances—sometimes": 1,
            "called": 1,
            "city-block": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para302",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 225,
              "end_char": 234,
              "context": "ances—sometimes called the\ncity-block distance\nor\nManhattan distance\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para303",
          "content": "h\n2\nis also admissible because all any move can do is move one tile one step closer to the goal. Tiles 1 to 8 in the start state of\nFigure 3.25\ngive a Manhattan distance of\nh\n2\n= 3 + 1 + 2 + 2 + 2 + 3 + 3 + 2 = 18\n.",
          "sentence_count": 2,
          "char_count": 183,
          "prev_para_id": "chap3_para302",
          "next_para_id": "chap3_para304",
          "style_metadata": {
            "para_id": "chap3_para303",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 2
          },
          "terminology": {
            "admissible": 1,
            "move": 2,
            "tile": 2,
            "step": 1,
            "goal": 1,
            "start": 1,
            "state": 1,
            "figure": 1,
            "give": 1,
            "manhattan": 1,
            "distance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para303",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 151,
              "end_char": 160,
              "context": "s 1 to 8 in the start state of\nFigure 3.25\ngive a Manhattan distance of\nh\n2\n= 3 + 1 + 2 + 2 + 2 + 3 + 3 + 2 ="
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para304",
          "content": "As expected, neither of these overestimates the true solution cost, which is 26.",
          "sentence_count": 1,
          "char_count": 68,
          "prev_para_id": "chap3_para303",
          "next_para_id": "chap3_para305",
          "style_metadata": {
            "para_id": "chap3_para304",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "expected": 1,
            "overestimate": 1,
            "true": 1,
            "solution": 1,
            "cost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para305",
          "content": "3.6.1\nThe effect of heuristic accuracy on performance\nOne way to characterize the quality of a heuristic is the\neffective branching factor\nb\n*. If the total number of nodes generated by A* for a particular problem is\nN\nand the solution depth is\nd\n, then\nb\n* is the branching factor that a uniform tree of depth\nd\nwould have to have in order to contain\nN\n+ 1 nodes. Thus,\nN\n+1 = 1 +\nb\n*\n+ (\nb\n*\n)\n2\n+\n…\n+(\nb\n*\n)\nd\n.",
          "sentence_count": 3,
          "char_count": 357,
          "prev_para_id": "chap3_para304",
          "next_para_id": "chap3_para306",
          "style_metadata": {
            "para_id": "chap3_para305",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 3
          },
          "terminology": {
            "effect": 1,
            "heuristic": 2,
            "accuracy": 1,
            "performance": 1,
            "way": 1,
            "characterize": 1,
            "quality": 1,
            "effective": 1,
            "branching": 2,
            "factor": 2,
            "total": 1,
            "number": 1,
            "node": 2,
            "generated": 1,
            "particular": 1,
            "problem": 1,
            "solution": 1,
            "depth": 2,
            "uniform": 1,
            "tree": 1,
            "order": 1,
            "contain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para306",
          "content": "For example, if A* finds a solution at depth 5 using 52 nodes, then the effective branching factor is 1.92. The effective branching factor can vary across problem instances, but usually for a specific domain (such as 8-puzzles) it is fairly constant across all nontrivial problem instances. Therefore, experimental measurements of\nb*\non a small set of problems can provide a good guide to the heuristic’s overall usefulness. A well-designed heuristic would have a value of\nb\n* close to 1, allowing fairly large problems to be solved at reasonable computational cost.",
          "sentence_count": 4,
          "char_count": 479,
          "prev_para_id": "chap3_para305",
          "next_para_id": "chap3_para307",
          "style_metadata": {
            "para_id": "chap3_para306",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 106,
            "sentence_count": 4
          },
          "terminology": {
            "example": 1,
            "find": 1,
            "solution": 1,
            "depth": 1,
            "using": 1,
            "node": 1,
            "effective": 2,
            "branching": 2,
            "factor": 2,
            "vary": 1,
            "problem": 4,
            "instance": 2,
            "specific": 1,
            "domain": 1,
            "8-puzzles": 1,
            "constant": 1,
            "nontrivial": 1,
            "experimental": 1,
            "measurement": 1,
            "small": 1,
            "set": 1,
            "provide": 1,
            "good": 1,
            "guide": 1,
            "heuristic": 2,
            "overall": 1,
            "usefulness": 1,
            "well-designed": 1,
            "value": 1,
            "allowing": 1,
            "large": 1,
            "solved": 1,
            "reasonable": 1,
            "computational": 1,
            "cost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para307",
          "content": "Korf and Reid (1998) argue that a better way to characterize the effect of A* pruning with a given heuristic\nh\nis that it reduces the\neffective depth\nby a constant\nk\nh\ncompared to the true depth. This means that the total search cost is\nO\n(\nb\nd–k\nh\n) compared to\nO\n(\nb\nd\n) for an uninformed search. Their experiments on Rubik’s Cube and\nn-\npuzzle problems show that this formula gives accurate predictions for total search cost for sampled problem instances across a wide range of solution lengths—at least for solution lengths larger than\nk\nh\n.",
          "sentence_count": 3,
          "char_count": 466,
          "prev_para_id": "chap3_para306",
          "next_para_id": "chap3_para308",
          "style_metadata": {
            "para_id": "chap3_para307",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 110,
            "sentence_count": 3
          },
          "terminology": {
            "korf": 1,
            "reid": 1,
            "argue": 1,
            "better": 1,
            "way": 1,
            "characterize": 1,
            "effect": 1,
            "pruning": 1,
            "given": 1,
            "heuristic": 1,
            "reduces": 1,
            "effective": 1,
            "depth": 2,
            "constant": 1,
            "compared": 2,
            "true": 1,
            "mean": 1,
            "total": 2,
            "search": 3,
            "cost": 2,
            "d–k": 1,
            "uninformed": 1,
            "experiment": 1,
            "rubik": 1,
            "cube": 1,
            "puzzle": 1,
            "problem": 2,
            "show": 1,
            "formula": 1,
            "give": 1,
            "accurate": 1,
            "prediction": 1,
            "sampled": 1,
            "instance": 1,
            "wide": 1,
            "range": 1,
            "solution": 2,
            "lengths—at": 1,
            "least": 1,
            "length": 1,
            "larger": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para307",
              "entity_text": "Korf",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 4,
              "context": "Korf and Reid (1998) argue that a better way to charac"
            },
            {
              "para_id": "chap3_para307",
              "entity_text": "Reid",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 13,
              "context": "Korf and Reid (1998) argue that a better way to characterize th"
            },
            {
              "para_id": "chap3_para307",
              "entity_text": "Rubik’s Cube",
              "entity_type": "ORG",
              "start_char": 320,
              "end_char": 332,
              "context": "\n) for an uninformed search. Their experiments on Rubik’s Cube and\nn-\npuzzle problems show that this formula giv"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para308",
          "content": "For\nFigure 3.26\nwe generated random 8-puzzle problems and solved them with an uninformed breadth-first search and with A\n*\nsearch using both\nh\n1\nand\nh\n2\n, reporting the average number of nodes generated and the corresponding effective branching factor for each search strategy and for each solution length. The results suggest that\nh\n2\nis better than\nh\n1\n, and both are better than no heuristic at all.",
          "sentence_count": 2,
          "char_count": 347,
          "prev_para_id": "chap3_para307",
          "next_para_id": "chap3_para309",
          "style_metadata": {
            "para_id": "chap3_para308",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "generated": 2,
            "random": 1,
            "8-puzzle": 1,
            "problem": 1,
            "solved": 1,
            "uninformed": 1,
            "breadth-first": 1,
            "search": 3,
            "using": 1,
            "reporting": 1,
            "average": 1,
            "number": 1,
            "node": 1,
            "corresponding": 1,
            "effective": 1,
            "branching": 1,
            "factor": 1,
            "strategy": 1,
            "solution": 1,
            "length": 1,
            "result": 1,
            "suggest": 1,
            "heuristic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para309",
          "content": "Description\nA square labeled Start state has three rows and three columns. Row 1: Column 1, Asterisk. Column 2, 2. Column 3, 4. Row 2: Column 1, Asterisk. Column 2, blank. Column 3, Asterisk. Row 3: Column 1, Asterisk. Column 2, 3. Column 3, 1. Another square labeled Goal state has three rows and three columns. Row 1: Column 1, blank. Column 2, 1. Column 3, 2. Row 2: Column 1, 3. Column 2, 4. Column 3, Asterisk. Row 3: Column 1, Asterisk. Column 2, Asterisk. Column 3, Asterisk.",
          "sentence_count": 20,
          "char_count": 395,
          "prev_para_id": "chap3_para308",
          "next_para_id": "chap3_para310",
          "style_metadata": {
            "para_id": "chap3_para309",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 125,
            "sentence_count": 20
          },
          "terminology": {
            "description": 1,
            "square": 2,
            "labeled": 2,
            "start": 1,
            "state": 2,
            "row": 8,
            "column": 20,
            "asterisk": 8,
            "blank": 2,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para309",
              "entity_text": "Start",
              "entity_type": "PRODUCT",
              "start_char": 29,
              "end_char": 34,
              "context": "Description\nA square labeled Start state has three rows and three columns. Row 1: Co"
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 92,
              "end_char": 100,
              "context": "as three rows and three columns. Row 1: Column 1, Asterisk. Column 2, 2. Column 3, 4. Row 2: Column 1, Aster"
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 145,
              "end_char": 153,
              "context": "erisk. Column 2, 2. Column 3, 4. Row 2: Column 1, Asterisk. Column 2, blank. Column 3, Asterisk. Row 3: Colu"
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 182,
              "end_char": 190,
              "context": "2: Column 1, Asterisk. Column 2, blank. Column 3, Asterisk. Row 3: Column 1, Asterisk. Column 2, 3. Column 3"
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 209,
              "end_char": 217,
              "context": "mn 2, blank. Column 3, Asterisk. Row 3: Column 1, Asterisk. Column 2, 3. Column 3, 1. Another square labeled"
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 406,
              "end_char": 414,
              "context": " 3, 2. Row 2: Column 1, 3. Column 2, 4. Column 3, Asterisk. Row 3: Column 1, Asterisk. Column 2, Asterisk. C"
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 433,
              "end_char": 441,
              "context": "Column 2, 4. Column 3, Asterisk. Row 3: Column 1, Asterisk. Column 2, Asterisk. Column 3, Asterisk."
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 453,
              "end_char": 461,
              "context": "3, Asterisk. Row 3: Column 1, Asterisk. Column 2, Asterisk. Column 3, Asterisk."
            },
            {
              "para_id": "chap3_para309",
              "entity_text": "Asterisk",
              "entity_type": "PERSON",
              "start_char": 473,
              "end_char": 481,
              "context": "Column 1, Asterisk. Column 2, Asterisk. Column 3, Asterisk."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para310",
          "content": "×\nFigure 3.26\nComparison of the search costs and effective branching factors for 8-puzzle problems using breadth-first search, A* with\nh\n1\n(misplaced tiles), and A* with\nh\n2\n(Manhattan distance). Data are averaged over 100 puzzles for each solution length\nd\nfrom 6 to 28.",
          "sentence_count": 2,
          "char_count": 236,
          "prev_para_id": "chap3_para309",
          "next_para_id": "chap3_para311",
          "style_metadata": {
            "para_id": "chap3_para310",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 56,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "comparison": 1,
            "search": 2,
            "cost": 1,
            "effective": 1,
            "branching": 1,
            "factor": 1,
            "8-puzzle": 1,
            "problem": 1,
            "using": 1,
            "breadth-first": 1,
            "misplaced": 1,
            "tile": 1,
            "manhattan": 1,
            "distance": 1,
            "data": 1,
            "averaged": 1,
            "puzzle": 1,
            "solution": 1,
            "length": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para310",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 175,
              "end_char": 184,
              "context": ", A* with\nh\n1\n(misplaced tiles), and A* with\nh\n2\n(Manhattan distance). Data are averaged over 100 puzzles for"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para311",
          "content": "One might ask whether\nh\n2\nis\nalways\nbetter than\nh\n1\n. The answer is “Essentially, yes.” It is easy to see from the definitions of the two heuristics that for any node\nn, h\n2\n(\nn\n) ≥\nh\n1\n(\nn\n). We thus say that\nh\n2\ndominates\nh\n1\n. Domination translates directly into efficiency: A* using\nh\n2\nwill never expand more nodes than A* using\nh\n1\n(except in the case of breaking ties unluckily). The argument is simple. Recall the observation on\npage 108\nthat every node with\nf\n(\nn\n) <\nC\n* will surely be expanded. This is the same as saying that every node with\nh(n) < C* – g(n)\nis surely expanded when\nh\nis consistent. But because\nh\n2\nis at least as big as\nh\n1\nfor all nodes, every node that is surely expanded by A* search with\nh\n2\nis also surely expanded with\nh\n1\n, and\nh\n1\nmight cause other nodes to be expanded as well. Hence, it is generally better to use a heuristic function with higher values, provided it is consistent and that the computation time for the heuristic is not too long.",
          "sentence_count": 9,
          "char_count": 837,
          "prev_para_id": "chap3_para310",
          "next_para_id": "chap3_para312",
          "style_metadata": {
            "para_id": "chap3_para311",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.89,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 233,
            "sentence_count": 9
          },
          "terminology": {
            "ask": 1,
            "better": 2,
            "answer": 1,
            "yes.": 1,
            "easy": 1,
            "see": 1,
            "definition": 1,
            "heuristic": 3,
            "node": 7,
            "say": 1,
            "dominates": 1,
            "domination": 1,
            "translates": 1,
            "efficiency": 1,
            "using": 2,
            "expand": 1,
            "case": 1,
            "breaking": 1,
            "tie": 1,
            "argument": 1,
            "simple": 1,
            "recall": 1,
            "observation": 1,
            "page": 1,
            "expanded": 5,
            "saying": 1,
            "consistent": 2,
            "least": 1,
            "big": 1,
            "search": 1,
            "cause": 1,
            "use": 1,
            "function": 1,
            "higher": 1,
            "value": 1,
            "provided": 1,
            "computation": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para311",
              "entity_text": "≥",
              "entity_type": "PERSON",
              "start_char": 180,
              "end_char": 181,
              "context": "the two heuristics that for any node\nn, h\n2\n(\nn\n) ≥\nh\n1\n(\nn\n). We thus say that\nh\n2\ndominates\nh\n1\n. D"
            },
            {
              "para_id": "chap3_para311",
              "entity_text": "h(n",
              "entity_type": "PERSON",
              "start_char": 554,
              "end_char": 557,
              "context": ". This is the same as saying that every node with\nh(n) < C* – g(n)\nis surely expanded when\nh\nis consist"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para312",
          "content": "3.6.2\nGenerating heuristics from relaxed problems\nWe have seen that both\nh\n1\n(misplaced tiles) and\nh\n2\n(Manhattan distance) are fairly good heuristics for the 8-puzzle and that\nh\n2\nis better. How might one have come up with\nh\n2\n? Is it possible for a computer to invent such a heuristic mechanically?",
          "sentence_count": 3,
          "char_count": 260,
          "prev_para_id": "chap3_para311",
          "next_para_id": "chap3_para313",
          "style_metadata": {
            "para_id": "chap3_para312",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 3
          },
          "terminology": {
            "generating": 1,
            "heuristic": 3,
            "relaxed": 1,
            "problem": 1,
            "seen": 1,
            "misplaced": 1,
            "tile": 1,
            "distance": 1,
            "good": 1,
            "8-puzzle": 1,
            "better": 1,
            "come": 1,
            "possible": 1,
            "computer": 1,
            "invent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para312",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 104,
              "end_char": 113,
              "context": "ave seen that both\nh\n1\n(misplaced tiles) and\nh\n2\n(Manhattan distance) are fairly good heuristics for the 8-pu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para313",
          "content": "h\n1\nand\nh\n2\nare estimates of the remaining path length for the 8-puzzle, but they are also perfectly accurate path lengths for\nsimplified\nversions of the puzzle. If the rules of the puzzle were changed so that a tile could move anywhere instead of just to the adjacent empty square, then\nh\n1\nwould give the exact length of the shortest solution. Similarly, if a tile could move one square in any direction, even onto an occupied square, then\nh\n2\nwould give the exact length of the shortest solution. A problem with fewer restrictions on the actions is called a\nrelaxed problem\n. The state-space graph of the relaxed problem is a\nsupergraph\nof the original state space because the removal of restrictions creates added edges in the graph.",
          "sentence_count": 5,
          "char_count": 623,
          "prev_para_id": "chap3_para312",
          "next_para_id": "chap3_para314",
          "style_metadata": {
            "para_id": "chap3_para313",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.2,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 141,
            "sentence_count": 5
          },
          "terminology": {
            "estimate": 1,
            "remaining": 1,
            "path": 2,
            "length": 4,
            "accurate": 1,
            "simplified": 1,
            "version": 1,
            "puzzle": 2,
            "rule": 1,
            "changed": 1,
            "tile": 2,
            "move": 2,
            "adjacent": 1,
            "empty": 1,
            "square": 3,
            "give": 2,
            "exact": 2,
            "shortest": 2,
            "solution": 2,
            "direction": 1,
            "occupied": 1,
            "problem": 3,
            "fewer": 1,
            "restriction": 2,
            "action": 1,
            "called": 1,
            "relaxed": 2,
            "state-space": 1,
            "graph": 2,
            "supergraph": 1,
            "original": 1,
            "state": 1,
            "space": 1,
            "removal": 1,
            "creates": 1,
            "added": 1,
            "edge": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para314",
          "content": "Because the relaxed problem adds edges to the state-space graph, any optimal solution in the original problem is, by definition, also a solution in the relaxed problem; but the relaxed\nproblem may have\nbetter\nsolutions if the added edges provide shortcuts. Hence,\nthe cost of an optimal solution to a relaxed problem is an admissible heuristic for the original problem.",
          "sentence_count": 2,
          "char_count": 314,
          "prev_para_id": "chap3_para313",
          "next_para_id": "chap3_para315",
          "style_metadata": {
            "para_id": "chap3_para314",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 2
          },
          "terminology": {
            "relaxed": 4,
            "problem": 6,
            "add": 1,
            "edge": 2,
            "state-space": 1,
            "graph": 1,
            "optimal": 2,
            "solution": 4,
            "original": 2,
            "definition": 1,
            "better": 1,
            "added": 1,
            "provide": 1,
            "shortcut": 1,
            "cost": 1,
            "admissible": 1,
            "heuristic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para315",
          "content": "Furthermore, because the derived heuristic is an exact cost for the relaxed problem, it must obey the triangle inequality and is therefore consistent (see\npage 106\n).",
          "sentence_count": 1,
          "char_count": 142,
          "prev_para_id": "chap3_para314",
          "next_para_id": "chap3_para316",
          "style_metadata": {
            "para_id": "chap3_para315",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 9.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore",
              "furthermore"
            ],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "derived": 1,
            "heuristic": 1,
            "exact": 1,
            "cost": 1,
            "relaxed": 1,
            "problem": 1,
            "obey": 1,
            "triangle": 1,
            "inequality": 1,
            "consistent": 1,
            "see": 1,
            "page": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para316",
          "content": "If a problem definition is written down in a formal language, it is possible to construct relaxed problems automatically.",
          "sentence_count": 1,
          "char_count": 103,
          "prev_para_id": "chap3_para315",
          "next_para_id": "chap3_para317",
          "style_metadata": {
            "para_id": "chap3_para316",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "problem": 2,
            "definition": 1,
            "written": 1,
            "formal": 1,
            "language": 1,
            "possible": 1,
            "construct": 1,
            "relaxed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para317",
          "content": "14\nFor example, if the 8-puzzle actions are described as\nA tile can move from square X to square Y if\nX is adjacent to Y\nand\nY is blank,\nwe can generate three relaxed problems by removing one or both of the conditions:\n(a) A tile can move from square X to square Y if X is adjacent to Y.",
          "sentence_count": 1,
          "char_count": 234,
          "prev_para_id": "chap3_para316",
          "next_para_id": "chap3_para318",
          "style_metadata": {
            "para_id": "chap3_para317",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 67.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 1
          },
          "terminology": {
            "example": 1,
            "8-puzzle": 1,
            "action": 1,
            "described": 1,
            "tile": 1,
            "move": 2,
            "square": 4,
            "adjacent": 2,
            "blank": 1,
            "generate": 1,
            "relaxed": 1,
            "problem": 1,
            "removing": 1,
            "condition": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para318",
          "content": "(b) A tile can move from square X to square Y if Y is blank.",
          "sentence_count": 1,
          "char_count": 46,
          "prev_para_id": "chap3_para317",
          "next_para_id": "chap3_para319",
          "style_metadata": {
            "para_id": "chap3_para318",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "tile": 1,
            "move": 1,
            "square": 2,
            "blank": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para319",
          "content": "(c) A tile can move from square X to square Y.",
          "sentence_count": 1,
          "char_count": 36,
          "prev_para_id": "chap3_para318",
          "next_para_id": "chap3_para320",
          "style_metadata": {
            "para_id": "chap3_para319",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "tile": 1,
            "move": 1,
            "square": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para320",
          "content": "From (a), we can derive\nh\n2\n(Manhattan distance). The reasoning is that\nh\n2\nwould be the proper score if we moved each tile in turn to its destination. The heuristic derived from (b) is discussed in Exercise\n3.",
          "sentence_count": 3,
          "char_count": 178,
          "prev_para_id": "chap3_para319",
          "next_para_id": "chap3_para321",
          "style_metadata": {
            "para_id": "chap3_para320",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.67,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 3
          },
          "terminology": {
            "derive": 1,
            "manhattan": 1,
            "distance": 1,
            "reasoning": 1,
            "proper": 1,
            "score": 1,
            "moved": 1,
            "tile": 1,
            "turn": 1,
            "destination": 1,
            "heuristic": 1,
            "derived": 1,
            "discussed": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para320",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 29,
              "end_char": 38,
              "context": "From (a), we can derive\nh\n2\n(Manhattan distance). The reasoning is that\nh\n2\nwould be the"
            },
            {
              "para_id": "chap3_para320",
              "entity_text": "Exercise",
              "entity_type": "PRODUCT",
              "start_char": 199,
              "end_char": 207,
              "context": "n. The heuristic derived from (b) is discussed in Exercise\n3."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para321",
          "content": "GASC\n. From (c), we can derive\nh\n1\n(misplaced tiles) because it would be the proper score if tiles could move to their intended destination in one action. Notice that it is crucial that the relaxed problems generated by this technique can be solved essentially\nwithout search\n, because the relaxed rules allow the problem to be decomposed into eight independent subproblems. If the relaxed problem is hard to solve, then the values of the corresponding heuristic will be expensive to obtain.",
          "sentence_count": 4,
          "char_count": 415,
          "prev_para_id": "chap3_para320",
          "next_para_id": "chap3_para322",
          "style_metadata": {
            "para_id": "chap3_para321",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 92,
            "sentence_count": 4
          },
          "terminology": {
            "gasc": 1,
            "derive": 1,
            "misplaced": 1,
            "tile": 2,
            "proper": 1,
            "score": 1,
            "move": 1,
            "intended": 1,
            "destination": 1,
            "action": 1,
            "notice": 1,
            "crucial": 1,
            "relaxed": 3,
            "problem": 3,
            "generated": 1,
            "technique": 1,
            "solved": 1,
            "search": 1,
            "rule": 1,
            "allow": 1,
            "decomposed": 1,
            "independent": 1,
            "subproblems": 1,
            "hard": 1,
            "solve": 1,
            "value": 1,
            "corresponding": 1,
            "heuristic": 1,
            "expensive": 1,
            "obtain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para322",
          "content": "A program called A\nBSOLVER\ncan generate heuristics automatically from problem definitions, using the “relaxed problem” method and various other techniques (Prieditis, 1993). A\nBSOLVER\ngenerated a new heuristic for the 8-puzzle that was better than any preexisting heuristic and found the first useful heuristic for the famous Rubik’s Cube puzzle.",
          "sentence_count": 2,
          "char_count": 300,
          "prev_para_id": "chap3_para321",
          "next_para_id": "chap3_para323",
          "style_metadata": {
            "para_id": "chap3_para322",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 2
          },
          "terminology": {
            "program": 1,
            "called": 1,
            "generate": 1,
            "heuristic": 4,
            "problem": 2,
            "definition": 1,
            "using": 1,
            "relaxed": 1,
            "method": 1,
            "various": 1,
            "technique": 1,
            "prieditis": 1,
            "generated": 1,
            "new": 1,
            "8-puzzle": 1,
            "preexisting": 1,
            "found": 1,
            "useful": 1,
            "famous": 1,
            "rubik": 1,
            "cube": 1,
            "puzzle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para322",
              "entity_text": "Prieditis",
              "entity_type": "PERSON",
              "start_char": 156,
              "end_char": 165,
              "context": "xed problem” method and various other techniques (Prieditis, 1993). A\nBSOLVER\ngenerated a new heuristic for t"
            },
            {
              "para_id": "chap3_para322",
              "entity_text": "Rubik’s Cube",
              "entity_type": "ORG",
              "start_char": 326,
              "end_char": 338,
              "context": "d found the first useful heuristic for the famous Rubik’s Cube puzzle."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para323",
          "content": "If a collection of admissible heuristics\nh\n1\n...",
          "sentence_count": 1,
          "char_count": 43,
          "prev_para_id": "chap3_para322",
          "next_para_id": "chap3_para324",
          "style_metadata": {
            "para_id": "chap3_para323",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "collection": 1,
            "admissible": 1,
            "heuristic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para324",
          "content": "h\nm\nis available for a problem and none of them is clearly better than the others, which should we choose? As it turns out, we can have the best of all worlds, by defining\nh(n) =\nmax{\nh\n1\n(\nn\n),...,\nh\nk\n(\nn\n)}.",
          "sentence_count": 2,
          "char_count": 177,
          "prev_para_id": "chap3_para323",
          "next_para_id": "chap3_para325",
          "style_metadata": {
            "para_id": "chap3_para324",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 2
          },
          "terminology": {
            "available": 1,
            "problem": 1,
            "none": 1,
            "others": 1,
            "choose": 1,
            "turn": 1,
            "best": 1,
            "world": 1,
            "defining": 1,
            "max": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para324",
              "entity_text": "h(n",
              "entity_type": "PERSON",
              "start_char": 172,
              "end_char": 175,
              "context": ", we can have the best of all worlds, by defining\nh(n) =\nmax{\nh\n1\n(\nn\n),...,\nh\nk\n(\nn\n)}."
            },
            {
              "para_id": "chap3_para324",
              "entity_text": "max",
              "entity_type": "PERSON",
              "start_char": 179,
              "end_char": 182,
              "context": "n have the best of all worlds, by defining\nh(n) =\nmax{\nh\n1\n(\nn\n),...,\nh\nk\n(\nn\n)}."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para325",
          "content": "This composite heuristic picks whichever function is most accurate on the node in question. Because the\nh\ni\ncomponents are admissible,\nh\nis admissible (and if\nh\ni\nare all consistent,\nh\nis consistent). Furthermore,\nh\ndominates all of its component heuristics. The only drawback is that\nh\n(\nn\n) takes longer to compute. If that is an issue, an alternative is to randomly select one of the heuristics at each evaluation, or use a machine learning algorithm to predict which heuristic will be best. Doing this can result in a heuristic that is inconsistent (even if every\nh\ni\nis consistent), but in practice it usually leads to faster problem solving.",
          "sentence_count": 6,
          "char_count": 554,
          "prev_para_id": "chap3_para324",
          "next_para_id": "chap3_para326",
          "style_metadata": {
            "para_id": "chap3_para325",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 21.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore"
            ],
            "word_count": 129,
            "sentence_count": 6
          },
          "terminology": {
            "composite": 1,
            "heuristic": 5,
            "pick": 1,
            "function": 1,
            "accurate": 1,
            "node": 1,
            "question": 1,
            "component": 2,
            "admissible": 2,
            "consistent": 3,
            "furthermore": 1,
            "dominates": 1,
            "drawback": 1,
            "take": 1,
            "longer": 1,
            "compute": 1,
            "issue": 1,
            "alternative": 1,
            "select": 1,
            "evaluation": 1,
            "use": 1,
            "machine": 1,
            "learning": 1,
            "algorithm": 1,
            "predict": 1,
            "best": 1,
            "result": 1,
            "inconsistent": 1,
            "practice": 1,
            "lead": 1,
            "problem": 1,
            "solving": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para326",
          "content": "3.6.3\nGenerating heuristics from subproblems: Pattern databases\nAdmissible heuristics can also be derived from the solution cost of a\nsubproblem\nof a given problem. For example,\nFigure 3.27\nshows a subproblem of the 8-puzzle instance in\nFigure 3.25\n. The subproblem involves getting tiles 1, 2, 3, 4, and the blank into their correct positions. Clearly, the cost of the optimal solution of this subproblem is a lower bound on\nthe cost of the complete problem. It turns out to be more accurate than Manhattan distance in some cases.",
          "sentence_count": 5,
          "char_count": 452,
          "prev_para_id": "chap3_para325",
          "next_para_id": "chap3_para327",
          "style_metadata": {
            "para_id": "chap3_para326",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 100,
            "sentence_count": 5
          },
          "terminology": {
            "generating": 1,
            "heuristic": 2,
            "subproblems": 1,
            "pattern": 1,
            "database": 1,
            "admissible": 1,
            "derived": 1,
            "solution": 2,
            "cost": 3,
            "subproblem": 4,
            "given": 1,
            "problem": 2,
            "example": 1,
            "figure": 2,
            "show": 1,
            "8-puzzle": 1,
            "instance": 1,
            "involves": 1,
            "getting": 1,
            "tile": 1,
            "blank": 1,
            "correct": 1,
            "position": 1,
            "optimal": 1,
            "lower": 1,
            "bound": 1,
            "complete": 1,
            "turn": 1,
            "accurate": 1,
            "manhattan": 1,
            "distance": 1,
            "case": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para326",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 498,
              "end_char": 507,
              "context": "te problem. It turns out to be more accurate than Manhattan distance in some cases."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para327",
          "content": "Description\nThe map shows various highways, signs, and city and place names. Two possible routes between Arad and Bucharest are shown. The first route passes through Sibiu, Rimnicu Vilcea, Pitesti, and reaches Bucharest. The distance and estimated time are displayed to be 578 kilometers and 7 hours 17 minutes, respectively. The second route passes through Lugoj, Drobeta, Pitesti, and reaches Bucharest. The estimated time is displayed to be 7 hours and 35 minutes. The first road is highlighted in blue as the selected route. A window pane to the left of the map shows the exact directions to start from Arad and reach Bucharest.",
          "sentence_count": 8,
          "char_count": 530,
          "prev_para_id": "chap3_para326",
          "next_para_id": "chap3_para328",
          "style_metadata": {
            "para_id": "chap3_para327",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.12,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "map": 2,
            "show": 2,
            "various": 1,
            "highway": 1,
            "sign": 1,
            "city": 1,
            "place": 1,
            "possible": 1,
            "route": 4,
            "arad": 1,
            "bucharest": 3,
            "shown": 1,
            "first": 1,
            "pass": 2,
            "sibiu": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "pitesti": 2,
            "reach": 3,
            "distance": 1,
            "estimated": 2,
            "time": 2,
            "displayed": 2,
            "kilometer": 1,
            "hour": 2,
            "minute": 2,
            "second": 1,
            "lugoj": 1,
            "drobeta": 1,
            "road": 1,
            "highlighted": 1,
            "selected": 1,
            "window": 1,
            "pane": 1,
            "left": 1,
            "exact": 1,
            "direction": 1,
            "start": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para327",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 105,
              "end_char": 109,
              "context": "city and place names. Two possible routes between Arad and Bucharest are shown. The first route passes t"
            },
            {
              "para_id": "chap3_para327",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 166,
              "end_char": 171,
              "context": "charest are shown. The first route passes through Sibiu, Rimnicu Vilcea, Pitesti, and reaches Bucharest. "
            },
            {
              "para_id": "chap3_para327",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 358,
              "end_char": 363,
              "context": "es, respectively. The second route passes through Lugoj, Drobeta, Pitesti, and reaches Bucharest. The est"
            },
            {
              "para_id": "chap3_para327",
              "entity_text": "Drobeta",
              "entity_type": "PERSON",
              "start_char": 365,
              "end_char": 372,
              "context": "pectively. The second route passes through Lugoj, Drobeta, Pitesti, and reaches Bucharest. The estimated ti"
            },
            {
              "para_id": "chap3_para327",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 607,
              "end_char": 611,
              "context": " the map shows the exact directions to start from Arad and reach Bucharest."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para328",
          "content": "×\nFigure 3.27\nA subproblem of the 8-puzzle instance given in\nFigure 3.25\n. The task is to get tiles 1, 2, 3, 4, and the blank into their correct positions, without worrying about what happens to the other tiles.",
          "sentence_count": 2,
          "char_count": 176,
          "prev_para_id": "chap3_para327",
          "next_para_id": "chap3_para329",
          "style_metadata": {
            "para_id": "chap3_para328",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 2,
            "subproblem": 1,
            "8-puzzle": 1,
            "instance": 1,
            "given": 1,
            "task": 1,
            "get": 1,
            "tile": 2,
            "blank": 1,
            "correct": 1,
            "position": 1,
            "worrying": 1,
            "happens": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para329",
          "content": "The idea behind\npattern databases\nis to store these exact solution costs for every possible subproblem instance—in our example, every possible configuration of the four tiles and the blank. (There will be 9 × 8 × 7 × 6 × 5 = 15,120 patterns in the database. The identities of the other four tiles are irrelevant for the purposes of solving the subproblem, but moves of those tiles do count toward the solution cost of the subproblem.) Then we compute an admissible heuristic\nh\nDB\nfor each state encountered during a search simply by looking up the corresponding subproblem configuration in the database. The database itself is constructed by searching back from the goal and recording the cost of each new pattern encountered;\n15\nthe expense of this search is amortized over subsequent problem instances, and so makes sense if we expect to be asked to solve many problems.",
          "sentence_count": 5,
          "char_count": 731,
          "prev_para_id": "chap3_para328",
          "next_para_id": "chap3_para330",
          "style_metadata": {
            "para_id": "chap3_para329",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 160,
            "sentence_count": 5
          },
          "terminology": {
            "idea": 1,
            "pattern": 3,
            "database": 4,
            "store": 1,
            "exact": 1,
            "solution": 2,
            "cost": 3,
            "possible": 2,
            "subproblem": 4,
            "instance—in": 1,
            "example": 1,
            "configuration": 2,
            "tile": 3,
            "blank": 1,
            "identity": 1,
            "irrelevant": 1,
            "purpose": 1,
            "solving": 1,
            "move": 1,
            "count": 1,
            "compute": 1,
            "admissible": 1,
            "heuristic": 1,
            "state": 1,
            "encountered": 2,
            "search": 2,
            "looking": 1,
            "corresponding": 1,
            "constructed": 1,
            "searching": 1,
            "goal": 1,
            "recording": 1,
            "new": 1,
            "expense": 1,
            "amortized": 1,
            "subsequent": 1,
            "problem": 2,
            "instance": 1,
            "make": 1,
            "sense": 1,
            "expect": 1,
            "asked": 1,
            "solve": 1,
            "many": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para330",
          "content": "The choice of tiles 1-2-3-4 to go with the blank is fairly arbitrary; we could also construct databases for 5-6-7-8, for 2-4-6-8, and so on. Each database yields an admissible heuristic, and these heuristics can be combined, as explained earlier, by taking the maximum value. A combined heuristic of this kind is much more accurate than the Manhattan distance; the number of nodes generated when solving random 15-puzzles can be reduced by a factor of 1000. However, with each additional database there are diminishing returns and increased memory and computation costs.",
          "sentence_count": 4,
          "char_count": 480,
          "prev_para_id": "chap3_para329",
          "next_para_id": "chap3_para331",
          "style_metadata": {
            "para_id": "chap3_para330",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 102,
            "sentence_count": 4
          },
          "terminology": {
            "choice": 1,
            "tile": 1,
            "1-2-3-4": 1,
            "blank": 1,
            "arbitrary": 1,
            "construct": 1,
            "database": 3,
            "5-6-7-8": 1,
            "2-4-6-8": 1,
            "yield": 1,
            "admissible": 1,
            "heuristic": 3,
            "combined": 2,
            "explained": 1,
            "taking": 1,
            "maximum": 1,
            "value": 1,
            "kind": 1,
            "much": 1,
            "accurate": 1,
            "manhattan": 1,
            "distance": 1,
            "number": 1,
            "node": 1,
            "generated": 1,
            "solving": 1,
            "random": 1,
            "15-puzzles": 1,
            "reduced": 1,
            "factor": 1,
            "additional": 1,
            "diminishing": 1,
            "return": 1,
            "increased": 1,
            "memory": 1,
            "computation": 1,
            "cost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para330",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 341,
              "end_char": 350,
              "context": "istic of this kind is much more accurate than the Manhattan distance; the number of nodes generated when solv"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para331",
          "content": "One might wonder whether the heuristics obtained from the 1-2-3-4 database and the 5-6-7-8 could be\nadded,\nsince the two subproblems seem not to overlap. Would this still give an admissible heuristic? The answer is no, because the solutions of the 1-2-3-4 subproblem and the 5-6-7-8 subproblem for a given state will almost certainly share some moves—it is unlikely that 1-2-3-4 can be moved into place without touching 5-6-7-8, and vice versa. But what if we don’t count those moves—what if we don’t abstract the other tiles to stars, but rather make them disappear? That is, we record not the total cost of solving the 1-2-3-4 subproblem, but just the number of moves involving 1-2-3-4. Then the sum of the two costs is still a lower bound on the cost of solving the entire problem. This is the idea behind\ndisjoint pattern databases\n. With such databases, it is possible to solve random 15-puzzles in a few\nmilliseconds—the number of nodes generated is reduced by a factor of 10,000 compared with the use of Manhattan distance. For 24-puzzles, a speedup of roughly a factor of a million can be obtained. Disjoint pattern databases work for sliding-tile puzzles because the problem can be divided up in such a way that each move affects only one subproblem—because only one tile is moved at a time.",
          "sentence_count": 10,
          "char_count": 1083,
          "prev_para_id": "chap3_para330",
          "next_para_id": "chap3_para332",
          "style_metadata": {
            "para_id": "chap3_para331",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.3,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 243,
            "sentence_count": 10
          },
          "terminology": {
            "wonder": 1,
            "heuristic": 2,
            "obtained": 2,
            "1-2-3-4": 4,
            "database": 4,
            "5-6-7-8": 3,
            "added": 1,
            "subproblems": 1,
            "seem": 1,
            "give": 1,
            "admissible": 1,
            "answer": 1,
            "solution": 1,
            "subproblem": 3,
            "given": 1,
            "state": 1,
            "share": 1,
            "unlikely": 1,
            "moved": 2,
            "place": 1,
            "touching": 1,
            "vice": 1,
            "versa": 1,
            "count": 1,
            "abstract": 1,
            "tile": 2,
            "star": 1,
            "make": 1,
            "disappear": 1,
            "record": 1,
            "total": 1,
            "cost": 3,
            "solving": 2,
            "number": 2,
            "move": 2,
            "involving": 1,
            "1-2-3-4.": 1,
            "sum": 1,
            "lower": 1,
            "bound": 1,
            "entire": 1,
            "problem": 2,
            "idea": 1,
            "disjoint": 2,
            "pattern": 2,
            "possible": 1,
            "solve": 1,
            "random": 1,
            "15-puzzles": 1,
            "milliseconds—the": 1,
            "node": 1,
            "generated": 1,
            "reduced": 1,
            "factor": 2,
            "compared": 1,
            "use": 1,
            "manhattan": 1,
            "distance": 1,
            "speedup": 1,
            "work": 1,
            "sliding-tile": 1,
            "puzzle": 1,
            "divided": 1,
            "way": 1,
            "affect": 1,
            "subproblem—because": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para331",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 1011,
              "end_char": 1020,
              "context": "ed by a factor of 10,000 compared with the use of Manhattan distance. For 24-puzzles, a speedup of roughly a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para332",
          "content": "3.6.4\nGenerating heuristics with landmarks\nThere are online services that host maps with tens of millions of vertices and find cost-optimal driving directions in milliseconds (\nFigure 3.28\n). How can they do that, when the best search algorithms we have considered so far are about a million times slower? There are many tricks, but the most important one is\nprecomputation\nof some optimal path costs. Although the precomputation can be time-consuming, it need only be done once, and then can be amortized over billions of user search requests.",
          "sentence_count": 4,
          "char_count": 462,
          "prev_para_id": "chap3_para331",
          "next_para_id": "chap3_para333",
          "style_metadata": {
            "para_id": "chap3_para332",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 97,
            "sentence_count": 4
          },
          "terminology": {
            "generating": 1,
            "heuristic": 1,
            "landmark": 1,
            "online": 1,
            "service": 1,
            "host": 1,
            "map": 1,
            "ten": 1,
            "million": 1,
            "vertex": 1,
            "find": 1,
            "cost-optimal": 1,
            "driving": 1,
            "direction": 1,
            "millisecond": 1,
            "figure": 1,
            "best": 1,
            "search": 2,
            "algorithm": 1,
            "considered": 1,
            "time": 1,
            "slower": 1,
            "many": 1,
            "trick": 1,
            "important": 1,
            "precomputation": 2,
            "optimal": 1,
            "path": 1,
            "cost": 1,
            "time-consuming": 1,
            "need": 1,
            "done": 1,
            "amortized": 1,
            "billion": 1,
            "user": 1,
            "request": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para333",
          "content": "Description\nThe map shows various highways, signs, and city and place names. Two possible routes between Arad and Bucharest are shown. The first route passes through Sibiu, Rimnicu Vilcea, Pitesti, and reaches Bucharest. The distance and estimated time are displayed to be 578 kilometers and 7 hours 17 minutes, respectively. The second route passes through Lugoj, Drobeta, Pitesti, and reaches Bucharest. The estimated time is displayed to be 7 hours and 35 minutes. The first road is highlighted in blue as the selected route. A window pane to the left of the map shows the exact directions to start from Arad and reach Bucharest.",
          "sentence_count": 8,
          "char_count": 530,
          "prev_para_id": "chap3_para332",
          "next_para_id": "chap3_para334",
          "style_metadata": {
            "para_id": "chap3_para333",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.12,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "map": 2,
            "show": 2,
            "various": 1,
            "highway": 1,
            "sign": 1,
            "city": 1,
            "place": 1,
            "possible": 1,
            "route": 4,
            "arad": 1,
            "bucharest": 3,
            "shown": 1,
            "first": 1,
            "pass": 2,
            "sibiu": 1,
            "rimnicu": 1,
            "vilcea": 1,
            "pitesti": 2,
            "reach": 3,
            "distance": 1,
            "estimated": 2,
            "time": 2,
            "displayed": 2,
            "kilometer": 1,
            "hour": 2,
            "minute": 2,
            "second": 1,
            "lugoj": 1,
            "drobeta": 1,
            "road": 1,
            "highlighted": 1,
            "selected": 1,
            "window": 1,
            "pane": 1,
            "left": 1,
            "exact": 1,
            "direction": 1,
            "start": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para333",
              "entity_text": "Arad",
              "entity_type": "PERSON",
              "start_char": 105,
              "end_char": 109,
              "context": "city and place names. Two possible routes between Arad and Bucharest are shown. The first route passes t"
            },
            {
              "para_id": "chap3_para333",
              "entity_text": "Sibiu",
              "entity_type": "GPE",
              "start_char": 166,
              "end_char": 171,
              "context": "charest are shown. The first route passes through Sibiu, Rimnicu Vilcea, Pitesti, and reaches Bucharest. "
            },
            {
              "para_id": "chap3_para333",
              "entity_text": "Lugoj",
              "entity_type": "ORG",
              "start_char": 358,
              "end_char": 363,
              "context": "es, respectively. The second route passes through Lugoj, Drobeta, Pitesti, and reaches Bucharest. The est"
            },
            {
              "para_id": "chap3_para333",
              "entity_text": "Drobeta",
              "entity_type": "PERSON",
              "start_char": 365,
              "end_char": 372,
              "context": "pectively. The second route passes through Lugoj, Drobeta, Pitesti, and reaches Bucharest. The estimated ti"
            },
            {
              "para_id": "chap3_para333",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 607,
              "end_char": 611,
              "context": " the map shows the exact directions to start from Arad and reach Bucharest."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para334",
          "content": "×\nFigure 3.28\nA Web service providing driving directions, computed by a search algorithm.",
          "sentence_count": 1,
          "char_count": 78,
          "prev_para_id": "chap3_para333",
          "next_para_id": "chap3_para335",
          "style_metadata": {
            "para_id": "chap3_para334",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "web": 1,
            "service": 1,
            "providing": 1,
            "driving": 1,
            "direction": 1,
            "computed": 1,
            "search": 1,
            "algorithm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para335",
          "content": "We could generate a perfect heuristic by precomputing and storing the cost of the optimal path between every pair of vertices. That would take\nO\n(|\nV|\n2\n) space, and\nO\n(|\nE\n|\n3\n) time—practical for graphs with 10 thousand vertices, but not 10 million.",
          "sentence_count": 2,
          "char_count": 215,
          "prev_para_id": "chap3_para334",
          "next_para_id": "chap3_para336",
          "style_metadata": {
            "para_id": "chap3_para335",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 2
          },
          "terminology": {
            "generate": 1,
            "perfect": 1,
            "heuristic": 1,
            "precomputing": 1,
            "storing": 1,
            "cost": 1,
            "optimal": 1,
            "path": 1,
            "pair": 1,
            "vertex": 2,
            "take": 1,
            "space": 1,
            "time—practical": 1,
            "graph": 1,
            "thousand": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para336",
          "content": "A better approach is to choose a few (perhaps 10 or 20)\nlandmark points\n16\nfrom the vertices. Then for each landmark\nL\nand for each other vertex\nv\nin the graph, we compute and store\nC\n* (\nv\n,\nL\n), the exact cost of the optimal path from\nv\nto\nL\n. (We also need\nC\n* (\nL\n,\nv\n); on an undirected graph this is the same as\nC\n* (\nv\n,\nL\n); on a directed graph—e.g., with one-way streets—we need to compute this separately.) Given the stored\nC\n* tables, we can easily create an efficient (although inadmissible) heuristic: the minimum, over all landmarks, of the cost of getting from the current node to the landmark, and then to the goal:\nh\nL\n(\nn\n)\n=\nmin\nL\n∈\nL\na\nn\nd\nm\na\nr\nk\ns\nC\n*\n(\nn\n,\nL\n)\n+\nC\n*\n(\nL\n,\ng\no\na\nl\n)\nIf the optimal path happens to go through a landmark, this heuristic will be exact; if not it is inadmissible—it overestimates the cost to the goal. In an A* search, if you have exact heuristics, then once you reach a node that is on an optimal path, every node you expand\nfrom then on will be on an optimal path. Think of the contour lines as following along this optimal path. The search will trace along the optimal path, on each iteration adding an action with cost\nc\nto get to a result state whose\nh\n-value will be\nc\nless, meaning that the total\nf = g\n+\nh\nscore will remain constant at\nC*\nall along the path.",
          "sentence_count": 7,
          "char_count": 1115,
          "prev_para_id": "chap3_para335",
          "next_para_id": "chap3_para337",
          "style_metadata": {
            "para_id": "chap3_para336",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 318,
            "sentence_count": 7
          },
          "terminology": {
            "better": 1,
            "approach": 1,
            "choose": 1,
            "landmark": 5,
            "point": 1,
            "vertex": 2,
            "graph": 2,
            "compute": 2,
            "store": 1,
            "exact": 3,
            "cost": 4,
            "optimal": 6,
            "path": 7,
            "undirected": 1,
            "directed": 1,
            "graph—e.g.": 1,
            "one-way": 1,
            "streets—we": 1,
            "need": 1,
            "given": 1,
            "stored": 1,
            "table": 1,
            "create": 1,
            "efficient": 1,
            "inadmissible": 1,
            "heuristic": 3,
            "minimum": 1,
            "getting": 1,
            "current": 1,
            "node": 3,
            "goal": 2,
            "min": 1,
            "happens": 1,
            "inadmissible—it": 1,
            "overestimate": 1,
            "search": 2,
            "reach": 1,
            "expand": 1,
            "think": 1,
            "contour": 1,
            "line": 1,
            "following": 1,
            "trace": 1,
            "iteration": 1,
            "adding": 1,
            "action": 1,
            "get": 1,
            "result": 1,
            "state": 1,
            "-value": 1,
            "meaning": 1,
            "total": 1,
            "score": 1,
            "remain": 1,
            "constant": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para336",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 924,
              "end_char": 928,
              "context": " you have exact heuristics, then once you reach a node that is on an optimal path, every node you expand"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para337",
          "content": "Some route-finding algorithms save even more time by adding\nshortcuts\n—artificial edges in the graph that define an optimal multi-action path. For example, if there were shortcuts predefined between all the 100 biggest cities in the U.S., and we were trying to navigate from the Berkeley campus in California to NYU in New York, we could take the shortcut between Sacramento and Manhattan and cover 90% of the path in one action.",
          "sentence_count": 2,
          "char_count": 360,
          "prev_para_id": "chap3_para336",
          "next_para_id": "chap3_para338",
          "style_metadata": {
            "para_id": "chap3_para337",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 2
          },
          "terminology": {
            "route-finding": 1,
            "algorithm": 1,
            "save": 1,
            "time": 1,
            "adding": 1,
            "shortcut": 3,
            "—artificial": 1,
            "edge": 1,
            "graph": 1,
            "define": 1,
            "optimal": 1,
            "multi-action": 1,
            "path": 2,
            "example": 1,
            "predefined": 1,
            "biggest": 1,
            "city": 1,
            "u.s.": 1,
            "trying": 1,
            "navigate": 1,
            "berkeley": 1,
            "campus": 1,
            "california": 1,
            "nyu": 1,
            "new": 1,
            "york": 1,
            "take": 1,
            "sacramento": 1,
            "manhattan": 1,
            "cover": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para337",
              "entity_text": "U.S.",
              "entity_type": "GPE",
              "start_char": 233,
              "end_char": 237,
              "context": "defined between all the 100 biggest cities in the U.S., and we were trying to navigate from the Berkeley"
            },
            {
              "para_id": "chap3_para337",
              "entity_text": "Berkeley",
              "entity_type": "ORG",
              "start_char": 279,
              "end_char": 287,
              "context": "the U.S., and we were trying to navigate from the Berkeley campus in California to NYU in New York, we could"
            },
            {
              "para_id": "chap3_para337",
              "entity_text": "California",
              "entity_type": "GPE",
              "start_char": 298,
              "end_char": 308,
              "context": "re trying to navigate from the Berkeley campus in California to NYU in New York, we could take the shortcut be"
            },
            {
              "para_id": "chap3_para337",
              "entity_text": "NYU",
              "entity_type": "ORG",
              "start_char": 312,
              "end_char": 315,
              "context": "avigate from the Berkeley campus in California to NYU in New York, we could take the shortcut between S"
            },
            {
              "para_id": "chap3_para337",
              "entity_text": "New York",
              "entity_type": "GPE",
              "start_char": 319,
              "end_char": 327,
              "context": " from the Berkeley campus in California to NYU in New York, we could take the shortcut between Sacramento an"
            },
            {
              "para_id": "chap3_para337",
              "entity_text": "Sacramento",
              "entity_type": "GPE",
              "start_char": 364,
              "end_char": 374,
              "context": "U in New York, we could take the shortcut between Sacramento and Manhattan and cover 90% of the path in one ac"
            },
            {
              "para_id": "chap3_para337",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 379,
              "end_char": 388,
              "context": "we could take the shortcut between Sacramento and Manhattan and cover 90% of the path in one action."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para338",
          "content": "h\nL\n(\nn\n) is efficient but not admissible. But with a bit more care, we can come up with a heuristic that is both efficient and admissible:\nh\nD\nH\n(\nn\n) =\nmin\nL\n∈\nL\na\nn\nd\nm\na\nr\nk\ns\n|\nC\n*\n(\nn\n,\nL\n)\n−\nC\n*\n(\ng\no\na\nl\n,\nL\n) |\nThis is called a\ndifferential heuristic\n(because of the subtraction). Think of this with a landmark that is somewhere out beyond the goal. If the goal happens to be on the optimal path from\nn\nto the landmark, then this is saying “consider the entire path from\nn\nto\nL,\nthen subtract off the last part of that path, from\ngoal\nto\nL\n, giving us the exact cost of the path from\nn\nto\ngoal\n” To the extent that the goal is a bit off of the optimal path to the landmark, the heuristic will be inexact, but still admissible. Landmarks that are not out beyond the goal will not be useful; a landmark that is exactly halfway between\nn\nand\ngoal\nwill give\nh\nDH\n= 0, which is not helpful.",
          "sentence_count": 5,
          "char_count": 760,
          "prev_para_id": "chap3_para337",
          "next_para_id": "chap3_para339",
          "style_metadata": {
            "para_id": "chap3_para338",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 43.8,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 219,
            "sentence_count": 5
          },
          "terminology": {
            "efficient": 2,
            "admissible": 3,
            "bit": 2,
            "care": 1,
            "come": 1,
            "heuristic": 3,
            "min": 1,
            "called": 1,
            "differential": 1,
            "subtraction": 1,
            "think": 1,
            "landmark": 5,
            "goal": 7,
            "happens": 1,
            "optimal": 2,
            "path": 5,
            "saying": 1,
            "consider": 1,
            "entire": 1,
            "subtract": 1,
            "last": 1,
            "part": 1,
            "giving": 1,
            "exact": 1,
            "cost": 1,
            "extent": 1,
            "inexact": 1,
            "useful": 1,
            "give": 1,
            "helpful": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para338",
              "entity_text": "−",
              "entity_type": "GPE",
              "start_char": 196,
              "end_char": 197,
              "context": "(\nn\n) =\nmin\nL\n∈\nL\na\nn\nd\nm\na\nr\nk\ns\n|\nC\n*\n(\nn\n,\nL\n)\n−\nC\n*\n(\ng\no\na\nl\n,\nL\n) |\nThis is called a\ndifferenti"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para339",
          "content": "There are several ways to pick landmark points. Selecting points at random is fast, but we get better results if we take care to spread the landmarks out so they are not too close to each other. A greedy approach is to pick a first landmark at random, then find the point that is furthest from that, and add it to the set of landmarks, and continue, at each iteration adding the point that maximizes the distance to the nearest landmark. If you have logs of past search requests by your users, then you can pick landmarks that are frequently requested in searches. For the differential heuristic it is good if the landmarks are spread around the perimeter of the graph. Thus, a good technique is to find the centroid of the graph, arrange\nk\npie-shaped wedges around the centroid, and in each wedge select the vertex that is farthest from the center.",
          "sentence_count": 6,
          "char_count": 699,
          "prev_para_id": "chap3_para338",
          "next_para_id": "chap3_para340",
          "style_metadata": {
            "para_id": "chap3_para339",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 168,
            "sentence_count": 6
          },
          "terminology": {
            "several": 1,
            "way": 1,
            "pick": 3,
            "landmark": 7,
            "point": 4,
            "selecting": 1,
            "random": 2,
            "get": 1,
            "better": 1,
            "result": 1,
            "take": 1,
            "care": 1,
            "spread": 2,
            "greedy": 1,
            "approach": 1,
            "find": 2,
            "furthest": 1,
            "add": 1,
            "set": 1,
            "continue": 1,
            "iteration": 1,
            "adding": 1,
            "maximizes": 1,
            "distance": 1,
            "nearest": 1,
            "log": 1,
            "search": 2,
            "request": 1,
            "user": 1,
            "requested": 1,
            "differential": 1,
            "heuristic": 1,
            "good": 2,
            "perimeter": 1,
            "graph": 2,
            "technique": 1,
            "centroid": 2,
            "arrange": 1,
            "pie-shaped": 1,
            "wedge": 2,
            "select": 1,
            "vertex": 1,
            "farthest": 1,
            "center": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para340",
          "content": "Landmarks work especially well in route-finding problems because of the way roads are laid out in the world: a lot of traffic actually wants to travel between landmarks, so civil engineers build the widest and fastest roads along these routes; landmark search makes it easier to recover these routes.",
          "sentence_count": 1,
          "char_count": 252,
          "prev_para_id": "chap3_para339",
          "next_para_id": "chap3_para341",
          "style_metadata": {
            "para_id": "chap3_para340",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 53.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 1
          },
          "terminology": {
            "landmark": 3,
            "work": 1,
            "route-finding": 1,
            "problem": 1,
            "way": 1,
            "road": 2,
            "laid": 1,
            "world": 1,
            "lot": 1,
            "traffic": 1,
            "want": 1,
            "travel": 1,
            "civil": 1,
            "engineer": 1,
            "build": 1,
            "widest": 1,
            "fastest": 1,
            "route": 2,
            "search": 1,
            "make": 1,
            "easier": 1,
            "recover": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para341",
          "content": "3.6.5\nLearning to search better\nWe have presented several fixed search strategies—breadth-first, A*, and so on—that have been carefully designed and programmed by computer scientists. Could an agent\nlearn\nhow to search better? The answer is yes, and the method rests on an important concept called the\nmetalevel state space\n. Each state in a metalevel state space captures the internal (computational) state of a program that is searching in an ordinary state space such as the map of Romania. (To keep the two concepts separate, we call the map of Romania an\nobject-level state space\n.) For example, the internal state of the A* algorithm consists of the current search tree. Each action in the metalevel state space is a computation step that alters the internal\nstate; for example, each computation step in A* expands a leaf node and adds its successors to the tree. Thus,\nFigure 3.18\n, which shows a sequence of larger and larger search trees, can be seen as depicting a path in the metalevel state space where each state on the path is an object-level search tree.",
          "sentence_count": 8,
          "char_count": 898,
          "prev_para_id": "chap3_para340",
          "next_para_id": "chap3_para342",
          "style_metadata": {
            "para_id": "chap3_para341",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.62,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 205,
            "sentence_count": 8
          },
          "terminology": {
            "learning": 1,
            "search": 6,
            "presented": 1,
            "several": 1,
            "fixed": 1,
            "strategies—breadth-first": 1,
            "designed": 1,
            "programmed": 1,
            "computer": 1,
            "scientist": 1,
            "agent": 1,
            "learn": 1,
            "answer": 1,
            "method": 1,
            "rest": 1,
            "important": 1,
            "concept": 2,
            "called": 1,
            "metalevel": 4,
            "state": 11,
            "space": 6,
            "capture": 1,
            "internal": 3,
            "computational": 1,
            "program": 1,
            "searching": 1,
            "ordinary": 1,
            "map": 2,
            "romania": 2,
            "keep": 1,
            "separate": 1,
            "call": 1,
            "object-level": 2,
            "example": 2,
            "algorithm": 1,
            "consists": 1,
            "current": 1,
            "tree": 4,
            "action": 1,
            "computation": 2,
            "step": 2,
            "alters": 1,
            "expands": 1,
            "leaf": 1,
            "node": 1,
            "add": 1,
            "successor": 1,
            "figure": 1,
            "show": 1,
            "sequence": 1,
            "larger": 2,
            "seen": 1,
            "depicting": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para341",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 485,
              "end_char": 492,
              "context": "ing in an ordinary state space such as the map of Romania. (To keep the two concepts separate, we call the "
            },
            {
              "para_id": "chap3_para341",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 549,
              "end_char": 556,
              "context": "eep the two concepts separate, we call the map of Romania an\nobject-level state space\n.) For example, the i"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para342",
          "content": "Now, the path in\nFigure 3.18\nhas five steps, including one step, the expansion of Fagaras, that is not especially helpful. For harder problems, there will be many such missteps, and a\nmetalevel learning\nalgorithm can learn from these experiences to avoid exploring unpromising subtrees. The techniques used for this kind of learning are described in\nChapter 23\n. The goal of learning is to minimize the\ntotal cost\nof problem solving, trading off computational expense and path cost.",
          "sentence_count": 4,
          "char_count": 412,
          "prev_para_id": "chap3_para341",
          "next_para_id": "chap3_para343",
          "style_metadata": {
            "para_id": "chap3_para342",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 4
          },
          "terminology": {
            "path": 2,
            "figure": 1,
            "step": 2,
            "including": 1,
            "expansion": 1,
            "fagaras": 1,
            "helpful": 1,
            "harder": 1,
            "problem": 2,
            "many": 1,
            "misstep": 1,
            "metalevel": 1,
            "learning": 3,
            "algorithm": 1,
            "learn": 1,
            "experience": 1,
            "avoid": 1,
            "exploring": 1,
            "unpromising": 1,
            "subtrees": 1,
            "technique": 1,
            "used": 1,
            "kind": 1,
            "described": 1,
            "chapter": 1,
            "goal": 1,
            "minimize": 1,
            "total": 1,
            "cost": 2,
            "solving": 1,
            "trading": 1,
            "computational": 1,
            "expense": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para343",
          "content": "3.6.6\nLearning heuristics from experience\nWe have seen that one way to invent a heuristic is to devise a relaxed problem for which an optimal solution can be found easily. An alternative is to learn from experience. “Experience” here means solving lots of 8-puzzles, for instance. Each optimal solution to an 8-puzzle problem provides an example (goal, path) pair. From these examples, a learning algorithm can be used to construct a function\nh\nthat can (with luck) approximate the true path cost for other states that arise during search. Most of these approaches learn an imperfect approximation to the heuristic function, and thus risk inadmissibility. This leads to an inevitable tradeoff between learning time, search run time, and solution cost. Techniques for machine learning are demonstrated in\nChapter 19\n. The reinforcement learning methods described in\nChapter 23\nare also applicable to search.",
          "sentence_count": 9,
          "char_count": 772,
          "prev_para_id": "chap3_para342",
          "next_para_id": "chap3_para344",
          "style_metadata": {
            "para_id": "chap3_para343",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.11,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 163,
            "sentence_count": 9
          },
          "terminology": {
            "learning": 5,
            "heuristic": 3,
            "experience": 3,
            "seen": 1,
            "way": 1,
            "invent": 1,
            "devise": 1,
            "relaxed": 1,
            "problem": 2,
            "optimal": 2,
            "solution": 3,
            "found": 1,
            "alternative": 1,
            "learn": 2,
            "mean": 1,
            "solving": 1,
            "lot": 1,
            "8-puzzles": 1,
            "instance": 1,
            "8-puzzle": 1,
            "provides": 1,
            "example": 2,
            "goal": 1,
            "path": 2,
            "pair": 1,
            "algorithm": 1,
            "used": 1,
            "construct": 1,
            "function": 2,
            "luck": 1,
            "approximate": 1,
            "true": 1,
            "cost": 2,
            "state": 1,
            "arise": 1,
            "search": 3,
            "approach": 1,
            "imperfect": 1,
            "approximation": 1,
            "risk": 1,
            "inadmissibility": 1,
            "lead": 1,
            "inevitable": 1,
            "time": 2,
            "run": 1,
            "technique": 1,
            "machine": 1,
            "demonstrated": 1,
            "chapter": 2,
            "reinforcement": 1,
            "method": 1,
            "described": 1,
            "applicable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para344",
          "content": "Some machine learning techniques work better when supplied with\nfeatures\nof a state that are relevant to predicting the state’s heuristic value, rather than with just the raw state description. For example, the feature “number of misplaced tiles” might be helpful in predicting the actual distance of an 8-puzzle state from the goal. Let’s call this feature\nx\n1\n(\nn\n). We could take 100 randomly generated 8-puzzle configurations and gather statistics on their actual solution costs. We might find that when\nx\n1\n(\nn\n) is 5, the average solution cost is around 14, and so on. Of course, we can use multiple features. A second feature\nx\n2\n(\nn\n) might be “number of pairs of adjacent tiles that are not adjacent in the goal state.” How should\nx\n1\n(\nn\n) and\nx\n2\n(\nn\n) be combined to predict\nh\n(\nn\n)? A common approach is to use a linear combination:\nh\n(\nn\n) =\nc\n1\nx\n1\n(\nn\n) +\nc\n2\nx\n2\n(\nn\n)\n.",
          "sentence_count": 8,
          "char_count": 758,
          "prev_para_id": "chap3_para343",
          "next_para_id": "chap3_para345",
          "style_metadata": {
            "para_id": "chap3_para344",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.38,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 203,
            "sentence_count": 8
          },
          "terminology": {
            "machine": 1,
            "learning": 1,
            "technique": 1,
            "work": 1,
            "supplied": 1,
            "feature": 5,
            "state": 4,
            "relevant": 1,
            "predicting": 2,
            "heuristic": 1,
            "value": 1,
            "raw": 1,
            "description": 1,
            "example": 1,
            "number": 2,
            "misplaced": 1,
            "tile": 2,
            "helpful": 1,
            "actual": 2,
            "distance": 1,
            "8-puzzle": 2,
            "goal": 2,
            "let": 1,
            "call": 1,
            "take": 1,
            "generated": 1,
            "configuration": 1,
            "gather": 1,
            "statistic": 1,
            "solution": 2,
            "cost": 2,
            "find": 1,
            "average": 1,
            "course": 1,
            "use": 2,
            "multiple": 1,
            "second": 1,
            "pair": 1,
            "adjacent": 2,
            "state.": 1,
            "combined": 1,
            "predict": 1,
            "common": 1,
            "approach": 1,
            "linear": 1,
            "combination": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para345",
          "content": "The constants\nc\n1\nand\nc\n2\nare adjusted to give the best fit to the actual data across the randomly generated configurations. One expects both\nc\n1\nand\nc\n2\nto be positive because misplaced tiles and incorrect adjacent pairs make the problem harder to solve. Notice that this heuristic satisfies the condition\nh\n(\nn\n) = 0 for goal states, but it is not necessarily admissible or consistent.",
          "sentence_count": 3,
          "char_count": 333,
          "prev_para_id": "chap3_para344",
          "next_para_id": "chap3_para346",
          "style_metadata": {
            "para_id": "chap3_para345",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 3
          },
          "terminology": {
            "constant": 1,
            "adjusted": 1,
            "give": 1,
            "best": 1,
            "fit": 1,
            "actual": 1,
            "data": 1,
            "generated": 1,
            "configuration": 1,
            "expects": 1,
            "positive": 1,
            "misplaced": 1,
            "tile": 1,
            "incorrect": 1,
            "adjacent": 1,
            "pair": 1,
            "make": 1,
            "problem": 1,
            "harder": 1,
            "solve": 1,
            "heuristic": 1,
            "satisfies": 1,
            "condition": 1,
            "goal": 1,
            "state": 1,
            "admissible": 1,
            "consistent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para346",
          "content": "Summary\nSummary\nThis chapter has introduced search algorithms that an agent can use to select action sequences in a wide variety of environments—as long as they are episodic, single-agent, fully observable, deterministic, static, discrete, and completely known. There are tradeoffs to be made between the amount of time the search takes, the amount of memory available, and the quality of the solution. We can be more efficient if we have domain-dependent knowledge in the\nform of a heuristic function that estimates how far a given state is from the goal, or if we precompute partial solutions involving patterns or landmarks.",
          "sentence_count": 3,
          "char_count": 531,
          "prev_para_id": "chap3_para345",
          "next_para_id": "chap3_para347",
          "style_metadata": {
            "para_id": "chap3_para346",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 3
          },
          "terminology": {
            "summary": 2,
            "chapter": 1,
            "introduced": 1,
            "search": 2,
            "algorithm": 1,
            "agent": 1,
            "use": 1,
            "select": 1,
            "action": 1,
            "sequence": 1,
            "wide": 1,
            "variety": 1,
            "environments—as": 1,
            "long": 1,
            "episodic": 1,
            "single-agent": 1,
            "observable": 1,
            "deterministic": 1,
            "static": 1,
            "discrete": 1,
            "known": 1,
            "tradeoff": 1,
            "made": 1,
            "amount": 2,
            "time": 1,
            "take": 1,
            "memory": 1,
            "available": 1,
            "quality": 1,
            "solution": 2,
            "efficient": 1,
            "domain-dependent": 1,
            "knowledge": 1,
            "form": 1,
            "heuristic": 1,
            "function": 1,
            "estimate": 1,
            "given": 1,
            "state": 1,
            "goal": 1,
            "precompute": 1,
            "partial": 1,
            "involving": 1,
            "pattern": 1,
            "landmark": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para347",
          "content": "•\nBefore an agent can start searching, a well-defined\nproblem\nmust be formulated.",
          "sentence_count": 1,
          "char_count": 72,
          "prev_para_id": "chap3_para346",
          "next_para_id": "chap3_para348",
          "style_metadata": {
            "para_id": "chap3_para347",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "agent": 1,
            "start": 1,
            "searching": 1,
            "well-defined": 1,
            "problem": 1,
            "formulated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para348",
          "content": "•\nA problem consists of five parts: the\ninitial state\n, a set of\nactions\n, a\ntransition model\ndescribing the results of those actions, a set of\ngoal states\n, and an\naction cost function\n.",
          "sentence_count": 1,
          "char_count": 162,
          "prev_para_id": "chap3_para347",
          "next_para_id": "chap3_para349",
          "style_metadata": {
            "para_id": "chap3_para348",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 1
          },
          "terminology": {
            "problem": 1,
            "consists": 1,
            "part": 1,
            "initial": 1,
            "state": 2,
            "set": 2,
            "action": 3,
            "transition": 1,
            "model": 1,
            "describing": 1,
            "result": 1,
            "goal": 1,
            "cost": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para349",
          "content": "•\nThe environment of the problem is represented by a\nstate space graph\n. A\npath\nthrough the state space (a sequence of actions) from the initial state to a goal state is a\nsolution\n.",
          "sentence_count": 2,
          "char_count": 154,
          "prev_para_id": "chap3_para348",
          "next_para_id": "chap3_para350",
          "style_metadata": {
            "para_id": "chap3_para349",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.026,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "environment": 1,
            "problem": 1,
            "represented": 1,
            "state": 4,
            "space": 2,
            "graph": 1,
            "path": 1,
            "sequence": 1,
            "action": 1,
            "initial": 1,
            "goal": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para350",
          "content": "•\nSearch algorithms generally treat states and actions as\natomic\n, without any internal structure (although we introduced features of states when it came time to do learning).",
          "sentence_count": 1,
          "char_count": 151,
          "prev_para_id": "chap3_para349",
          "next_para_id": "chap3_para351",
          "style_metadata": {
            "para_id": "chap3_para350",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "search": 1,
            "algorithm": 1,
            "treat": 1,
            "state": 2,
            "action": 1,
            "atomic": 1,
            "internal": 1,
            "structure": 1,
            "introduced": 1,
            "feature": 1,
            "came": 1,
            "time": 1,
            "learning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para351",
          "content": "•\nSearch algorithms are judged on the basis of\ncompleteness, cost optimality, time complexity\n, and\nspace complexity\n.",
          "sentence_count": 1,
          "char_count": 105,
          "prev_para_id": "chap3_para350",
          "next_para_id": "chap3_para352",
          "style_metadata": {
            "para_id": "chap3_para351",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "search": 1,
            "algorithm": 1,
            "judged": 1,
            "basis": 1,
            "completeness": 1,
            "cost": 1,
            "optimality": 1,
            "time": 1,
            "complexity": 2,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para352",
          "content": "•\nUninformed search\nmethods have access only to the problem definition. Algorithms build a search tree in an attempt to find a solution. Algorithms differ based on which node they expand first:\n–\nBest-first search\nselects nodes for expansion using an\nevaluation function\n.",
          "sentence_count": 3,
          "char_count": 236,
          "prev_para_id": "chap3_para351",
          "next_para_id": "chap3_para353",
          "style_metadata": {
            "para_id": "chap3_para352",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 3
          },
          "terminology": {
            "uninformed": 1,
            "search": 3,
            "method": 1,
            "access": 1,
            "problem": 1,
            "definition": 1,
            "algorithm": 2,
            "build": 1,
            "tree": 1,
            "attempt": 1,
            "find": 1,
            "solution": 1,
            "differ": 1,
            "based": 1,
            "expand": 1,
            "first": 1,
            "best-first": 1,
            "selects": 1,
            "node": 1,
            "expansion": 1,
            "using": 1,
            "evaluation": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para353",
          "content": "–\nBreadth-first search\nexpands the shallowest nodes first; it is complete, optimal for unit action costs, but has exponential space complexity.",
          "sentence_count": 1,
          "char_count": 125,
          "prev_para_id": "chap3_para352",
          "next_para_id": "chap3_para354",
          "style_metadata": {
            "para_id": "chap3_para353",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "breadth-first": 1,
            "search": 1,
            "expands": 1,
            "shallowest": 1,
            "node": 1,
            "complete": 1,
            "optimal": 1,
            "unit": 1,
            "action": 1,
            "cost": 1,
            "exponential": 1,
            "space": 1,
            "complexity": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para354",
          "content": "–\nUniform-cost search\nexpands the node with lowest path cost,\ng\n(\nn\n), and is optimal for general action costs.",
          "sentence_count": 1,
          "char_count": 97,
          "prev_para_id": "chap3_para353",
          "next_para_id": "chap3_para355",
          "style_metadata": {
            "para_id": "chap3_para354",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "uniform-cost": 1,
            "search": 1,
            "expands": 1,
            "node": 1,
            "lowest": 1,
            "path": 1,
            "cost": 2,
            "optimal": 1,
            "general": 1,
            "action": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para355",
          "content": "–\nDepth-first search\nexpands the deepest unexpanded node first. It is neither complete nor optimal, but has linear space complexity.",
          "sentence_count": 2,
          "char_count": 115,
          "prev_para_id": "chap3_para354",
          "next_para_id": "chap3_para356",
          "style_metadata": {
            "para_id": "chap3_para355",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 23,
            "sentence_count": 2
          },
          "terminology": {
            "depth-first": 1,
            "search": 1,
            "expands": 1,
            "unexpanded": 1,
            "node": 1,
            "complete": 1,
            "optimal": 1,
            "linear": 1,
            "space": 1,
            "complexity": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para356",
          "content": "Depth-limited search\nadds a depth bound.",
          "sentence_count": 1,
          "char_count": 36,
          "prev_para_id": "chap3_para355",
          "next_para_id": "chap3_para357",
          "style_metadata": {
            "para_id": "chap3_para356",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 7,
            "sentence_count": 1
          },
          "terminology": {
            "depth-limited": 1,
            "search": 1,
            "add": 1,
            "bound": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para357",
          "content": "–\nIterative deepening search\ncalls depth-first search with increasing depth limits until a goal is found. It is complete when full cycle checking is done, optimal for unit action costs, has time complexity comparable to breadth-first search, and has linear space complexity.",
          "sentence_count": 2,
          "char_count": 235,
          "prev_para_id": "chap3_para356",
          "next_para_id": "chap3_para358",
          "style_metadata": {
            "para_id": "chap3_para357",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 2
          },
          "terminology": {
            "iterative": 1,
            "deepening": 1,
            "search": 3,
            "call": 1,
            "depth-first": 1,
            "increasing": 1,
            "depth": 1,
            "limit": 1,
            "goal": 1,
            "found": 1,
            "complete": 1,
            "full": 1,
            "cycle": 1,
            "checking": 1,
            "done": 1,
            "optimal": 1,
            "unit": 1,
            "action": 1,
            "cost": 1,
            "time": 1,
            "complexity": 2,
            "comparable": 1,
            "breadth-first": 1,
            "linear": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para358",
          "content": "–\nBidirectional search\nexpands two frontiers, one around the initial state and one around the goal, stopping when the two frontiers meet.",
          "sentence_count": 1,
          "char_count": 118,
          "prev_para_id": "chap3_para357",
          "next_para_id": "chap3_para359",
          "style_metadata": {
            "para_id": "chap3_para358",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "bidirectional": 1,
            "search": 1,
            "expands": 1,
            "frontier": 2,
            "initial": 1,
            "state": 1,
            "goal": 1,
            "stopping": 1,
            "meet": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para359",
          "content": "•\nInformed search\nmethods have access to a\nheuristic\nfunction\nh\n(\nn\n) that estimates the cost of a solution from\nn\n. They may have access to additional information such as pattern databases with solution costs.",
          "sentence_count": 2,
          "char_count": 183,
          "prev_para_id": "chap3_para358",
          "next_para_id": "chap3_para360",
          "style_metadata": {
            "para_id": "chap3_para359",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 2
          },
          "terminology": {
            "informed": 1,
            "search": 1,
            "method": 1,
            "access": 2,
            "heuristic": 1,
            "function": 1,
            "estimate": 1,
            "cost": 2,
            "solution": 2,
            "additional": 1,
            "information": 1,
            "pattern": 1,
            "database": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para360",
          "content": "–\nGreedy best-first search\nexpands nodes with minimal\nh\n(\nn\n). It is not optimal but is often efficient.",
          "sentence_count": 2,
          "char_count": 91,
          "prev_para_id": "chap3_para359",
          "next_para_id": "chap3_para361",
          "style_metadata": {
            "para_id": "chap3_para360",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 2
          },
          "terminology": {
            "greedy": 1,
            "best-first": 1,
            "search": 1,
            "expands": 1,
            "node": 1,
            "minimal": 1,
            "optimal": 1,
            "efficient": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para361",
          "content": "–\nA\n*\nsearch\nexpands nodes with minimal\nf\n(\nn\n) =\ng\n(\nn\n) +\nh\n(\nn\n). A* is complete and optimal, provided that\nh\n(\nn\n) is admissible. The space complexity of A* is still an issue for many problems.",
          "sentence_count": 3,
          "char_count": 171,
          "prev_para_id": "chap3_para360",
          "next_para_id": "chap3_para362",
          "style_metadata": {
            "para_id": "chap3_para361",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 3
          },
          "terminology": {
            "search": 1,
            "expands": 1,
            "node": 1,
            "minimal": 1,
            "complete": 1,
            "optimal": 1,
            "provided": 1,
            "admissible": 1,
            "space": 1,
            "complexity": 1,
            "issue": 1,
            "many": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para362",
          "content": "–\nBidirectional A\n*\nsearch\nis sometimes more efficient than A* itself.",
          "sentence_count": 1,
          "char_count": 63,
          "prev_para_id": "chap3_para361",
          "next_para_id": "chap3_para363",
          "style_metadata": {
            "para_id": "chap3_para362",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "bidirectional": 1,
            "search": 1,
            "efficient": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para363",
          "content": "–\nIDA\n* (iterative deepening A* search) is an iterative deepening version of A*, and thus adresses the space complexity issue.",
          "sentence_count": 1,
          "char_count": 108,
          "prev_para_id": "chap3_para362",
          "next_para_id": "chap3_para364",
          "style_metadata": {
            "para_id": "chap3_para363",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 1
          },
          "terminology": {
            "ida": 1,
            "iterative": 2,
            "deepening": 2,
            "search": 1,
            "version": 1,
            "adresses": 1,
            "space": 1,
            "complexity": 1,
            "issue": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para364",
          "content": "–\nRBFS\n(recursive best-first search) and\nSMA\n* (simplified memory-bounded A*) are robust, optimal search algorithms that use limited amounts of memory; given enough time, they can solve problems for which A\n*\nruns out of memory.",
          "sentence_count": 1,
          "char_count": 198,
          "prev_para_id": "chap3_para363",
          "next_para_id": "chap3_para365",
          "style_metadata": {
            "para_id": "chap3_para364",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 46.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 1
          },
          "terminology": {
            "rbfs": 1,
            "recursive": 1,
            "best-first": 1,
            "search": 2,
            "sma": 1,
            "simplified": 1,
            "memory-bounded": 1,
            "robust": 1,
            "optimal": 1,
            "algorithm": 1,
            "use": 1,
            "limited": 1,
            "amount": 1,
            "memory": 2,
            "given": 1,
            "enough": 1,
            "time": 1,
            "solve": 1,
            "problem": 1,
            "run": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para365",
          "content": "–\nBeam search\nputs a limit on the size of the frontier; that makes it incomplete and suboptimal, but it often finds reasonably good solutions and runs faster than complete searches.",
          "sentence_count": 1,
          "char_count": 153,
          "prev_para_id": "chap3_para364",
          "next_para_id": "chap3_para366",
          "style_metadata": {
            "para_id": "chap3_para365",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "beam": 1,
            "search": 2,
            "put": 1,
            "limit": 1,
            "size": 1,
            "frontier": 1,
            "make": 1,
            "incomplete": 1,
            "suboptimal": 1,
            "find": 1,
            "good": 1,
            "solution": 1,
            "run": 1,
            "faster": 1,
            "complete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para365",
              "entity_text": "Beam",
              "entity_type": "ORG",
              "start_char": 2,
              "end_char": 6,
              "context": "–\nBeam search\nputs a limit on the size of the frontier; "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para366",
          "content": "–\nWeighted A\n* search focuses the search towards a goal, expanding fewer nodes, but sacrificing optimality.",
          "sentence_count": 1,
          "char_count": 93,
          "prev_para_id": "chap3_para365",
          "next_para_id": "chap3_para367",
          "style_metadata": {
            "para_id": "chap3_para366",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "weighted": 1,
            "search": 2,
            "focus": 1,
            "towards": 1,
            "goal": 1,
            "expanding": 1,
            "fewer": 1,
            "node": 1,
            "sacrificing": 1,
            "optimality": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para367",
          "content": "•\nThe performance of heuristic search algorithms depends on the quality of the heuristic function. One can sometimes construct good heuristics by relaxing the problem definition, by storing precomputed solution costs for subproblems in a pattern database, by defining landmarks, or by learning from experience with the problem class.",
          "sentence_count": 2,
          "char_count": 286,
          "prev_para_id": "chap3_para366",
          "next_para_id": "chap3_para368",
          "style_metadata": {
            "para_id": "chap3_para367",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 2
          },
          "terminology": {
            "performance": 1,
            "heuristic": 3,
            "search": 1,
            "algorithm": 1,
            "depends": 1,
            "quality": 1,
            "function": 1,
            "construct": 1,
            "good": 1,
            "relaxing": 1,
            "problem": 2,
            "definition": 1,
            "storing": 1,
            "precomputed": 1,
            "solution": 1,
            "cost": 1,
            "subproblems": 1,
            "pattern": 1,
            "database": 1,
            "defining": 1,
            "landmark": 1,
            "learning": 1,
            "experience": 1,
            "class": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para368",
          "content": "Bibliographical and Historical Notes\nBibliographical and Historical Notes\nThe topic of state-space search originated in the early years of AI. Newell and Simon’s work on the Logic Theorist (1957) and GPS (1961) led to the establishment of search algorithms as the primary tool for 1960s AI researchers and to the establishment of problem solving as the canonical AI task. Work in operations research by Richard Bellman (1957) showed the importance of additive path costs in simplifying optimization algorithms. The text by Nils Nilsson (1971) established the area on a solid theoretical footing.",
          "sentence_count": 4,
          "char_count": 506,
          "prev_para_id": "chap3_para367",
          "next_para_id": "chap3_para369",
          "style_metadata": {
            "para_id": "chap3_para368",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 4
          },
          "terminology": {
            "bibliographical": 2,
            "historical": 2,
            "note": 2,
            "state-space": 1,
            "search": 2,
            "originated": 1,
            "early": 1,
            "year": 1,
            "simon": 1,
            "work": 2,
            "logic": 1,
            "theorist": 1,
            "gps": 1,
            "led": 1,
            "establishment": 2,
            "algorithm": 1,
            "primary": 1,
            "tool": 1,
            "researcher": 1,
            "problem": 1,
            "solving": 1,
            "canonical": 1,
            "task": 1,
            "operation": 1,
            "research": 1,
            "richard": 1,
            "bellman": 1,
            "showed": 1,
            "importance": 1,
            "additive": 1,
            "path": 1,
            "cost": 1,
            "simplifying": 1,
            "optimization": 1,
            "text": 1,
            "nil": 1,
            "established": 1,
            "area": 1,
            "solid": 1,
            "theoretical": 1,
            "footing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para368",
              "entity_text": "AI",
              "entity_type": "GPE",
              "start_char": 139,
              "end_char": 141,
              "context": "ate-space search originated in the early years of AI. Newell and Simon’s work on the Logic Theorist (1"
            },
            {
              "para_id": "chap3_para368",
              "entity_text": "Newell",
              "entity_type": "PERSON",
              "start_char": 143,
              "end_char": 149,
              "context": "space search originated in the early years of AI. Newell and Simon’s work on the Logic Theorist (1957) and"
            },
            {
              "para_id": "chap3_para368",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 154,
              "end_char": 159,
              "context": "h originated in the early years of AI. Newell and Simon’s work on the Logic Theorist (1957) and GPS (1961"
            },
            {
              "para_id": "chap3_para368",
              "entity_text": "the Logic Theorist",
              "entity_type": "ORG",
              "start_char": 170,
              "end_char": 188,
              "context": "the early years of AI. Newell and Simon’s work on the Logic Theorist (1957) and GPS (1961) led to the establishment of"
            },
            {
              "para_id": "chap3_para368",
              "entity_text": "Richard Bellman",
              "entity_type": "PERSON",
              "start_char": 403,
              "end_char": 418,
              "context": "canonical AI task. Work in operations research by Richard Bellman (1957) showed the importance of additive path cos"
            },
            {
              "para_id": "chap3_para368",
              "entity_text": "Nils Nilsson",
              "entity_type": "PERSON",
              "start_char": 523,
              "end_char": 535,
              "context": " simplifying optimization algorithms. The text by Nils Nilsson (1971) established the area on a solid theoretica"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para369",
          "content": "The 8-puzzle is a smaller cousin of the 15-puzzle, whose history is recounted at length by Slocum and Sonneveld (2006). In 1880, the 15-puzzle attracted broad attention from the public and mathematicians (Johnson and Story, 1879; Tait, 1880). The editors of the\nAmerican Journal of Mathematics\nstated, “The ‘15’ puzzle for the last few weeks has been prominently before the American public, and may safely be said to have engaged the attention of nine out of ten persons of both sexes and all ages and conditions of the community,” while the\nWeekly News-Democrat\nof Emporia, Kansas wrote on March 12, 1880 that “It has become literally an epidemic all over the country.”\nThe famous American game designer Sam Loyd falsely claimed to have invented the 15 puzzle (Loyd, 1959); actually it was invented by Noyes Chapman, a postmaster in Canastota, New York, in the mid-1870s (although a generic patent covering sliding blocks was granted to Ernest Kinsey in 1878). Ratner and Warmuth (1986) showed that the general\nn\n×\nn\nversion of the 15-puzzle belongs to the class of NP-complete problems.",
          "sentence_count": 4,
          "char_count": 917,
          "prev_para_id": "chap3_para368",
          "next_para_id": "chap3_para370",
          "style_metadata": {
            "para_id": "chap3_para369",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 54.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 216,
            "sentence_count": 4
          },
          "terminology": {
            "8-puzzle": 1,
            "smaller": 1,
            "cousin": 1,
            "15-puzzle": 3,
            "history": 1,
            "recounted": 1,
            "length": 1,
            "slocum": 1,
            "sonneveld": 1,
            "attracted": 1,
            "broad": 1,
            "attention": 2,
            "public": 2,
            "mathematician": 1,
            "johnson": 1,
            "story": 1,
            "tait": 1,
            "editor": 1,
            "american": 3,
            "journal": 1,
            "mathematics": 1,
            "stated": 1,
            "last": 1,
            "week": 1,
            "said": 1,
            "engaged": 1,
            "ten": 1,
            "person": 1,
            "sex": 1,
            "age": 1,
            "condition": 1,
            "community": 1,
            "news-democrat": 1,
            "emporium": 1,
            "kansa": 1,
            "wrote": 1,
            "march": 1,
            "become": 1,
            "epidemic": 1,
            "country.": 1,
            "famous": 1,
            "game": 1,
            "designer": 1,
            "sam": 1,
            "claimed": 1,
            "invented": 2,
            "puzzle": 1,
            "noyes": 1,
            "chapman": 1,
            "postmaster": 1,
            "canastota": 1,
            "new": 1,
            "york": 1,
            "mid-1870s": 1,
            "generic": 1,
            "patent": 1,
            "covering": 1,
            "sliding": 1,
            "block": 1,
            "granted": 1,
            "ernest": 1,
            "kinsey": 1,
            "ratner": 1,
            "warmuth": 1,
            "showed": 1,
            "general": 1,
            "version": 1,
            "belongs": 1,
            "class": 1,
            "np-complete": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para369",
              "entity_text": "Slocum",
              "entity_type": "GPE",
              "start_char": 91,
              "end_char": 97,
              "context": "5-puzzle, whose history is recounted at length by Slocum and Sonneveld (2006). In 1880, the 15-puzzle attr"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Johnson",
              "entity_type": "PERSON",
              "start_char": 205,
              "end_char": 212,
              "context": "oad attention from the public and mathematicians (Johnson and Story, 1879; Tait, 1880). The editors of the\n"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Story",
              "entity_type": "PERSON",
              "start_char": 217,
              "end_char": 222,
              "context": "n from the public and mathematicians (Johnson and Story, 1879; Tait, 1880). The editors of the\nAmerican J"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Tait",
              "entity_type": "PERSON",
              "start_char": 230,
              "end_char": 234,
              "context": "blic and mathematicians (Johnson and Story, 1879; Tait, 1880). The editors of the\nAmerican Journal of Ma"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "American Journal of Mathematics",
              "entity_type": "ORG",
              "start_char": 262,
              "end_char": 293,
              "context": " and Story, 1879; Tait, 1880). The editors of the\nAmerican Journal of Mathematics\nstated, “The ‘15’ puzzle for the last few weeks h"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "The ‘15",
              "entity_type": "WORK_OF_ART",
              "start_char": 303,
              "end_char": 310,
              "context": "s of the\nAmerican Journal of Mathematics\nstated, “The ‘15’ puzzle for the last few weeks has been prominent"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Weekly News-Democrat",
              "entity_type": "ORG",
              "start_char": 542,
              "end_char": 562,
              "context": " ages and conditions of the community,” while the\nWeekly News-Democrat\nof Emporia, Kansas wrote on March 12, 1880 that “"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Emporia",
              "entity_type": "GPE",
              "start_char": 566,
              "end_char": 573,
              "context": "the community,” while the\nWeekly News-Democrat\nof Emporia, Kansas wrote on March 12, 1880 that “It has beco"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Kansas",
              "entity_type": "GPE",
              "start_char": 575,
              "end_char": 581,
              "context": "nity,” while the\nWeekly News-Democrat\nof Emporia, Kansas wrote on March 12, 1880 that “It has become liter"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Sam Loyd",
              "entity_type": "PERSON",
              "start_char": 705,
              "end_char": 713,
              "context": "r the country.”\nThe famous American game designer Sam Loyd falsely claimed to have invented the 15 puzzle (L"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Loyd",
              "entity_type": "PERSON",
              "start_char": 762,
              "end_char": 766,
              "context": "d falsely claimed to have invented the 15 puzzle (Loyd, 1959); actually it was invented by Noyes Chapman"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Noyes Chapman",
              "entity_type": "PERSON",
              "start_char": 803,
              "end_char": 816,
              "context": " puzzle (Loyd, 1959); actually it was invented by Noyes Chapman, a postmaster in Canastota, New York, in the mid-"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Canastota",
              "entity_type": "GPE",
              "start_char": 834,
              "end_char": 843,
              "context": "it was invented by Noyes Chapman, a postmaster in Canastota, New York, in the mid-1870s (although a generic p"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "New York",
              "entity_type": "GPE",
              "start_char": 845,
              "end_char": 853,
              "context": "nted by Noyes Chapman, a postmaster in Canastota, New York, in the mid-1870s (although a generic patent cove"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Ernest Kinsey",
              "entity_type": "PERSON",
              "start_char": 938,
              "end_char": 951,
              "context": "ric patent covering sliding blocks was granted to Ernest Kinsey in 1878). Ratner and Warmuth (1986) showed that t"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Ratner",
              "entity_type": "ORG",
              "start_char": 962,
              "end_char": 968,
              "context": "ing blocks was granted to Ernest Kinsey in 1878). Ratner and Warmuth (1986) showed that the general\nn\n×\nn\n"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "Warmuth",
              "entity_type": "PERSON",
              "start_char": 973,
              "end_char": 980,
              "context": "was granted to Ernest Kinsey in 1878). Ratner and Warmuth (1986) showed that the general\nn\n×\nn\nversion of t"
            },
            {
              "para_id": "chap3_para369",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 1067,
              "end_char": 1069,
              "context": "\nversion of the 15-puzzle belongs to the class of NP-complete problems."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para370",
          "content": "Rubik’s Cube was of course invented in 1974 by Ernő Rubik, who also discovered an algorithm for finding good, but not optimal solutions. Korf (1997) found optimal solutions for some random problem instances using pattern databases and IDA* search. Rokicki\net al.",
          "sentence_count": 3,
          "char_count": 222,
          "prev_para_id": "chap3_para369",
          "next_para_id": "chap3_para371",
          "style_metadata": {
            "para_id": "chap3_para370",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 3
          },
          "terminology": {
            "rubik": 2,
            "cube": 1,
            "course": 1,
            "invented": 1,
            "ernő": 1,
            "discovered": 1,
            "algorithm": 1,
            "finding": 1,
            "good": 1,
            "optimal": 2,
            "solution": 2,
            "korf": 1,
            "found": 1,
            "random": 1,
            "problem": 1,
            "instance": 1,
            "using": 1,
            "pattern": 1,
            "database": 1,
            "ida": 1,
            "search": 1,
            "rokicki": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para370",
              "entity_text": "Rubik’s Cube",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 12,
              "context": "Rubik’s Cube was of course invented in 1974 by Ernő Rubik, who"
            },
            {
              "para_id": "chap3_para370",
              "entity_text": "Ernő Rubik",
              "entity_type": "PERSON",
              "start_char": 47,
              "end_char": 57,
              "context": "Rubik’s Cube was of course invented in 1974 by Ernő Rubik, who also discovered an algorithm for finding goo"
            },
            {
              "para_id": "chap3_para370",
              "entity_text": "Korf",
              "entity_type": "PERSON",
              "start_char": 137,
              "end_char": 141,
              "context": "ithm for finding good, but not optimal solutions. Korf (1997) found optimal solutions for some random pr"
            },
            {
              "para_id": "chap3_para370",
              "entity_text": "IDA",
              "entity_type": "PERSON",
              "start_char": 235,
              "end_char": 238,
              "context": "dom problem instances using pattern databases and IDA* search. Rokicki\net al."
            },
            {
              "para_id": "chap3_para370",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 259,
              "end_char": 261,
              "context": "ing pattern databases and IDA* search. Rokicki\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para371",
          "content": "(2014) proved that any instance can be solved in 26 moves (if you consider a 180° twist to be two moves; 20 if it counts as one). The proof consumed 35 CPU years of computation; it does not lead immediately to an efficient algorithm. Agostinelli\net al.",
          "sentence_count": 3,
          "char_count": 207,
          "prev_para_id": "chap3_para370",
          "next_para_id": "chap3_para372",
          "style_metadata": {
            "para_id": "chap3_para371",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 56,
            "sentence_count": 3
          },
          "terminology": {
            "proved": 1,
            "instance": 1,
            "solved": 1,
            "move": 2,
            "consider": 1,
            "twist": 1,
            "count": 1,
            "proof": 1,
            "consumed": 1,
            "cpu": 1,
            "year": 1,
            "computation": 1,
            "lead": 1,
            "efficient": 1,
            "algorithm": 1,
            "agostinelli": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para371",
              "entity_text": "Agostinelli",
              "entity_type": "PERSON",
              "start_char": 234,
              "end_char": 245,
              "context": "s not lead immediately to an efficient algorithm. Agostinelli\net al."
            },
            {
              "para_id": "chap3_para371",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 249,
              "end_char": 251,
              "context": "diately to an efficient algorithm. Agostinelli\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para372",
          "content": "(2019) used reinforcement learning, deep learning networks, and Monte Carlo tree search to learn a much more efficient solver for Rubik’s cube. It is not guaranteed to find a cost-optimal solution, but does so about 60% of the time, and typical solutions times are less than a second.",
          "sentence_count": 2,
          "char_count": 237,
          "prev_para_id": "chap3_para371",
          "next_para_id": "chap3_para373",
          "style_metadata": {
            "para_id": "chap3_para372",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 2
          },
          "terminology": {
            "used": 1,
            "reinforcement": 1,
            "learning": 2,
            "deep": 1,
            "network": 1,
            "monte": 1,
            "carlo": 1,
            "tree": 1,
            "search": 1,
            "learn": 1,
            "much": 1,
            "efficient": 1,
            "solver": 1,
            "rubik": 1,
            "cube": 1,
            "guaranteed": 1,
            "find": 1,
            "cost-optimal": 1,
            "solution": 2,
            "time": 2,
            "typical": 1,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para372",
              "entity_text": "Monte Carlo",
              "entity_type": "PERSON",
              "start_char": 64,
              "end_char": 75,
              "context": "inforcement learning, deep learning networks, and Monte Carlo tree search to learn a much more efficient solver"
            },
            {
              "para_id": "chap3_para372",
              "entity_text": "Rubik",
              "entity_type": "ORG",
              "start_char": 130,
              "end_char": 135,
              "context": " search to learn a much more efficient solver for Rubik’s cube. It is not guaranteed to find a cost-optim"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para373",
          "content": "Each of the real-world search problems listed in the chapter has been the subject of a good deal of research effort. Methods for selecting optimal airline flights remain proprietary for the most part, but Carl de Marcken has shown by a reduction to Diophantine decision problems that airline ticket pricing and restrictions have become so convoluted that the\nproblem of selecting an optimal flight is formally\nundecidable\n(Robinson, 2002). The traveling salesperson problem (TSP) is a standard combinatorial problem in theoretical computer science (Lawler\net al.,\n1992). Karp (1972) proved the TSP decision problem to be NP-hard, but effective heuristic approximation methods were developed (Lin and Kernighan, 1973). Arora (1998) devised a fully polynomial approximation scheme for Euclidean TSPs. VLSI layout methods are surveyed by LaPaugh (2010), and many layout optimization papers appear in VLSI journals. Robotic navigation is discussed in\nChapter 26\n. Automatic assembly sequencing was first demonstrated by F\nREDDY\n(Michie, 1972); a comprehensive review is given by (Bahubalendruni and Biswal, 2016).",
          "sentence_count": 8,
          "char_count": 954,
          "prev_para_id": "chap3_para372",
          "next_para_id": "chap3_para374",
          "style_metadata": {
            "para_id": "chap3_para373",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.88,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 199,
            "sentence_count": 8
          },
          "terminology": {
            "real-world": 1,
            "search": 1,
            "problem": 6,
            "listed": 1,
            "chapter": 2,
            "subject": 1,
            "good": 1,
            "deal": 1,
            "research": 1,
            "effort": 1,
            "method": 3,
            "selecting": 2,
            "optimal": 2,
            "airline": 2,
            "flight": 2,
            "remain": 1,
            "proprietary": 1,
            "part": 1,
            "carl": 1,
            "marcken": 1,
            "shown": 1,
            "reduction": 1,
            "diophantine": 1,
            "decision": 2,
            "ticket": 1,
            "pricing": 1,
            "restriction": 1,
            "become": 1,
            "convoluted": 1,
            "undecidable": 1,
            "robinson": 1,
            "traveling": 1,
            "salesperson": 1,
            "tsp": 2,
            "standard": 1,
            "combinatorial": 1,
            "theoretical": 1,
            "computer": 1,
            "science": 1,
            "lawler": 1,
            "al.": 1,
            "karp": 1,
            "proved": 1,
            "effective": 1,
            "heuristic": 1,
            "approximation": 2,
            "developed": 1,
            "lin": 1,
            "kernighan": 1,
            "arora": 1,
            "devised": 1,
            "polynomial": 1,
            "scheme": 1,
            "euclidean": 1,
            "tsps": 1,
            "vlsi": 2,
            "surveyed": 1,
            "many": 1,
            "layout": 1,
            "optimization": 1,
            "paper": 1,
            "appear": 1,
            "journal": 1,
            "robotic": 1,
            "navigation": 1,
            "discussed": 1,
            "automatic": 1,
            "assembly": 1,
            "sequencing": 1,
            "demonstrated": 1,
            "reddy": 1,
            "comprehensive": 1,
            "review": 1,
            "given": 1,
            "bahubalendruni": 1,
            "biswal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para373",
              "entity_text": "Carl de Marcken",
              "entity_type": "PERSON",
              "start_char": 205,
              "end_char": 220,
              "context": "flights remain proprietary for the most part, but Carl de Marcken has shown by a reduction to Diophantine decision "
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Robinson",
              "entity_type": "PERSON",
              "start_char": 423,
              "end_char": 431,
              "context": "ecting an optimal flight is formally\nundecidable\n(Robinson, 2002). The traveling salesperson problem (TSP) i"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Lawler",
              "entity_type": "PERSON",
              "start_char": 549,
              "end_char": 555,
              "context": "natorial problem in theoretical computer science (Lawler\net al.,\n1992). Karp (1972) proved the TSP decisio"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 559,
              "end_char": 562,
              "context": "roblem in theoretical computer science (Lawler\net al.,\n1992). Karp (1972) proved the TSP decision probl"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Karp",
              "entity_type": "PERSON",
              "start_char": 571,
              "end_char": 575,
              "context": "eoretical computer science (Lawler\net al.,\n1992). Karp (1972) proved the TSP decision problem to be NP-h"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "TSP",
              "entity_type": "ORG",
              "start_char": 594,
              "end_char": 597,
              "context": "nce (Lawler\net al.,\n1992). Karp (1972) proved the TSP decision problem to be NP-hard, but effective heu"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 621,
              "end_char": 623,
              "context": "Karp (1972) proved the TSP decision problem to be NP-hard, but effective heuristic approximation metho"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Lin",
              "entity_type": "PERSON",
              "start_char": 692,
              "end_char": 695,
              "context": "e heuristic approximation methods were developed (Lin and Kernighan, 1973). Arora (1998) devised a full"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Kernighan",
              "entity_type": "GPE",
              "start_char": 700,
              "end_char": 709,
              "context": "tic approximation methods were developed (Lin and Kernighan, 1973). Arora (1998) devised a fully polynomial a"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Arora",
              "entity_type": "PERSON",
              "start_char": 718,
              "end_char": 723,
              "context": "methods were developed (Lin and Kernighan, 1973). Arora (1998) devised a fully polynomial approximation s"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "LaPaugh",
              "entity_type": "ORG",
              "start_char": 835,
              "end_char": 842,
              "context": "clidean TSPs. VLSI layout methods are surveyed by LaPaugh (2010), and many layout optimization papers appea"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "VLSI",
              "entity_type": "ORG",
              "start_char": 897,
              "end_char": 901,
              "context": "0), and many layout optimization papers appear in VLSI journals. Robotic navigation is discussed in\nChap"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Automatic",
              "entity_type": "GPE",
              "start_char": 960,
              "end_char": 969,
              "context": ". Robotic navigation is discussed in\nChapter 26\n. Automatic assembly sequencing was first demonstrated by F\nR"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "F\nREDDY\n",
              "entity_type": "PRODUCT",
              "start_char": 1016,
              "end_char": 1024,
              "context": "tic assembly sequencing was first demonstrated by F\nREDDY\n(Michie, 1972); a comprehensive review is given by"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Michie",
              "entity_type": "PERSON",
              "start_char": 1025,
              "end_char": 1031,
              "context": "bly sequencing was first demonstrated by F\nREDDY\n(Michie, 1972); a comprehensive review is given by (Bahub"
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Bahubalendruni",
              "entity_type": "PERSON",
              "start_char": 1076,
              "end_char": 1090,
              "context": "ichie, 1972); a comprehensive review is given by (Bahubalendruni and Biswal, 2016)."
            },
            {
              "para_id": "chap3_para373",
              "entity_text": "Biswal",
              "entity_type": "ORG",
              "start_char": 1095,
              "end_char": 1101,
              "context": "prehensive review is given by (Bahubalendruni and Biswal, 2016)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para374",
          "content": "Uninformed search algorithms are a central topic of computer science (Cormen\net al\n., 2009) and operations research (Dreyfus, 1969). Breadth-first search was formulated for solving mazes by Moore (1959). The method of dynamic programming (Bellman, 1957; Bellman and Dreyfus, 1962), which systematically records solutions for all subproblems of increasing lengths, can be seen as a form of breadth-first search.",
          "sentence_count": 3,
          "char_count": 353,
          "prev_para_id": "chap3_para373",
          "next_para_id": "chap3_para375",
          "style_metadata": {
            "para_id": "chap3_para374",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "uninformed": 1,
            "search": 3,
            "algorithm": 1,
            "central": 1,
            "topic": 1,
            "computer": 1,
            "science": 1,
            "cormen": 1,
            "operation": 1,
            "research": 1,
            "dreyfus": 2,
            "breadth-first": 2,
            "formulated": 1,
            "solving": 1,
            "maze": 1,
            "method": 1,
            "dynamic": 1,
            "programming": 1,
            "bellman": 2,
            "record": 1,
            "solution": 1,
            "subproblems": 1,
            "increasing": 1,
            "length": 1,
            "seen": 1,
            "form": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para374",
              "entity_text": "Dreyfus",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 124,
              "context": "e (Cormen\net al\n., 2009) and operations research (Dreyfus, 1969). Breadth-first search was formulated for s"
            },
            {
              "para_id": "chap3_para374",
              "entity_text": "Moore",
              "entity_type": "PERSON",
              "start_char": 190,
              "end_char": 195,
              "context": "-first search was formulated for solving mazes by Moore (1959). The method of dynamic programming (Bellma"
            },
            {
              "para_id": "chap3_para374",
              "entity_text": "Bellman and Dreyfus",
              "entity_type": "ORG",
              "start_char": 254,
              "end_char": 273,
              "context": "The method of dynamic programming (Bellman, 1957; Bellman and Dreyfus, 1962), which systematically records solutions fo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para375",
          "content": "Dijkstra’s algorithm in the form it is usually presented in (Dijkstra, 1959) is applicable to explicit finite graphs. Nilsson (1971) introduced a version of Dijkstra’s algorithm that he called uniform-cost search (because the algorithm “spreads out along contours of equal path cost”) that allows for implicitly defined, infinite graphs. Nilsson’s work also introduced the idea of closed and open lists, and the term “graph search.” The name B\nEST\n-F\nIRST\n-S\nEARCH\nwas introduced in the\nHandbook of AI\n(Barr and Feigenbaum, 1981). The Floyd–Warshall (Floyd, 1962) and Bellman-Ford (Bellman, 1958; Ford, 1956) algorithms allow negative step costs (as long as there are no negative cycles).",
          "sentence_count": 4,
          "char_count": 590,
          "prev_para_id": "chap3_para374",
          "next_para_id": "chap3_para376",
          "style_metadata": {
            "para_id": "chap3_para375",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.75,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 143,
            "sentence_count": 4
          },
          "terminology": {
            "dijkstra": 3,
            "algorithm": 4,
            "form": 1,
            "presented": 1,
            "applicable": 1,
            "explicit": 1,
            "finite": 1,
            "graph": 3,
            "nilsson": 2,
            "introduced": 3,
            "version": 1,
            "called": 1,
            "uniform-cost": 1,
            "search": 1,
            "spread": 1,
            "contour": 1,
            "equal": 1,
            "path": 1,
            "cost": 2,
            "allows": 1,
            "defined": 1,
            "infinite": 1,
            "work": 1,
            "idea": 1,
            "closed": 1,
            "open": 1,
            "list": 1,
            "term": 1,
            "search.": 1,
            "name": 1,
            "est": 1,
            "irst": 1,
            "earch": 1,
            "handbook": 1,
            "barr": 1,
            "feigenbaum": 1,
            "floyd–warshall": 1,
            "floyd": 1,
            "bellman-ford": 1,
            "bellman": 1,
            "ford": 1,
            "allow": 1,
            "negative": 2,
            "step": 1,
            "cycle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para375",
              "entity_text": "Dijkstra",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 8,
              "context": "Dijkstra’s algorithm in the form it is usually presented i"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Dijkstra",
              "entity_type": "ORG",
              "start_char": 61,
              "end_char": 69,
              "context": "algorithm in the form it is usually presented in (Dijkstra, 1959) is applicable to explicit finite graphs. N"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 118,
              "end_char": 125,
              "context": "a, 1959) is applicable to explicit finite graphs. Nilsson (1971) introduced a version of Dijkstra’s algorit"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Dijkstra",
              "entity_type": "ORG",
              "start_char": 157,
              "end_char": 165,
              "context": "te graphs. Nilsson (1971) introduced a version of Dijkstra’s algorithm that he called uniform-cost search (b"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 338,
              "end_char": 345,
              "context": "t allows for implicitly defined, infinite graphs. Nilsson’s work also introduced the idea of closed and ope"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Barr",
              "entity_type": "PERSON",
              "start_char": 503,
              "end_char": 507,
              "context": "ST\n-S\nEARCH\nwas introduced in the\nHandbook of AI\n(Barr and Feigenbaum, 1981). The Floyd–Warshall (Floyd,"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Feigenbaum",
              "entity_type": "ORG",
              "start_char": 512,
              "end_char": 522,
              "context": "CH\nwas introduced in the\nHandbook of AI\n(Barr and Feigenbaum, 1981). The Floyd–Warshall (Floyd, 1962) and Bell"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "The Floyd–Warshall",
              "entity_type": "ORG",
              "start_char": 531,
              "end_char": 549,
              "context": "n the\nHandbook of AI\n(Barr and Feigenbaum, 1981). The Floyd–Warshall (Floyd, 1962) and Bellman-Ford (Bellman, 1958; Fo"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Bellman-Ford",
              "entity_type": "ORG",
              "start_char": 568,
              "end_char": 580,
              "context": "baum, 1981). The Floyd–Warshall (Floyd, 1962) and Bellman-Ford (Bellman, 1958; Ford, 1956) algorithms allow nega"
            },
            {
              "para_id": "chap3_para375",
              "entity_text": "Ford",
              "entity_type": "ORG",
              "start_char": 597,
              "end_char": 601,
              "context": "ll (Floyd, 1962) and Bellman-Ford (Bellman, 1958; Ford, 1956) algorithms allow negative step costs (as l"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para376",
          "content": "A version of iterative deepening designed to make efficient use of the chess clock was first used by Slate and Atkin (1977) in the C\nHESS\n4.5 game-playing program. Martelli’s algorithm B (1977) also includes an iterative deepening aspect. The iterative deepening technique was introduced by Bertram Raphael (1976) and came to the fore in work by Korf (1985a).",
          "sentence_count": 3,
          "char_count": 303,
          "prev_para_id": "chap3_para375",
          "next_para_id": "chap3_para377",
          "style_metadata": {
            "para_id": "chap3_para376",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 3
          },
          "terminology": {
            "version": 1,
            "iterative": 3,
            "deepening": 3,
            "designed": 1,
            "make": 1,
            "efficient": 1,
            "use": 1,
            "chess": 1,
            "clock": 1,
            "used": 1,
            "slate": 1,
            "atkin": 1,
            "hess": 1,
            "game-playing": 1,
            "program": 1,
            "martelli": 1,
            "algorithm": 1,
            "includes": 1,
            "aspect": 1,
            "technique": 1,
            "introduced": 1,
            "raphael": 1,
            "came": 1,
            "work": 1,
            "korf": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para376",
              "entity_text": "Slate",
              "entity_type": "ORG",
              "start_char": 101,
              "end_char": 106,
              "context": "fficient use of the chess clock was first used by Slate and Atkin (1977) in the C\nHESS\n4.5 game-playing p"
            },
            {
              "para_id": "chap3_para376",
              "entity_text": "Atkin",
              "entity_type": "GPE",
              "start_char": 111,
              "end_char": 116,
              "context": "se of the chess clock was first used by Slate and Atkin (1977) in the C\nHESS\n4.5 game-playing program. Ma"
            },
            {
              "para_id": "chap3_para376",
              "entity_text": "Martelli’s",
              "entity_type": "PERSON",
              "start_char": 164,
              "end_char": 174,
              "context": "in (1977) in the C\nHESS\n4.5 game-playing program. Martelli’s algorithm B (1977) also includes an iterative dee"
            },
            {
              "para_id": "chap3_para376",
              "entity_text": "Bertram Raphael",
              "entity_type": "PERSON",
              "start_char": 291,
              "end_char": 306,
              "context": "e iterative deepening technique was introduced by Bertram Raphael (1976) and came to the fore in work by Korf (1985"
            },
            {
              "para_id": "chap3_para376",
              "entity_text": "Korf",
              "entity_type": "ORG",
              "start_char": 346,
              "end_char": 350,
              "context": "am Raphael (1976) and came to the fore in work by Korf (1985a)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para377",
          "content": "The use of heuristic information in problem solving appears in an early paper by Simon and Newell (1958), but the phrase “heuristic search” and the use of heuristic functions that estimate the distance to the goal came somewhat later (Newell and Ernst, 1965; Lin, 1965). Doran and Michie (1966) conducted extensive experimental studies of heuristic search. Although they analyzed path length and “penetrance” (the ratio of path length to the total number of nodes examined so far), they appear to have ignored the information provided by the path cost\ng\n(\nn\n). The A* algorithm, incorporating the current path cost into heuristic search, was developed by Hart, Nilsson, and Raphael (1968). Dechter and Pearl (1985) studied the conditions under which A\n*\nis optimally efficient (in number of nodes expanded).",
          "sentence_count": 5,
          "char_count": 683,
          "prev_para_id": "chap3_para376",
          "next_para_id": "chap3_para378",
          "style_metadata": {
            "para_id": "chap3_para377",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.8,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 164,
            "sentence_count": 5
          },
          "terminology": {
            "heuristic": 5,
            "information": 2,
            "problem": 1,
            "solving": 1,
            "appears": 1,
            "early": 1,
            "paper": 1,
            "simon": 1,
            "phrase": 1,
            "search": 3,
            "use": 1,
            "function": 1,
            "estimate": 1,
            "distance": 1,
            "goal": 1,
            "came": 1,
            "ernst": 1,
            "lin": 1,
            "doran": 1,
            "michie": 1,
            "conducted": 1,
            "extensive": 1,
            "experimental": 1,
            "study": 1,
            "analyzed": 1,
            "path": 4,
            "length": 2,
            "penetrance": 1,
            "ratio": 1,
            "total": 1,
            "number": 2,
            "node": 2,
            "examined": 1,
            "appear": 1,
            "ignored": 1,
            "provided": 1,
            "cost": 2,
            "incorporating": 1,
            "current": 1,
            "developed": 1,
            "hart": 1,
            "nilsson": 1,
            "raphael": 1,
            "dechter": 1,
            "pearl": 1,
            "studied": 1,
            "condition": 1,
            "efficient": 1,
            "expanded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para377",
              "entity_text": "Simon",
              "entity_type": "PERSON",
              "start_char": 81,
              "end_char": 86,
              "context": "n in problem solving appears in an early paper by Simon and Newell (1958), but the phrase “heuristic sear"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Newell",
              "entity_type": "PERSON",
              "start_char": 91,
              "end_char": 97,
              "context": "em solving appears in an early paper by Simon and Newell (1958), but the phrase “heuristic search” and the"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Newell and Ernst",
              "entity_type": "ORG",
              "start_char": 235,
              "end_char": 251,
              "context": "ate the distance to the goal came somewhat later (Newell and Ernst, 1965; Lin, 1965). Doran and Michie (1966) conduc"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Lin",
              "entity_type": "PERSON",
              "start_char": 259,
              "end_char": 262,
              "context": "goal came somewhat later (Newell and Ernst, 1965; Lin, 1965). Doran and Michie (1966) conducted extensi"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Doran",
              "entity_type": "PERSON",
              "start_char": 271,
              "end_char": 276,
              "context": "mewhat later (Newell and Ernst, 1965; Lin, 1965). Doran and Michie (1966) conducted extensive experimenta"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Michie",
              "entity_type": "PERSON",
              "start_char": 281,
              "end_char": 287,
              "context": "er (Newell and Ernst, 1965; Lin, 1965). Doran and Michie (1966) conducted extensive experimental studies o"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Hart",
              "entity_type": "ORG",
              "start_char": 655,
              "end_char": 659,
              "context": "path cost into heuristic search, was developed by Hart, Nilsson, and Raphael (1968). Dechter and Pearl ("
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 661,
              "end_char": 668,
              "context": "ost into heuristic search, was developed by Hart, Nilsson, and Raphael (1968). Dechter and Pearl (1985) stu"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Raphael",
              "entity_type": "PERSON",
              "start_char": 674,
              "end_char": 681,
              "context": "istic search, was developed by Hart, Nilsson, and Raphael (1968). Dechter and Pearl (1985) studied the cond"
            },
            {
              "para_id": "chap3_para377",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 702,
              "end_char": 707,
              "context": "by Hart, Nilsson, and Raphael (1968). Dechter and Pearl (1985) studied the conditions under which A\n*\nis "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para378",
          "content": "The original A* paper (Hart\net al\n., 1968) introduced the consistency condition on heuristic functions. The monotone condition was introduced by Pohl (1977) as a simpler replacement, but Pearl (1984) showed that the two were equivalent.",
          "sentence_count": 2,
          "char_count": 202,
          "prev_para_id": "chap3_para377",
          "next_para_id": "chap3_para379",
          "style_metadata": {
            "para_id": "chap3_para378",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.021,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "original": 1,
            "paper": 1,
            "hart": 1,
            "introduced": 2,
            "consistency": 1,
            "condition": 2,
            "heuristic": 1,
            "function": 1,
            "monotone": 1,
            "pohl": 1,
            "simpler": 1,
            "replacement": 1,
            "pearl": 1,
            "showed": 1,
            "equivalent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para378",
              "entity_text": "Pohl",
              "entity_type": "PERSON",
              "start_char": 145,
              "end_char": 149,
              "context": "nctions. The monotone condition was introduced by Pohl (1977) as a simpler replacement, but Pearl (1984)"
            },
            {
              "para_id": "chap3_para378",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 187,
              "end_char": 192,
              "context": "uced by Pohl (1977) as a simpler replacement, but Pearl (1984) showed that the two were equivalent."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para379",
          "content": "Pohl (1977) pioneered the study of the relationship between the error in heuristic functions and the time complexity of A*. Basic results were obtained for tree-like search with unit action costs and a single goal state (Pohl, 1977; Gaschnig, 1979; Huyn\net al.,\n1980; Pearl, 1984) and with multiple goal states (Dinh\net al.,\n2007). Korf and Reid (1998) showed how to predict the exact number of nodes expanded (not just an asymptotic approximation) on a variety of actual problem domains. The “effective branching factor” was proposed by Nilsson (1971) as an empirical measure of efficiency. For graph search, Helmert and Röger (2008)\nnoted that several well-known problems contained exponentially many nodes on optimal-cost solution paths, implying exponential time complexity for A*.",
          "sentence_count": 5,
          "char_count": 669,
          "prev_para_id": "chap3_para378",
          "next_para_id": "chap3_para380",
          "style_metadata": {
            "para_id": "chap3_para379",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 155,
            "sentence_count": 5
          },
          "terminology": {
            "pohl": 2,
            "pioneered": 1,
            "study": 1,
            "relationship": 1,
            "error": 1,
            "heuristic": 1,
            "function": 1,
            "time": 2,
            "complexity": 2,
            "basic": 1,
            "result": 1,
            "obtained": 1,
            "tree-like": 1,
            "search": 2,
            "unit": 1,
            "action": 1,
            "cost": 1,
            "single": 1,
            "goal": 2,
            "state": 2,
            "gaschnig": 1,
            "huyn": 1,
            "al.": 2,
            "pearl": 1,
            "multiple": 1,
            "dinh": 1,
            "korf": 1,
            "reid": 1,
            "showed": 1,
            "predict": 1,
            "exact": 1,
            "number": 1,
            "node": 2,
            "expanded": 1,
            "asymptotic": 1,
            "approximation": 1,
            "variety": 1,
            "actual": 1,
            "problem": 2,
            "domain": 1,
            "effective": 1,
            "branching": 1,
            "factor": 1,
            "proposed": 1,
            "nilsson": 1,
            "empirical": 1,
            "measure": 1,
            "efficiency": 1,
            "graph": 1,
            "helmert": 1,
            "röger": 1,
            "noted": 1,
            "several": 1,
            "well-known": 1,
            "contained": 1,
            "many": 1,
            "optimal-cost": 1,
            "solution": 1,
            "path": 1,
            "implying": 1,
            "exponential": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para379",
              "entity_text": "Gaschnig",
              "entity_type": "PERSON",
              "start_char": 233,
              "end_char": 241,
              "context": "action costs and a single goal state (Pohl, 1977; Gaschnig, 1979; Huyn\net al.,\n1980; Pearl, 1984) and with m"
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 257,
              "end_char": 260,
              "context": "e goal state (Pohl, 1977; Gaschnig, 1979; Huyn\net al.,\n1980; Pearl, 1984) and with multiple goal states"
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "Pearl",
              "entity_type": "GPE",
              "start_char": 268,
              "end_char": 273,
              "context": "e (Pohl, 1977; Gaschnig, 1979; Huyn\net al.,\n1980; Pearl, 1984) and with multiple goal states (Dinh\net al."
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 320,
              "end_char": 323,
              "context": "arl, 1984) and with multiple goal states (Dinh\net al.,\n2007). Korf and Reid (1998) showed how to predic"
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "Korf",
              "entity_type": "PERSON",
              "start_char": 332,
              "end_char": 336,
              "context": "nd with multiple goal states (Dinh\net al.,\n2007). Korf and Reid (1998) showed how to predict the exact n"
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "Reid",
              "entity_type": "PERSON",
              "start_char": 341,
              "end_char": 345,
              "context": "ultiple goal states (Dinh\net al.,\n2007). Korf and Reid (1998) showed how to predict the exact number of "
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 538,
              "end_char": 545,
              "context": " The “effective branching factor” was proposed by Nilsson (1971) as an empirical measure of efficiency. For"
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "Helmert",
              "entity_type": "PERSON",
              "start_char": 610,
              "end_char": 617,
              "context": "mpirical measure of efficiency. For graph search, Helmert and Röger (2008)\nnoted that several well-known pr"
            },
            {
              "para_id": "chap3_para379",
              "entity_text": "Röger",
              "entity_type": "PERSON",
              "start_char": 622,
              "end_char": 627,
              "context": "sure of efficiency. For graph search, Helmert and Röger (2008)\nnoted that several well-known problems con"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para380",
          "content": "There are many variations on the A* algorithm. Pohl (1970) introduced weighted A* search, and later a dynamic version (1973), where the weight changes over the depth of the tree. Ebendt and Drechsler (2009) synthesize the results and examine some applications. Hatem and Ruml (2014) show a simplified and improved version of weighted A* that is easier to implement. Wilt and Ruml (2014) introduce speedy search as an alternative to greedy search that focuses on minimizing search time, and Wilt and Ruml (2016) show that the best heuristics for satisficing search are different from the ones for optimal search. Burns\net al.",
          "sentence_count": 6,
          "char_count": 524,
          "prev_para_id": "chap3_para379",
          "next_para_id": "chap3_para381",
          "style_metadata": {
            "para_id": "chap3_para380",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 126,
            "sentence_count": 6
          },
          "terminology": {
            "many": 1,
            "variation": 1,
            "algorithm": 1,
            "pohl": 1,
            "introduced": 1,
            "weighted": 2,
            "search": 6,
            "dynamic": 1,
            "version": 2,
            "weight": 1,
            "change": 1,
            "depth": 1,
            "tree": 1,
            "ebendt": 1,
            "drechsler": 1,
            "synthesize": 1,
            "result": 1,
            "examine": 1,
            "application": 1,
            "hatem": 1,
            "ruml": 3,
            "show": 2,
            "simplified": 1,
            "improved": 1,
            "easier": 1,
            "implement": 1,
            "wilt": 2,
            "introduce": 1,
            "speedy": 1,
            "alternative": 1,
            "greedy": 1,
            "focus": 1,
            "minimizing": 1,
            "time": 1,
            "best": 1,
            "heuristic": 1,
            "satisficing": 1,
            "different": 1,
            "one": 1,
            "optimal": 1,
            "burn": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para380",
              "entity_text": "Ebendt",
              "entity_type": "PERSON",
              "start_char": 179,
              "end_char": 185,
              "context": "re the weight changes over the depth of the tree. Ebendt and Drechsler (2009) synthesize the results and e"
            },
            {
              "para_id": "chap3_para380",
              "entity_text": "Drechsler",
              "entity_type": "PERSON",
              "start_char": 190,
              "end_char": 199,
              "context": "ht changes over the depth of the tree. Ebendt and Drechsler (2009) synthesize the results and examine some ap"
            },
            {
              "para_id": "chap3_para380",
              "entity_text": "Ruml",
              "entity_type": "PERSON",
              "start_char": 271,
              "end_char": 275,
              "context": " results and examine some applications. Hatem and Ruml (2014) show a simplified and improved version of "
            },
            {
              "para_id": "chap3_para380",
              "entity_text": "Ruml",
              "entity_type": "PERSON",
              "start_char": 375,
              "end_char": 379,
              "context": "weighted A* that is easier to implement. Wilt and Ruml (2014) introduce speedy search as an alternative "
            },
            {
              "para_id": "chap3_para380",
              "entity_text": "Ruml",
              "entity_type": "PERSON",
              "start_char": 499,
              "end_char": 503,
              "context": "t focuses on minimizing search time, and Wilt and Ruml (2016) show that the best heuristics for satisfic"
            },
            {
              "para_id": "chap3_para380",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 621,
              "end_char": 623,
              "context": "ferent from the ones for optimal search. Burns\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para381",
          "content": "(2012) give some implementation tricks for writing fast search code, and Felner (2018) considers how the implementation changes when using an early goal test.",
          "sentence_count": 1,
          "char_count": 135,
          "prev_para_id": "chap3_para380",
          "next_para_id": "chap3_para382",
          "style_metadata": {
            "para_id": "chap3_para381",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 1
          },
          "terminology": {
            "give": 1,
            "implementation": 2,
            "trick": 1,
            "writing": 1,
            "search": 1,
            "code": 1,
            "felner": 1,
            "considers": 1,
            "change": 1,
            "using": 1,
            "early": 1,
            "goal": 1,
            "test": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para381",
              "entity_text": "Felner",
              "entity_type": "PERSON",
              "start_char": 73,
              "end_char": 79,
              "context": "entation tricks for writing fast search code, and Felner (2018) considers how the implementation changes w"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para382",
          "content": "Pohl (1971) introduced bidirectional search. Holte\net al.",
          "sentence_count": 2,
          "char_count": 51,
          "prev_para_id": "chap3_para381",
          "next_para_id": "chap3_para383",
          "style_metadata": {
            "para_id": "chap3_para382",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 12,
            "sentence_count": 2
          },
          "terminology": {
            "pohl": 1,
            "introduced": 1,
            "bidirectional": 1,
            "search": 1,
            "holte": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para382",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 54,
              "end_char": 56,
              "context": " (1971) introduced bidirectional search. Holte\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para383",
          "content": "(2016) describe the version of bidirectional search that is guaranteed to meet in the middle, making it more widely applicable. Eckerle\net al.",
          "sentence_count": 2,
          "char_count": 121,
          "prev_para_id": "chap3_para382",
          "next_para_id": "chap3_para384",
          "style_metadata": {
            "para_id": "chap3_para383",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "describe": 1,
            "version": 1,
            "bidirectional": 1,
            "search": 1,
            "guaranteed": 1,
            "meet": 1,
            "middle": 1,
            "making": 1,
            "applicable": 1,
            "eckerle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para383",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 139,
              "end_char": 141,
              "context": "dle, making it more widely applicable. Eckerle\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para384",
          "content": "(2017) describe the set of surely expanded pairs of nodes, and show that no bidirectional search can be optimally efficient. The NBS algorithm (Chen\net al.",
          "sentence_count": 2,
          "char_count": 131,
          "prev_para_id": "chap3_para383",
          "next_para_id": "chap3_para385",
          "style_metadata": {
            "para_id": "chap3_para384",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 2
          },
          "terminology": {
            "describe": 1,
            "set": 1,
            "expanded": 1,
            "pair": 1,
            "show": 1,
            "bidirectional": 1,
            "search": 1,
            "efficient": 1,
            "nb": 1,
            "algorithm": 1,
            "chen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para384",
              "entity_text": "NBS",
              "entity_type": "ORG",
              "start_char": 129,
              "end_char": 132,
              "context": "irectional search can be optimally efficient. The NBS algorithm (Chen\net al."
            },
            {
              "para_id": "chap3_para384",
              "entity_text": "Chen",
              "entity_type": "PERSON",
              "start_char": 144,
              "end_char": 148,
              "context": "ch can be optimally efficient. The NBS algorithm (Chen\net al."
            },
            {
              "para_id": "chap3_para384",
              "entity_text": "al",
              "entity_type": "ORG",
              "start_char": 152,
              "end_char": 154,
              "context": "e optimally efficient. The NBS algorithm (Chen\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para385",
          "content": ", 2017) makes explicit use of a queue of pairs of nodes.",
          "sentence_count": 1,
          "char_count": 45,
          "prev_para_id": "chap3_para384",
          "next_para_id": "chap3_para386",
          "style_metadata": {
            "para_id": "chap3_para385",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "make": 1,
            "explicit": 1,
            "use": 1,
            "queue": 1,
            "pair": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para386",
          "content": "A combination of bidirectional A\n*\nand known landmarks was used to efficiently find driving routes for Microsoft’s online map service (Goldberg\net al.",
          "sentence_count": 1,
          "char_count": 130,
          "prev_para_id": "chap3_para385",
          "next_para_id": "chap3_para387",
          "style_metadata": {
            "para_id": "chap3_para386",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "combination": 1,
            "bidirectional": 1,
            "known": 1,
            "landmark": 1,
            "used": 1,
            "find": 1,
            "driving": 1,
            "route": 1,
            "microsoft": 1,
            "online": 1,
            "map": 1,
            "service": 1,
            "goldberg": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para386",
              "entity_text": "Microsoft",
              "entity_type": "ORG",
              "start_char": 103,
              "end_char": 112,
              "context": "s was used to efficiently find driving routes for Microsoft’s online map service (Goldberg\net al."
            },
            {
              "para_id": "chap3_para386",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 147,
              "end_char": 149,
              "context": "s for Microsoft’s online map service (Goldberg\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para387",
          "content": ", 2006). After caching a set of paths between landmarks, the algorithm can find an optimal-cost path between any pair of points in a 24-million-point graph of the United States, searching less than 0.1% of the graph. Korf (1987) shows how to use subgoals, macro-operators, and abstraction to achieve remarkable speedups over previous techniques. Delling\net al.",
          "sentence_count": 4,
          "char_count": 305,
          "prev_para_id": "chap3_para386",
          "next_para_id": "chap3_para388",
          "style_metadata": {
            "para_id": "chap3_para387",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 4
          },
          "terminology": {
            "caching": 1,
            "set": 1,
            "path": 2,
            "landmark": 1,
            "algorithm": 1,
            "find": 1,
            "optimal-cost": 1,
            "pair": 1,
            "point": 1,
            "24-million-point": 1,
            "graph": 2,
            "united": 1,
            "state": 1,
            "searching": 1,
            "less": 1,
            "korf": 1,
            "show": 1,
            "use": 1,
            "subgoals": 1,
            "macro-operators": 1,
            "abstraction": 1,
            "achieve": 1,
            "remarkable": 1,
            "speedup": 1,
            "previous": 1,
            "technique": 1,
            "delling": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para387",
              "entity_text": "the United States",
              "entity_type": "GPE",
              "start_char": 159,
              "end_char": 176,
              "context": "any pair of points in a 24-million-point graph of the United States, searching less than 0.1% of the graph. Korf (198"
            },
            {
              "para_id": "chap3_para387",
              "entity_text": "Korf",
              "entity_type": "PERSON",
              "start_char": 217,
              "end_char": 221,
              "context": "ed States, searching less than 0.1% of the graph. Korf (1987) shows how to use subgoals, macro-operators"
            },
            {
              "para_id": "chap3_para387",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 357,
              "end_char": 359,
              "context": "ble speedups over previous techniques. Delling\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para388",
          "content": "(2009) describe how to use bidirectional search, landmarks, hierarchical structure, and other tricks to find driving routes. Anderson\net al.",
          "sentence_count": 2,
          "char_count": 122,
          "prev_para_id": "chap3_para387",
          "next_para_id": "chap3_para389",
          "style_metadata": {
            "para_id": "chap3_para388",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 2
          },
          "terminology": {
            "describe": 1,
            "use": 1,
            "bidirectional": 1,
            "search": 1,
            "landmark": 1,
            "hierarchical": 1,
            "structure": 1,
            "trick": 1,
            "find": 1,
            "driving": 1,
            "route": 1,
            "anderson": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para388",
              "entity_text": "Anderson",
              "entity_type": "PERSON",
              "start_char": 125,
              "end_char": 133,
              "context": "ructure, and other tricks to find driving routes. Anderson\net al."
            },
            {
              "para_id": "chap3_para388",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 137,
              "end_char": 139,
              "context": " other tricks to find driving routes. Anderson\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para389",
          "content": "(2008) describe a related technique, called\ncoarse-to-fine search\n, which can be thought of as defining landmarks at various hierarchical levels of abstraction. Korf (1987) describes conditions under which coarse-to-fine search provides an exponential speedup. Knoblock (1991) provides experimental results and analysis to quantify the advantages of hierarchical search.",
          "sentence_count": 3,
          "char_count": 324,
          "prev_para_id": "chap3_para388",
          "next_para_id": "chap3_para390",
          "style_metadata": {
            "para_id": "chap3_para389",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 3
          },
          "terminology": {
            "describe": 1,
            "related": 1,
            "technique": 1,
            "called": 1,
            "coarse-to-fine": 2,
            "search": 3,
            "thought": 1,
            "defining": 1,
            "landmark": 1,
            "various": 1,
            "hierarchical": 2,
            "level": 1,
            "abstraction": 1,
            "korf": 1,
            "describes": 1,
            "condition": 1,
            "provides": 2,
            "exponential": 1,
            "speedup": 1,
            "knoblock": 1,
            "experimental": 1,
            "result": 1,
            "analysis": 1,
            "quantify": 1,
            "advantage": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para389",
              "entity_text": "Korf",
              "entity_type": "PERSON",
              "start_char": 161,
              "end_char": 165,
              "context": "ks at various hierarchical levels of abstraction. Korf (1987) describes conditions under which coarse-to"
            },
            {
              "para_id": "chap3_para389",
              "entity_text": "Knoblock",
              "entity_type": "PERSON",
              "start_char": 261,
              "end_char": 269,
              "context": "e-to-fine search provides an exponential speedup. Knoblock (1991) provides experimental results and analysis"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para390",
          "content": "A* and other state-space search algorithms are closely related to the\nbranch-and-bound\ntechniques that are widely used in operations research (Lawler and Wood, 1966; Rayward-Smith\net al.",
          "sentence_count": 1,
          "char_count": 163,
          "prev_para_id": "chap3_para389",
          "next_para_id": "chap3_para391",
          "style_metadata": {
            "para_id": "chap3_para390",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 1
          },
          "terminology": {
            "state-space": 1,
            "search": 1,
            "algorithm": 1,
            "related": 1,
            "branch-and-bound": 1,
            "technique": 1,
            "used": 1,
            "operation": 1,
            "research": 1,
            "lawler": 1,
            "wood": 1,
            "rayward-smith": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para390",
              "entity_text": "Lawler and Wood",
              "entity_type": "ORG",
              "start_char": 143,
              "end_char": 158,
              "context": "ques that are widely used in operations research (Lawler and Wood, 1966; Rayward-Smith\net al."
            },
            {
              "para_id": "chap3_para390",
              "entity_text": "Rayward-Smith",
              "entity_type": "PERSON",
              "start_char": 166,
              "end_char": 179,
              "context": "ed in operations research (Lawler and Wood, 1966; Rayward-Smith\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para391",
          "content": ", 1996). Kumar and Kanal (1988) attempt a “grand unification” of heuristic search, dynamic programming, and branch-and-bound techniques under the name of CDP—the “composite decision process.”\nBecause most computers in the 1960s had only a few thousand words of main memory, memory-bounded heuristic search was an early research topic. The Graph Traverser (Doran and Michie, 1966), one of the earliest search programs, commits to an action after searching best-first up to the memory limit. IDA* (Korf, 1985b) was the first widely used length- optimal, memory-bounded heuristic search algorithm, and a large number of variants have been developed. An analysis of the efficiency of IDA\n*\nand of its difficulties with real-valued heuristics appears in Patrick\net al.",
          "sentence_count": 5,
          "char_count": 651,
          "prev_para_id": "chap3_para390",
          "next_para_id": "chap3_para392",
          "style_metadata": {
            "para_id": "chap3_para391",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 143,
            "sentence_count": 5
          },
          "terminology": {
            "kumar": 1,
            "kanal": 1,
            "attempt": 1,
            "grand": 1,
            "unification": 1,
            "heuristic": 4,
            "search": 4,
            "dynamic": 1,
            "programming": 1,
            "branch-and-bound": 1,
            "technique": 1,
            "name": 1,
            "cdp—the": 1,
            "composite": 1,
            "decision": 1,
            "process.": 1,
            "computer": 1,
            "word": 1,
            "main": 1,
            "memory": 2,
            "memory-bounded": 2,
            "early": 1,
            "research": 1,
            "topic": 1,
            "traverser": 1,
            "doran": 1,
            "michie": 1,
            "earliest": 1,
            "program": 1,
            "commits": 1,
            "action": 1,
            "searching": 1,
            "best-first": 1,
            "limit": 1,
            "ida": 2,
            "korf": 1,
            "first": 1,
            "used": 1,
            "length-": 1,
            "optimal": 1,
            "algorithm": 1,
            "large": 1,
            "number": 1,
            "variant": 1,
            "developed": 1,
            "analysis": 1,
            "efficiency": 1,
            "difficulty": 1,
            "real-valued": 1,
            "appears": 1,
            "patrick": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para391",
              "entity_text": "Kumar",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 14,
              "context": ", 1996). Kumar and Kanal (1988) attempt a “grand unification” of"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "Kanal",
              "entity_type": "ORG",
              "start_char": 19,
              "end_char": 24,
              "context": ", 1996). Kumar and Kanal (1988) attempt a “grand unification” of heuristic"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "CDP",
              "entity_type": "ORG",
              "start_char": 154,
              "end_char": 157,
              "context": "and branch-and-bound techniques under the name of CDP—the “composite decision process.”\nBecause most co"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "The Graph Traverser",
              "entity_type": "PERSON",
              "start_char": 335,
              "end_char": 354,
              "context": "ded heuristic search was an early research topic. The Graph Traverser (Doran and Michie, 1966), one of the earliest sea"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "Doran",
              "entity_type": "PERSON",
              "start_char": 356,
              "end_char": 361,
              "context": "was an early research topic. The Graph Traverser (Doran and Michie, 1966), one of the earliest search pro"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "Michie",
              "entity_type": "PERSON",
              "start_char": 366,
              "end_char": 372,
              "context": "ly research topic. The Graph Traverser (Doran and Michie, 1966), one of the earliest search programs, comm"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "Korf",
              "entity_type": "ORG",
              "start_char": 496,
              "end_char": 500,
              "context": "earching best-first up to the memory limit. IDA* (Korf, 1985b) was the first widely used length- optimal"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "IDA",
              "entity_type": "PERSON",
              "start_char": 680,
              "end_char": 683,
              "context": " been developed. An analysis of the efficiency of IDA\n*\nand of its difficulties with real-valued heuris"
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "Patrick",
              "entity_type": "GPE",
              "start_char": 749,
              "end_char": 756,
              "context": "fficulties with real-valued heuristics appears in Patrick\net al."
            },
            {
              "para_id": "chap3_para391",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 760,
              "end_char": 762,
              "context": "with real-valued heuristics appears in Patrick\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para392",
          "content": "(1992).",
          "sentence_count": 1,
          "char_count": 7,
          "prev_para_id": "chap3_para391",
          "next_para_id": "chap3_para393",
          "style_metadata": {
            "para_id": "chap3_para392",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para393",
          "content": "The original version of RBFS (Korf, 1993) is actually somewhat more complicated than the algorithm shown in\nFigure 3.22\n, which is actually closer to an independently developed algorithm called\niterative expansion\nor IE (Russell, 1992). RBFS uses a lower bound as well as the upper bound; the two algorithms behave identically with admissible heuristics, but RBFS expands nodes in best-first order even with an inadmissible heuristic. The idea of\nkeeping track of the best alternative path appeared earlier in Bratko’s (2009) elegant Prolog implementation of A* and in the DTA* algorithm (Russell and Wefald, 1991). The latter work also discusses metalevel state spaces and metalevel learning.",
          "sentence_count": 4,
          "char_count": 592,
          "prev_para_id": "chap3_para392",
          "next_para_id": "chap3_para394",
          "style_metadata": {
            "para_id": "chap3_para393",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 4
          },
          "terminology": {
            "original": 1,
            "version": 1,
            "rbfs": 3,
            "korf": 1,
            "complicated": 1,
            "algorithm": 4,
            "shown": 1,
            "figure": 1,
            "developed": 1,
            "called": 1,
            "iterative": 1,
            "expansion": 1,
            "russell": 2,
            "us": 1,
            "lower": 1,
            "bound": 2,
            "upper": 1,
            "behave": 1,
            "admissible": 1,
            "heuristic": 2,
            "expands": 1,
            "node": 1,
            "best-first": 1,
            "order": 1,
            "inadmissible": 1,
            "idea": 1,
            "keeping": 1,
            "track": 1,
            "alternative": 1,
            "path": 1,
            "appeared": 1,
            "earlier": 1,
            "bratko": 1,
            "elegant": 1,
            "prolog": 1,
            "implementation": 1,
            "dta": 1,
            "wefald": 1,
            "latter": 1,
            "work": 1,
            "discusses": 1,
            "metalevel": 2,
            "state": 1,
            "space": 1,
            "learning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para393",
              "entity_text": "RBFS",
              "entity_type": "ORG",
              "start_char": 24,
              "end_char": 28,
              "context": "The original version of RBFS (Korf, 1993) is actually somewhat more complicate"
            },
            {
              "para_id": "chap3_para393",
              "entity_text": "Bratko’s",
              "entity_type": "ORG",
              "start_char": 510,
              "end_char": 518,
              "context": " of the best alternative path appeared earlier in Bratko’s (2009) elegant Prolog implementation of A* and in"
            },
            {
              "para_id": "chap3_para393",
              "entity_text": "Russell and Wefald",
              "entity_type": "WORK_OF_ART",
              "start_char": 589,
              "end_char": 607,
              "context": "g implementation of A* and in the DTA* algorithm (Russell and Wefald, 1991). The latter work also discusses metalevel "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para394",
          "content": "The MA* algorithm appeared in Chakrabarti\net al.",
          "sentence_count": 1,
          "char_count": 42,
          "prev_para_id": "chap3_para393",
          "next_para_id": "chap3_para395",
          "style_metadata": {
            "para_id": "chap3_para394",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "appeared": 1,
            "chakrabarti": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para394",
              "entity_text": "Chakrabarti",
              "entity_type": "GPE",
              "start_char": 30,
              "end_char": 41,
              "context": "The MA* algorithm appeared in Chakrabarti\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para395",
          "content": "(1989). SMA*, or Simplified MA*, emerged from an attempt to implement MA* (Russell, 1992). Kaindl and Khorsand (1994) applied SMA* to produce a bidirectional search algorithm that was substantially faster than previous algorithms. Korf and Zhang (2000) describe a divide-and-conquer approach, and Zhou and Hansen (2002) introduce memory-bounded A* graph search and a strategy for switching to breadth-first search to increase memory-efficiency (Zhou and Hansen, 2006).",
          "sentence_count": 4,
          "char_count": 403,
          "prev_para_id": "chap3_para394",
          "next_para_id": "chap3_para396",
          "style_metadata": {
            "para_id": "chap3_para395",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 92,
            "sentence_count": 4
          },
          "terminology": {
            "sma": 2,
            "simplified": 1,
            "emerged": 1,
            "attempt": 1,
            "implement": 1,
            "russell": 1,
            "khorsand": 1,
            "applied": 1,
            "produce": 1,
            "bidirectional": 1,
            "search": 3,
            "algorithm": 2,
            "previous": 1,
            "korf": 1,
            "zhang": 1,
            "describe": 1,
            "divide-and-conquer": 1,
            "approach": 1,
            "zhou": 2,
            "hansen": 2,
            "introduce": 1,
            "memory-bounded": 1,
            "graph": 1,
            "strategy": 1,
            "switching": 1,
            "breadth-first": 1,
            "increase": 1,
            "memory-efficiency": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para395",
              "entity_text": "Simplified MA*",
              "entity_type": "PERSON",
              "start_char": 17,
              "end_char": 31,
              "context": "(1989). SMA*, or Simplified MA*, emerged from an attempt to implement MA* (Russel"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "MA*",
              "entity_type": "ORG",
              "start_char": 70,
              "end_char": 73,
              "context": "plified MA*, emerged from an attempt to implement MA* (Russell, 1992). Kaindl and Khorsand (1994) appli"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Khorsand",
              "entity_type": "GPE",
              "start_char": 102,
              "end_char": 110,
              "context": "empt to implement MA* (Russell, 1992). Kaindl and Khorsand (1994) applied SMA* to produce a bidirectional se"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "SMA",
              "entity_type": "ORG",
              "start_char": 126,
              "end_char": 129,
              "context": "ussell, 1992). Kaindl and Khorsand (1994) applied SMA* to produce a bidirectional search algorithm that"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Korf",
              "entity_type": "PERSON",
              "start_char": 231,
              "end_char": 235,
              "context": "as substantially faster than previous algorithms. Korf and Zhang (2000) describe a divide-and-conquer ap"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Zhang",
              "entity_type": "PERSON",
              "start_char": 240,
              "end_char": 245,
              "context": "ntially faster than previous algorithms. Korf and Zhang (2000) describe a divide-and-conquer approach, an"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Zhou",
              "entity_type": "PERSON",
              "start_char": 297,
              "end_char": 301,
              "context": "2000) describe a divide-and-conquer approach, and Zhou and Hansen (2002) introduce memory-bounded A* gra"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Hansen",
              "entity_type": "PERSON",
              "start_char": 306,
              "end_char": 312,
              "context": "cribe a divide-and-conquer approach, and Zhou and Hansen (2002) introduce memory-bounded A* graph search a"
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Zhou",
              "entity_type": "PERSON",
              "start_char": 445,
              "end_char": 449,
              "context": "eadth-first search to increase memory-efficiency (Zhou and Hansen, 2006)."
            },
            {
              "para_id": "chap3_para395",
              "entity_text": "Hansen",
              "entity_type": "PERSON",
              "start_char": 454,
              "end_char": 460,
              "context": "st search to increase memory-efficiency (Zhou and Hansen, 2006)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para396",
          "content": "The idea that admissible heuristics can be derived by problem relaxation appears in the seminal paper by Held and Karp (1970), who used the minimum-spanning-tree heuristic to solve the TSP. (See Exercise\n3.",
          "sentence_count": 2,
          "char_count": 175,
          "prev_para_id": "chap3_para395",
          "next_para_id": "chap3_para397",
          "style_metadata": {
            "para_id": "chap3_para396",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 2
          },
          "terminology": {
            "idea": 1,
            "admissible": 1,
            "heuristic": 2,
            "derived": 1,
            "problem": 1,
            "relaxation": 1,
            "appears": 1,
            "seminal": 1,
            "paper": 1,
            "held": 1,
            "karp": 1,
            "used": 1,
            "minimum-spanning-tree": 1,
            "solve": 1,
            "tsp": 1,
            "see": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para396",
              "entity_text": "Karp",
              "entity_type": "PERSON",
              "start_char": 114,
              "end_char": 118,
              "context": "laxation appears in the seminal paper by Held and Karp (1970), who used the minimum-spanning-tree heuris"
            },
            {
              "para_id": "chap3_para396",
              "entity_text": "TSP",
              "entity_type": "ORG",
              "start_char": 185,
              "end_char": 188,
              "context": " the minimum-spanning-tree heuristic to solve the TSP. (See Exercise\n3."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para397",
          "content": "MSTR\n.) The automation of the relaxation process was implemented successfully by Prieditis (1993). There is a growing literature on the application of machine learning to discover heuristic functions (Samadi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al.",
          "sentence_count": 3,
          "char_count": 223,
          "prev_para_id": "chap3_para396",
          "next_para_id": "chap3_para398",
          "style_metadata": {
            "para_id": "chap3_para397",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.67,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 3
          },
          "terminology": {
            "mstr": 1,
            "automation": 1,
            "relaxation": 1,
            "process": 1,
            "implemented": 1,
            "prieditis": 1,
            "growing": 1,
            "literature": 1,
            "application": 1,
            "machine": 1,
            "learning": 1,
            "discover": 1,
            "heuristic": 1,
            "function": 1,
            "samadi": 1,
            "al.": 2,
            "arfaee": 1,
            "thayer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para397",
              "entity_text": "Prieditis",
              "entity_type": "PERSON",
              "start_char": 81,
              "end_char": 90,
              "context": "elaxation process was implemented successfully by Prieditis (1993). There is a growing literature on the appl"
            },
            {
              "para_id": "chap3_para397",
              "entity_text": "Samadi",
              "entity_type": "PRODUCT",
              "start_char": 201,
              "end_char": 207,
              "context": "machine learning to discover heuristic functions (Samadi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al."
            },
            {
              "para_id": "chap3_para397",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 211,
              "end_char": 214,
              "context": "arning to discover heuristic functions (Samadi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al."
            },
            {
              "para_id": "chap3_para397",
              "entity_text": "Arfaee",
              "entity_type": "PERSON",
              "start_char": 222,
              "end_char": 228,
              "context": "iscover heuristic functions (Samadi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al."
            },
            {
              "para_id": "chap3_para397",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 232,
              "end_char": 235,
              "context": "uristic functions (Samadi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al."
            },
            {
              "para_id": "chap3_para397",
              "entity_text": "Thayer",
              "entity_type": "PERSON",
              "start_char": 243,
              "end_char": 249,
              "context": "ctions (Samadi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al."
            },
            {
              "para_id": "chap3_para397",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 253,
              "end_char": 255,
              "context": "madi\net al.,\n2008; Arfaee\net al.,\n2010; Thayer\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para398",
          "content": ", 2011; Lelis\net al.,\n2012).",
          "sentence_count": 1,
          "char_count": 25,
          "prev_para_id": "chap3_para397",
          "next_para_id": "chap3_para399",
          "style_metadata": {
            "para_id": "chap3_para398",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "lelis": 1,
            "al.": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para398",
              "entity_text": "Lelis",
              "entity_type": "GPE",
              "start_char": 8,
              "end_char": 13,
              "context": ", 2011; Lelis\net al.,\n2012)."
            },
            {
              "para_id": "chap3_para398",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 17,
              "end_char": 20,
              "context": ", 2011; Lelis\net al.,\n2012)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para399",
          "content": "The use of pattern databases to derive admissible heuristics is due to Gasser (1995) and Culberson and Schaeffer (1996, 1998); disjoint pattern databases are described by Korf and Felner (2002); a similar method using symbolic patterns is due to Edelkamp (2009). Felner\net al.",
          "sentence_count": 2,
          "char_count": 234,
          "prev_para_id": "chap3_para398",
          "next_para_id": "chap3_para400",
          "style_metadata": {
            "para_id": "chap3_para399",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 2
          },
          "terminology": {
            "use": 1,
            "pattern": 3,
            "database": 2,
            "derive": 1,
            "admissible": 1,
            "heuristic": 1,
            "due": 2,
            "culberson": 1,
            "schaeffer": 1,
            "disjoint": 1,
            "described": 1,
            "korf": 1,
            "felner": 2,
            "similar": 1,
            "method": 1,
            "using": 1,
            "symbolic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para399",
              "entity_text": "Gasser",
              "entity_type": "PERSON",
              "start_char": 71,
              "end_char": 77,
              "context": "tabases to derive admissible heuristics is due to Gasser (1995) and Culberson and Schaeffer (1996, 1998); "
            },
            {
              "para_id": "chap3_para399",
              "entity_text": "Culberson",
              "entity_type": "ORG",
              "start_char": 89,
              "end_char": 98,
              "context": "admissible heuristics is due to Gasser (1995) and Culberson and Schaeffer (1996, 1998); disjoint pattern data"
            },
            {
              "para_id": "chap3_para399",
              "entity_text": "Schaeffer",
              "entity_type": "PERSON",
              "start_char": 103,
              "end_char": 112,
              "context": "ristics is due to Gasser (1995) and Culberson and Schaeffer (1996, 1998); disjoint pattern databases are desc"
            },
            {
              "para_id": "chap3_para399",
              "entity_text": "Korf and Felner (2002",
              "entity_type": "ORG",
              "start_char": 171,
              "end_char": 192,
              "context": "998); disjoint pattern databases are described by Korf and Felner (2002); a similar method using symbolic patterns is due"
            },
            {
              "para_id": "chap3_para399",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 273,
              "end_char": 275,
              "context": "lic patterns is due to Edelkamp (2009). Felner\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para400",
          "content": "(2007) show how to compress pattern databases to save space. The probabilistic interpretation of heuristics was investigated by Pearl (1984) and Hansson and Mayer (1989).",
          "sentence_count": 2,
          "char_count": 146,
          "prev_para_id": "chap3_para399",
          "next_para_id": "chap3_para401",
          "style_metadata": {
            "para_id": "chap3_para400",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.03,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "show": 1,
            "compress": 1,
            "pattern": 1,
            "database": 1,
            "save": 1,
            "space": 1,
            "probabilistic": 1,
            "interpretation": 1,
            "heuristic": 1,
            "investigated": 1,
            "pearl": 1,
            "hansson": 1,
            "mayer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para400",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 128,
              "end_char": 133,
              "context": " interpretation of heuristics was investigated by Pearl (1984) and Hansson and Mayer (1989)."
            },
            {
              "para_id": "chap3_para400",
              "entity_text": "Hansson",
              "entity_type": "PERSON",
              "start_char": 145,
              "end_char": 152,
              "context": "f heuristics was investigated by Pearl (1984) and Hansson and Mayer (1989)."
            },
            {
              "para_id": "chap3_para400",
              "entity_text": "Mayer",
              "entity_type": "PERSON",
              "start_char": 157,
              "end_char": 162,
              "context": " was investigated by Pearl (1984) and Hansson and Mayer (1989)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para401",
          "content": "Pearl’s (1984)\nHeuristics\nand Edelkamp and Schrödl’s (2012)\nHeuristic Search\nare influential textbooks on search. Papers about new search algorithms appear at the International Symposium on Combinatorial Search (SoCS) and the International Conference on Automated Planning and Scheduling (ICAPS), as well as in general AI conferences such as AAAI and IJCAI, and journals such as\nArtificial Intelligence\nand\nJournal of the ACM.",
          "sentence_count": 2,
          "char_count": 372,
          "prev_para_id": "chap3_para400",
          "next_para_id": "chap3_para402",
          "style_metadata": {
            "para_id": "chap3_para401",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 2
          },
          "terminology": {
            "pearl": 1,
            "heuristic": 2,
            "edelkamp": 1,
            "schrödl": 1,
            "search": 4,
            "influential": 1,
            "textbook": 1,
            "paper": 1,
            "new": 1,
            "algorithm": 1,
            "appear": 1,
            "international": 2,
            "symposium": 1,
            "combinatorial": 1,
            "socs": 1,
            "conference": 2,
            "automated": 1,
            "planning": 1,
            "scheduling": 1,
            "icaps": 1,
            "general": 1,
            "aaai": 1,
            "ijcai": 1,
            "journal": 2,
            "artificial": 1,
            "intelligence": 1,
            "acm": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para401",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 5,
              "context": "Pearl’s (1984)\nHeuristics\nand Edelkamp and Schrödl’s (2"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "Edelkamp and Schrödl’s",
              "entity_type": "WORK_OF_ART",
              "start_char": 30,
              "end_char": 52,
              "context": "Pearl’s (1984)\nHeuristics\nand Edelkamp and Schrödl’s (2012)\nHeuristic Search\nare influential textbooks"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "Heuristic Search",
              "entity_type": "ORG",
              "start_char": 60,
              "end_char": 76,
              "context": "984)\nHeuristics\nand Edelkamp and Schrödl’s (2012)\nHeuristic Search\nare influential textbooks on search. Papers about"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "the International Conference on Automated Planning and Scheduling",
              "entity_type": "ORG",
              "start_char": 222,
              "end_char": 287,
              "context": "onal Symposium on Combinatorial Search (SoCS) and the International Conference on Automated Planning and Scheduling (ICAPS), as well as in general AI conferences suc"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "ICAPS",
              "entity_type": "ORG",
              "start_char": 289,
              "end_char": 294,
              "context": " Conference on Automated Planning and Scheduling (ICAPS), as well as in general AI conferences such as AA"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "AAAI",
              "entity_type": "ORG",
              "start_char": 342,
              "end_char": 346,
              "context": "PS), as well as in general AI conferences such as AAAI and IJCAI, and journals such as\nArtificial Intell"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "IJCAI",
              "entity_type": "ORG",
              "start_char": 351,
              "end_char": 356,
              "context": "ell as in general AI conferences such as AAAI and IJCAI, and journals such as\nArtificial Intelligence\nand"
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "Artificial Intelligence",
              "entity_type": "ORG",
              "start_char": 379,
              "end_char": 402,
              "context": "nces such as AAAI and IJCAI, and journals such as\nArtificial Intelligence\nand\nJournal of the ACM."
            },
            {
              "para_id": "chap3_para401",
              "entity_text": "Journal of the ACM",
              "entity_type": "ORG",
              "start_char": 407,
              "end_char": 425,
              "context": " and journals such as\nArtificial Intelligence\nand\nJournal of the ACM."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para402",
          "content": "1\nWe are assuming that most readers are in the same position and can easily imagine themselves to be as clueless as our agent. We apologize to Romanian readers who are unable to take advantage of this pedagogical device.",
          "sentence_count": 2,
          "char_count": 183,
          "prev_para_id": "chap3_para401",
          "next_para_id": "chap3_para403",
          "style_metadata": {
            "para_id": "chap3_para402",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "assuming": 1,
            "reader": 2,
            "position": 1,
            "imagine": 1,
            "clueless": 1,
            "agent": 1,
            "apologize": 1,
            "romanian": 1,
            "unable": 1,
            "take": 1,
            "advantage": 1,
            "pedagogical": 1,
            "device": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para403",
          "content": "2\nFor problems with an infinite number of actions we would need techniques that go beyond this chapter.",
          "sentence_count": 1,
          "char_count": 87,
          "prev_para_id": "chap3_para402",
          "next_para_id": "chap3_para404",
          "style_metadata": {
            "para_id": "chap3_para403",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "problem": 1,
            "infinite": 1,
            "number": 1,
            "action": 1,
            "need": 1,
            "technique": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para404",
          "content": "3\nIn any problem with a cycle of net negative cost, the cost-optimal solution is to go around that cycle an infinite number of times. The Bellman–Ford and Floyd–Warshall algorithms (not covered here) handle negative-cost actions, as long as there are no negative cycles. It is easy to accommodate zero-cost actions, as long as the number of consecutive zero-cost actions is bounded. For example, we might have a robot where there is a cost to move, but zero cost to rotate 90\no\n; the algorithms in this chapter can handle this as long as no more than three consecutive 90\no\nturns are allowed. There is also a complication with problems that have an infinite number of arbitrarily small action costs. Consider a version of Zeno’s paradox where there is an action to move half way to the goal, at a cost of half of the previous move. This problem has no solution with a finite number of actions, but to prevent a search from taking an unbounded number of actions without quite reaching the goal, we can require that all action costs be at least\nϵ\n, for some small positive value\nϵ\n.",
          "sentence_count": 7,
          "char_count": 894,
          "prev_para_id": "chap3_para403",
          "next_para_id": "chap3_para405",
          "style_metadata": {
            "para_id": "chap3_para404",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.57,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 214,
            "sentence_count": 7
          },
          "terminology": {
            "problem": 3,
            "cycle": 3,
            "net": 1,
            "negative": 2,
            "cost": 6,
            "cost-optimal": 1,
            "solution": 2,
            "infinite": 2,
            "number": 5,
            "time": 1,
            "bellman–ford": 1,
            "floyd–warshall": 1,
            "algorithm": 2,
            "covered": 1,
            "handle": 2,
            "negative-cost": 1,
            "action": 8,
            "easy": 1,
            "accommodate": 1,
            "zero-cost": 2,
            "long": 1,
            "consecutive": 2,
            "bounded": 1,
            "example": 1,
            "robot": 1,
            "move": 3,
            "rotate": 1,
            "chapter": 1,
            "turn": 1,
            "allowed": 1,
            "complication": 1,
            "small": 2,
            "consider": 1,
            "version": 1,
            "zeno": 1,
            "paradox": 1,
            "way": 1,
            "goal": 2,
            "half": 1,
            "previous": 1,
            "finite": 1,
            "prevent": 1,
            "search": 1,
            "taking": 1,
            "unbounded": 1,
            "reaching": 1,
            "require": 1,
            "least": 1,
            "positive": 1,
            "value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para404",
              "entity_text": "Ford",
              "entity_type": "ORG",
              "start_char": 146,
              "end_char": 150,
              "context": "at cycle an infinite number of times. The Bellman–Ford and Floyd–Warshall algorithms (not covered here) "
            },
            {
              "para_id": "chap3_para404",
              "entity_text": "Floyd–Warshall",
              "entity_type": "PERSON",
              "start_char": 155,
              "end_char": 169,
              "context": "an infinite number of times. The Bellman–Ford and Floyd–Warshall algorithms (not covered here) handle negative-cos"
            },
            {
              "para_id": "chap3_para404",
              "entity_text": "Zeno’s",
              "entity_type": "PERSON",
              "start_char": 722,
              "end_char": 728,
              "context": "trarily small action costs. Consider a version of Zeno’s paradox where there is an action to move half way"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para405",
          "content": "4\nSee\nSection 11.4\n.",
          "sentence_count": 1,
          "char_count": 19,
          "prev_para_id": "chap3_para404",
          "next_para_id": "chap3_para406",
          "style_metadata": {
            "para_id": "chap3_para405",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 5,
            "sentence_count": 1
          },
          "terminology": {
            "see": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para406",
          "content": "5\nSome authors call the frontier the\nopen list\n, which is both geographically less evocative and computationally less appropriate, because a queue is more efficient than a list here. Those authors use the term\nclosed list\nto refer to the set of previously expanded nodes, which in our terminology would be the\nreached\nnodes minus the\nfrontier.",
          "sentence_count": 2,
          "char_count": 294,
          "prev_para_id": "chap3_para405",
          "next_para_id": "chap3_para407",
          "style_metadata": {
            "para_id": "chap3_para406",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 2
          },
          "terminology": {
            "author": 2,
            "call": 1,
            "frontier": 2,
            "open": 1,
            "list": 3,
            "evocative": 1,
            "appropriate": 1,
            "queue": 1,
            "efficient": 1,
            "use": 1,
            "term": 1,
            "closed": 1,
            "refer": 1,
            "set": 1,
            "expanded": 1,
            "node": 2,
            "terminology": 1,
            "reached": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para407",
          "content": "6\nWe say “tree-like search” because the state space is still the same graph no matter how we search it; we are just choosing to treat it\nas if\nit were a tree, with only one path from each node back to the root.",
          "sentence_count": 1,
          "char_count": 170,
          "prev_para_id": "chap3_para406",
          "next_para_id": "chap3_para408",
          "style_metadata": {
            "para_id": "chap3_para407",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 49,
            "sentence_count": 1
          },
          "terminology": {
            "say": 1,
            "tree-like": 1,
            "search": 2,
            "state": 1,
            "space": 1,
            "graph": 1,
            "matter": 1,
            "choosing": 1,
            "treat": 1,
            "tree": 1,
            "path": 1,
            "node": 1,
            "root": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para407",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 188,
              "end_char": 192,
              "context": "s if\nit were a tree, with only one path from each node back to the root."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para408",
          "content": "7\nSome authors use the term “admissibility” for the property of finding the lowest-cost solution, and some use just “optimality,” but that can be confused with other types of optimality.",
          "sentence_count": 1,
          "char_count": 158,
          "prev_para_id": "chap3_para407",
          "next_para_id": "chap3_para409",
          "style_metadata": {
            "para_id": "chap3_para408",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 1
          },
          "terminology": {
            "author": 1,
            "use": 2,
            "term": 1,
            "admissibility": 1,
            "property": 1,
            "finding": 1,
            "lowest-cost": 1,
            "solution": 1,
            "optimality": 2,
            "confused": 1,
            "type": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para409",
          "content": "8\nHere, and throughout the book, the “star” in\nC\n* means an optimal value for C.",
          "sentence_count": 1,
          "char_count": 67,
          "prev_para_id": "chap3_para408",
          "next_para_id": "chap3_para410",
          "style_metadata": {
            "para_id": "chap3_para409",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 1
          },
          "terminology": {
            "book": 1,
            "star": 1,
            "mean": 1,
            "optimal": 1,
            "value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para410",
          "content": "9\nIn our implementation, the\nreached\ndata structure supports a query asking whether a given state is a member, and the frontier data structure (a priority queue) does not, so we check for a collision using\nreached;\nbut conceptually we are asking if the two frontiers have met up. The implementation can be extended to handle multiple goal states by loading the node for each goal state into the backwards frontier and backwards reached table.",
          "sentence_count": 2,
          "char_count": 373,
          "prev_para_id": "chap3_para409",
          "next_para_id": "chap3_para411",
          "style_metadata": {
            "para_id": "chap3_para410",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 2
          },
          "terminology": {
            "implementation": 2,
            "reached": 3,
            "data": 2,
            "structure": 2,
            "support": 1,
            "asking": 2,
            "given": 1,
            "state": 3,
            "member": 1,
            "frontier": 2,
            "priority": 1,
            "check": 1,
            "collision": 1,
            "using": 1,
            "met": 1,
            "extended": 1,
            "handle": 1,
            "multiple": 1,
            "goal": 2,
            "loading": 1,
            "node": 1,
            "backwards": 2,
            "table": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para411",
          "content": "10\nIt may seem odd that the heuristic function operates on a node, when all it really needs is the node’s state. It is traditional to use\nh\n(\nn\n) rather than\nh\n(\ns\n) to be consistent with the evaluation function\nf\n(\nn\n) and the path cost\ng\n(\nn\n)\n.",
          "sentence_count": 2,
          "char_count": 209,
          "prev_para_id": "chap3_para410",
          "next_para_id": "chap3_para412",
          "style_metadata": {
            "para_id": "chap3_para411",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 2
          },
          "terminology": {
            "seem": 1,
            "odd": 1,
            "heuristic": 1,
            "function": 2,
            "operates": 1,
            "need": 1,
            "node": 1,
            "state": 1,
            "traditional": 1,
            "use": 1,
            "consistent": 1,
            "evaluation": 1,
            "path": 1,
            "cost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para411",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 61,
              "end_char": 65,
              "context": "eem odd that the heuristic function operates on a node, when all it really needs is the node’s state. It"
            },
            {
              "para_id": "chap3_para411",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 99,
              "end_char": 103,
              "context": "erates on a node, when all it really needs is the node’s state. It is traditional to use\nh\n(\nn\n) rather "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para412",
          "content": "11\nAgain, assuming all action costs are >\nϵ\n> 0, and the state space either has a solution or is finite.",
          "sentence_count": 1,
          "char_count": 86,
          "prev_para_id": "chap3_para411",
          "next_para_id": "chap3_para413",
          "style_metadata": {
            "para_id": "chap3_para412",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "assuming": 1,
            "action": 1,
            "cost": 1,
            "state": 1,
            "space": 1,
            "solution": 1,
            "finite": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para413",
          "content": "12\nTechnically, we say “strictly monotonic” for costs that always increase, and “monotonic” for costs that never decrease, but might remain the same.",
          "sentence_count": 1,
          "char_count": 128,
          "prev_para_id": "chap3_para412",
          "next_para_id": "chap3_para414",
          "style_metadata": {
            "para_id": "chap3_para413",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "say": 1,
            "monotonic": 2,
            "cost": 2,
            "increase": 1,
            "decrease": 1,
            "remain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para414",
          "content": "13\nIn fact, the term “monotonic heuristic” is a synonym for “consistent heuristic.” The two ideas were developed independently, and then it was proved that they are equivalent (Pearl, 1984).",
          "sentence_count": 1,
          "char_count": 162,
          "prev_para_id": "chap3_para413",
          "next_para_id": "chap3_para415",
          "style_metadata": {
            "para_id": "chap3_para414",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 9.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.05,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 1
          },
          "terminology": {
            "fact": 1,
            "term": 1,
            "monotonic": 1,
            "heuristic": 1,
            "synonym": 1,
            "consistent": 1,
            "heuristic.": 1,
            "idea": 1,
            "developed": 1,
            "proved": 1,
            "equivalent": 1,
            "pearl": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap3_para414",
              "entity_text": "Pearl",
              "entity_type": "GPE",
              "start_char": 177,
              "end_char": 182,
              "context": " and then it was proved that they are equivalent (Pearl, 1984)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para415",
          "content": "14\nIn\nChapters 8\nand\n11\n, we describe formal languages suitable for this task; with formal descriptions that can be manipulated, the construction of relaxed problems can be automated. For now, we use English.",
          "sentence_count": 2,
          "char_count": 179,
          "prev_para_id": "chap3_para414",
          "next_para_id": "chap3_para416",
          "style_metadata": {
            "para_id": "chap3_para415",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 2
          },
          "terminology": {
            "chapter": 1,
            "describe": 1,
            "formal": 2,
            "language": 1,
            "suitable": 1,
            "task": 1,
            "description": 1,
            "manipulated": 1,
            "construction": 1,
            "relaxed": 1,
            "problem": 1,
            "automated": 1,
            "use": 1,
            "english": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para416",
          "content": "15\nBy working backward from the goal, the exact solution cost of every instance encountered is immediately available. This is an example of\ndynamic programming\n, which we discuss further in\nChapter 16\n.",
          "sentence_count": 2,
          "char_count": 174,
          "prev_para_id": "chap3_para415",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap3_para416",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 2
          },
          "terminology": {
            "working": 1,
            "backward": 1,
            "goal": 1,
            "exact": 1,
            "solution": 1,
            "cost": 1,
            "instance": 1,
            "encountered": 1,
            "available": 1,
            "example": 1,
            "dynamic": 1,
            "programming": 1,
            "discus": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap3_para417",
          "content": "16\nLandmark points are sometimes called “pivots” or “anchors.”",
          "sentence_count": 1,
          "char_count": 55,
          "prev_para_id": "chap3_para416",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap3_para417",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "landmark": 1,
            "point": 1,
            "called": 1,
            "pivot": 1,
            "anchor": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        }
      ],
      "para_count": 417,
      "char_count": 129519
    },
    {
      "chapter_num": 4,
      "title": "Chapter 4: CHAPTER",
      "paragraphs": [
        {
          "para_id": "chap4_para1",
          "content": "4\nSEARCH IN COMPLEX ENVIRONMENTS\nIn which we relax the simplifying assumptions of the previous chapter, to get closer to the real world.",
          "sentence_count": 1,
          "char_count": 116,
          "prev_para_id": "None",
          "next_para_id": "chap4_para2",
          "style_metadata": {
            "para_id": "chap4_para1",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "search": 1,
            "complex": 1,
            "environment": 1,
            "relax": 1,
            "simplifying": 1,
            "assumption": 1,
            "previous": 1,
            "chapter": 1,
            "get": 1,
            "closer": 1,
            "real": 1,
            "world": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para2",
          "content": "Chapter 3\naddressed problems in fully observable, deterministic, static, known environments where the solution is a sequence of actions. In this chapter, we relax those constraints. We begin with the problem of finding a good state without worrying about the path to get there, covering both discrete (\nSection 4.1\n) and continuous (\nSection 4.2\n) states. Then we relax the assumptions of determinism (\nSection 4.3\n) and observability (\nSection 4.4\n). In a nondeterministic world, the agent will need a conditional plan and carry out different actions depending on what it observes—for example, stopping if the light is red and going if it is green. With partial observability, the agent will also need to keep track of the possible states it might be in. Finally,\nSection 4.5\nguides the agent through an unknown space that it must learn as it goes, using\nonline search\n.",
          "sentence_count": 7,
          "char_count": 736,
          "prev_para_id": "chap4_para1",
          "next_para_id": "chap4_para3",
          "style_metadata": {
            "para_id": "chap4_para2",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.57,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 165,
            "sentence_count": 7
          },
          "terminology": {
            "chapter": 2,
            "addressed": 1,
            "problem": 2,
            "observable": 1,
            "deterministic": 1,
            "static": 1,
            "known": 1,
            "environment": 1,
            "solution": 1,
            "sequence": 1,
            "action": 2,
            "relax": 2,
            "constraint": 1,
            "begin": 1,
            "finding": 1,
            "good": 1,
            "state": 3,
            "worrying": 1,
            "path": 1,
            "get": 1,
            "covering": 1,
            "discrete": 1,
            "section": 5,
            "continuous": 1,
            "assumption": 1,
            "determinism": 1,
            "observability": 2,
            "nondeterministic": 1,
            "world": 1,
            "agent": 3,
            "need": 2,
            "conditional": 1,
            "plan": 1,
            "carry": 1,
            "different": 1,
            "depending": 1,
            "observes—for": 1,
            "example": 1,
            "stopping": 1,
            "light": 1,
            "red": 1,
            "going": 1,
            "green": 1,
            "partial": 1,
            "keep": 1,
            "track": 1,
            "possible": 1,
            "guide": 1,
            "unknown": 1,
            "space": 1,
            "learn": 1,
            "go": 1,
            "using": 1,
            "online": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para3",
          "content": "4.1Local Search and Optimization Problems\n4.1\nLocal Search and Optimization Problems\nIn the search problems of\nChapter 3\nwe wanted to find paths through the search space, such as a path from Arad to Bucharest. But sometimes we care only about the final state, not the path to get there. For example, in the 8-queens problem (\nFigure 4.3\n), we care only about finding a valid final configuration of 8 queens (because if you know the configuration, it is trivial to reconstruct the steps that created it). This is also true for many important applications such as integrated-circuit design, factory floor layout, job shop scheduling, automatic programming, telecommunications network optimization, crop planning, and portfolio management.",
          "sentence_count": 4,
          "char_count": 628,
          "prev_para_id": "chap4_para2",
          "next_para_id": "chap4_para4",
          "style_metadata": {
            "para_id": "chap4_para3",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 133,
            "sentence_count": 4
          },
          "terminology": {
            "4.1local": 1,
            "search": 4,
            "optimization": 3,
            "problem": 4,
            "local": 1,
            "chapter": 1,
            "wanted": 1,
            "find": 1,
            "path": 3,
            "space": 1,
            "arad": 1,
            "bucharest": 1,
            "care": 2,
            "final": 2,
            "state": 1,
            "get": 1,
            "example": 1,
            "8-queens": 1,
            "figure": 1,
            "finding": 1,
            "valid": 1,
            "configuration": 2,
            "queen": 1,
            "know": 1,
            "trivial": 1,
            "reconstruct": 1,
            "step": 1,
            "created": 1,
            "true": 1,
            "many": 1,
            "important": 1,
            "application": 1,
            "integrated-circuit": 1,
            "design": 1,
            "factory": 1,
            "floor": 1,
            "job": 1,
            "shop": 1,
            "scheduling": 1,
            "automatic": 1,
            "programming": 1,
            "telecommunication": 1,
            "network": 1,
            "crop": 1,
            "planning": 1,
            "portfolio": 1,
            "management": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para3",
              "entity_text": "Search and Optimization Problems",
              "entity_type": "ORG",
              "start_char": 9,
              "end_char": 41,
              "context": "4.1Local Search and Optimization Problems\n4.1\nLocal Search and Optimization Problems\nIn the"
            },
            {
              "para_id": "chap4_para3",
              "entity_text": "Local Search and Optimization Problems",
              "entity_type": "ORG",
              "start_char": 46,
              "end_char": 84,
              "context": "4.1Local Search and Optimization Problems\n4.1\nLocal Search and Optimization Problems\nIn the search problems of\nChapter 3\nwe wanted to "
            },
            {
              "para_id": "chap4_para3",
              "entity_text": "Arad",
              "entity_type": "GPE",
              "start_char": 191,
              "end_char": 195,
              "context": "ths through the search space, such as a path from Arad to Bucharest. But sometimes we care only about th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para4",
          "content": "Local search\nalgorithms operate by searching from a start state to neighboring states, without keeping track of the paths, nor the set of states that have been reached. That means they are not systematic—they might never explore a portion of the search space where a solution actually resides. However, they have two key advantages: (1) they use very little memory; and (2) they can often find reasonable solutions in large or infinite state spaces for which systematic algorithms are unsuitable.",
          "sentence_count": 3,
          "char_count": 418,
          "prev_para_id": "chap4_para3",
          "next_para_id": "chap4_para5",
          "style_metadata": {
            "para_id": "chap4_para4",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 30.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 92,
            "sentence_count": 3
          },
          "terminology": {
            "local": 1,
            "search": 2,
            "algorithm": 2,
            "operate": 1,
            "searching": 1,
            "start": 1,
            "state": 4,
            "neighboring": 1,
            "keeping": 1,
            "track": 1,
            "path": 1,
            "set": 1,
            "reached": 1,
            "mean": 1,
            "systematic—they": 1,
            "explore": 1,
            "portion": 1,
            "space": 2,
            "solution": 2,
            "resides": 1,
            "key": 1,
            "advantage": 1,
            "use": 1,
            "little": 1,
            "memory": 1,
            "find": 1,
            "reasonable": 1,
            "large": 1,
            "infinite": 1,
            "systematic": 1,
            "unsuitable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para5",
          "content": "Local search algorithms can also solve\noptimization problems\n, in which the aim is to find the best state according to an\nobjective function\n.",
          "sentence_count": 1,
          "char_count": 122,
          "prev_para_id": "chap4_para4",
          "next_para_id": "chap4_para6",
          "style_metadata": {
            "para_id": "chap4_para5",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "local": 1,
            "search": 1,
            "algorithm": 1,
            "solve": 1,
            "optimization": 1,
            "problem": 1,
            "aim": 1,
            "find": 1,
            "best": 1,
            "state": 1,
            "according": 1,
            "objective": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para6",
          "content": "To understand local search, consider the states of a problem laid out in a\nstate-space landscape\n, as shown in\nFigure 4.1\n. Each point (state) in the landscape has an “elevation,” defined by the value of the objective function. If elevation corresponds to an objective function,\nthen the aim is to find the highest peak—a\nglobal maximum\n—and we call the process\nhill climbing\n. If elevation corresponds to cost, then the aim is to find the lowest valley—a\nglobal minimum\n—and we call it\ngradient descent\n.",
          "sentence_count": 4,
          "char_count": 430,
          "prev_para_id": "chap4_para5",
          "next_para_id": "chap4_para7",
          "style_metadata": {
            "para_id": "chap4_para6",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 98,
            "sentence_count": 4
          },
          "terminology": {
            "local": 1,
            "search": 1,
            "consider": 1,
            "state": 2,
            "problem": 1,
            "laid": 1,
            "state-space": 1,
            "landscape": 2,
            "shown": 1,
            "figure": 1,
            "point": 1,
            "elevation": 3,
            "defined": 1,
            "value": 1,
            "objective": 2,
            "function": 2,
            "corresponds": 2,
            "aim": 2,
            "find": 2,
            "highest": 1,
            "peak—a": 1,
            "global": 2,
            "maximum": 1,
            "—and": 2,
            "call": 2,
            "process": 1,
            "hill": 1,
            "climbing": 1,
            "cost": 1,
            "lowest": 1,
            "valley—a": 1,
            "minimum": 1,
            "gradient": 1,
            "descent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para7",
          "content": "Description\nThe curve starts from the right of the origin and rises toward the upper right until a mid-left point, and remains horizontally constant for a small distance. The constant area is labeled shoulder. The curve further rises and forms a peak labeled global maximum. The curve further drops to its minimum, rises toward the upper right, and forms a small peak labeled local maximum. A point is marked on the rising path toward this peak and is labeled current state. The curve further drops and forms a trough, then again rises, and forms a flat peak, labeled \"flat\" local maximum. The curve then further drops toward the lower right and ends at the lower right of the graph. The heights of the peak decrease from global maximum to flat local maximum.",
          "sentence_count": 8,
          "char_count": 629,
          "prev_para_id": "chap4_para6",
          "next_para_id": "chap4_para8",
          "style_metadata": {
            "para_id": "chap4_para7",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 148,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "curve": 5,
            "start": 1,
            "right": 5,
            "origin": 1,
            "rise": 4,
            "upper": 2,
            "mid-left": 1,
            "point": 2,
            "remains": 1,
            "constant": 2,
            "small": 2,
            "distance": 1,
            "area": 1,
            "labeled": 5,
            "shoulder": 1,
            "form": 4,
            "peak": 5,
            "global": 2,
            "maximum": 5,
            "drop": 3,
            "minimum": 1,
            "local": 3,
            "marked": 1,
            "rising": 1,
            "path": 1,
            "current": 1,
            "state": 1,
            "trough": 1,
            "flat": 3,
            "lower": 2,
            "end": 1,
            "graph": 1,
            "height": 1,
            "decrease": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para8",
          "content": "×\nFigure 4.1\nA one-dimensional state-space landscape in which elevation corresponds to the objective function. The aim is to find the global maximum.",
          "sentence_count": 2,
          "char_count": 129,
          "prev_para_id": "chap4_para7",
          "next_para_id": "chap4_para9",
          "style_metadata": {
            "para_id": "chap4_para8",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "one-dimensional": 1,
            "state-space": 1,
            "landscape": 1,
            "elevation": 1,
            "corresponds": 1,
            "objective": 1,
            "function": 1,
            "aim": 1,
            "find": 1,
            "global": 1,
            "maximum": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para9",
          "content": "4.1.1\nHill-climbing search\nThe\nhill-climbing\nsearch algorithm is shown in\nFigure 4.2\n. It keeps track of one current state and on each iteration moves to the neighboring state with highest value—that is, it heads in the direction that provides the\nsteepest ascent\n. It terminates when it reaches a “peak” where no neighbor has a higher value. Hill climbing does not look ahead beyond the immediate neighbors of the current state. This resembles trying to find the top of Mount Everest in a thick fog while suffering from amnesia. Note that one way to use hill-climbing search is to use the negative of a heuristic cost function as the objective function; that will climb locally to the state with smallest heuristic distance to the goal.",
          "sentence_count": 6,
          "char_count": 620,
          "prev_para_id": "chap4_para8",
          "next_para_id": "chap4_para10",
          "style_metadata": {
            "para_id": "chap4_para9",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 6
          },
          "terminology": {
            "hill-climbing": 3,
            "search": 3,
            "algorithm": 1,
            "shown": 1,
            "figure": 1,
            "keep": 1,
            "current": 2,
            "state": 4,
            "iteration": 1,
            "move": 1,
            "neighboring": 1,
            "highest": 1,
            "head": 1,
            "direction": 1,
            "provides": 1,
            "steepest": 1,
            "ascent": 1,
            "terminates": 1,
            "reach": 1,
            "peak": 1,
            "neighbor": 2,
            "higher": 1,
            "value": 1,
            "climbing": 1,
            "look": 1,
            "immediate": 1,
            "resembles": 1,
            "trying": 1,
            "find": 1,
            "top": 1,
            "mount": 1,
            "everest": 1,
            "thick": 1,
            "fog": 1,
            "suffering": 1,
            "amnesia": 1,
            "note": 1,
            "way": 1,
            "use": 1,
            "negative": 1,
            "heuristic": 2,
            "cost": 1,
            "function": 2,
            "objective": 1,
            "climb": 1,
            "smallest": 1,
            "distance": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para9",
              "entity_text": "Hill",
              "entity_type": "PERSON",
              "start_char": 6,
              "end_char": 10,
              "context": "4.1.1\nHill-climbing search\nThe\nhill-climbing\nsearch algorith"
            },
            {
              "para_id": "chap4_para9",
              "entity_text": "Hill",
              "entity_type": "PERSON",
              "start_char": 343,
              "end_char": 347,
              "context": "es a “peak” where no neighbor has a higher value. Hill climbing does not look ahead beyond the immediate"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para10",
          "content": "Description\nThe chessboard positions are usually named in such a way that the columns are named from “a” to h, and the rows are named from 1 to 8. The queens are placed at the following positions. “a” 1, b 6, c 2, d 5, e 7, f 4, g 8, and h 3.",
          "sentence_count": 3,
          "char_count": 190,
          "prev_para_id": "chap4_para9",
          "next_para_id": "chap4_para11",
          "style_metadata": {
            "para_id": "chap4_para10",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 3
          },
          "terminology": {
            "description": 1,
            "chessboard": 1,
            "position": 2,
            "named": 3,
            "way": 1,
            "column": 1,
            "row": 1,
            "queen": 1,
            "placed": 1,
            "following": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para11",
          "content": "×\nFigure 4.2\nThe hill-climbing search algorithm, which is the most basic local search technique. At each step the current node is replaced by the best neighbor.",
          "sentence_count": 2,
          "char_count": 136,
          "prev_para_id": "chap4_para10",
          "next_para_id": "chap4_para12",
          "style_metadata": {
            "para_id": "chap4_para11",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.033,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "hill-climbing": 1,
            "search": 2,
            "algorithm": 1,
            "basic": 1,
            "local": 1,
            "technique": 1,
            "step": 1,
            "current": 1,
            "node": 1,
            "replaced": 1,
            "best": 1,
            "neighbor": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para11",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 122,
              "end_char": 126,
              "context": " local search technique. At each step the current node is replaced by the best neighbor."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para12",
          "content": "To illustrate hill climbing, we will use the\n8-queens problem\n(\nFigure 4.3\n). We will use a\ncomplete-state formulation\n, which means that every state has all the components of a solution, but they might not all be in the right place. In this case every state has 8 queens\non the board, one per column. The initial state is chosen at random, and the successors of a state are all possible states generated by moving a single queen to another square in the same column (so each state has 8 × 7 = 56 successors). The heuristic cost function\nh\nis the number of pairs of queens that are attacking each other; this will be zero only for solutions. (It counts as an attack if two pieces are in the same line, even if there is an intervening piece between them.)\nFigure 4.3(b)\nshows a state that has\nh\n= 17. The figure also shows the\nh\nvalues of all its successors.",
          "sentence_count": 8,
          "char_count": 709,
          "prev_para_id": "chap4_para11",
          "next_para_id": "chap4_para13",
          "style_metadata": {
            "para_id": "chap4_para12",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 184,
            "sentence_count": 8
          },
          "terminology": {
            "illustrate": 1,
            "hill": 1,
            "climbing": 1,
            "use": 2,
            "8-queens": 1,
            "problem": 1,
            "figure": 3,
            "complete-state": 1,
            "formulation": 1,
            "mean": 1,
            "state": 7,
            "component": 1,
            "solution": 2,
            "place": 1,
            "case": 1,
            "queen": 3,
            "board": 1,
            "column": 2,
            "initial": 1,
            "chosen": 1,
            "random": 1,
            "successor": 3,
            "possible": 1,
            "generated": 1,
            "moving": 1,
            "single": 1,
            "square": 1,
            "heuristic": 1,
            "cost": 1,
            "function": 1,
            "number": 1,
            "pair": 1,
            "attacking": 1,
            "count": 1,
            "attack": 1,
            "piece": 2,
            "line": 1,
            "intervening": 1,
            "show": 2,
            "value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para13",
          "content": "Description\nThe board shows the value of h for each possible successor obtained by moving a queen within its column. The values on each row are as follows. Row 1: 14, 14, 13, 17, 12, 14, 12, 18. Row 2: 18, 14, queen, 15, 15, 14, queen, 16. Row 3: 17, queen, 16, 18, 15, queen, 15, queen. Row 4: queen, 14, 17, 15, queen, 14, 16, 16. Row 5: 15, 14, 14, queen, 13, 16, 13 16. Row 6: 14, 12, 18, 13, 15, 12, 14, 14. Row 7: 14, 16, 13, 15, 12, 14, 12, 16. Row 8: 18, 12, 14, 13, 13, 12, 14, 14.",
          "sentence_count": 10,
          "char_count": 384,
          "prev_para_id": "chap4_para12",
          "next_para_id": "chap4_para14",
          "style_metadata": {
            "para_id": "chap4_para13",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 175,
            "sentence_count": 10
          },
          "terminology": {
            "description": 1,
            "board": 1,
            "show": 1,
            "value": 2,
            "possible": 1,
            "successor": 1,
            "obtained": 1,
            "moving": 1,
            "queen": 9,
            "column": 1,
            "row": 9,
            "follows": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para14",
          "content": "×\nFigure 4.3\n(a) The 8-queens problem: place 8 queens on a chess board so that no queen attacks another. (A queen attacks any piece in the same row, column, or diagonal.) This position is almost a solution, except for the two queens in the fourth and seventh columns that attack each other along the diagonal. (b) An 8-queens state with heuristic cost estimate\nh =\n17. The board shows the value of\nh\nfor each possible successor obtained by moving a queen within its column. There are 8 moves that are tied for best, with\nh\n= 12. The hill-climbing algorithm will pick one of these.",
          "sentence_count": 7,
          "char_count": 482,
          "prev_para_id": "chap4_para13",
          "next_para_id": "chap4_para15",
          "style_metadata": {
            "para_id": "chap4_para14",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.57,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 123,
            "sentence_count": 7
          },
          "terminology": {
            "figure": 1,
            "8-queens": 2,
            "problem": 1,
            "place": 1,
            "queen": 5,
            "chess": 1,
            "board": 2,
            "attack": 3,
            "piece": 1,
            "row": 1,
            "column": 3,
            "diagonal": 2,
            "position": 1,
            "solution": 1,
            "fourth": 1,
            "seventh": 1,
            "state": 1,
            "heuristic": 1,
            "cost": 1,
            "estimate": 1,
            "show": 1,
            "value": 1,
            "possible": 1,
            "successor": 1,
            "obtained": 1,
            "moving": 1,
            "move": 1,
            "tied": 1,
            "best": 1,
            "hill-climbing": 1,
            "algorithm": 1,
            "pick": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para15",
          "content": "Hill climbing is sometimes called\ngreedy local search\nbecause it grabs a good neighbor state without thinking ahead about where to go next. Although greed is considered one of the seven deadly sins, it turns out that greedy algorithms often perform quite well. Hill climbing can make rapid progress toward a solution because it is usually quite easy to improve a bad state. For example, from the state in\nFigure 4.3(b)\n, it takes just five steps to reach the state in\nFigure 4.3(a)\n, which has\nh\n= 1 and is very nearly a solution. Unfortunately, hill climbing can get stuck for any of the following reasons:\n•\nLocal maxima\n: A local maximum is a peak that is higher than each of its neighboring states but lower than the global maximum. Hill-climbing algorithms that reach the vicinity of a local maximum will be drawn upward toward the peak but will then be stuck with nowhere else to go.",
          "sentence_count": 6,
          "char_count": 741,
          "prev_para_id": "chap4_para14",
          "next_para_id": "chap4_para16",
          "style_metadata": {
            "para_id": "chap4_para15",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 176,
            "sentence_count": 6
          },
          "terminology": {
            "hill": 3,
            "climbing": 3,
            "called": 1,
            "greedy": 2,
            "local": 4,
            "search": 1,
            "grab": 1,
            "good": 1,
            "neighbor": 1,
            "state": 5,
            "thinking": 1,
            "next": 1,
            "greed": 1,
            "considered": 1,
            "deadly": 1,
            "sin": 1,
            "turn": 1,
            "algorithm": 2,
            "perform": 1,
            "make": 1,
            "rapid": 1,
            "progress": 1,
            "solution": 2,
            "easy": 1,
            "improve": 1,
            "bad": 1,
            "example": 1,
            "figure": 2,
            "take": 1,
            "step": 1,
            "reach": 2,
            "get": 1,
            "stuck": 2,
            "following": 1,
            "reason": 1,
            "maximum": 4,
            "peak": 2,
            "higher": 1,
            "neighboring": 1,
            "lower": 1,
            "global": 1,
            "hill-climbing": 1,
            "vicinity": 1,
            "drawn": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para15",
              "entity_text": "Hill",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 4,
              "context": "Hill climbing is sometimes called\ngreedy local search\n"
            },
            {
              "para_id": "chap4_para15",
              "entity_text": "Hill",
              "entity_type": "PERSON",
              "start_char": 261,
              "end_char": 265,
              "context": " that greedy algorithms often perform quite well. Hill climbing can make rapid progress toward a solutio"
            },
            {
              "para_id": "chap4_para15",
              "entity_text": "Hill",
              "entity_type": "PERSON",
              "start_char": 737,
              "end_char": 741,
              "context": "hboring states but lower than the global maximum. Hill-climbing algorithms that reach the vicinity of a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para16",
          "content": "Figure 4.1\nillustrates the problem schematically. More concretely, the state in\nFigure 4.3(a)\nis a local maximum (i.e., a local minimum for the cost\nh\n); every move of a single queen makes the situation worse.",
          "sentence_count": 2,
          "char_count": 179,
          "prev_para_id": "chap4_para15",
          "next_para_id": "chap4_para17",
          "style_metadata": {
            "para_id": "chap4_para16",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 2,
            "illustrates": 1,
            "problem": 1,
            "state": 1,
            "local": 2,
            "maximum": 1,
            "i.e.": 1,
            "minimum": 1,
            "cost": 1,
            "move": 1,
            "single": 1,
            "queen": 1,
            "make": 1,
            "situation": 1,
            "worse": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para17",
          "content": "•\nRidges\n: A ridge is shown in\nFigure 4.4\n. Ridges result in a sequence of local maxima that is very difficult for greedy algorithms to navigate.",
          "sentence_count": 2,
          "char_count": 122,
          "prev_para_id": "chap4_para16",
          "next_para_id": "chap4_para18",
          "style_metadata": {
            "para_id": "chap4_para17",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 2
          },
          "terminology": {
            "ridge": 3,
            "shown": 1,
            "figure": 1,
            "result": 1,
            "sequence": 1,
            "local": 1,
            "maximum": 1,
            "difficult": 1,
            "greedy": 1,
            "algorithm": 1,
            "navigate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para18",
          "content": "•\nPlateaus\n: A plateau is a flat area of the state-space landscape. It can be a flat local maximum, from which no uphill exit exists, or a\nshoulder\n, from which progress is possible. (See\nFigure 4.1\n.) A hill-climbing search can get lost wandering on the plateau.",
          "sentence_count": 4,
          "char_count": 221,
          "prev_para_id": "chap4_para17",
          "next_para_id": "chap4_para19",
          "style_metadata": {
            "para_id": "chap4_para18",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 56,
            "sentence_count": 4
          },
          "terminology": {
            "plateau": 3,
            "flat": 2,
            "area": 1,
            "state-space": 1,
            "landscape": 1,
            "local": 1,
            "maximum": 1,
            "uphill": 1,
            "exit": 1,
            "exists": 1,
            "shoulder": 1,
            "progress": 1,
            "possible": 1,
            "see": 1,
            "figure": 1,
            "hill-climbing": 1,
            "search": 1,
            "get": 1,
            "lost": 1,
            "wandering": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para19",
          "content": "Description\nFrom each of the local maxima, arrows point downward in either direction. The intersecting points are depicted by dark circles.",
          "sentence_count": 2,
          "char_count": 120,
          "prev_para_id": "chap4_para18",
          "next_para_id": "chap4_para20",
          "style_metadata": {
            "para_id": "chap4_para19",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "local": 1,
            "maximum": 1,
            "arrow": 1,
            "point": 2,
            "direction": 1,
            "intersecting": 1,
            "depicted": 1,
            "dark": 1,
            "circle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para20",
          "content": "×\nFigure 4.4\nIllustration of why ridges cause difficulties for hill climbing. The grid of states (dark circles) is superimposed on a ridge rising from left to right, creating a sequence of local maxima that are not directly connected to each other. From each local maximum, all the available actions point downhill. Topologies like this are common in low-dimensional state spaces, such as points in a two-dimensional plane. But in state spaces with hundreds or thousands of dimensions, this intuitive picture does not hold, and there are usually at least a few dimensions that make it possible to escape from ridges and plateaus.",
          "sentence_count": 5,
          "char_count": 529,
          "prev_para_id": "chap4_para19",
          "next_para_id": "chap4_para21",
          "style_metadata": {
            "para_id": "chap4_para20",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "illustration": 1,
            "ridge": 3,
            "cause": 1,
            "difficulty": 1,
            "hill": 1,
            "climbing": 1,
            "grid": 1,
            "state": 3,
            "dark": 1,
            "circle": 1,
            "superimposed": 1,
            "rising": 1,
            "left": 1,
            "right": 1,
            "creating": 1,
            "sequence": 1,
            "local": 2,
            "maximum": 2,
            "connected": 1,
            "available": 1,
            "action": 1,
            "point": 2,
            "downhill": 1,
            "topology": 1,
            "common": 1,
            "low-dimensional": 1,
            "space": 2,
            "two-dimensional": 1,
            "plane": 1,
            "hundred": 1,
            "thousand": 1,
            "dimension": 2,
            "intuitive": 1,
            "picture": 1,
            "hold": 1,
            "least": 1,
            "make": 1,
            "possible": 1,
            "escape": 1,
            "plateau": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para21",
          "content": "In each case, the algorithm reaches a point at which no progress is being made. Starting from a randomly generated 8-queens state, steepest-ascent hill climbing gets stuck 86% of the time, solving only 14% of problem instances. On the other hand, it works quickly, taking just 4 steps on average when it succeeds and 3 when it gets stuck—not bad for a state space with 8\n8\n≈ 17 million states.",
          "sentence_count": 3,
          "char_count": 325,
          "prev_para_id": "chap4_para20",
          "next_para_id": "chap4_para22",
          "style_metadata": {
            "para_id": "chap4_para21",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 3
          },
          "terminology": {
            "case": 1,
            "algorithm": 1,
            "reach": 1,
            "point": 1,
            "progress": 1,
            "made": 1,
            "starting": 1,
            "generated": 1,
            "8-queens": 1,
            "state": 3,
            "steepest-ascent": 1,
            "hill": 1,
            "climbing": 1,
            "get": 2,
            "stuck": 1,
            "time": 1,
            "solving": 1,
            "problem": 1,
            "instance": 1,
            "hand": 1,
            "work": 1,
            "taking": 1,
            "step": 1,
            "average": 1,
            "succeeds": 1,
            "stuck—not": 1,
            "bad": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para22",
          "content": "How could we solve more problems? One answer is to keep going when we reach a plateau—to allow a\nsideways move\nin the hope that the plateau is really a shoulder, as shown in\nFigure 4.1\n. But if we are actually on a flat local maximum, then this approach will wander on the plateau forever. Therefore, we can limit the number of consecutive sideways moves, stopping after, say, 100 consecutive sideways moves. This raises the percentage of problem instances solved by hill climbing from 14% to 94%. Success comes at a cost: the algorithm averages roughly 21 steps for each successful instance and 64 for each failure.",
          "sentence_count": 6,
          "char_count": 513,
          "prev_para_id": "chap4_para21",
          "next_para_id": "chap4_para23",
          "style_metadata": {
            "para_id": "chap4_para22",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 20.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 122,
            "sentence_count": 6
          },
          "terminology": {
            "solve": 1,
            "problem": 2,
            "answer": 1,
            "keep": 1,
            "going": 1,
            "reach": 1,
            "plateau—to": 1,
            "allow": 1,
            "sideways": 3,
            "move": 3,
            "hope": 1,
            "plateau": 2,
            "shoulder": 1,
            "shown": 1,
            "figure": 1,
            "flat": 1,
            "local": 1,
            "maximum": 1,
            "approach": 1,
            "wander": 1,
            "limit": 1,
            "number": 1,
            "consecutive": 2,
            "stopping": 1,
            "say": 1,
            "raise": 1,
            "percentage": 1,
            "instance": 2,
            "solved": 1,
            "hill": 1,
            "climbing": 1,
            "success": 1,
            "come": 1,
            "algorithm": 1,
            "average": 1,
            "step": 1,
            "successful": 1,
            "failure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para22",
              "entity_text": "Success",
              "entity_type": "ORG",
              "start_char": 498,
              "end_char": 505,
              "context": "nstances solved by hill climbing from 14% to 94%. Success comes at a cost: the algorithm averages roughly 2"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para23",
          "content": "Many variants of hill climbing have been invented.",
          "sentence_count": 1,
          "char_count": 43,
          "prev_para_id": "chap4_para22",
          "next_para_id": "chap4_para24",
          "style_metadata": {
            "para_id": "chap4_para23",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 9,
            "sentence_count": 1
          },
          "terminology": {
            "many": 1,
            "variant": 1,
            "hill": 1,
            "climbing": 1,
            "invented": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para24",
          "content": "Stochastic hill climbing\nchooses at random from among the uphill moves; the probability of selection can vary with the steepness of the uphill move. This usually converges more slowly than steepest ascent, but in some state landscapes, it finds better solutions.",
          "sentence_count": 2,
          "char_count": 223,
          "prev_para_id": "chap4_para23",
          "next_para_id": "chap4_para25",
          "style_metadata": {
            "para_id": "chap4_para24",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "stochastic": 1,
            "hill": 1,
            "climbing": 1,
            "chooses": 1,
            "random": 1,
            "uphill": 2,
            "move": 2,
            "probability": 1,
            "selection": 1,
            "vary": 1,
            "steepness": 1,
            "converges": 1,
            "steepest": 1,
            "ascent": 1,
            "state": 1,
            "landscape": 1,
            "find": 1,
            "better": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para25",
          "content": "First-choice hill climbing\nimplements stochastic hill climbing by generating successors randomly until one is generated that is better than the current state. This is a good strategy when a state has many (e.g., thousands) of successors.",
          "sentence_count": 2,
          "char_count": 203,
          "prev_para_id": "chap4_para24",
          "next_para_id": "chap4_para26",
          "style_metadata": {
            "para_id": "chap4_para25",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.024,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "first-choice": 1,
            "hill": 2,
            "climbing": 2,
            "implement": 1,
            "stochastic": 1,
            "generating": 1,
            "successor": 2,
            "generated": 1,
            "current": 1,
            "state": 2,
            "good": 1,
            "strategy": 1,
            "many": 1,
            "e.g.": 1,
            "thousand": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para26",
          "content": "Another variant is\nrandom-restart hill climbing\n, which adopts the adage, “If at first you don’t succeed, try, try again.” It conducts a series of hill-climbing searches from randomly\ngenerated initial states, until a goal is found. It is complete with probability 1, because it will eventually generate a goal state as the initial state. If each hill-climbing search has a probability\np\nof success, then the expected number of restarts required is 1/\np.",
          "sentence_count": 3,
          "char_count": 386,
          "prev_para_id": "chap4_para25",
          "next_para_id": "chap4_para27",
          "style_metadata": {
            "para_id": "chap4_para26",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "variant": 1,
            "random-restart": 1,
            "hill": 1,
            "climbing": 1,
            "adopts": 1,
            "adage": 1,
            "first": 1,
            "succeed": 1,
            "try": 2,
            "again.": 1,
            "conduct": 1,
            "series": 1,
            "hill-climbing": 2,
            "search": 2,
            "generated": 1,
            "initial": 2,
            "state": 3,
            "goal": 2,
            "found": 1,
            "complete": 1,
            "probability": 2,
            "generate": 1,
            "success": 1,
            "expected": 1,
            "number": 1,
            "restarts": 1,
            "required": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para27",
          "content": "For 8-queens instances with no sideways moves allowed,\np\n≈ 0.14, so we need roughly 7 iterations to find a goal (6 failures and 1 success). The expected number of steps is the cost of one successful iteration plus (1 –\np\n)/\np\ntimes the cost of failure, or roughly 22 steps in all. When we allow sideways moves, 1/0.94 ≈ 1.06 iterations are needed on average and (1 × 21) + (0.06/0.94) × 64 ≈ 25 steps. For 8-queens, then, random-restart hill climbing is very effective indeed. Even for three million queens, the approach can find solutions in seconds.",
          "sentence_count": 5,
          "char_count": 457,
          "prev_para_id": "chap4_para26",
          "next_para_id": "chap4_para28",
          "style_metadata": {
            "para_id": "chap4_para27",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 5
          },
          "terminology": {
            "8-queens": 2,
            "instance": 1,
            "sideways": 2,
            "move": 2,
            "allowed": 1,
            "need": 1,
            "iteration": 3,
            "find": 2,
            "goal": 1,
            "failure": 2,
            "success": 1,
            "expected": 1,
            "number": 1,
            "step": 3,
            "cost": 2,
            "successful": 1,
            "time": 1,
            "allow": 1,
            "needed": 1,
            "average": 1,
            "random-restart": 1,
            "hill": 1,
            "climbing": 1,
            "effective": 1,
            "queen": 1,
            "approach": 1,
            "solution": 1,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para28",
          "content": "1\nThe success of hill climbing depends very much on the shape of the state-space landscape: if there are few local maxima and plateaus, random-restart hill climbing will find a good solution very quickly. On the other hand, many real problems have a landscape that looks more like a widely scattered family of balding porcupines on a flat floor, with miniature porcupines living on the tip of each porcupine needle. NP-hard problems (see Appendix A) typically have an exponential number of local maxima to get stuck on. Despite this, a reasonably good local maximum can often be found after a small number of restarts.",
          "sentence_count": 4,
          "char_count": 516,
          "prev_para_id": "chap4_para27",
          "next_para_id": "chap4_para29",
          "style_metadata": {
            "para_id": "chap4_para28",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 4
          },
          "terminology": {
            "success": 1,
            "hill": 2,
            "climbing": 2,
            "depends": 1,
            "much": 1,
            "shape": 1,
            "state-space": 1,
            "landscape": 2,
            "local": 3,
            "maximum": 3,
            "plateau": 1,
            "random-restart": 1,
            "good": 2,
            "solution": 1,
            "hand": 1,
            "many": 1,
            "real": 1,
            "problem": 2,
            "look": 1,
            "scattered": 1,
            "family": 1,
            "balding": 1,
            "porcupine": 3,
            "flat": 1,
            "floor": 1,
            "miniature": 1,
            "living": 1,
            "tip": 1,
            "needle": 1,
            "np-hard": 1,
            "see": 1,
            "exponential": 1,
            "number": 2,
            "get": 1,
            "stuck": 1,
            "found": 1,
            "small": 1,
            "restarts": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para28",
              "entity_text": "maxima",
              "entity_type": "PRODUCT",
              "start_char": 115,
              "end_char": 121,
              "context": "the state-space landscape: if there are few local maxima and plateaus, random-restart hill climbing will f"
            },
            {
              "para_id": "chap4_para28",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 416,
              "end_char": 418,
              "context": "pines living on the tip of each porcupine needle. NP-hard problems (see Appendix A) typically have an "
            },
            {
              "para_id": "chap4_para28",
              "entity_text": "Appendix A",
              "entity_type": "PERSON",
              "start_char": 438,
              "end_char": 448,
              "context": "p of each porcupine needle. NP-hard problems (see Appendix A) typically have an exponential number of local ma"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para29",
          "content": "4.1.2\nSimulated annealing\nA hill-climbing algorithm that never makes “downhill” moves toward states with lower value (or higher cost) is always vulnerable to getting stuck in a local maximum. In contrast, a purely random walk that moves to a successor state without concern for the value will eventually stumble upon the global maximum, but will be extremely inefficient. Therefore, it seems reasonable to try to combine hill climbing with a random walk in a way that yields both efficiency and completeness.",
          "sentence_count": 3,
          "char_count": 430,
          "prev_para_id": "chap4_para28",
          "next_para_id": "chap4_para30",
          "style_metadata": {
            "para_id": "chap4_para29",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 30.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 91,
            "sentence_count": 3
          },
          "terminology": {
            "simulated": 1,
            "annealing": 1,
            "hill-climbing": 1,
            "algorithm": 1,
            "make": 1,
            "downhill": 1,
            "move": 2,
            "state": 2,
            "lower": 1,
            "value": 2,
            "higher": 1,
            "cost": 1,
            "vulnerable": 1,
            "getting": 1,
            "stuck": 1,
            "local": 1,
            "maximum": 2,
            "contrast": 1,
            "random": 2,
            "walk": 2,
            "successor": 1,
            "concern": 1,
            "stumble": 1,
            "global": 1,
            "inefficient": 1,
            "seems": 1,
            "reasonable": 1,
            "try": 1,
            "combine": 1,
            "hill": 1,
            "climbing": 1,
            "way": 1,
            "yield": 1,
            "efficiency": 1,
            "completeness": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para30",
          "content": "Simulated annealing\nis such an algorithm. In metallurgy,\nannealing\nis the process used to temper or harden metals and glass by heating them to a high temperature and then gradually cooling them, thus allowing the material to reach a low-energy crystalline state. To explain simulated annealing, we switch our point of view from hill climbing to\ngradient descent\n(i.e., minimizing cost) and imagine the task of getting a ping-pong ball into the deepest crevice in a very bumpy surface. If we just let the ball roll, it will come to rest at a local minimum. If we shake the surface, we can bounce the ball out of the local minimum—perhaps into a deeper local minimum, where it will spend more time. The trick is to shake just hard enough to bounce the ball out of local minima but not hard enough to dislodge it from the global minimum. The simulated-annealing solution is to start by shaking hard (i.e., at a high temperature) and then gradually reduce the intensity of the shaking (i.e., lower the temperature).",
          "sentence_count": 7,
          "char_count": 842,
          "prev_para_id": "chap4_para29",
          "next_para_id": "chap4_para31",
          "style_metadata": {
            "para_id": "chap4_para30",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.14,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 197,
            "sentence_count": 7
          },
          "terminology": {
            "simulated": 2,
            "annealing": 3,
            "algorithm": 1,
            "metallurgy": 1,
            "process": 1,
            "used": 1,
            "harden": 1,
            "metal": 1,
            "glass": 1,
            "heating": 1,
            "high": 2,
            "temperature": 3,
            "cooling": 1,
            "allowing": 1,
            "material": 1,
            "reach": 1,
            "low-energy": 1,
            "crystalline": 1,
            "state": 1,
            "explain": 1,
            "switch": 1,
            "point": 1,
            "view": 1,
            "hill": 1,
            "climbing": 1,
            "gradient": 1,
            "descent": 1,
            "i.e.": 3,
            "minimizing": 1,
            "cost": 1,
            "imagine": 1,
            "task": 1,
            "getting": 1,
            "ping-pong": 1,
            "ball": 4,
            "deepest": 1,
            "crevice": 1,
            "bumpy": 1,
            "surface": 2,
            "let": 1,
            "roll": 1,
            "come": 1,
            "rest": 1,
            "local": 4,
            "minimum": 3,
            "shake": 2,
            "bounce": 2,
            "minimum—perhaps": 1,
            "deeper": 1,
            "spend": 1,
            "time": 1,
            "trick": 1,
            "hard": 2,
            "enough": 1,
            "dislodge": 1,
            "global": 1,
            "simulated-annealing": 1,
            "solution": 1,
            "start": 1,
            "shaking": 2,
            "reduce": 1,
            "intensity": 1,
            "lower": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para30",
              "entity_text": "harden",
              "entity_type": "GPE",
              "start_char": 100,
              "end_char": 106,
              "context": "lurgy,\nannealing\nis the process used to temper or harden metals and glass by heating them to a high temper"
            },
            {
              "para_id": "chap4_para30",
              "entity_text": "minima",
              "entity_type": "PRODUCT",
              "start_char": 768,
              "end_char": 774,
              "context": " just hard enough to bounce the ball out of local minima but not hard enough to dislodge it from the globa"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para31",
          "content": "The overall structure of the simulated-annealing algorithm (\nFigure 4.5\n) is similar to hill climbing. Instead of picking the\nbest\nmove, however, it picks a\nrandom\nmove. If the move improves the situation, it is always accepted. Otherwise, the algorithm accepts the move with some probability less than 1. The probability decreases exponentially with the “badness” of the move—the amount\n∆E\nby which the evaluation is worsened. The probability also decreases as the “temperature”\nT\ngoes down: “bad” moves are more likely to be allowed at the start when\nT\nis high, and they become more unlikely as\nT\ndecreases. If the\nschedule\nlowers\nT\nto 0 slowly enough, then a property of the Boltzmann distribution,\ne\n∆\nE/T\n, is that\nall the probability is concentrated on the global maxima, which the algorithm will find with probability approaching 1.",
          "sentence_count": 7,
          "char_count": 722,
          "prev_para_id": "chap4_para30",
          "next_para_id": "chap4_para32",
          "style_metadata": {
            "para_id": "chap4_para31",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.14,
            "passive_voice_ratio": 0.012,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 162,
            "sentence_count": 7
          },
          "terminology": {
            "overall": 1,
            "structure": 1,
            "simulated-annealing": 1,
            "algorithm": 3,
            "figure": 1,
            "similar": 1,
            "hill": 1,
            "climbing": 1,
            "picking": 1,
            "best": 1,
            "move": 5,
            "pick": 1,
            "random": 1,
            "improves": 1,
            "situation": 1,
            "accepted": 1,
            "accepts": 1,
            "probability": 5,
            "less": 1,
            "decrease": 3,
            "badness": 1,
            "move—the": 1,
            "amount": 1,
            "evaluation": 1,
            "worsened": 1,
            "temperature": 1,
            "go": 1,
            "bad": 1,
            "allowed": 1,
            "high": 1,
            "become": 1,
            "unlikely": 1,
            "schedule": 1,
            "lower": 1,
            "property": 1,
            "boltzmann": 1,
            "distribution": 1,
            "concentrated": 1,
            "global": 1,
            "maximum": 1,
            "find": 1,
            "approaching": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para31",
              "entity_text": "Boltzmann",
              "entity_type": "PERSON",
              "start_char": 678,
              "end_char": 687,
              "context": "wers\nT\nto 0 slowly enough, then a property of the Boltzmann distribution,\ne\n∆\nE/T\n, is that\nall the probabili"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para32",
          "content": "Description\nThe genetic algorithm is represented by four sets of blocks, each having four rows of blocks. Each block consists of a real number. Part (“a”) to Part (d) is labeled Initial population, Fitness function, Selection, Cross over, and Mutation. The four 8-digit strings on the initial population blocks are as follows. 24748552, 32752411, 24415124, and 32543213. Selection. The numbers labeled on the selection blocks are as follows, 32752411, 24748552, 32752411, and 24415124. blocks 32752411 and 32752411 are shaded in brown, and the others in blue. Each block is divided into two pairs as follows. First block: 327 and 52411. Second block: 247 and 48552. Third block: 32752 and 411. Fourth block: 24415 and 124. Arrows labeled with a real number and the corresponding percentage depict the ranking by a fitness function. An arrow labeled 24, 31 percent from 24748552 in the initial population set points to a block labeled 24748552 in the selection set. An arrow labeled 23, 29 percent from 32752411 in the initial population set points to 32752411 in the selection set. An arrow labeled 20, 26 percent from 32752411 in the initial population set points to 32752411 in the selection set. An arrow labeled 11, 14 percent from 24415124 in the initial population set points to 24415124 in the selection set. The next section is labeled crossover. The numbers labeled on the cross over section blocks are as follows. 32748552, 24752411, 32752124, and 24415411. Arrows from blocks 32752411 and 24748552 in the selection set point to blocks 32748552, and 24752411 in the crossover set. Arrows from blocks 32752411 and 24415124 in the selection set point to blocks 32752124, and 24415411 in the crossover set. Each block is divided into two pairs as follows. First block: 327 and 48552. Second block: 247 and 52411. Third block: 32752 and 124. Fourth block: 24415 and 411. The numbers labeled on the mutation set blocks are as follows. 32748152 (1 highlighted), 24752411, 32752124 (2 highlighted), and 24415417 (7 highlighted). An arrow from block 32748552 in the crossover set points to the block labeled 32748152 in the mutation set. An arrow from block 24752411 in the crossover set points to the block labeled 24752411 in the mutation set. An arrow from block 32752124 in the crossover set points to the block labeled 32252124 in the mutation set. An arrow from block 24415411 in the crossover set points to the block labeled 24415417 in the mutation set.",
          "sentence_count": 33,
          "char_count": 2060,
          "prev_para_id": "chap4_para31",
          "next_para_id": "chap4_para33",
          "style_metadata": {
            "para_id": "chap4_para32",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.33,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 473,
            "sentence_count": 33
          },
          "terminology": {
            "description": 1,
            "genetic": 1,
            "algorithm": 1,
            "represented": 1,
            "set": 22,
            "block": 31,
            "row": 1,
            "consists": 1,
            "real": 2,
            "number": 5,
            "part": 2,
            "labeled": 15,
            "initial": 6,
            "population": 6,
            "fitness": 2,
            "function": 2,
            "selection": 9,
            "cross": 2,
            "mutation": 6,
            "8-digit": 1,
            "string": 1,
            "follows": 6,
            "shaded": 1,
            "brown": 1,
            "others": 1,
            "blue": 1,
            "divided": 2,
            "pair": 2,
            "first": 2,
            "second": 2,
            "third": 2,
            "fourth": 2,
            "arrow": 11,
            "corresponding": 1,
            "percentage": 1,
            "depict": 1,
            "ranking": 1,
            "percent": 4,
            "point": 10,
            "next": 1,
            "section": 2,
            "crossover": 7,
            "highlighted": 3,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para32",
              "entity_text": "Selection",
              "entity_type": "ORG",
              "start_char": 216,
              "end_char": 225,
              "context": " is labeled Initial population, Fitness function, Selection, Cross over, and Mutation. The four 8-digit strin"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para33",
          "content": "×\nFigure 4.5\nThe simulated annealing algorithm, a version of stochastic hill climbing where some downhill moves are allowed. The\nschedule\ninput determines the value of the “temperature”\nT\nas a function of time.",
          "sentence_count": 2,
          "char_count": 183,
          "prev_para_id": "chap4_para32",
          "next_para_id": "chap4_para34",
          "style_metadata": {
            "para_id": "chap4_para33",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "simulated": 1,
            "annealing": 1,
            "algorithm": 1,
            "version": 1,
            "stochastic": 1,
            "hill": 1,
            "climbing": 1,
            "downhill": 1,
            "move": 1,
            "allowed": 1,
            "schedule": 1,
            "input": 1,
            "determines": 1,
            "value": 1,
            "temperature": 1,
            "function": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para34",
          "content": "Simulated annealing was used to solve VLSI layout problems beginning in the 1980s. It has been applied widely to factory scheduling and other large-scale optimization tasks.",
          "sentence_count": 2,
          "char_count": 148,
          "prev_para_id": "chap4_para33",
          "next_para_id": "chap4_para35",
          "style_metadata": {
            "para_id": "chap4_para34",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "simulated": 1,
            "annealing": 1,
            "used": 1,
            "solve": 1,
            "vlsi": 1,
            "layout": 1,
            "problem": 1,
            "beginning": 1,
            "applied": 1,
            "factory": 1,
            "scheduling": 1,
            "large-scale": 1,
            "optimization": 1,
            "task": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para34",
              "entity_text": "VLSI",
              "entity_type": "ORG",
              "start_char": 38,
              "end_char": 42,
              "context": "Simulated annealing was used to solve VLSI layout problems beginning in the 1980s. It has be"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para35",
          "content": "4.1.3\nLocal beam search\nKeeping just one node in memory might seem to be an extreme reaction to the problem of memory limitations. The\nlocal beam search\nalgorithm keeps track of\nk\nstates rather than just one. It begins with\nk\nrandomly generated states. At each step, all the successors of all\nk\nstates are generated. If any one is a goal, the algorithm halts. Otherwise, it selects the\nk\nbest successors from the complete list and repeats.",
          "sentence_count": 6,
          "char_count": 374,
          "prev_para_id": "chap4_para34",
          "next_para_id": "chap4_para36",
          "style_metadata": {
            "para_id": "chap4_para35",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 87,
            "sentence_count": 6
          },
          "terminology": {
            "local": 2,
            "beam": 2,
            "search": 2,
            "keeping": 1,
            "node": 1,
            "memory": 2,
            "seem": 1,
            "extreme": 1,
            "reaction": 1,
            "problem": 1,
            "limitation": 1,
            "algorithm": 2,
            "keep": 1,
            "track": 1,
            "state": 3,
            "begin": 1,
            "generated": 2,
            "step": 1,
            "successor": 2,
            "goal": 1,
            "halt": 1,
            "selects": 1,
            "best": 1,
            "complete": 1,
            "list": 1,
            "repeat": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para36",
          "content": "At first sight, a local beam search with\nk\nstates might seem to be nothing more than running\nk\nrandom restarts in parallel instead of in sequence. In fact, the two algorithms are quite different. In a random-restart search, each search process runs independently of the others.",
          "sentence_count": 3,
          "char_count": 235,
          "prev_para_id": "chap4_para35",
          "next_para_id": "chap4_para37",
          "style_metadata": {
            "para_id": "chap4_para36",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 3
          },
          "terminology": {
            "sight": 1,
            "local": 1,
            "beam": 1,
            "search": 3,
            "state": 1,
            "seem": 1,
            "nothing": 1,
            "running": 1,
            "random": 1,
            "restarts": 1,
            "parallel": 1,
            "sequence": 1,
            "fact": 1,
            "algorithm": 1,
            "different": 1,
            "random-restart": 1,
            "process": 1,
            "run": 1,
            "others": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para37",
          "content": "In a local beam search, useful information is passed among the parallel search threads.",
          "sentence_count": 1,
          "char_count": 74,
          "prev_para_id": "chap4_para36",
          "next_para_id": "chap4_para38",
          "style_metadata": {
            "para_id": "chap4_para37",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.062,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "local": 1,
            "beam": 1,
            "search": 2,
            "useful": 1,
            "information": 1,
            "passed": 1,
            "parallel": 1,
            "thread": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para38",
          "content": "In effect, the states that generate the best successors say to the others, “Come over here, the grass is greener!” The algorithm quickly abandons unfruitful searches and moves its resources to where the most progress is being made.",
          "sentence_count": 1,
          "char_count": 194,
          "prev_para_id": "chap4_para37",
          "next_para_id": "chap4_para39",
          "style_metadata": {
            "para_id": "chap4_para38",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 1
          },
          "terminology": {
            "effect": 1,
            "state": 1,
            "generate": 1,
            "best": 1,
            "successor": 1,
            "say": 1,
            "others": 1,
            "come": 1,
            "grass": 1,
            "greener": 1,
            "algorithm": 1,
            "abandon": 1,
            "unfruitful": 1,
            "search": 1,
            "move": 1,
            "resource": 1,
            "progress": 1,
            "made": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para39",
          "content": "Local beam search can suffer from a lack of diversity among the\nk\nstates—they can become clustered in a small region of the state space, making the search little more than a\nk\n-times-slower version of hill climbing. A variant called\nstochastic beam search\n, analogous to stochastic hill climbing, helps alleviate this problem. Instead of choosing the top\nk\nsuccessors, stochastic beam search chooses successors with probability proportional to the successor’s value, thus increasing diversity.",
          "sentence_count": 3,
          "char_count": 426,
          "prev_para_id": "chap4_para38",
          "next_para_id": "chap4_para40",
          "style_metadata": {
            "para_id": "chap4_para39",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 3
          },
          "terminology": {
            "local": 1,
            "beam": 3,
            "search": 4,
            "suffer": 1,
            "lack": 1,
            "diversity": 2,
            "states—they": 1,
            "become": 1,
            "clustered": 1,
            "small": 1,
            "region": 1,
            "state": 1,
            "space": 1,
            "making": 1,
            "little": 1,
            "-times-slower": 1,
            "version": 1,
            "hill": 2,
            "climbing": 2,
            "variant": 1,
            "called": 1,
            "stochastic": 3,
            "analogous": 1,
            "help": 1,
            "alleviate": 1,
            "problem": 1,
            "choosing": 1,
            "top": 1,
            "successor": 3,
            "chooses": 1,
            "probability": 1,
            "proportional": 1,
            "value": 1,
            "increasing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para40",
          "content": "4.1.4\nEvolutionary algorithms\nEvolutionary algorithms\ncan be seen as variants of stochastic beam search that are explicitly motivated by the metaphor of natural selection in biology: there is a population of individuals (states), in which the fittest (highest value) individuals produce offspring (successor states) that populate the next generation, a process called\nrecombination\n. There are endless forms of evolutionary algorithms, varying in the following ways:\n•\nThe size of the population.",
          "sentence_count": 2,
          "char_count": 432,
          "prev_para_id": "chap4_para39",
          "next_para_id": "chap4_para41",
          "style_metadata": {
            "para_id": "chap4_para40",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 2
          },
          "terminology": {
            "evolutionary": 3,
            "algorithm": 3,
            "seen": 1,
            "variant": 1,
            "stochastic": 1,
            "beam": 1,
            "search": 1,
            "motivated": 1,
            "metaphor": 1,
            "natural": 1,
            "selection": 1,
            "biology": 1,
            "population": 2,
            "individual": 2,
            "state": 2,
            "fittest": 1,
            "highest": 1,
            "value": 1,
            "produce": 1,
            "offspring": 1,
            "successor": 1,
            "populate": 1,
            "next": 1,
            "generation": 1,
            "process": 1,
            "called": 1,
            "recombination": 1,
            "endless": 1,
            "form": 1,
            "varying": 1,
            "following": 1,
            "way": 1,
            "size": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para41",
          "content": "•\nThe representation of each individual. In\ngenetic algorithms\n, each individual is a string over a finite alphabet (often a Boolean string), just as DNA is a string over the alphabet\nACGT\n. In\nevolution strategies\n, an individual is a sequence of real numbers, and in\ngenetic programming\nan individual is a computer program.",
          "sentence_count": 3,
          "char_count": 279,
          "prev_para_id": "chap4_para40",
          "next_para_id": "chap4_para42",
          "style_metadata": {
            "para_id": "chap4_para41",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 3
          },
          "terminology": {
            "representation": 1,
            "individual": 4,
            "genetic": 2,
            "algorithm": 1,
            "string": 3,
            "finite": 1,
            "alphabet": 2,
            "boolean": 1,
            "dna": 1,
            "acgt": 1,
            "evolution": 1,
            "strategy": 1,
            "sequence": 1,
            "real": 1,
            "number": 1,
            "programming": 1,
            "computer": 1,
            "program": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para42",
          "content": "•\nThe mixing number,\nρ\n, which is the number of parents that come together to form offspring. The most common case is\nρ\n= 2: two parents combine their “genes” (parts of their representation) to form offspring. When\nρ\n= 1 we have stochastic beam search (which can be seen as asexual reproduction). It is possible to have\nρ\n> 2, which occurs only rarely in nature but is easy enough to simulate on computers.",
          "sentence_count": 4,
          "char_count": 340,
          "prev_para_id": "chap4_para41",
          "next_para_id": "chap4_para43",
          "style_metadata": {
            "para_id": "chap4_para42",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 4
          },
          "terminology": {
            "mixing": 1,
            "number": 2,
            "parent": 2,
            "come": 1,
            "form": 2,
            "offspring": 2,
            "common": 1,
            "case": 1,
            "combine": 1,
            "gene": 1,
            "part": 1,
            "representation": 1,
            "stochastic": 1,
            "beam": 1,
            "search": 1,
            "seen": 1,
            "asexual": 1,
            "reproduction": 1,
            "possible": 1,
            "occurs": 1,
            "nature": 1,
            "easy": 1,
            "simulate": 1,
            "computer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para43",
          "content": "•\nThe\nselection\nprocess for selecting the individuals who will become the parents of the next generation: one possibility is to select from all individuals with probability proportional to their fitness score. Another possibility is to randomly select\nn\nindividuals (\nn\n>\nρ\n), and then select the\nρ\nmost fit ones as parents.",
          "sentence_count": 2,
          "char_count": 281,
          "prev_para_id": "chap4_para42",
          "next_para_id": "chap4_para44",
          "style_metadata": {
            "para_id": "chap4_para43",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 2
          },
          "terminology": {
            "selection": 1,
            "process": 1,
            "selecting": 1,
            "individual": 3,
            "become": 1,
            "parent": 2,
            "next": 1,
            "generation": 1,
            "possibility": 2,
            "select": 3,
            "probability": 1,
            "proportional": 1,
            "fitness": 1,
            "score": 1,
            "fit": 1,
            "one": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para44",
          "content": "•\nThe recombination procedure. One common approach (assuming\nρ\n= 2), is to randomly select a\ncrossover point\nto split each of the parent strings, and recombine the parts to form two children, one with the first part of parent 1 and the second part of parent 2; the other with the second part of parent 1 and the first part of parent 2.",
          "sentence_count": 2,
          "char_count": 277,
          "prev_para_id": "chap4_para43",
          "next_para_id": "chap4_para45",
          "style_metadata": {
            "para_id": "chap4_para44",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 2
          },
          "terminology": {
            "recombination": 1,
            "procedure": 1,
            "common": 1,
            "approach": 1,
            "assuming": 1,
            "select": 1,
            "crossover": 1,
            "point": 1,
            "split": 1,
            "parent": 5,
            "string": 1,
            "recombine": 1,
            "part": 5,
            "form": 1,
            "child": 1,
            "first": 2,
            "second": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para45",
          "content": "•\nThe\nmutation rate\n, which determines how often offspring have random mutations to their representation. Once an offspring has been generated, every bit in its composition is flipped with probability equal to the mutation rate.",
          "sentence_count": 2,
          "char_count": 196,
          "prev_para_id": "chap4_para44",
          "next_para_id": "chap4_para46",
          "style_metadata": {
            "para_id": "chap4_para45",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.026,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 2
          },
          "terminology": {
            "mutation": 3,
            "rate": 2,
            "determines": 1,
            "offspring": 2,
            "random": 1,
            "representation": 1,
            "generated": 1,
            "bit": 1,
            "composition": 1,
            "flipped": 1,
            "probability": 1,
            "equal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para46",
          "content": "•\nThe makeup of the next generation. This can be just the newly formed offspring, or it can include a few top-scoring parents from the previous generation (a practice called\nelitism\n, which guarantees that overall fitness will never decrease over time). The practice of\nculling\n, in which all individuals below a given threshold are discarded, can lead to a speedup (Baum\net al.",
          "sentence_count": 3,
          "char_count": 320,
          "prev_para_id": "chap4_para45",
          "next_para_id": "chap4_para47",
          "style_metadata": {
            "para_id": "chap4_para46",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 3
          },
          "terminology": {
            "makeup": 1,
            "next": 1,
            "generation": 2,
            "formed": 1,
            "offspring": 1,
            "include": 1,
            "top-scoring": 1,
            "parent": 1,
            "previous": 1,
            "practice": 2,
            "called": 1,
            "elitism": 1,
            "guarantee": 1,
            "overall": 1,
            "fitness": 1,
            "decrease": 1,
            "time": 1,
            "culling": 1,
            "individual": 1,
            "given": 1,
            "discarded": 1,
            "lead": 1,
            "speedup": 1,
            "baum": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para46",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 375,
              "end_char": 377,
              "context": "old are discarded, can lead to a speedup (Baum\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para47",
          "content": ", 1995).",
          "sentence_count": 1,
          "char_count": 7,
          "prev_para_id": "chap4_para46",
          "next_para_id": "chap4_para48",
          "style_metadata": {
            "para_id": "chap4_para47",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para48",
          "content": "Figure 4.6(a)\nshows a population of four 8-digit strings, each representing a state of the 8-queens puzzle: the\nc\n-th digit represents the row number of the queen in column\nc\n. In (b), each state is rated by the fitness function. Higher fitness values are better, so for the 8-queens\nproblem we use the number of\nnonattacking\npairs of queens, which has a value of 8 × 7/2 = 28 for a solution. The values of the four states in (b) are 24, 23, 20, and 11. The fitness scores are then normalized to probabilities, and the resulting values are shown next to the fitness values in (b).",
          "sentence_count": 5,
          "char_count": 480,
          "prev_para_id": "chap4_para47",
          "next_para_id": "chap4_para49",
          "style_metadata": {
            "para_id": "chap4_para48",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 130,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "population": 1,
            "8-digit": 1,
            "string": 1,
            "representing": 1,
            "state": 3,
            "8-queens": 2,
            "puzzle": 1,
            "-th": 1,
            "digit": 1,
            "represents": 1,
            "row": 1,
            "number": 2,
            "queen": 2,
            "column": 1,
            "rated": 1,
            "fitness": 4,
            "function": 1,
            "higher": 1,
            "value": 5,
            "problem": 1,
            "use": 1,
            "nonattacking": 1,
            "pair": 1,
            "solution": 1,
            "score": 1,
            "normalized": 1,
            "probability": 1,
            "resulting": 1,
            "shown": 1,
            "next": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para49",
          "content": "Description\nThe first two chessboard arrangements are added up to form the third, which depicts the three steps of recombination. In the first step, the queens are positioned at G 1, H 1, B 2, E 2, “a” 3, F 4, D 5, and C 7. The first three columns are shaded in red, which are retained in the cross over step, and the next five columns are shaded in green which are lost. In the second step, the queens are positioned at “a” 2, H 2, B 4, D 4, F 5, G 5, C 7, and E 8. The first three columns are shaded in green, that are lost in the cross over step, and the next five columns are shaded in red and retained. In the last step, the queens are arranged at B 2, H 2, “a” 3, D 4, F 5, G 5, C 7, and E 8. All the columns are retained after the crossover step.",
          "sentence_count": 7,
          "char_count": 593,
          "prev_para_id": "chap4_para48",
          "next_para_id": "chap4_para50",
          "style_metadata": {
            "para_id": "chap4_para49",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.71,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 201,
            "sentence_count": 7
          },
          "terminology": {
            "description": 1,
            "chessboard": 1,
            "arrangement": 1,
            "added": 1,
            "form": 1,
            "third": 1,
            "depicts": 1,
            "step": 7,
            "recombination": 1,
            "queen": 3,
            "positioned": 2,
            "column": 5,
            "shaded": 4,
            "red": 2,
            "retained": 3,
            "cross": 2,
            "next": 2,
            "green": 2,
            "lost": 2,
            "second": 1,
            "last": 1,
            "arranged": 1,
            "crossover": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para50",
          "content": "×\nFigure 4.6\nA genetic algorithm, illustrated for digit strings representing 8-queens states. The initial population in (a) is ranked by a fitness function in (b) resulting in pairs for mating in (c). They produce offspring in (d), which are subject to mutation in (e).",
          "sentence_count": 3,
          "char_count": 227,
          "prev_para_id": "chap4_para49",
          "next_para_id": "chap4_para51",
          "style_metadata": {
            "para_id": "chap4_para50",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 60,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "genetic": 1,
            "algorithm": 1,
            "illustrated": 1,
            "digit": 1,
            "string": 1,
            "representing": 1,
            "8-queens": 1,
            "state": 1,
            "initial": 1,
            "population": 1,
            "ranked": 1,
            "fitness": 1,
            "function": 1,
            "resulting": 1,
            "pair": 1,
            "mating": 1,
            "produce": 1,
            "offspring": 1,
            "subject": 1,
            "mutation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para51",
          "content": "In (c), two pairs of parents are selected, in accordance with the probabilities in (b). Notice that one individual is selected twice and one not at all. For each selected pair, a crossover point (dotted line) is chosen randomly. In (d), we cross over the parent strings at the crossover points, yielding new offspring. For example, the first child of the first pair gets the first three digits (327) from the first parent and the remaining digits (48552) from the second parent. The 8-queens states involved in this recombination step are shown in\nFigure 4.7\n.",
          "sentence_count": 6,
          "char_count": 467,
          "prev_para_id": "chap4_para50",
          "next_para_id": "chap4_para52",
          "style_metadata": {
            "para_id": "chap4_para51",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.83,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 119,
            "sentence_count": 6
          },
          "terminology": {
            "pair": 3,
            "parent": 4,
            "selected": 3,
            "accordance": 1,
            "probability": 1,
            "notice": 1,
            "individual": 1,
            "crossover": 2,
            "point": 2,
            "dotted": 1,
            "line": 1,
            "chosen": 1,
            "cross": 1,
            "string": 1,
            "yielding": 1,
            "new": 1,
            "offspring": 1,
            "example": 1,
            "child": 1,
            "get": 1,
            "first": 2,
            "digit": 2,
            "remaining": 1,
            "second": 1,
            "8-queens": 1,
            "state": 1,
            "involved": 1,
            "recombination": 1,
            "step": 1,
            "shown": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para52",
          "content": "Description\nTwo squares are marked at each stage depicting the left and right sides.",
          "sentence_count": 1,
          "char_count": 72,
          "prev_para_id": "chap4_para51",
          "next_para_id": "chap4_para53",
          "style_metadata": {
            "para_id": "chap4_para52",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "description": 1,
            "square": 1,
            "marked": 1,
            "stage": 1,
            "depicting": 1,
            "left": 1,
            "right": 1,
            "side": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para53",
          "content": "State 1: Dirts are at the left and right squares. The vacuum cleaner is cleaning the dirt on the left square.",
          "sentence_count": 2,
          "char_count": 89,
          "prev_para_id": "chap4_para52",
          "next_para_id": "chap4_para54",
          "style_metadata": {
            "para_id": "chap4_para53",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 2
          },
          "terminology": {
            "state": 1,
            "dirt": 2,
            "left": 2,
            "right": 1,
            "square": 2,
            "vacuum": 1,
            "cleaner": 1,
            "cleaning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para54",
          "content": "State 2: Dirts are at the left and right squares. The vacuum cleaner is cleaning the dirt on the right square.",
          "sentence_count": 2,
          "char_count": 90,
          "prev_para_id": "chap4_para53",
          "next_para_id": "chap4_para55",
          "style_metadata": {
            "para_id": "chap4_para54",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 2
          },
          "terminology": {
            "state": 1,
            "dirt": 2,
            "left": 1,
            "right": 1,
            "square": 2,
            "vacuum": 1,
            "cleaner": 1,
            "cleaning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para55",
          "content": "State 3: Dirt is on the left square. The vacuum cleaner is cleaning the dirt on the left square. The right square is clean.",
          "sentence_count": 3,
          "char_count": 100,
          "prev_para_id": "chap4_para54",
          "next_para_id": "chap4_para56",
          "style_metadata": {
            "para_id": "chap4_para55",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 3
          },
          "terminology": {
            "state": 1,
            "dirt": 2,
            "left": 2,
            "square": 3,
            "vacuum": 1,
            "cleaner": 1,
            "cleaning": 1,
            "right": 1,
            "clean": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para55",
              "entity_text": "Dirt",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 13,
              "context": "State 3: Dirt is on the left square. The vacuum cleaner is clea"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para56",
          "content": "State 4: Dirt is on the left square. The vacuum cleaner is on the right square with no dirt.",
          "sentence_count": 2,
          "char_count": 74,
          "prev_para_id": "chap4_para55",
          "next_para_id": "chap4_para57",
          "style_metadata": {
            "para_id": "chap4_para56",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 2
          },
          "terminology": {
            "state": 1,
            "dirt": 2,
            "left": 1,
            "square": 2,
            "vacuum": 1,
            "cleaner": 1,
            "right": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para56",
              "entity_text": "Dirt",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 13,
              "context": "State 4: Dirt is on the left square. The vacuum cleaner is on t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para57",
          "content": "State 5: Dirt is on the right square. The vacuum cleaner is in the clean left square.",
          "sentence_count": 2,
          "char_count": 69,
          "prev_para_id": "chap4_para56",
          "next_para_id": "chap4_para58",
          "style_metadata": {
            "para_id": "chap4_para57",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 2
          },
          "terminology": {
            "state": 1,
            "dirt": 1,
            "square": 2,
            "vacuum": 1,
            "cleaner": 1,
            "clean": 1,
            "left": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para57",
              "entity_text": "Dirt",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 13,
              "context": "State 5: Dirt is on the right square. The vacuum cleaner is in "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para58",
          "content": "State 6: Dirt is on the right square. The vacuum cleaner is on the right square. The left square is clean.",
          "sentence_count": 3,
          "char_count": 86,
          "prev_para_id": "chap4_para57",
          "next_para_id": "chap4_para59",
          "style_metadata": {
            "para_id": "chap4_para58",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 3
          },
          "terminology": {
            "state": 1,
            "dirt": 1,
            "square": 3,
            "vacuum": 1,
            "cleaner": 1,
            "right": 1,
            "left": 1,
            "clean": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para58",
              "entity_text": "Dirt",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 13,
              "context": "State 6: Dirt is on the right square. The vacuum cleaner is on "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para59",
          "content": "State 7: Both the squares are clean. The vacuum cleaner is on the left square.",
          "sentence_count": 2,
          "char_count": 64,
          "prev_para_id": "chap4_para58",
          "next_para_id": "chap4_para60",
          "style_metadata": {
            "para_id": "chap4_para59",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 2
          },
          "terminology": {
            "state": 1,
            "square": 2,
            "clean": 1,
            "vacuum": 1,
            "cleaner": 1,
            "left": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para60",
          "content": "State 8: Both the squares are clean. The vacuum cleaner is on the right square.",
          "sentence_count": 2,
          "char_count": 65,
          "prev_para_id": "chap4_para59",
          "next_para_id": "chap4_para61",
          "style_metadata": {
            "para_id": "chap4_para60",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 2
          },
          "terminology": {
            "state": 1,
            "square": 2,
            "clean": 1,
            "vacuum": 1,
            "cleaner": 1,
            "right": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para61",
          "content": "×\nFigure 4.7\nThe 8-queens states corresponding to the first two parents in\nFigure 4.6(c)\nand the first offspring in\nFigure 4.6(d)\n. The green columns are lost in the crossover step and the red columns are retained. (To interpret the numbers in\nFigure 4.6\n: row 1 is the bottom row, and 8 is the top row.)\nFinally, in (e), each location in each string is subject to random mutation with a small independent probability. One digit was mutated in the first, third, and fourth offspring. In the 8-queens problem, this corresponds to choosing a queen at random and moving it to a random square in its column. It is often the case that the population is diverse early on in the process, so crossover frequently takes large steps in the state space early in the search process (as in simulated annealing). After many generations of selection towards higher fitness, the population becomes less diverse, and smaller steps are typical.",
          "sentence_count": 8,
          "char_count": 775,
          "prev_para_id": "chap4_para60",
          "next_para_id": "chap4_para62",
          "style_metadata": {
            "para_id": "chap4_para61",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.62,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 189,
            "sentence_count": 8
          },
          "terminology": {
            "figure": 4,
            "8-queens": 2,
            "state": 2,
            "corresponding": 1,
            "parent": 1,
            "first": 2,
            "offspring": 2,
            "green": 1,
            "column": 3,
            "lost": 1,
            "crossover": 2,
            "step": 3,
            "red": 1,
            "retained": 1,
            "interpret": 1,
            "number": 1,
            "row": 3,
            "bottom": 1,
            "top": 1,
            "location": 1,
            "string": 1,
            "subject": 1,
            "random": 3,
            "mutation": 1,
            "small": 1,
            "independent": 1,
            "probability": 1,
            "digit": 1,
            "mutated": 1,
            "third": 1,
            "fourth": 1,
            "problem": 1,
            "corresponds": 1,
            "choosing": 1,
            "queen": 1,
            "moving": 1,
            "square": 1,
            "case": 1,
            "population": 2,
            "diverse": 2,
            "early": 2,
            "process": 2,
            "take": 1,
            "large": 1,
            "space": 1,
            "search": 1,
            "simulated": 1,
            "annealing": 1,
            "many": 1,
            "generation": 1,
            "selection": 1,
            "higher": 1,
            "fitness": 1,
            "becomes": 1,
            "less": 1,
            "smaller": 1,
            "typical": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para62",
          "content": "Figure 4.8\ndescribes an algorithm that implements all these steps.",
          "sentence_count": 1,
          "char_count": 58,
          "prev_para_id": "chap4_para61",
          "next_para_id": "chap4_para63",
          "style_metadata": {
            "para_id": "chap4_para62",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "describes": 1,
            "algorithm": 1,
            "implement": 1,
            "step": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para63",
          "content": "Description\nA bold arrow labeled suck and an arrow labeled Right from the first state of the vacuum world point to the first two circular nodes. Two bold arrows from the first circular node with an arc point to states 7 and 5 of the vacuum world. State 7 is labeled Goal. An arrow from the second circular node on the right points to state 2 of the vacuum world. A bold arrow labeled Right, and a light arrow labeled suck points to the third and the fourth circular nodes. Arrows labeled left and suck from state 2 points to the fifth and the sixth nodes. Arrows from the third node with an arc point to states 5 and 1 labeled Loop. A bold arrow from the fourth node points to state 6 of the vacuum world. An arrow from the fifth node points to state 1 of vacuum world labeled Loop. Two arrows from the sixth node with an arc point to states 8 and 4 of the vacuum world. State 8 is labeled Goal. Two bold arrows from state 4 points outward. A bold arrow labeled Suck, and a light arrow labeled Left from state 6 points to the seventh and eighth nodes. A bold arrow from the seventh node points to state 8 labeled goal state. A light arrow from the eighth node points to state 5 labeled Loop.",
          "sentence_count": 15,
          "char_count": 961,
          "prev_para_id": "chap4_para62",
          "next_para_id": "chap4_para64",
          "style_metadata": {
            "para_id": "chap4_para63",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.6,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 249,
            "sentence_count": 15
          },
          "terminology": {
            "description": 1,
            "bold": 7,
            "arrow": 16,
            "labeled": 13,
            "suck": 4,
            "right": 3,
            "first": 1,
            "state": 15,
            "vacuum": 6,
            "world": 6,
            "point": 13,
            "circular": 4,
            "node": 12,
            "arc": 3,
            "goal": 3,
            "second": 1,
            "light": 3,
            "third": 2,
            "fourth": 2,
            "left": 2,
            "fifth": 2,
            "sixth": 2,
            "loop": 3,
            "seventh": 2,
            "eighth": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para63",
              "entity_text": "Goal",
              "entity_type": "PERSON",
              "start_char": 266,
              "end_char": 270,
              "context": "s 7 and 5 of the vacuum world. State 7 is labeled Goal. An arrow from the second circular node on the ri"
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "Loop",
              "entity_type": "ORG",
              "start_char": 627,
              "end_char": 631,
              "context": " node with an arc point to states 5 and 1 labeled Loop. A bold arrow from the fourth node points to stat"
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "Loop",
              "entity_type": "ORG",
              "start_char": 777,
              "end_char": 781,
              "context": "th node points to state 1 of vacuum world labeled Loop. Two arrows from the sixth node with an arc point"
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "Goal",
              "entity_type": "PERSON",
              "start_char": 890,
              "end_char": 894,
              "context": "s 8 and 4 of the vacuum world. State 8 is labeled Goal. Two bold arrows from state 4 points outward. A b"
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "Suck",
              "entity_type": "PERSON",
              "start_char": 962,
              "end_char": 966,
              "context": "from state 4 points outward. A bold arrow labeled Suck, and a light arrow labeled Left from state 6 poin"
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "Left",
              "entity_type": "PRODUCT",
              "start_char": 994,
              "end_char": 998,
              "context": "old arrow labeled Suck, and a light arrow labeled Left from state 6 points to the seventh and eighth nod"
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 1155,
              "end_char": 1159,
              "context": "labeled goal state. A light arrow from the eighth node points to state 5 labeled Loop."
            },
            {
              "para_id": "chap4_para63",
              "entity_text": "Loop",
              "entity_type": "ORG",
              "start_char": 1186,
              "end_char": 1190,
              "context": "ow from the eighth node points to state 5 labeled Loop."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para64",
          "content": "×\nFigure 4.8\nA genetic algorithm. Within the function,\npopulation\nis an ordered list of individuals,\nweights\nis a list of corresponding fitness values for each individual, and\nfitness\nis a function to compute these values.",
          "sentence_count": 2,
          "char_count": 195,
          "prev_para_id": "chap4_para63",
          "next_para_id": "chap4_para65",
          "style_metadata": {
            "para_id": "chap4_para64",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "genetic": 1,
            "algorithm": 1,
            "function": 2,
            "population": 1,
            "ordered": 1,
            "list": 2,
            "individual": 2,
            "weight": 1,
            "corresponding": 1,
            "fitness": 2,
            "value": 2,
            "compute": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para65",
          "content": "Genetic algorithms are similar to stochastic beam search, but with the addition of the crossover operation. This is advantageous if there are blocks that perform useful functions. For example, it could be that putting the first three queens in positions 2, 4, and 6 (where they do not attack each other) constitutes a useful block that can be combined with other useful blocks that appear in other individuals to construct a solution. It can be shown mathematically that, if the blocks do not serve a purpose—for example if the positions of the genetic code are randomly permuted—then crossover conveys no advantage.",
          "sentence_count": 4,
          "char_count": 516,
          "prev_para_id": "chap4_para64",
          "next_para_id": "chap4_para66",
          "style_metadata": {
            "para_id": "chap4_para65",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 4
          },
          "terminology": {
            "genetic": 2,
            "algorithm": 1,
            "similar": 1,
            "stochastic": 1,
            "beam": 1,
            "search": 1,
            "addition": 1,
            "crossover": 2,
            "operation": 1,
            "advantageous": 1,
            "block": 4,
            "perform": 1,
            "useful": 3,
            "function": 1,
            "example": 2,
            "putting": 1,
            "queen": 1,
            "position": 2,
            "attack": 1,
            "constitutes": 1,
            "combined": 1,
            "appear": 1,
            "individual": 1,
            "construct": 1,
            "solution": 1,
            "shown": 1,
            "serve": 1,
            "purpose—for": 1,
            "code": 1,
            "randomly": 1,
            "permuted—then": 1,
            "conveys": 1,
            "advantage": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para66",
          "content": "The theory of genetic algorithms explains how this works using the idea of a\nschema\n, which is a substring in which some of the positions can be left unspecified. For example, the schema 246***** describes all 8-queens states in which the first three queens are in positions 2, 4, and 6, respectively. Strings that match the schema (such as 24613578) are called\ninstances\nof the schema. It can be shown that if the average fitness of the instances of a schema is above the mean, then the number of instances of the schema will grow over time.",
          "sentence_count": 4,
          "char_count": 449,
          "prev_para_id": "chap4_para65",
          "next_para_id": "chap4_para67",
          "style_metadata": {
            "para_id": "chap4_para66",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "theory": 1,
            "genetic": 1,
            "algorithm": 1,
            "explains": 1,
            "work": 1,
            "using": 1,
            "idea": 1,
            "schema": 6,
            "substring": 1,
            "position": 2,
            "left": 1,
            "unspecified": 1,
            "example": 1,
            "describes": 1,
            "state": 1,
            "queen": 1,
            "string": 1,
            "match": 1,
            "called": 1,
            "instance": 3,
            "shown": 1,
            "average": 1,
            "fitness": 1,
            "mean": 1,
            "number": 1,
            "grow": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para67",
          "content": "Evolution and Search\nThe theory of\nevolution\nwas developed by Charles Darwin in\nOn the Origin of Species by Means of Natural Selection\n(1859) and independently by Alfred Russel Wallace (1858). The central idea is simple: variations occur in reproduction and will be preserved in successive generations approximately in proportion to their effect on reproductive fitness.",
          "sentence_count": 2,
          "char_count": 320,
          "prev_para_id": "chap4_para66",
          "next_para_id": "chap4_para68",
          "style_metadata": {
            "para_id": "chap4_para67",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "evolution": 2,
            "search": 1,
            "theory": 1,
            "developed": 1,
            "charles": 1,
            "darwin": 1,
            "origin": 1,
            "specie": 1,
            "mean": 1,
            "natural": 1,
            "selection": 1,
            "alfred": 1,
            "russel": 1,
            "wallace": 1,
            "central": 1,
            "idea": 1,
            "simple": 1,
            "variation": 1,
            "occur": 1,
            "reproduction": 1,
            "preserved": 1,
            "successive": 1,
            "generation": 1,
            "proportion": 1,
            "effect": 1,
            "reproductive": 1,
            "fitness": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para67",
              "entity_text": "Charles Darwin",
              "entity_type": "PERSON",
              "start_char": 62,
              "end_char": 76,
              "context": "d Search\nThe theory of\nevolution\nwas developed by Charles Darwin in\nOn the Origin of Species by Means of Natural S"
            },
            {
              "para_id": "chap4_para67",
              "entity_text": "the Origin of Species",
              "entity_type": "ORG",
              "start_char": 83,
              "end_char": 104,
              "context": "f\nevolution\nwas developed by Charles Darwin in\nOn the Origin of Species by Means of Natural Selection\n(1859) and independ"
            },
            {
              "para_id": "chap4_para67",
              "entity_text": "Alfred Russel Wallace",
              "entity_type": "PERSON",
              "start_char": 163,
              "end_char": 184,
              "context": " of Natural Selection\n(1859) and independently by Alfred Russel Wallace (1858). The central idea is simple: variations oc"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para68",
          "content": "Darwin’s theory was developed with no knowledge of how the traits of organisms can be inherited and modified. The probabilistic laws governing these processes were first identified by Gregor Mendel (1866), a monk who experimented with sweet peas. Much later, Watson and Crick (1953) identified the structure of the DNA molecule and its alphabet, AGTC (adenine, guanine, thymine, cytosine). In the standard model, variation occurs both by point mutations in the letter sequence and by “crossover” (in which the DNA of an offspring is generated by combining long sections of DNA from each parent).",
          "sentence_count": 4,
          "char_count": 502,
          "prev_para_id": "chap4_para67",
          "next_para_id": "chap4_para69",
          "style_metadata": {
            "para_id": "chap4_para68",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.25,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 117,
            "sentence_count": 4
          },
          "terminology": {
            "darwin": 1,
            "theory": 1,
            "developed": 1,
            "knowledge": 1,
            "trait": 1,
            "inherited": 1,
            "modified": 1,
            "probabilistic": 1,
            "law": 1,
            "governing": 1,
            "process": 1,
            "identified": 2,
            "gregor": 1,
            "mendel": 1,
            "monk": 1,
            "experimented": 1,
            "sweet": 1,
            "watson": 1,
            "crick": 1,
            "structure": 1,
            "dna": 3,
            "molecule": 1,
            "alphabet": 1,
            "agtc": 1,
            "adenine": 1,
            "guanine": 1,
            "thymine": 1,
            "cytosine": 1,
            "standard": 1,
            "model": 1,
            "variation": 1,
            "occurs": 1,
            "point": 1,
            "mutation": 1,
            "letter": 1,
            "sequence": 1,
            "crossover": 1,
            "offspring": 1,
            "generated": 1,
            "combining": 1,
            "long": 1,
            "section": 1,
            "parent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para68",
              "entity_text": "Darwin",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 6,
              "context": "Darwin’s theory was developed with no knowledge of how t"
            },
            {
              "para_id": "chap4_para68",
              "entity_text": "Gregor Mendel",
              "entity_type": "PERSON",
              "start_char": 184,
              "end_char": 197,
              "context": "overning these processes were first identified by Gregor Mendel (1866), a monk who experimented with sweet peas. "
            },
            {
              "para_id": "chap4_para68",
              "entity_text": "Watson",
              "entity_type": "PERSON",
              "start_char": 259,
              "end_char": 265,
              "context": "onk who experimented with sweet peas. Much later, Watson and Crick (1953) identified the structure of the "
            },
            {
              "para_id": "chap4_para68",
              "entity_text": "Crick",
              "entity_type": "PERSON",
              "start_char": 270,
              "end_char": 275,
              "context": "erimented with sweet peas. Much later, Watson and Crick (1953) identified the structure of the DNA molecu"
            },
            {
              "para_id": "chap4_para68",
              "entity_text": "AGTC",
              "entity_type": "ORG",
              "start_char": 346,
              "end_char": 350,
              "context": "e structure of the DNA molecule and its alphabet, AGTC (adenine, guanine, thymine, cytosine). In the sta"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para69",
          "content": "The analogy to local search algorithms has already been described; the principal difference between stochastic beam search and evolution is the use of\nsexual\nreproduction, wherein successors are generated from\nmultiple\nindividuals rather than just one. The actual mechanisms of evolution are, however, far richer than most genetic algorithms allow. For example, mutations can involve reversals, duplications, and movement of large chunks of DNA; some viruses borrow DNA from one organism and insert it into another; and there are transposable genes that do nothing but copy themselves many thousands of times within the genome.",
          "sentence_count": 3,
          "char_count": 538,
          "prev_para_id": "chap4_para68",
          "next_para_id": "chap4_para70",
          "style_metadata": {
            "para_id": "chap4_para69",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 35.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 106,
            "sentence_count": 3
          },
          "terminology": {
            "analogy": 1,
            "local": 1,
            "search": 2,
            "algorithm": 2,
            "described": 1,
            "principal": 1,
            "difference": 1,
            "stochastic": 1,
            "beam": 1,
            "evolution": 2,
            "use": 1,
            "sexual": 1,
            "reproduction": 1,
            "wherein": 1,
            "successor": 1,
            "generated": 1,
            "multiple": 1,
            "individual": 1,
            "actual": 1,
            "mechanism": 1,
            "richer": 1,
            "genetic": 1,
            "allow": 1,
            "example": 1,
            "mutation": 1,
            "involve": 1,
            "reversal": 1,
            "duplication": 1,
            "movement": 1,
            "large": 1,
            "chunk": 1,
            "dna": 2,
            "virus": 1,
            "borrow": 1,
            "organism": 1,
            "insert": 1,
            "transposable": 1,
            "gene": 1,
            "nothing": 1,
            "copy": 1,
            "many": 1,
            "thousand": 1,
            "time": 1,
            "genome": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para70",
          "content": "There are even genes that poison cells from potential mates that do not carry the gene, thereby increasing their own chances of replication. Most important is the fact that the\ngenes themselves encode the mechanisms\nwhereby the genome is reproduced and translated into an organism. In genetic algorithms, those mechanisms are a separate program that is not represented within the strings being manipulated.",
          "sentence_count": 3,
          "char_count": 346,
          "prev_para_id": "chap4_para69",
          "next_para_id": "chap4_para71",
          "style_metadata": {
            "para_id": "chap4_para70",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.67,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 3
          },
          "terminology": {
            "gene": 3,
            "poison": 1,
            "cell": 1,
            "potential": 1,
            "mate": 1,
            "carry": 1,
            "increasing": 1,
            "chance": 1,
            "replication": 1,
            "important": 1,
            "fact": 1,
            "encode": 1,
            "mechanism": 2,
            "genome": 1,
            "reproduced": 1,
            "translated": 1,
            "organism": 1,
            "genetic": 1,
            "algorithm": 1,
            "separate": 1,
            "program": 1,
            "represented": 1,
            "string": 1,
            "manipulated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para71",
          "content": "Darwinian evolution may appear inefficient, having generated blindly some 10\n43\nor so organisms without improving its search heuristics one iota. But learning does play a role in evolution. Although the otherwise great French naturalist Jean Lamarck (1809) was wrong to propose that traits acquired by adaptation during an organism’s lifetime would be passed on to its offspring, James Baldwin’s (1896) superficially similar theory is correct: learning can effectively relax the fitness landscape, leading to an acceleration in the rate of evolution. An organism that has a trait that is not quite adaptive for its environment will pass on the trait if it also has enough plasticity to learn to adapt to the environment in a way that is beneficial. Computer simulations (Hinton and Nowlan, 1987) confirm that this\nBaldwin effect\nis real, and that a consequence is that things that are hard to learn end up in the genome, but things that are easy to learn need not reside there (Morgan and Griffiths, 2015).",
          "sentence_count": 5,
          "char_count": 846,
          "prev_para_id": "chap4_para70",
          "next_para_id": "chap4_para72",
          "style_metadata": {
            "para_id": "chap4_para71",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 190,
            "sentence_count": 5
          },
          "terminology": {
            "darwinian": 1,
            "evolution": 3,
            "appear": 1,
            "inefficient": 1,
            "generated": 1,
            "organism": 3,
            "improving": 1,
            "search": 1,
            "heuristic": 1,
            "iota": 1,
            "learning": 2,
            "play": 1,
            "role": 1,
            "great": 1,
            "french": 1,
            "naturalist": 1,
            "jean": 1,
            "lamarck": 1,
            "wrong": 1,
            "propose": 1,
            "trait": 3,
            "acquired": 1,
            "adaptation": 1,
            "lifetime": 1,
            "passed": 1,
            "offspring": 1,
            "james": 1,
            "baldwin": 2,
            "similar": 1,
            "theory": 1,
            "correct": 1,
            "relax": 1,
            "fitness": 1,
            "landscape": 1,
            "leading": 1,
            "acceleration": 1,
            "rate": 1,
            "adaptive": 1,
            "environment": 2,
            "pas": 1,
            "plasticity": 1,
            "learn": 3,
            "adapt": 1,
            "way": 1,
            "beneficial": 1,
            "computer": 1,
            "simulation": 1,
            "hinton": 1,
            "nowlan": 1,
            "confirm": 1,
            "effect": 1,
            "real": 1,
            "consequence": 1,
            "thing": 2,
            "end": 1,
            "genome": 1,
            "easy": 1,
            "need": 1,
            "reside": 1,
            "morgan": 1,
            "griffith": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para71",
              "entity_text": "Jean Lamarck",
              "entity_type": "PERSON",
              "start_char": 237,
              "end_char": 249,
              "context": "n. Although the otherwise great French naturalist Jean Lamarck (1809) was wrong to propose that traits acquired "
            },
            {
              "para_id": "chap4_para71",
              "entity_text": "James Baldwin’s",
              "entity_type": "PERSON",
              "start_char": 380,
              "end_char": 395,
              "context": "m’s lifetime would be passed on to its offspring, James Baldwin’s (1896) superficially similar theory is correct: l"
            },
            {
              "para_id": "chap4_para71",
              "entity_text": "Hinton and",
              "entity_type": "ORG",
              "start_char": 771,
              "end_char": 781,
              "context": "n a way that is beneficial. Computer simulations (Hinton and Nowlan, 1987) confirm that this\nBaldwin effect\nis"
            },
            {
              "para_id": "chap4_para71",
              "entity_text": "Nowlan",
              "entity_type": "ORG",
              "start_char": 782,
              "end_char": 788,
              "context": "t is beneficial. Computer simulations (Hinton and Nowlan, 1987) confirm that this\nBaldwin effect\nis real, "
            },
            {
              "para_id": "chap4_para71",
              "entity_text": "Baldwin",
              "entity_type": "PERSON",
              "start_char": 814,
              "end_char": 821,
              "context": "tions (Hinton and Nowlan, 1987) confirm that this\nBaldwin effect\nis real, and that a consequence is that th"
            },
            {
              "para_id": "chap4_para71",
              "entity_text": "Morgan",
              "entity_type": "PERSON",
              "start_char": 978,
              "end_char": 984,
              "context": "ngs that are easy to learn need not reside there (Morgan and Griffiths, 2015)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para72",
          "content": "Clearly, this effect is unlikely to be significant if adjacent bits are totally unrelated to each other, because then there will be few contiguous blocks that provide a consistent benefit. Genetic algorithms work best when schemas correspond to meaningful components of a solution. For example, if the string is a representation of an antenna, then the schemas may represent components of the antenna, such as reflectors and deflectors. A good component is likely to be good in a variety of different designs. This suggests that successful use of genetic algorithms requires careful engineering of the representation.",
          "sentence_count": 5,
          "char_count": 522,
          "prev_para_id": "chap4_para71",
          "next_para_id": "chap4_para73",
          "style_metadata": {
            "para_id": "chap4_para72",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 5
          },
          "terminology": {
            "effect": 1,
            "unlikely": 1,
            "significant": 1,
            "adjacent": 1,
            "bit": 1,
            "unrelated": 1,
            "contiguous": 1,
            "block": 1,
            "provide": 1,
            "consistent": 1,
            "benefit": 1,
            "genetic": 2,
            "algorithm": 2,
            "work": 1,
            "schema": 2,
            "correspond": 1,
            "meaningful": 1,
            "component": 3,
            "solution": 1,
            "example": 1,
            "string": 1,
            "representation": 2,
            "represent": 1,
            "antenna": 1,
            "reflector": 1,
            "deflector": 1,
            "good": 2,
            "variety": 1,
            "different": 1,
            "design": 1,
            "suggests": 1,
            "successful": 1,
            "use": 1,
            "requires": 1,
            "careful": 1,
            "engineering": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para72",
              "entity_text": "schemas correspond",
              "entity_type": "PERSON",
              "start_char": 223,
              "end_char": 241,
              "context": "istent benefit. Genetic algorithms work best when schemas correspond to meaningful components of a solution. For examp"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para73",
          "content": "In practice, genetic algorithms have their place within the broad landscape of optimization methods (Marler and Arora, 2004), particularly for complex structured problems such as circuit layout or job-shop scheduling, and more recently for evolving the architecture of deep neural networks (Miikkulainen\net al.,\n2019). It is not clear how much of the appeal of genetic algorithms arises from their superiority on specific tasks, and how much from the appealing metaphor of evolution.",
          "sentence_count": 2,
          "char_count": 413,
          "prev_para_id": "chap4_para72",
          "next_para_id": "chap4_para74",
          "style_metadata": {
            "para_id": "chap4_para73",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 2
          },
          "terminology": {
            "practice": 1,
            "genetic": 2,
            "algorithm": 2,
            "place": 1,
            "broad": 1,
            "landscape": 1,
            "optimization": 1,
            "method": 1,
            "marler": 1,
            "arora": 1,
            "complex": 1,
            "structured": 1,
            "problem": 1,
            "circuit": 1,
            "job-shop": 1,
            "scheduling": 1,
            "evolving": 1,
            "architecture": 1,
            "deep": 1,
            "neural": 1,
            "network": 1,
            "miikkulainen": 1,
            "al.": 1,
            "clear": 1,
            "much": 2,
            "appeal": 1,
            "arises": 1,
            "superiority": 1,
            "specific": 1,
            "task": 1,
            "appealing": 1,
            "metaphor": 1,
            "evolution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para73",
              "entity_text": "Marler",
              "entity_type": "ORG",
              "start_char": 101,
              "end_char": 107,
              "context": "thin the broad landscape of optimization methods (Marler and Arora, 2004), particularly for complex struct"
            },
            {
              "para_id": "chap4_para73",
              "entity_text": "Arora",
              "entity_type": "PERSON",
              "start_char": 112,
              "end_char": 117,
              "context": "oad landscape of optimization methods (Marler and Arora, 2004), particularly for complex structured probl"
            },
            {
              "para_id": "chap4_para73",
              "entity_text": "Miikkulainen",
              "entity_type": "PERSON",
              "start_char": 291,
              "end_char": 303,
              "context": "volving the architecture of deep neural networks (Miikkulainen\net al.,\n2019). It is not clear how much of the ap"
            },
            {
              "para_id": "chap4_para73",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 307,
              "end_char": 310,
              "context": "itecture of deep neural networks (Miikkulainen\net al.,\n2019). It is not clear how much of the appeal of"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para74",
          "content": "4.2Local Search in Continuous Spaces\n4.2\nLocal Search in Continuous Spaces\nIn\nChapter 2\n, we explained the distinction between discrete and continuous environments, pointing out that most real-world environments are continuous. A continuous action space has an infinite branching factor, and thus can’t be handled by most of the algorithms we have covered so far (with the exception of first-choice hill climbing and simulated annealing).",
          "sentence_count": 2,
          "char_count": 378,
          "prev_para_id": "chap4_para73",
          "next_para_id": "chap4_para75",
          "style_metadata": {
            "para_id": "chap4_para74",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 74,
            "sentence_count": 2
          },
          "terminology": {
            "4.2local": 1,
            "search": 2,
            "continuous": 5,
            "space": 3,
            "local": 1,
            "chapter": 1,
            "explained": 1,
            "distinction": 1,
            "environment": 2,
            "pointing": 1,
            "real-world": 1,
            "action": 1,
            "infinite": 1,
            "branching": 1,
            "factor": 1,
            "handled": 1,
            "algorithm": 1,
            "covered": 1,
            "exception": 1,
            "first-choice": 1,
            "hill": 1,
            "climbing": 1,
            "simulated": 1,
            "annealing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para74",
              "entity_text": "Continuous Spaces",
              "entity_type": "ORG",
              "start_char": 19,
              "end_char": 36,
              "context": "4.2Local Search in Continuous Spaces\n4.2\nLocal Search in Continuous Spaces\nIn\nChapter "
            },
            {
              "para_id": "chap4_para74",
              "entity_text": "Local Search",
              "entity_type": "ORG",
              "start_char": 41,
              "end_char": 53,
              "context": "4.2Local Search in Continuous Spaces\n4.2\nLocal Search in Continuous Spaces\nIn\nChapter 2\n, we explained "
            },
            {
              "para_id": "chap4_para74",
              "entity_text": "Continuous Spaces",
              "entity_type": "ORG",
              "start_char": 57,
              "end_char": 74,
              "context": "l Search in Continuous Spaces\n4.2\nLocal Search in Continuous Spaces\nIn\nChapter 2\n, we explained the distinction betwe"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para75",
          "content": "This section provides a\nvery brief\nintroduction to some local search techniques for continuous spaces. The literature on this topic is vast; many of the basic techniques originated\nin the 17th century, after the development of calculus by Newton and Leibniz.",
          "sentence_count": 2,
          "char_count": 221,
          "prev_para_id": "chap4_para74",
          "next_para_id": "chap4_para76",
          "style_metadata": {
            "para_id": "chap4_para75",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "section": 1,
            "provides": 1,
            "brief": 1,
            "introduction": 1,
            "local": 1,
            "search": 1,
            "technique": 2,
            "continuous": 1,
            "space": 1,
            "literature": 1,
            "topic": 1,
            "vast": 1,
            "many": 1,
            "basic": 1,
            "originated": 1,
            "17th": 1,
            "century": 1,
            "development": 1,
            "calculus": 1,
            "newton": 1,
            "leibniz": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para75",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 239,
              "end_char": 245,
              "context": "7th century, after the development of calculus by Newton and Leibniz."
            },
            {
              "para_id": "chap4_para75",
              "entity_text": "Leibniz",
              "entity_type": "ORG",
              "start_char": 250,
              "end_char": 257,
              "context": ", after the development of calculus by Newton and Leibniz."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para76",
          "content": "2\nWe find uses for these techniques in several places in this book, including the chapters on learning, vision, and robotics.",
          "sentence_count": 1,
          "char_count": 106,
          "prev_para_id": "chap4_para75",
          "next_para_id": "chap4_para77",
          "style_metadata": {
            "para_id": "chap4_para76",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "find": 1,
            "us": 1,
            "technique": 1,
            "several": 1,
            "place": 1,
            "book": 1,
            "including": 1,
            "chapter": 1,
            "learning": 1,
            "vision": 1,
            "robotics": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para77",
          "content": "We begin with an example. Suppose we want to place three new airports anywhere in Romania, such that the sum of squared straight-line distances from each city on the map to its nearest airport is minimized. (See\nFigure 3.1\nfor the map of Romania.) The state space is then defined by the coordinates of the three airports: (\nx\n1\n,\ny\n1\n), (\nx\n2\n,\ny\n2\n), and (\nx\n3\n,\ny\n3\n). This is a\nsix-dimensional\nspace; we also say that states are defined by six\nvariables\n. In general, states are defined by an\nn\n-dimensional vector of variables,\nx\n. Moving around in this space corresponds to moving one or more of the airports on the map. The objective function\nf\n(\nx\n) =\nf\n(\nx\n1\n,\ny\n1\n,\nx\n2\n,\ny\n2\n,\nx\n3\n,\ny\n3\n) is relatively easy to compute for any particular state once we compute the closest cities. Let\nC\ni\nbe the set of cities whose closest airport (in the state\nx\n) is airport\ni\n. Then, we have\nf\n(x) =\nf\n(\nx\n1\n,\ny\n1\n,\nx\n2\n,\ny\n2\n,\nx\n3\n,\ny\n3\n) =\n∑\ni\n=\n1\n3\n∑\nc\n∈\nC\ni\n(\nx\ni\n−\nx\nc\n)\n2\n+ (\ny\ni\n−\ny\nc\n)\n2\n.",
          "sentence_count": 10,
          "char_count": 861,
          "prev_para_id": "chap4_para76",
          "next_para_id": "chap4_para78",
          "style_metadata": {
            "para_id": "chap4_para77",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.3,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 263,
            "sentence_count": 10
          },
          "terminology": {
            "begin": 1,
            "example": 1,
            "suppose": 1,
            "want": 1,
            "place": 1,
            "new": 1,
            "airport": 6,
            "romania": 2,
            "sum": 1,
            "squared": 1,
            "straight-line": 1,
            "distance": 1,
            "city": 3,
            "map": 2,
            "nearest": 1,
            "minimized": 1,
            "see": 1,
            "figure": 1,
            "state": 5,
            "space": 3,
            "defined": 3,
            "coordinate": 1,
            "six-dimensional": 1,
            "say": 1,
            "variable": 2,
            "general": 1,
            "-dimensional": 1,
            "vector": 1,
            "moving": 2,
            "corresponds": 1,
            "objective": 1,
            "function": 1,
            "easy": 1,
            "compute": 2,
            "particular": 1,
            "closest": 2,
            "let": 1,
            "set": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para77",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 82,
              "end_char": 89,
              "context": "e we want to place three new airports anywhere in Romania, such that the sum of squared straight-line dista"
            },
            {
              "para_id": "chap4_para77",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 238,
              "end_char": 245,
              "context": "port is minimized. (See\nFigure 3.1\nfor the map of Romania.) The state space is then defined by the coordina"
            },
            {
              "para_id": "chap4_para77",
              "entity_text": "−",
              "entity_type": "GPE",
              "start_char": 964,
              "end_char": 965,
              "context": "2\n,\ny\n2\n,\nx\n3\n,\ny\n3\n) =\n∑\ni\n=\n1\n3\n∑\nc\n∈\nC\ni\n(\nx\ni\n−\nx\nc\n)\n2\n+ (\ny\ni\n−\ny\nc\n)\n2\n."
            },
            {
              "para_id": "chap4_para77",
              "entity_text": "−",
              "entity_type": "GPE",
              "start_char": 982,
              "end_char": 983,
              "context": "3\n) =\n∑\ni\n=\n1\n3\n∑\nc\n∈\nC\ni\n(\nx\ni\n−\nx\nc\n)\n2\n+ (\ny\ni\n−\ny\nc\n)\n2\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para78",
          "content": "(\n4.1\n)\nThis equation is correct not only for the state\nx\nbut also for states in the local neighborhood of\nx\n. However, it is not correct globally; if we stray too far from\nx\n(by altering the location of one or more of the airports by a large amount) then the set of closest cities for that airport changes, and we need to recompute\nC\ni\n.",
          "sentence_count": 2,
          "char_count": 281,
          "prev_para_id": "chap4_para77",
          "next_para_id": "chap4_para79",
          "style_metadata": {
            "para_id": "chap4_para78",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 37.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 75,
            "sentence_count": 2
          },
          "terminology": {
            "equation": 1,
            "correct": 2,
            "state": 2,
            "local": 1,
            "neighborhood": 1,
            "stray": 1,
            "altering": 1,
            "location": 1,
            "airport": 2,
            "large": 1,
            "amount": 1,
            "set": 1,
            "closest": 1,
            "city": 1,
            "change": 1,
            "need": 1,
            "recompute": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para79",
          "content": "One way to deal with a continuous state space is to\ndiscretize\nit. For example, instead of allowing the (\nx\ni\n,\ny\ni\n) locations to be any point in continuous two-dimensional space, we could limit them to fixed points on a rectangular grid with spacing of size\nδ\n(delta). Then instead of having an infinite number of successors, each state in the space would have only 12 successors, corresponding to incrementing one of the 6 variables by ±\nδ\n. We can then apply any of our local search algorithms to this discrete space. Alternatively, we could make the branching factor finite by sampling successor states randomly, moving in a random direction by a small amount,\nδ\n. Methods that measure progress by the change in the value of the objective function between two nearby points are called\nempirical gradient\nmethods. Empirical gradient search is the same as steepest-ascent hill climbing in a discretized version of the state space. Reducing the value of\nδ\nover time can give a more accurate solution, but does not necessarily converge to a global optimum in the limit.",
          "sentence_count": 8,
          "char_count": 902,
          "prev_para_id": "chap4_para78",
          "next_para_id": "chap4_para80",
          "style_metadata": {
            "para_id": "chap4_para79",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.38,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 203,
            "sentence_count": 8
          },
          "terminology": {
            "way": 1,
            "deal": 1,
            "continuous": 2,
            "state": 4,
            "space": 5,
            "discretize": 1,
            "example": 1,
            "allowing": 1,
            "location": 1,
            "point": 3,
            "two-dimensional": 1,
            "limit": 2,
            "fixed": 1,
            "rectangular": 1,
            "grid": 1,
            "spacing": 1,
            "size": 1,
            "delta": 1,
            "infinite": 1,
            "number": 1,
            "successor": 3,
            "corresponding": 1,
            "incrementing": 1,
            "variable": 1,
            "local": 1,
            "search": 2,
            "algorithm": 1,
            "discrete": 1,
            "make": 1,
            "branching": 1,
            "factor": 1,
            "finite": 1,
            "sampling": 1,
            "moving": 1,
            "random": 1,
            "direction": 1,
            "small": 1,
            "amount": 1,
            "method": 2,
            "measure": 1,
            "progress": 1,
            "change": 1,
            "value": 2,
            "objective": 1,
            "function": 1,
            "nearby": 1,
            "called": 1,
            "empirical": 2,
            "gradient": 2,
            "steepest-ascent": 1,
            "hill": 1,
            "climbing": 1,
            "discretized": 1,
            "version": 1,
            "reducing": 1,
            "time": 1,
            "give": 1,
            "accurate": 1,
            "solution": 1,
            "converge": 1,
            "global": 1,
            "optimum": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para80",
          "content": "Often we have an objective function expressed in a mathematical form such that we can use calculus to solve the problem analytically rather than empirically. Many methods attempt to use the\ngradient\nof the landscape to find a maximum. The gradient of the objective function is a vector ∇\nf\nthat gives the magnitude and direction of the steepest slope. For our problem, we have\n∇\nf\n=\n(\n∂\nf\n∂\nx\n1\n,\n∂\nf\n∂\ny\n1\n,\n∂\nf\n∂\nx\n2\n,\n∂\nf\n∂\ny\n2\n,\n∂\nf\n∂\nx\n3\n,\n∂\nf\n∂\ny\n3\n,\n)\n.",
          "sentence_count": 4,
          "char_count": 400,
          "prev_para_id": "chap4_para79",
          "next_para_id": "chap4_para81",
          "style_metadata": {
            "para_id": "chap4_para80",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 111,
            "sentence_count": 4
          },
          "terminology": {
            "objective": 2,
            "function": 2,
            "expressed": 1,
            "mathematical": 1,
            "form": 1,
            "use": 2,
            "calculus": 1,
            "solve": 1,
            "problem": 2,
            "many": 1,
            "method": 1,
            "attempt": 1,
            "gradient": 2,
            "landscape": 1,
            "find": 1,
            "maximum": 1,
            "vector": 1,
            "give": 1,
            "magnitude": 1,
            "direction": 1,
            "steepest": 1,
            "slope": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para81",
          "content": "In some cases, we can find a maximum by solving the equation ∇\nf =\n0. (This could be done, for example, if we were placing just one airport; the solution is the arithmetic mean of all the cities’ coordinates.) In many cases, however, this equation cannot be solved in closed form. For example, with three airports, the expression for the gradient depends on what cities are\nclosest to each airport in the current state. This means we can compute the gradient\nlocally\n(but not\nglobally\n); for example,\n∂\nf\n∂\nx\n1\n=\n2\n∑\nc\n∈\nC\n1\n(\nx\n1\n−\nx\nc\n)\n.",
          "sentence_count": 5,
          "char_count": 459,
          "prev_para_id": "chap4_para80",
          "next_para_id": "chap4_para82",
          "style_metadata": {
            "para_id": "chap4_para81",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 25.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 128,
            "sentence_count": 5
          },
          "terminology": {
            "case": 2,
            "find": 1,
            "maximum": 1,
            "solving": 1,
            "equation": 2,
            "done": 1,
            "example": 3,
            "placing": 1,
            "airport": 3,
            "solution": 1,
            "arithmetic": 1,
            "mean": 2,
            "city": 2,
            "coordinate": 1,
            "many": 1,
            "solved": 1,
            "closed": 1,
            "form": 1,
            "expression": 1,
            "gradient": 2,
            "depends": 1,
            "closest": 1,
            "current": 1,
            "state": 1,
            "compute": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para82",
          "content": "(\n4.2\n)\nGiven a locally correct expression for the gradient, we can perform steepest-ascent hill climbing by updating the current state according to the formula\nx\n←\nx\n+\nα\n∇\nf\n(\nx\n)\n,\nwhere α (alpha) is a small constant often called the\nstep size\n. There exist a huge variety of methods for adjusting α. The basic problem is that if α is too small, too many steps are needed; if α is too large, the search could overshoot the maximum. The technique of\nline search\ntries to overcome this dilemma by extending the current gradient direction—usually by repeatedly doubling α—until\nf\nstarts to decrease again. The point at which this occurs becomes the new current state. There are several schools of thought about how the new direction should be chosen at this point.",
          "sentence_count": 6,
          "char_count": 646,
          "prev_para_id": "chap4_para81",
          "next_para_id": "chap4_para83",
          "style_metadata": {
            "para_id": "chap4_para82",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 149,
            "sentence_count": 6
          },
          "terminology": {
            "given": 1,
            "correct": 1,
            "expression": 1,
            "gradient": 2,
            "perform": 1,
            "steepest-ascent": 1,
            "hill": 1,
            "climbing": 1,
            "updating": 1,
            "current": 3,
            "state": 2,
            "according": 1,
            "formula": 1,
            "alpha": 1,
            "small": 2,
            "constant": 1,
            "called": 1,
            "step": 2,
            "size": 1,
            "exist": 1,
            "huge": 1,
            "variety": 1,
            "method": 1,
            "adjusting": 1,
            "basic": 1,
            "problem": 1,
            "many": 1,
            "needed": 1,
            "large": 1,
            "search": 2,
            "overshoot": 1,
            "maximum": 1,
            "technique": 1,
            "line": 1,
            "try": 1,
            "overcome": 1,
            "dilemma": 1,
            "extending": 1,
            "doubling": 1,
            "α—until": 1,
            "start": 1,
            "decrease": 1,
            "point": 2,
            "occurs": 1,
            "becomes": 1,
            "new": 2,
            "several": 1,
            "school": 1,
            "thought": 1,
            "direction": 1,
            "chosen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para82",
              "entity_text": "←\nx\n+\nα\n∇\nf\n",
              "entity_type": "PERSON",
              "start_char": 163,
              "end_char": 175,
              "context": "ting the current state according to the formula\nx\n←\nx\n+\nα\n∇\nf\n(\nx\n)\n,\nwhere α (alpha) is a small constant often "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para83",
          "content": "For many problems, the most effective algorithm is the venerable\nNewton–Raphson\nmethod. This is a general technique for finding roots of functions—that is, solving equations of the form\ng\n(\nx\n) = 0. It works by computing a new estimate for the root\nx\naccording to Newton’s formula\nx\n←\nx\n−\ng\n(\nx\n)\n/\ng\n'\n(\nx\n)\n.",
          "sentence_count": 3,
          "char_count": 270,
          "prev_para_id": "chap4_para82",
          "next_para_id": "chap4_para84",
          "style_metadata": {
            "para_id": "chap4_para83",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 3
          },
          "terminology": {
            "many": 1,
            "problem": 1,
            "effective": 1,
            "algorithm": 1,
            "venerable": 1,
            "newton–raphson": 1,
            "method": 1,
            "general": 1,
            "technique": 1,
            "finding": 1,
            "root": 2,
            "solving": 1,
            "equation": 1,
            "form": 1,
            "work": 1,
            "computing": 1,
            "new": 1,
            "estimate": 1,
            "according": 1,
            "newton": 1,
            "formula": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para83",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 65,
              "end_char": 71,
              "context": "ms, the most effective algorithm is the venerable\nNewton–Raphson\nmethod. This is a general technique for f"
            },
            {
              "para_id": "chap4_para83",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 264,
              "end_char": 270,
              "context": "puting a new estimate for the root\nx\naccording to Newton’s formula\nx\n←\nx\n−\ng\n(\nx\n)\n/\ng\n'\n(\nx\n)\n."
            },
            {
              "para_id": "chap4_para83",
              "entity_text": "←\nx",
              "entity_type": "PERSON",
              "start_char": 283,
              "end_char": 286,
              "context": "te for the root\nx\naccording to Newton’s formula\nx\n←\nx\n−\ng\n(\nx\n)\n/\ng\n'\n(\nx\n)\n."
            },
            {
              "para_id": "chap4_para83",
              "entity_text": "−",
              "entity_type": "GPE",
              "start_char": 287,
              "end_char": 288,
              "context": "or the root\nx\naccording to Newton’s formula\nx\n←\nx\n−\ng\n(\nx\n)\n/\ng\n'\n(\nx\n)\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para84",
          "content": "To find a maximum or minimum of\nf\n, we need to find\nx\nsuch that the\ngradient\nis a zero vector (i.e., ∇\nf\n(\nx\n) =\n0\n). Thus,\ng\n(\nx\n) in Newton’s formula becomes ∇\nf\n(\nx\n), and the update equation can be written in matrix–vector form as\nx\n←\nx\n−\nH\nf\n−\n1\n(\nx\n)\n∇\nf\n(\nx\n)\n,\nwhere\nH\nf\n(\nx\n) is the\nHessian\nmatrix of second derivatives, whose elements\nH\nij\nare given by ∂\n2\nf\n/∂\nx\ni\n∂\nx\nj\n. For our airport example, we can see from\nEquation (4.2)\nthat\nH\nf\n(\nx\n) is particularly simple: the off-diagonal elements are zero and the diagonal elements for airport\ni\nare just twice the number of cities in\nC\ni\n. A moment’s calculation shows that one step of the update moves airport\ni\ndirectly to the centroid of\nC\ni\n, which is the minimum of the local expression for\nf\nfrom\nEquation (4.1)\n.",
          "sentence_count": 4,
          "char_count": 677,
          "prev_para_id": "chap4_para83",
          "next_para_id": "chap4_para85",
          "style_metadata": {
            "para_id": "chap4_para84",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 196,
            "sentence_count": 4
          },
          "terminology": {
            "find": 2,
            "maximum": 1,
            "minimum": 2,
            "need": 1,
            "gradient": 1,
            "vector": 1,
            "formula": 1,
            "becomes": 1,
            "update": 2,
            "equation": 3,
            "written": 1,
            "matrix–vector": 1,
            "form": 1,
            "hessian": 1,
            "matrix": 1,
            "second": 1,
            "derivative": 1,
            "element": 3,
            "given": 1,
            "airport": 2,
            "example": 1,
            "see": 1,
            "simple": 1,
            "off-diagonal": 1,
            "diagonal": 1,
            "number": 1,
            "city": 1,
            "moment": 1,
            "calculation": 1,
            "show": 1,
            "step": 1,
            "move": 1,
            "centroid": 1,
            "local": 1,
            "expression": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para84",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 135,
              "end_char": 141,
              "context": "o vector (i.e., ∇\nf\n(\nx\n) =\n0\n). Thus,\ng\n(\nx\n) in Newton’s formula becomes ∇\nf\n(\nx\n), and the update equat"
            },
            {
              "para_id": "chap4_para84",
              "entity_text": "←\nx",
              "entity_type": "PERSON",
              "start_char": 237,
              "end_char": 240,
              "context": "quation can be written in matrix–vector form as\nx\n←\nx\n−\nH\nf\n−\n1\n(\nx\n)\n∇\nf\n(\nx\n)\n,\nwhere\nH\nf\n(\nx\n) is th"
            },
            {
              "para_id": "chap4_para84",
              "entity_text": "−",
              "entity_type": "GPE",
              "start_char": 241,
              "end_char": 242,
              "context": "ion can be written in matrix–vector form as\nx\n←\nx\n−\nH\nf\n−\n1\n(\nx\n)\n∇\nf\n(\nx\n)\n,\nwhere\nH\nf\n(\nx\n) is the\n"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para85",
          "content": "3\nFor high-dimensional problems, however, computing the\nn\n2\nentries of the Hessian and inverting it may be expensive, so many approximate versions of the Newton–Raphson method have been developed.",
          "sentence_count": 1,
          "char_count": 171,
          "prev_para_id": "chap4_para84",
          "next_para_id": "chap4_para86",
          "style_metadata": {
            "para_id": "chap4_para85",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 34.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 34,
            "sentence_count": 1
          },
          "terminology": {
            "high-dimensional": 1,
            "problem": 1,
            "computing": 1,
            "entry": 1,
            "hessian": 1,
            "inverting": 1,
            "expensive": 1,
            "many": 1,
            "approximate": 1,
            "version": 1,
            "newton–raphson": 1,
            "method": 1,
            "developed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para85",
              "entity_text": "Newton",
              "entity_type": "ORG",
              "start_char": 154,
              "end_char": 160,
              "context": "be expensive, so many approximate versions of the Newton–Raphson method have been developed."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para86",
          "content": "Local search methods suffer from local maxima, ridges, and plateaus in continuous state spaces just as much as in discrete spaces. Random restarts and simulated annealing are often helpful. High-dimensional continuous spaces are, however, big places in which it is very easy to get lost.",
          "sentence_count": 3,
          "char_count": 243,
          "prev_para_id": "chap4_para85",
          "next_para_id": "chap4_para87",
          "style_metadata": {
            "para_id": "chap4_para86",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 17.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 52,
            "sentence_count": 3
          },
          "terminology": {
            "local": 2,
            "search": 1,
            "method": 1,
            "suffer": 1,
            "maximum": 1,
            "ridge": 1,
            "plateau": 1,
            "continuous": 2,
            "state": 1,
            "space": 3,
            "discrete": 1,
            "random": 1,
            "restarts": 1,
            "simulated": 1,
            "annealing": 1,
            "helpful": 1,
            "high-dimensional": 1,
            "big": 1,
            "place": 1,
            "easy": 1,
            "get": 1,
            "lost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para86",
              "entity_text": "maxima",
              "entity_type": "PRODUCT",
              "start_char": 39,
              "end_char": 45,
              "context": "Local search methods suffer from local maxima, ridges, and plateaus in continuous state spaces "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para87",
          "content": "A final topic is\nconstrained optimization\n. An optimization problem is constrained if solutions must satisfy some hard constraints on the values of the variables. For example, in our airport-siting problem, we might constrain sites to be inside Romania and on dry land (rather than in the middle of lakes). The difficulty of constrained optimization problems depends on the nature of the constraints and the objective function. The best-known category is that of\nlinear programming\nproblems, in which constraints must be linear inequalities\nforming a\nconvex set\n4\nand the objective function is also linear. The time complexity of linear programming is polynomial in the number of variables.",
          "sentence_count": 6,
          "char_count": 591,
          "prev_para_id": "chap4_para86",
          "next_para_id": "chap4_para88",
          "style_metadata": {
            "para_id": "chap4_para87",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.67,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 118,
            "sentence_count": 6
          },
          "terminology": {
            "final": 1,
            "topic": 1,
            "constrained": 3,
            "optimization": 3,
            "problem": 4,
            "solution": 1,
            "satisfy": 1,
            "hard": 1,
            "constraint": 3,
            "value": 1,
            "variable": 2,
            "example": 1,
            "airport-siting": 1,
            "constrain": 1,
            "site": 1,
            "romania": 1,
            "dry": 1,
            "land": 1,
            "middle": 1,
            "lake": 1,
            "difficulty": 1,
            "depends": 1,
            "nature": 1,
            "objective": 2,
            "function": 2,
            "best-known": 1,
            "category": 1,
            "linear": 4,
            "programming": 2,
            "inequality": 1,
            "forming": 1,
            "convex": 1,
            "set": 1,
            "time": 1,
            "complexity": 1,
            "polynomial": 1,
            "number": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para87",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 245,
              "end_char": 252,
              "context": "ng problem, we might constrain sites to be inside Romania and on dry land (rather than in the middle of lak"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para88",
          "content": "Linear programming is probably the most widely studied and broadly useful method for optimization. It is a special case of the more general problem of\nconvex optimization\n, which allows the constraint region to be any convex region and the objective to be any function that is convex within the constraint region. Under certain conditions, convex optimization problems are also polynomially solvable and may be feasible in practice with thousands of variables. Several important problems in machine learning and control theory can be formulated as convex optimization problems (see\nChapter 21\n).",
          "sentence_count": 4,
          "char_count": 508,
          "prev_para_id": "chap4_para87",
          "next_para_id": "chap4_para89",
          "style_metadata": {
            "para_id": "chap4_para88",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 98,
            "sentence_count": 4
          },
          "terminology": {
            "linear": 1,
            "programming": 1,
            "studied": 1,
            "useful": 1,
            "method": 1,
            "optimization": 4,
            "special": 1,
            "case": 1,
            "general": 1,
            "problem": 4,
            "convex": 5,
            "allows": 1,
            "constraint": 2,
            "region": 3,
            "objective": 1,
            "function": 1,
            "certain": 1,
            "condition": 1,
            "solvable": 1,
            "feasible": 1,
            "practice": 1,
            "thousand": 1,
            "variable": 1,
            "several": 1,
            "important": 1,
            "machine": 1,
            "learning": 1,
            "control": 1,
            "theory": 1,
            "formulated": 1,
            "see": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para88",
              "entity_text": "Linear",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 6,
              "context": "Linear programming is probably the most widely studied a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para89",
          "content": "4.3Search with Nondeterministic Actions\n4.3\nSearch with Nondeterministic Actions\nIn\nChapter 3\n, we assumed a fully observable, deterministic, known environment. Therefore, an agent can observe the initial state, calculate a sequence of actions that reach the goal, and execute the actions with its “eyes closed,” never having to use its percepts.",
          "sentence_count": 2,
          "char_count": 300,
          "prev_para_id": "chap4_para88",
          "next_para_id": "chap4_para90",
          "style_metadata": {
            "para_id": "chap4_para89",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 62,
            "sentence_count": 2
          },
          "terminology": {
            "nondeterministic": 2,
            "action": 4,
            "search": 1,
            "chapter": 1,
            "assumed": 1,
            "observable": 1,
            "deterministic": 1,
            "known": 1,
            "environment": 1,
            "therefore": 1,
            "agent": 1,
            "observe": 1,
            "initial": 1,
            "state": 1,
            "calculate": 1,
            "sequence": 1,
            "reach": 1,
            "goal": 1,
            "execute": 1,
            "eye": 1,
            "closed": 1,
            "use": 1,
            "percept": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para89",
              "entity_text": "Nondeterministic Actions",
              "entity_type": "ORG",
              "start_char": 15,
              "end_char": 39,
              "context": "4.3Search with Nondeterministic Actions\n4.3\nSearch with Nondeterministic Actions\nIn\nChapt"
            },
            {
              "para_id": "chap4_para89",
              "entity_text": "Nondeterministic Actions",
              "entity_type": "ORG",
              "start_char": 56,
              "end_char": 80,
              "context": "rch with Nondeterministic Actions\n4.3\nSearch with Nondeterministic Actions\nIn\nChapter 3\n, we assumed a fully observable, det"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para90",
          "content": "When the environment is partially observable, however, the agent doesn’t know for sure what state it is in; and when the environment is nondeterministic, the agent doesn’t know what state it transitions to after taking an action. That means that rather than thinking “I’m in state\ns\n1\nand if I do action\na\nI’ll end up in state\ns\n2\n,” an agent will now be thinking “I’m either in state\ns\n1\nor\ns\n3\n, and if I do action\na\nI’ll end up in state\ns\n2\n,\ns\n4\nor\ns\n5\n.” We call a set of physical states that the agent believes are possible a\nbelief state.",
          "sentence_count": 2,
          "char_count": 458,
          "prev_para_id": "chap4_para89",
          "next_para_id": "chap4_para91",
          "style_metadata": {
            "para_id": "chap4_para90",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 68.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 136,
            "sentence_count": 2
          },
          "terminology": {
            "environment": 2,
            "observable": 1,
            "agent": 4,
            "know": 2,
            "sure": 1,
            "state": 8,
            "nondeterministic": 1,
            "transition": 1,
            "taking": 1,
            "action": 3,
            "mean": 1,
            "thinking": 2,
            "end": 2,
            "call": 1,
            "set": 1,
            "physical": 1,
            "belief": 2,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para90",
              "entity_text": "I’m",
              "entity_type": "WORK_OF_ART",
              "start_char": 268,
              "end_char": 271,
              "context": " an action. That means that rather than thinking “I’m in state\ns\n1\nand if I do action\na\nI’ll end up in "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para91",
          "content": "In partially observable and nondeterministic environments, the solution to a problem is no longer a sequence, but rather a\nconditional plan\n(sometimes called a contingency plan or a strategy) that specifies what to do depending on what percepts agent receives while executing the plan. We examine nondeterminism in this section and partial observability in the next.",
          "sentence_count": 2,
          "char_count": 313,
          "prev_para_id": "chap4_para90",
          "next_para_id": "chap4_para92",
          "style_metadata": {
            "para_id": "chap4_para91",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 2
          },
          "terminology": {
            "observable": 1,
            "nondeterministic": 1,
            "environment": 1,
            "solution": 1,
            "problem": 1,
            "longer": 1,
            "sequence": 1,
            "conditional": 1,
            "plan": 3,
            "called": 1,
            "contingency": 1,
            "strategy": 1,
            "specifies": 1,
            "depending": 1,
            "percept": 1,
            "agent": 1,
            "receives": 1,
            "executing": 1,
            "examine": 1,
            "nondeterminism": 1,
            "section": 1,
            "partial": 1,
            "observability": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para92",
          "content": "4.3.1\nThe erratic vacuum world\nThe vacuum world from\nChapter 2\nhas eight states, as shown in\nFigure 4.9\n. There are three actions—\nRight, Left,\nand\nSuck\n—and the goal is to clean up all the dirt (states 7 and 8). If the environment is fully observable, deterministic, and completely known, then the problem is easy to solve with any of the algorithms in\nChapter 3\n, and the solution is an action sequence. For example, if the initial state is 1, then the action sequence [\nSuck\n,\nRight, Suck\n] will reach a goal state, 8.",
          "sentence_count": 4,
          "char_count": 439,
          "prev_para_id": "chap4_para91",
          "next_para_id": "chap4_para93",
          "style_metadata": {
            "para_id": "chap4_para92",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "erratic": 1,
            "vacuum": 2,
            "world": 2,
            "chapter": 2,
            "state": 4,
            "shown": 1,
            "figure": 1,
            "actions—": 1,
            "right": 2,
            "left": 1,
            "suck": 3,
            "—and": 1,
            "goal": 2,
            "clean": 1,
            "dirt": 1,
            "environment": 1,
            "observable": 1,
            "deterministic": 1,
            "known": 1,
            "problem": 1,
            "easy": 1,
            "solve": 1,
            "algorithm": 1,
            "solution": 1,
            "action": 2,
            "sequence": 2,
            "example": 1,
            "initial": 1,
            "reach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para93",
          "content": "Description\nA bold arrow labeled suck and another arrow labeled Right from the first state of the vacuum world point to the first two circular nodes. An arrow from the second node on the right with an arc points back to state 1 and another arrow points to state 2 of the vacuum world. Two bold arrows from state 2 points outward. A bold arrow from the first node points to state 5 of the vacuum world. A bold arrow labeled Right, from state 5, points to the third node with an arc. A bold arrow from the third node points back to state 5. Another bold arrow from the third node points to state 6 of the vacuum world. Two arrows from state 6 points outward.",
          "sentence_count": 8,
          "char_count": 531,
          "prev_para_id": "chap4_para92",
          "next_para_id": "chap4_para94",
          "style_metadata": {
            "para_id": "chap4_para93",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 136,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "bold": 6,
            "arrow": 10,
            "labeled": 3,
            "suck": 1,
            "right": 2,
            "first": 1,
            "state": 9,
            "vacuum": 4,
            "world": 4,
            "point": 9,
            "circular": 1,
            "node": 6,
            "second": 1,
            "arc": 2,
            "third": 3,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para93",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 510,
              "end_char": 514,
              "context": "ird node with an arc. A bold arrow from the third node points back to state 5. Another bold arrow from t"
            },
            {
              "para_id": "chap4_para93",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 573,
              "end_char": 577,
              "context": "ack to state 5. Another bold arrow from the third node points to state 6 of the vacuum world. Two arrows"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para94",
          "content": "×\nFigure 4.9\nThe eight possible states of the vacuum world; states 7 and 8 are goal states.",
          "sentence_count": 1,
          "char_count": 76,
          "prev_para_id": "chap4_para93",
          "next_para_id": "chap4_para95",
          "style_metadata": {
            "para_id": "chap4_para94",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "possible": 1,
            "state": 3,
            "vacuum": 1,
            "world": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para95",
          "content": "Now suppose that we introduce nondeterminism in the form of a powerful but erratic vacuum cleaner. In the\nerratic vacuum world\n, the\nSuck\naction works as follows:\n•\nWhen applied to a dirty square the action cleans the square and sometimes cleans up dirt in an adjacent square, too.",
          "sentence_count": 2,
          "char_count": 238,
          "prev_para_id": "chap4_para94",
          "next_para_id": "chap4_para96",
          "style_metadata": {
            "para_id": "chap4_para95",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 2
          },
          "terminology": {
            "suppose": 1,
            "introduce": 1,
            "nondeterminism": 1,
            "form": 1,
            "powerful": 1,
            "erratic": 2,
            "vacuum": 2,
            "cleaner": 1,
            "world": 1,
            "suck": 1,
            "action": 2,
            "work": 1,
            "follows": 1,
            "applied": 1,
            "dirty": 1,
            "square": 3,
            "clean": 2,
            "dirt": 1,
            "adjacent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para96",
          "content": "•\nWhen applied to a clean square the action sometimes deposits dirt on the carpet.",
          "sentence_count": 1,
          "char_count": 69,
          "prev_para_id": "chap4_para95",
          "next_para_id": "chap4_para97",
          "style_metadata": {
            "para_id": "chap4_para96",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "applied": 1,
            "clean": 1,
            "square": 1,
            "action": 1,
            "deposit": 1,
            "dirt": 1,
            "carpet": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para97",
          "content": "5\nTo provide a precise formulation of this problem, we need to generalize the notion of a\ntransition model\nfrom\nChapter 3\n. Instead of defining the transition model by a R\nESULT\nfunction\nthat returns a single outcome state, we use a R\nESULTS\nfunction that returns a set of possible outcome states. For example, in the erratic vacuum world, the\nSuck\naction in state 1 cleans up either just the current location, or both locations:\nRESULTS(1,\nS\nu\nc\nk\n) = {5,7}\nIf we start in state 1, no single\nsequence\nof actions solves the problem, but the following\nconditional plan\ndoes:\n[\nS\nu\nc\nk\n,\ni\nf\nS\nt\na\nt\ne\n= 5\nt\nh\ne\nn\n[\nR\ni\ng\nh\nt\n,\nS\nu\nc\nk\n]\ne\nl\ns\ne\n[ ]]\n.",
          "sentence_count": 3,
          "char_count": 571,
          "prev_para_id": "chap4_para96",
          "next_para_id": "chap4_para98",
          "style_metadata": {
            "para_id": "chap4_para97",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 53.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 159,
            "sentence_count": 3
          },
          "terminology": {
            "precise": 1,
            "formulation": 1,
            "problem": 2,
            "need": 1,
            "generalize": 1,
            "notion": 1,
            "transition": 2,
            "model": 2,
            "chapter": 1,
            "defining": 1,
            "esult": 1,
            "function": 2,
            "return": 2,
            "single": 2,
            "outcome": 2,
            "state": 4,
            "use": 1,
            "esults": 1,
            "set": 1,
            "possible": 1,
            "example": 1,
            "erratic": 1,
            "vacuum": 1,
            "world": 1,
            "suck": 1,
            "action": 2,
            "clean": 1,
            "current": 1,
            "location": 2,
            "result": 1,
            "start": 1,
            "sequence": 1,
            "solves": 1,
            "following": 1,
            "conditional": 1,
            "plan": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para98",
          "content": "(\n4.3\n)\nHere we see that a conditional plan can contain\nif–then–else\nsteps; this means that solutions are\ntrees\nrather than sequences. Here the conditional in the\nif\nstatement tests to see what the current state is; this is something the agent will be able to observe at runtime, but doesn’t know at planning time. Alternatively, we could have had a formulation that tests the percept rather than the state. Many problems in the real, physical world are contingency problems, because exact prediction of the future is impossible. For this reason, many people keep their eyes open while walking around.",
          "sentence_count": 5,
          "char_count": 510,
          "prev_para_id": "chap4_para97",
          "next_para_id": "chap4_para99",
          "style_metadata": {
            "para_id": "chap4_para98",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 5
          },
          "terminology": {
            "see": 2,
            "conditional": 2,
            "plan": 1,
            "contain": 1,
            "if–then–else": 1,
            "step": 1,
            "mean": 1,
            "solution": 1,
            "tree": 1,
            "sequence": 1,
            "statement": 1,
            "test": 2,
            "current": 1,
            "state": 2,
            "something": 1,
            "agent": 1,
            "able": 1,
            "observe": 1,
            "runtime": 1,
            "know": 1,
            "planning": 1,
            "time": 1,
            "formulation": 1,
            "many": 2,
            "problem": 2,
            "real": 1,
            "physical": 1,
            "world": 1,
            "contingency": 1,
            "exact": 1,
            "prediction": 1,
            "future": 1,
            "impossible": 1,
            "reason": 1,
            "people": 1,
            "keep": 1,
            "eye": 1,
            "open": 1,
            "walking": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para99",
          "content": "4.3.2\nAND–OR\nsearch trees\nHow do we find these contingent solutions to nondeterministic problems? As in\nChapter 3\n, we begin by constructing search trees, but here the trees have a different character. In a deterministic environment, the only branching is introduced by the agent’s own choices in each state: I can do this action or that action. We call these nodes\nOR\nnodes\n. In the vacuum world, for example, at an\nOR\nnode the agent chooses\nLeft or Right or Suck\n. In a nondeterministic environment, branching is also introduced by the\nenvironment’s\nchoice of outcome for each action. We call these nodes\nAND\nnodes\n. For example, the\nSuck\naction in state 1 results in the belief state {5,7}, so the agent would need to find a plan for state 5\nand\nfor state 7. These two kinds of nodes alternate, leading to an\nAND\n-\nOR\ntree\nas illustrated in\nFigure 4.10\n.",
          "sentence_count": 9,
          "char_count": 729,
          "prev_para_id": "chap4_para98",
          "next_para_id": "chap4_para100",
          "style_metadata": {
            "para_id": "chap4_para99",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.56,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 176,
            "sentence_count": 9
          },
          "terminology": {
            "and–or": 1,
            "search": 2,
            "tree": 4,
            "find": 2,
            "contingent": 1,
            "solution": 1,
            "nondeterministic": 2,
            "problem": 1,
            "chapter": 1,
            "begin": 1,
            "constructing": 1,
            "different": 1,
            "character": 1,
            "deterministic": 1,
            "environment": 3,
            "branching": 2,
            "introduced": 2,
            "agent": 3,
            "choice": 2,
            "state": 5,
            "action": 4,
            "call": 2,
            "node": 5,
            "vacuum": 1,
            "world": 1,
            "example": 2,
            "chooses": 1,
            "left": 1,
            "right": 1,
            "suck": 2,
            "outcome": 1,
            "result": 1,
            "belief": 1,
            "need": 1,
            "plan": 1,
            "kind": 1,
            "alternate": 1,
            "leading": 1,
            "illustrated": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para99",
              "entity_text": "Left or Right or Suck",
              "entity_type": "WORK_OF_ART",
              "start_char": 443,
              "end_char": 464,
              "context": "rld, for example, at an\nOR\nnode the agent chooses\nLeft or Right or Suck\n. In a nondeterministic environment, branching is"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para100",
          "content": "Description\nThe belief states are depicted by circular sections enclosing the vacuum world states. Part (“a”): State 1 and 3 of the vacuum world are enclosed in a single section and states 2 and 4 of the vacuum world are enclosed in another section. An arrow from state 1 points to state 2 and an arrow from state 3 points to state 4 of the vacuum world. Part (b): State 1 and state 3 of the vacuum world are enclosed in a single section. State 1, 2, 3, and 4 of the vacuum world are enclosed in another section. Two arrows from state 1 in the first section point to states 1 and 2 in the second section. Two arrows from state 3 of the first section point to states 3 and 4 of the second section.",
          "sentence_count": 7,
          "char_count": 561,
          "prev_para_id": "chap4_para99",
          "next_para_id": "chap4_para101",
          "style_metadata": {
            "para_id": "chap4_para100",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.14,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 155,
            "sentence_count": 7
          },
          "terminology": {
            "description": 1,
            "belief": 1,
            "state": 15,
            "depicted": 1,
            "circular": 1,
            "section": 9,
            "enclosing": 1,
            "vacuum": 6,
            "world": 6,
            "part": 2,
            "enclosed": 4,
            "single": 2,
            "arrow": 4,
            "point": 4,
            "first": 2,
            "second": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para101",
          "content": "×\nFigure 4.10\nThe first two levels of the search tree for the erratic vacuum world. State nodes are\nOR\nnodes where some action must be chosen. At the\nAND\nnodes, shown as circles, every outcome must be handled, as indicated by the arc linking the outgoing branches. The solution found is shown in bold lines.",
          "sentence_count": 4,
          "char_count": 258,
          "prev_para_id": "chap4_para100",
          "next_para_id": "chap4_para102",
          "style_metadata": {
            "para_id": "chap4_para101",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "first": 1,
            "level": 1,
            "search": 1,
            "tree": 1,
            "erratic": 1,
            "vacuum": 1,
            "world": 1,
            "state": 1,
            "node": 3,
            "action": 1,
            "chosen": 1,
            "shown": 2,
            "circle": 1,
            "outcome": 1,
            "handled": 1,
            "indicated": 1,
            "arc": 1,
            "linking": 1,
            "outgoing": 1,
            "branch": 1,
            "solution": 1,
            "found": 1,
            "bold": 1,
            "line": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para102",
          "content": "A solution for an\nAND\n–\nOR\nsearch problem is a subtree of the complete search tree that (1) has a goal node at every leaf, (2) specifies one action at each of its\nOR\nnodes, and (3) includes every outcome branch at each of its\nAND\nnodes. The solution is shown in bold lines in the figure; it corresponds to the plan given in\nEquation (4.3)\n.",
          "sentence_count": 2,
          "char_count": 283,
          "prev_para_id": "chap4_para101",
          "next_para_id": "chap4_para103",
          "style_metadata": {
            "para_id": "chap4_para102",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 2
          },
          "terminology": {
            "solution": 2,
            "search": 2,
            "problem": 1,
            "subtree": 1,
            "complete": 1,
            "tree": 1,
            "goal": 1,
            "node": 3,
            "leaf": 1,
            "specifies": 1,
            "action": 1,
            "includes": 1,
            "outcome": 1,
            "branch": 1,
            "shown": 1,
            "bold": 1,
            "line": 1,
            "figure": 1,
            "corresponds": 1,
            "plan": 1,
            "given": 1,
            "equation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para103",
          "content": "Figure 4.11\ngives a recursive, depth-first algorithm for\nAND\n–\nOR\ngraph search. One key aspect of the algorithm is the way in which it deals with cycles, which often arise in nondeterministic problems (e.g., if an action sometimes has no effect or if an unintended effect can be corrected). If the current state is identical to a state on the path from the root, then it returns with failure. This doesn’t mean that there is\nno\nsolution from the current state; it simply means that if there is a noncyclic solution, it must be reachable from the earlier incarnation of the current state, so the new incarnation can be discarded. With this check, we ensure that the algorithm terminates in every finite state space, because every path must reach a goal, a dead end, or a repeated state. Notice that the algorithm does not check whether the current state is a repetition of a state on some\nother\npath from the root, which is important for efficiency.",
          "sentence_count": 6,
          "char_count": 790,
          "prev_para_id": "chap4_para102",
          "next_para_id": "chap4_para104",
          "style_metadata": {
            "para_id": "chap4_para103",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 190,
            "sentence_count": 6
          },
          "terminology": {
            "figure": 1,
            "give": 1,
            "recursive": 1,
            "depth-first": 1,
            "algorithm": 3,
            "graph": 1,
            "search": 1,
            "key": 1,
            "aspect": 1,
            "way": 1,
            "deal": 1,
            "cycle": 1,
            "arise": 1,
            "nondeterministic": 1,
            "problem": 1,
            "e.g.": 1,
            "action": 1,
            "effect": 2,
            "unintended": 1,
            "corrected": 1,
            "current": 4,
            "state": 8,
            "identical": 1,
            "path": 3,
            "root": 2,
            "return": 1,
            "failure": 1,
            "mean": 2,
            "solution": 2,
            "noncyclic": 1,
            "reachable": 1,
            "earlier": 1,
            "incarnation": 2,
            "new": 1,
            "discarded": 1,
            "check": 2,
            "ensure": 1,
            "terminates": 1,
            "finite": 1,
            "space": 1,
            "reach": 1,
            "goal": 1,
            "dead": 1,
            "end": 1,
            "repeated": 1,
            "notice": 1,
            "repetition": 1,
            "important": 1,
            "efficiency": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para104",
          "content": "Description\nEach of the belief state spaces is depicted by rectangular boxes with states of vacuum world inscribed within the box. The initial belief state is at the top center with states 1 to 8 of the vacuum world states. An arrow labeled L from the initial belief state points to a belief state on the left which has states 1, 3, 5, and 7. An arrow labeled R from the initial belief state points to a third belief state on the right which has states 2, 4, 6, and 8. An arrow labeled R from the second belief state points to the third and an arrow labeled L from the third belief state points to the second belief state. An arrow labeled S from the initial belief state points to a fourth belief state below, which has states 4, 5, 7, and 8. Arrows labeled L and R from the fourth belief state point to the fifth and sixth belief states that have 5, 3, 7, and 6, 4, 8 vacuum world states, respectively. An arrow labeled L from the sixth belief state points to the fifth, and an arrow labeled R from the fifth belief state points to the sixth. Arrows labeled S from the fifth and the second belief states point to the seventh belief state, which has the states 5 and 7. Arrows labeled S from the sixth and the third belief states point to the eighth belief state, which has 4 and 8 vacuum world states in it. An arrow labeled L from the eighth belief state points to the ninth belief state which has 3 and 7 vacuum world states in it. An arrow labeled R from the ninth belief state points to the eighth belief state. An arrow labeled S from the ninth belief state points to the tenth which has state 7. An arrow labeled R from the tenth belief state points to the eleventh, which has state 8 in it. An arrow labeled L from the eleventh belief state points back to the tenth. An arrow labeled S from the twelfth belief state points to the eleventh, and an arrow labeled L from the twelfth belief state points to the seventh belief state. An arrow labeled R from the seventh belief state points to the twelfth belief state. The twelfth belief state has the vacuum world states 6 and 8 in it.",
          "sentence_count": 18,
          "char_count": 1691,
          "prev_para_id": "chap4_para103",
          "next_para_id": "chap4_para105",
          "style_metadata": {
            "para_id": "chap4_para104",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.17,
            "passive_voice_ratio": 0.002,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 435,
            "sentence_count": 18
          },
          "terminology": {
            "description": 1,
            "belief": 32,
            "state": 45,
            "space": 1,
            "depicted": 1,
            "rectangular": 1,
            "box": 2,
            "vacuum": 6,
            "world": 6,
            "inscribed": 1,
            "initial": 4,
            "top": 1,
            "center": 1,
            "arrow": 17,
            "labeled": 18,
            "point": 18,
            "left": 1,
            "third": 4,
            "right": 1,
            "second": 3,
            "fourth": 2,
            "fifth": 4,
            "sixth": 4,
            "seventh": 3,
            "eighth": 3,
            "ninth": 3,
            "tenth": 3,
            "eleventh": 3,
            "twelfth": 4,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para105",
          "content": "×\nFigure 4.11\nAn algorithm for searching\nAND\n-\nOR\ngraphs generated by nondeterministic environments. A solution is a conditional plan that considers every nondeterministic outcome and makes a plan for each one.",
          "sentence_count": 2,
          "char_count": 184,
          "prev_para_id": "chap4_para104",
          "next_para_id": "chap4_para106",
          "style_metadata": {
            "para_id": "chap4_para105",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "algorithm": 1,
            "searching": 1,
            "graph": 1,
            "generated": 1,
            "nondeterministic": 2,
            "environment": 1,
            "solution": 1,
            "conditional": 1,
            "plan": 2,
            "considers": 1,
            "outcome": 1,
            "make": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para106",
          "content": "AND\n-\nOR\ngraphs can be explored either breadth-first or best-first. The concept of a heuristic function must be modified to estimate the cost of a contingent solution rather than a sequence, but the notion of admissibility carries over and there is an analog of the A* algorithm for finding optimal solutions. (See the bibliographical notes at the end of the chapter.)\n4.3.3\nTry, try again\nConsider a\nslippery\nvacuum world, which is identical to the ordinary (non-erratic) vacuum world except that movement actions sometimes fail, leaving the agent in the same location. For example, moving\nRight\nin state 1 leads to the belief state {1, 2}.",
          "sentence_count": 5,
          "char_count": 545,
          "prev_para_id": "chap4_para105",
          "next_para_id": "chap4_para107",
          "style_metadata": {
            "para_id": "chap4_para106",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 125,
            "sentence_count": 5
          },
          "terminology": {
            "graph": 1,
            "explored": 1,
            "breadth-first": 1,
            "best-first": 1,
            "concept": 1,
            "heuristic": 1,
            "function": 1,
            "modified": 1,
            "estimate": 1,
            "cost": 1,
            "contingent": 1,
            "solution": 2,
            "sequence": 1,
            "notion": 1,
            "admissibility": 1,
            "carry": 1,
            "algorithm": 1,
            "finding": 1,
            "optimal": 1,
            "see": 1,
            "bibliographical": 1,
            "note": 1,
            "end": 1,
            "chapter": 1,
            "try": 2,
            "consider": 1,
            "slippery": 1,
            "vacuum": 2,
            "world": 2,
            "identical": 1,
            "ordinary": 1,
            "non-erratic": 1,
            "movement": 1,
            "action": 1,
            "fail": 1,
            "leaving": 1,
            "agent": 1,
            "location": 1,
            "example": 1,
            "moving": 1,
            "right": 1,
            "state": 2,
            "lead": 1,
            "belief": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para107",
          "content": "Figure 4.12\nshows part of the search graph; clearly, there are no longer any acyclic solutions from state 1, and A\nND\n-O\nR\n-S\nEARCH\nwould return with failure. There is, however, a\ncyclic solution\n, which is to keep trying\nRight\nuntil it works. We can express this with a new\nwhile\nconstruct:\nDescription\nThe belief states are depicted by circular shapes, and the vacuum world states are depicted by square blocks with the corresponding state labeled on them. Example “a”, Deterministic world: Vacuum world states 1 and 3 are included in the first belief state. An arrow labeled R from state 1 of the first belief state points to state 2 of the second belief state. An arrow from state 3 of the first belief state points to the vacuum world state 4 of the second belief state. An arrow labeled open square bracket B, Dirty close square bracket, points to the vacuum world state 2 of the third belief state. An arrow labeled open square bracket B, Clean close square bracket, from the vacuum world state 4 of the second belief state points to the vacuum world state 4 of the fourth belief state. Example b, Slippery world: An arrow from the vacuum world state 1 of the first belief state points to the vacuum world state 2 and 1 of the second belief state. An arrow from the vacuum world state 3 of the first belief state points to the vacuum world state 3 and 4 of the second belief state. An arrow labeled open square bracket B, Dirty close square bracket, from the vacuum world state 2 of the second belief state points to the vacuum world state 2 of the third belief state. An arrow from the vacuum world state 1 and 3 of the second belief state points to the vacuum world state 1 and 3 of the fourth belief state. An arrow from the vacuum world state 4 of the second belief state points to the vacuum world state 4 of the fifth belief state.",
          "sentence_count": 13,
          "char_count": 1516,
          "prev_para_id": "chap4_para106",
          "next_para_id": "chap4_para108",
          "style_metadata": {
            "para_id": "chap4_para107",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 28.92,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 376,
            "sentence_count": 13
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "part": 1,
            "search": 1,
            "graph": 1,
            "acyclic": 1,
            "solution": 2,
            "state": 40,
            "earch": 1,
            "return": 1,
            "failure": 1,
            "cyclic": 1,
            "keep": 1,
            "trying": 1,
            "right": 1,
            "work": 1,
            "new": 1,
            "construct": 1,
            "description": 1,
            "belief": 19,
            "depicted": 2,
            "circular": 1,
            "shape": 1,
            "vacuum": 16,
            "world": 18,
            "square": 7,
            "block": 1,
            "corresponding": 1,
            "labeled": 5,
            "example": 2,
            "deterministic": 1,
            "included": 1,
            "first": 5,
            "arrow": 9,
            "point": 9,
            "second": 8,
            "open": 3,
            "bracket": 6,
            "dirty": 2,
            "close": 3,
            "third": 2,
            "clean": 1,
            "fourth": 2,
            "slippery": 1,
            "fifth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para107",
              "entity_text": "Vacuum",
              "entity_type": "PERSON",
              "start_char": 493,
              "end_char": 499,
              "context": "abeled on them. Example “a”, Deterministic world: Vacuum world states 1 and 3 are included in the first be"
            },
            {
              "para_id": "chap4_para107",
              "entity_text": "Dirty",
              "entity_type": "ORG",
              "start_char": 816,
              "end_char": 821,
              "context": "ef state. An arrow labeled open square bracket B, Dirty close square bracket, points to the vacuum world "
            },
            {
              "para_id": "chap4_para107",
              "entity_text": "Dirty",
              "entity_type": "ORG",
              "start_char": 1429,
              "end_char": 1434,
              "context": "ef state. An arrow labeled open square bracket B, Dirty close square bracket, from the vacuum world state"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para108",
          "content": "×\nFigure 4.12\nPart of the search graph for a slippery vacuum world, where we have shown (some) cycles explicitly. All solutions for this problem are cyclic plans because there is no way to move reliably.",
          "sentence_count": 2,
          "char_count": 170,
          "prev_para_id": "chap4_para107",
          "next_para_id": "chap4_para109",
          "style_metadata": {
            "para_id": "chap4_para108",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "part": 1,
            "search": 1,
            "graph": 1,
            "slippery": 1,
            "vacuum": 1,
            "world": 1,
            "shown": 1,
            "cycle": 1,
            "solution": 1,
            "problem": 1,
            "cyclic": 1,
            "plan": 1,
            "way": 1,
            "move": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para109",
          "content": "[\nS\nu\nc\nk\n,\nw\nh\ni\nl\ne\nS\nt\na\nt\ne\n= 5\nd\no\nR\ni\ng\nh\nt\n,\nS\nu\nc\nk\n]\nor by adding a\nlabel\nto denote some portion of the plan and referring to that label later:\n[\nS\nu\nc\nk\n,\nL\n1\n:\nR\ni\ng\nh\nt\n,\ni\nf\nS\nt\na\nt\ne\n= 5\nt\nh\ne\nn\nL\n1\ne\nl\ns\ne\nS\nu\nc\nk\n]\n.",
          "sentence_count": 1,
          "char_count": 217,
          "prev_para_id": "chap4_para108",
          "next_para_id": "chap4_para110",
          "style_metadata": {
            "para_id": "chap4_para109",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 90.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 90,
            "sentence_count": 1
          },
          "terminology": {
            "adding": 1,
            "label": 2,
            "denote": 1,
            "portion": 1,
            "plan": 1,
            "referring": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para110",
          "content": "When is a cyclic plan a solution? A minimum condition is that every leaf is a goal state and that a leaf is reachable from every point in the plan. In addition to that, we need to consider the cause of the nondeterminism. If it is really the case that the vacuum robot’s drive mechanism works some of the time, but randomly and independently slips on other occasions, then the agent can be confident that if the action is repeated enough times, eventually it will work and the plan will succeed. But if the nondeterminism is due to some unobserved fact about the robot or environment—perhaps a drive belt has snapped and the robot will never move—then repeating the action will not help.",
          "sentence_count": 5,
          "char_count": 565,
          "prev_para_id": "chap4_para109",
          "next_para_id": "chap4_para111",
          "style_metadata": {
            "para_id": "chap4_para110",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.8,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 5
          },
          "terminology": {
            "cyclic": 1,
            "plan": 3,
            "solution": 1,
            "minimum": 1,
            "condition": 1,
            "leaf": 2,
            "goal": 1,
            "state": 1,
            "reachable": 1,
            "point": 1,
            "addition": 1,
            "consider": 1,
            "cause": 1,
            "nondeterminism": 2,
            "case": 1,
            "vacuum": 1,
            "robot": 3,
            "drive": 2,
            "mechanism": 1,
            "work": 2,
            "time": 2,
            "slip": 1,
            "occasion": 1,
            "agent": 1,
            "confident": 1,
            "action": 2,
            "repeated": 1,
            "succeed": 1,
            "due": 1,
            "unobserved": 1,
            "fact": 1,
            "environment—perhaps": 1,
            "belt": 1,
            "snapped": 1,
            "move—then": 1,
            "repeating": 1,
            "help": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para111",
          "content": "One way to understand this decision is to say that the initial problem formulation (fully observable, nondeterministic) is abandoned in favor of a different formulation (partially observable, deterministic) where the failure of the cyclic plan is attributed to an unobserved property of the drive belt. In\nChapter 12\nwe discuss how to decide which of several uncertain possibilities is more likely.",
          "sentence_count": 2,
          "char_count": 340,
          "prev_para_id": "chap4_para110",
          "next_para_id": "chap4_para112",
          "style_metadata": {
            "para_id": "chap4_para111",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.5,
            "passive_voice_ratio": 0.029,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 2
          },
          "terminology": {
            "way": 1,
            "understand": 1,
            "decision": 1,
            "say": 1,
            "initial": 1,
            "problem": 1,
            "formulation": 2,
            "observable": 2,
            "nondeterministic": 1,
            "abandoned": 1,
            "favor": 1,
            "different": 1,
            "deterministic": 1,
            "failure": 1,
            "cyclic": 1,
            "plan": 1,
            "attributed": 1,
            "unobserved": 1,
            "property": 1,
            "drive": 1,
            "belt": 1,
            "chapter": 1,
            "discus": 1,
            "several": 1,
            "uncertain": 1,
            "possibility": 1,
            "likely": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para112",
          "content": "4.4Search in Partially Observable Environments\n4.4\nSearch in Partially Observable Environments\nWe now turn to the problem of partial observability, where the agent’s percepts are not enough to pin down the exact state. That means that some of the agent’s actions will be aimed at reducing uncertainty about the current state.",
          "sentence_count": 2,
          "char_count": 278,
          "prev_para_id": "chap4_para111",
          "next_para_id": "chap4_para113",
          "style_metadata": {
            "para_id": "chap4_para112",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "observable": 2,
            "environment": 2,
            "search": 1,
            "turn": 1,
            "problem": 1,
            "partial": 1,
            "observability": 1,
            "agent": 2,
            "percept": 1,
            "pin": 1,
            "exact": 1,
            "state": 2,
            "mean": 1,
            "action": 1,
            "aimed": 1,
            "reducing": 1,
            "uncertainty": 1,
            "current": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para112",
              "entity_text": "Partially Observable Environments",
              "entity_type": "ORG",
              "start_char": 13,
              "end_char": 46,
              "context": "4.4Search in Partially Observable Environments\n4.4\nSearch in Partially Observable Environments\nW"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para113",
          "content": "4.4.1\nSearching with no observation\nWhen the agent’s percepts provide\nno information at all,\nwe have what is called a\nsensorless\nproblem (or a\nconformant\nproblem). At first, you might think the sensorless agent has no hope of solving a problem if it has no idea what state it starts in, but sensorless solutions are surprisingly common and useful, primarily because they\ndon’t\nrely on sensors working properly. In manufacturing systems, for example, many ingenious methods have been developed for orienting parts correctly from an unknown initial position by using a sequence of actions with no sensing at all. Sometimes a sensorless plan is better even when a conditional plan with sensing is available. For example, doctors often prescribe a broad-spectrum antibiotic rather than using the conditional plan of doing a blood test, then waiting for the results to come back, and then prescribing a more specific antibiotic. The sensorless plan saves time and money, and avoids the risk of the infection worsening before the test results are available.",
          "sentence_count": 6,
          "char_count": 893,
          "prev_para_id": "chap4_para112",
          "next_para_id": "chap4_para114",
          "style_metadata": {
            "para_id": "chap4_para113",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.83,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 191,
            "sentence_count": 6
          },
          "terminology": {
            "searching": 1,
            "observation": 1,
            "agent": 2,
            "percept": 1,
            "provide": 1,
            "information": 1,
            "called": 1,
            "sensorless": 5,
            "problem": 3,
            "conformant": 1,
            "think": 1,
            "hope": 1,
            "solving": 1,
            "idea": 1,
            "state": 1,
            "start": 1,
            "solution": 1,
            "common": 1,
            "useful": 1,
            "rely": 1,
            "sensor": 1,
            "working": 1,
            "manufacturing": 1,
            "system": 1,
            "example": 2,
            "many": 1,
            "ingenious": 1,
            "method": 1,
            "developed": 1,
            "orienting": 1,
            "part": 1,
            "unknown": 1,
            "initial": 1,
            "position": 1,
            "using": 2,
            "sequence": 1,
            "action": 1,
            "sensing": 2,
            "plan": 4,
            "conditional": 2,
            "available": 2,
            "doctor": 1,
            "prescribe": 1,
            "broad-spectrum": 1,
            "antibiotic": 2,
            "blood": 1,
            "waiting": 1,
            "result": 2,
            "come": 1,
            "prescribing": 1,
            "specific": 1,
            "save": 1,
            "time": 1,
            "money": 1,
            "avoids": 1,
            "risk": 1,
            "infection": 1,
            "worsening": 1,
            "test": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para114",
          "content": "Consider a sensorless version of the (deterministic) vacuum world. Assume that the agent knows the geography of its world, but not its own location or the distribution of dirt. In that case, its initial belief state is {1, 2, 3, 4, 5, 6, 7, 8} (see\nFigure 4.9\n). Now, if the agent moves\nRight\nit will be in one of the states {2, 4, 6, 8}—the agent has gained information without perceiving anything! After [\nRight,Suck\n] the agent will always end up in one of the states {4, 8}. Finally, after [\nRight,Suck,Left,Suck\n] the agent is guaranteed to reach the goal state 7, no matter what the start state. We say that the agent can\ncoerce\nthe world into state 7.",
          "sentence_count": 7,
          "char_count": 545,
          "prev_para_id": "chap4_para113",
          "next_para_id": "chap4_para115",
          "style_metadata": {
            "para_id": "chap4_para114",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.57,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 165,
            "sentence_count": 7
          },
          "terminology": {
            "consider": 1,
            "sensorless": 1,
            "version": 1,
            "deterministic": 1,
            "vacuum": 1,
            "world": 3,
            "assume": 1,
            "agent": 6,
            "know": 1,
            "geography": 1,
            "location": 1,
            "distribution": 1,
            "dirt": 1,
            "case": 1,
            "initial": 1,
            "belief": 1,
            "state": 6,
            "see": 1,
            "figure": 1,
            "move": 1,
            "gained": 1,
            "information": 1,
            "perceiving": 1,
            "anything": 1,
            "right": 2,
            "suck": 3,
            "end": 1,
            "left": 1,
            "guaranteed": 1,
            "reach": 1,
            "goal": 1,
            "matter": 1,
            "start": 1,
            "say": 1,
            "coerce": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para114",
              "entity_text": "Suck",
              "entity_type": "PERSON",
              "start_char": 414,
              "end_char": 418,
              "context": "mation without perceiving anything! After [\nRight,Suck\n] the agent will always end up in one of the stat"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para115",
          "content": "The solution to a sensorless problem is a sequence of actions, not a conditional plan (because there is no perceiving). But we search in the space of belief states rather than physical states.",
          "sentence_count": 2,
          "char_count": 160,
          "prev_para_id": "chap4_para114",
          "next_para_id": "chap4_para116",
          "style_metadata": {
            "para_id": "chap4_para115",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "solution": 1,
            "sensorless": 1,
            "problem": 1,
            "sequence": 1,
            "action": 1,
            "conditional": 1,
            "plan": 1,
            "perceiving": 1,
            "search": 1,
            "space": 1,
            "belief": 1,
            "state": 2,
            "physical": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para116",
          "content": "6\nIn belief-state space, the problem is\nfully observable\nbecause the agent always knows its own belief state. Furthermore, the solution (if any) for a sensorless problem is always a sequence of actions. This is because, as in the ordinary problems of\nChapter 3\n, the percepts received after each action are completely predictable—they’re always empty! So there are no contingencies to plan for. This is true\neven if the environment is nondeterministic\n.",
          "sentence_count": 5,
          "char_count": 387,
          "prev_para_id": "chap4_para115",
          "next_para_id": "chap4_para117",
          "style_metadata": {
            "para_id": "chap4_para116",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore"
            ],
            "word_count": 85,
            "sentence_count": 5
          },
          "terminology": {
            "belief-state": 1,
            "space": 1,
            "problem": 3,
            "observable": 1,
            "agent": 1,
            "know": 1,
            "belief": 1,
            "state": 1,
            "furthermore": 1,
            "solution": 1,
            "sensorless": 1,
            "sequence": 1,
            "action": 2,
            "ordinary": 1,
            "chapter": 1,
            "percept": 1,
            "received": 1,
            "predictable—they": 1,
            "empty": 1,
            "contingency": 1,
            "plan": 1,
            "true": 1,
            "environment": 1,
            "nondeterministic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para117",
          "content": "We could introduce new algorithms for sensorless search problems. But instead, we can use the existing algorithms from\nChapter 3\nif we transform the underlying physical problem into a belief-state problem, in which we search over belief states rather than physical states. The original problem,\nP\n, has components\nActions\nP\n, Result\nP\netc., and the belief-state problem has the following components:\n•\nStates:\nThe belief-state space contains every possible subset of the physical states. If\nP\nhas\nN\nstates, then the belief-state problem has 2\nN\nbelief states, although many of those may be unreachable from the initial state.",
          "sentence_count": 4,
          "char_count": 543,
          "prev_para_id": "chap4_para116",
          "next_para_id": "chap4_para118",
          "style_metadata": {
            "para_id": "chap4_para117",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 113,
            "sentence_count": 4
          },
          "terminology": {
            "introduce": 1,
            "new": 1,
            "algorithm": 2,
            "sensorless": 1,
            "search": 2,
            "problem": 6,
            "use": 1,
            "existing": 1,
            "chapter": 1,
            "transform": 1,
            "underlying": 1,
            "physical": 3,
            "belief-state": 4,
            "belief": 2,
            "state": 7,
            "original": 1,
            "component": 2,
            "action": 1,
            "result": 1,
            "etc.": 1,
            "following": 1,
            "space": 1,
            "contains": 1,
            "possible": 1,
            "subset": 1,
            "many": 1,
            "unreachable": 1,
            "initial": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para118",
          "content": "•\nInitial state:\nTypically the belief state consisting of all states in\nP\n, although in some cases the agent will have more knowledge than this.",
          "sentence_count": 1,
          "char_count": 123,
          "prev_para_id": "chap4_para117",
          "next_para_id": "chap4_para119",
          "style_metadata": {
            "para_id": "chap4_para118",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "initial": 1,
            "state": 3,
            "belief": 1,
            "consisting": 1,
            "case": 1,
            "agent": 1,
            "knowledge": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para119",
          "content": "•\nActions:\nThis is slightly tricky. Suppose the agent is in belief state\nb =\n{\ns\n1\n,\ns\n2\n}, but A\nCTIONS\nP\n(\ns\n1\n) ≠ A\nCTIONS\nP\n(\ns\n2\n); then the agent is unsure of which actions are legal. If we assume that illegal actions have no effect on the environment, then it is safe to take the\nunion\nof all the actions in any of the physical states in the current belief state\nb\n:\nACTIONS(\nb\n)\n=\n∪\ns\n∈\nb\nACTIONS\np\n(\ns\n)\n.",
          "sentence_count": 3,
          "char_count": 356,
          "prev_para_id": "chap4_para118",
          "next_para_id": "chap4_para120",
          "style_metadata": {
            "para_id": "chap4_para119",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 3
          },
          "terminology": {
            "action": 6,
            "tricky": 1,
            "suppose": 1,
            "agent": 2,
            "belief": 2,
            "state": 3,
            "ctions": 2,
            "unsure": 1,
            "legal": 1,
            "assume": 1,
            "illegal": 1,
            "effect": 1,
            "environment": 1,
            "safe": 1,
            "take": 1,
            "union": 1,
            "physical": 1,
            "current": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para120",
          "content": "On the other hand, if an illegal action might lead to catastrophe, it is safer to allow only the\nintersection,\nthat is, the set of actions legal in\nall\nthe states. For the vacuum world, every state has the same legal actions, so both methods give the same result.",
          "sentence_count": 2,
          "char_count": 219,
          "prev_para_id": "chap4_para119",
          "next_para_id": "chap4_para121",
          "style_metadata": {
            "para_id": "chap4_para120",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 2
          },
          "terminology": {
            "hand": 1,
            "illegal": 1,
            "action": 3,
            "lead": 1,
            "catastrophe": 1,
            "safer": 1,
            "allow": 1,
            "intersection": 1,
            "set": 1,
            "legal": 2,
            "state": 2,
            "vacuum": 1,
            "world": 1,
            "method": 1,
            "give": 1,
            "result": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para121",
          "content": "•\nTransition model:\nFor deterministic actions, the new belief state has one result state for each of the current possible states (although some result states may be the same):\nb\n'\n= RESULT (\nb\n,\na\n) = {\ns\n'\n:\ns\n'\n= RESULT\nP\n(\ns\n,\na\n) and\ns\n∈\nb\n}\n.",
          "sentence_count": 1,
          "char_count": 221,
          "prev_para_id": "chap4_para120",
          "next_para_id": "chap4_para122",
          "style_metadata": {
            "para_id": "chap4_para121",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 64.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 1
          },
          "terminology": {
            "transition": 1,
            "model": 1,
            "deterministic": 1,
            "action": 1,
            "new": 1,
            "belief": 1,
            "state": 4,
            "result": 4,
            "current": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para122",
          "content": "(4\n.4)\nWith nondeterminism, the new belief state consists of all the possible results of applying the action to any of the states in the current belief state:\nb\n'\n= RESULT (\nb\n,\na\n)\n=\n{\ns\n'\n:\ns\n'\n∈\nRESULTS\nP\n(\ns\n,\na\n) and\ns\n∈\nb\n}\n=\n∪\ns\n∈\nb\nRESULTS\nP\n(\ns\n,\na\n) ,\nThe size of\nbʹ\nwill be the same or smaller than\nb\nfor deterministic actions, but may be larger than\nb\nwith nondeterministic actions (see\nFigure 4.13\n).",
          "sentence_count": 1,
          "char_count": 369,
          "prev_para_id": "chap4_para121",
          "next_para_id": "chap4_para123",
          "style_metadata": {
            "para_id": "chap4_para122",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 105.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 105,
            "sentence_count": 1
          },
          "terminology": {
            "nondeterminism": 1,
            "new": 1,
            "belief": 2,
            "state": 3,
            "consists": 1,
            "possible": 1,
            "result": 4,
            "applying": 1,
            "action": 3,
            "current": 1,
            "size": 1,
            "smaller": 1,
            "deterministic": 1,
            "larger": 1,
            "nondeterministic": 1,
            "see": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para123",
          "content": "Description\nThe belief states are depicted by circular sections enclosing the vacuum world states that are depicted by square blocks with corresponding states labeled on them. A bold arrow labeled suck from the first belief state, which includes vacuum world states 1 and 3, points to the first node. A bold arrow labeled open square bracket \"A\", clean close square bracket points to the second belief state, which has 5 and 7 vacuum world states. An arrow labeled right from the first belief state points to a second node with an arc. An arrow labeled open square bracket B, Dirty close square bracket, from the second node points to a third belief state which has singleton vacuum world state 2. An arrow labeled open square bracket B, clean close square bracket, from the second node points to a third belief state which has singleton vacuum world state 4.",
          "sentence_count": 6,
          "char_count": 713,
          "prev_para_id": "chap4_para122",
          "next_para_id": "chap4_para124",
          "style_metadata": {
            "para_id": "chap4_para123",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 163,
            "sentence_count": 6
          },
          "terminology": {
            "description": 1,
            "belief": 6,
            "state": 12,
            "depicted": 2,
            "circular": 1,
            "section": 1,
            "enclosing": 1,
            "vacuum": 5,
            "world": 5,
            "square": 7,
            "block": 1,
            "corresponding": 1,
            "labeled": 6,
            "bold": 2,
            "arrow": 5,
            "suck": 1,
            "includes": 1,
            "point": 5,
            "first": 2,
            "node": 4,
            "open": 3,
            "bracket": 6,
            "clean": 2,
            "close": 3,
            "second": 4,
            "arc": 1,
            "dirty": 1,
            "third": 2,
            "singleton": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para123",
              "entity_text": "Dirty",
              "entity_type": "ORG",
              "start_char": 576,
              "end_char": 581,
              "context": "h an arc. An arrow labeled open square bracket B, Dirty close square bracket, from the second node points"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para124",
          "content": "×\nFigure 4.13\n(a) Predicting the next belief state for the sensorless vacuum world with the deterministic action,\nRight.",
          "sentence_count": 1,
          "char_count": 105,
          "prev_para_id": "chap4_para123",
          "next_para_id": "chap4_para125",
          "style_metadata": {
            "para_id": "chap4_para124",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 23,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "predicting": 1,
            "next": 1,
            "belief": 1,
            "state": 1,
            "sensorless": 1,
            "vacuum": 1,
            "world": 1,
            "deterministic": 1,
            "action": 1,
            "right": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para125",
          "content": "(b) Prediction for the same belief state and action in the slippery version of the sensorless vacuum world.",
          "sentence_count": 1,
          "char_count": 90,
          "prev_para_id": "chap4_para124",
          "next_para_id": "chap4_para126",
          "style_metadata": {
            "para_id": "chap4_para125",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 21,
            "sentence_count": 1
          },
          "terminology": {
            "prediction": 1,
            "belief": 1,
            "state": 1,
            "action": 1,
            "slippery": 1,
            "version": 1,
            "sensorless": 1,
            "vacuum": 1,
            "world": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para126",
          "content": "•\nGoal test:\nThe agent\npossibly\nachieves the goal if\nany\nstate\ns\nin the belief state satisfies the goal test of the underlying problem, I\nS\n-G\nOAL\nP\n(\ns\n). The agent\nnecessarily\nachieves the goal if\nevery\nstate satisfies I\nS\n-G\nOAL\nP\n(\ns\n). We aim to necessarily achieve the goal.",
          "sentence_count": 3,
          "char_count": 249,
          "prev_para_id": "chap4_para125",
          "next_para_id": "chap4_para127",
          "style_metadata": {
            "para_id": "chap4_para126",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 3
          },
          "terminology": {
            "goal": 5,
            "test": 2,
            "agent": 2,
            "achieves": 2,
            "state": 3,
            "belief": 1,
            "satisfies": 2,
            "underlying": 1,
            "problem": 1,
            "oal": 2,
            "aim": 1,
            "achieve": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para126",
              "entity_text": "OAL",
              "entity_type": "ORG",
              "start_char": 143,
              "end_char": 146,
              "context": "s the goal test of the underlying problem, I\nS\n-G\nOAL\nP\n(\ns\n). The agent\nnecessarily\nachieves the goal "
            },
            {
              "para_id": "chap4_para126",
              "entity_text": "OAL",
              "entity_type": "ORG",
              "start_char": 228,
              "end_char": 231,
              "context": "achieves the goal if\nevery\nstate satisfies I\nS\n-G\nOAL\nP\n(\ns\n). We aim to necessarily achieve the goal."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para127",
          "content": "•\nAction cost:\nThis is also tricky. If the same action can have different costs in different states, then the cost of taking an action in a given belief state could be one of\nseveral values. (This gives rise to a new class of problems, which we explore in Exercise\n4.",
          "sentence_count": 3,
          "char_count": 221,
          "prev_para_id": "chap4_para126",
          "next_para_id": "chap4_para128",
          "style_metadata": {
            "para_id": "chap4_para127",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 3
          },
          "terminology": {
            "action": 3,
            "cost": 3,
            "tricky": 1,
            "different": 2,
            "state": 2,
            "taking": 1,
            "given": 1,
            "belief": 1,
            "several": 1,
            "value": 1,
            "give": 1,
            "rise": 1,
            "new": 1,
            "class": 1,
            "problem": 1,
            "explore": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para128",
          "content": "MVAL\n.) For now we assume that the cost of an action is the same in all states and so can be transferred directly from the underlying physical problem.",
          "sentence_count": 2,
          "char_count": 124,
          "prev_para_id": "chap4_para127",
          "next_para_id": "chap4_para129",
          "style_metadata": {
            "para_id": "chap4_para128",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 2
          },
          "terminology": {
            "mval": 1,
            "assume": 1,
            "cost": 1,
            "action": 1,
            "state": 1,
            "transferred": 1,
            "underlying": 1,
            "physical": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para129",
          "content": "Figure 4.14\nshows the reachable belief-state space for the deterministic, sensorless vacuum world. There are only 12 reachable belief states out of 2\n8\n= 256 possible belief states.",
          "sentence_count": 2,
          "char_count": 156,
          "prev_para_id": "chap4_para128",
          "next_para_id": "chap4_para130",
          "style_metadata": {
            "para_id": "chap4_para129",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "reachable": 2,
            "belief-state": 1,
            "space": 1,
            "deterministic": 1,
            "sensorless": 1,
            "vacuum": 1,
            "world": 1,
            "belief": 2,
            "state": 2,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para130",
          "content": "Description\nThe belief states are depicted by circular sections, and the vacuum world states are depicted by square blocks with corresponding states labeled in them. Five belief states are shown. The transmission from one belief state to the next is labeled in the order Suck, Open square bracket \"A\", clean close square bracket, Right, and Open square bracket B, Dirty close square bracket. An arrow from the vacuum world state 1 of the first belief state points to the vacuum world state 5 of the second belief state. Two arrows from the vacuum world state 3 of the first belief state point to the vacuum world states 5 and 7 of the second belief state. Arrows from the vacuum world states 5 and 7 of the second belief state point to the vacuum world state 5 and 7 of the third belief state. Two arrows from the vacuum world state 5 of the third belief state point to the vacuum world state 2 and 6 of the fourth belief state. Four arrows from the vacuum world state 7 of the third belief state point to the vacuum world states 2, 6, 4, and 8 of the fourth belief state. Arrows from the vacuum world state 2 and 6 of the fourth belief state together point to the vacuum world state 2 of the fifth belief state.",
          "sentence_count": 9,
          "char_count": 988,
          "prev_para_id": "chap4_para129",
          "next_para_id": "chap4_para131",
          "style_metadata": {
            "para_id": "chap4_para130",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.33,
            "passive_voice_ratio": 0.004,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 246,
            "sentence_count": 9
          },
          "terminology": {
            "description": 1,
            "belief": 15,
            "state": 29,
            "depicted": 2,
            "circular": 1,
            "section": 1,
            "vacuum": 13,
            "world": 13,
            "square": 5,
            "block": 1,
            "corresponding": 1,
            "labeled": 2,
            "shown": 1,
            "transmission": 1,
            "next": 1,
            "order": 1,
            "suck": 1,
            "open": 2,
            "bracket": 4,
            "clean": 1,
            "close": 2,
            "right": 1,
            "dirty": 1,
            "arrow": 6,
            "first": 2,
            "point": 6,
            "second": 3,
            "third": 3,
            "fourth": 3,
            "fifth": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para130",
              "entity_text": "Suck",
              "entity_type": "PERSON",
              "start_char": 271,
              "end_char": 275,
              "context": " belief state to the next is labeled in the order Suck, Open square bracket \"A\", clean close square brac"
            },
            {
              "para_id": "chap4_para130",
              "entity_text": "Open",
              "entity_type": "PRODUCT",
              "start_char": 341,
              "end_char": 345,
              "context": "acket \"A\", clean close square bracket, Right, and Open square bracket B, Dirty close square bracket. An "
            },
            {
              "para_id": "chap4_para130",
              "entity_text": "Dirty",
              "entity_type": "ORG",
              "start_char": 364,
              "end_char": 369,
              "context": "square bracket, Right, and Open square bracket B, Dirty close square bracket. An arrow from the vacuum wo"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para131",
          "content": "×\nFigure 4.14\nThe reachable portion of the belief-state space for the deterministic, sensorless vacuum world. Each rectangular box corresponds to a single belief state. At any given point, the agent has a belief state but does not know which physical state it is in. The initial belief state (complete ignorance) is the top center box.",
          "sentence_count": 4,
          "char_count": 282,
          "prev_para_id": "chap4_para130",
          "next_para_id": "chap4_para132",
          "style_metadata": {
            "para_id": "chap4_para131",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "reachable": 1,
            "portion": 1,
            "belief-state": 1,
            "space": 1,
            "deterministic": 1,
            "sensorless": 1,
            "vacuum": 1,
            "world": 1,
            "rectangular": 1,
            "box": 2,
            "corresponds": 1,
            "single": 1,
            "belief": 3,
            "state": 4,
            "given": 1,
            "point": 1,
            "agent": 1,
            "know": 1,
            "physical": 1,
            "initial": 1,
            "complete": 1,
            "ignorance": 1,
            "top": 1,
            "center": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para132",
          "content": "The preceding definitions enable the automatic construction of the belief-state problem formulation from the definition of the underlying physical problem. Once this is done, we can solve sensorless problems with any of the ordinary search algorithms of\nChapter 3\n.",
          "sentence_count": 2,
          "char_count": 228,
          "prev_para_id": "chap4_para131",
          "next_para_id": "chap4_para133",
          "style_metadata": {
            "para_id": "chap4_para132",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 2
          },
          "terminology": {
            "preceding": 1,
            "definition": 2,
            "enable": 1,
            "automatic": 1,
            "construction": 1,
            "belief-state": 1,
            "problem": 3,
            "formulation": 1,
            "underlying": 1,
            "physical": 1,
            "done": 1,
            "solve": 1,
            "sensorless": 1,
            "ordinary": 1,
            "search": 1,
            "algorithm": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para133",
          "content": "In ordinary graph search, newly reached states are tested to see if they were previously reached. This works for belief states, too; for example, in\nFigure 4.14\n, the action sequence [\nSuck,Left,Suck\n] starting at the initial state reaches the same belief state as [\nRight,Left,Suck\n], namely, {5, 7}. Now, consider the belief state reached by [Left], namely, {1, 3, 5, 7}. Obviously, this is not identical to {5, 7}, but it is a\nsuperset.",
          "sentence_count": 4,
          "char_count": 370,
          "prev_para_id": "chap4_para132",
          "next_para_id": "chap4_para134",
          "style_metadata": {
            "para_id": "chap4_para133",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 113,
            "sentence_count": 4
          },
          "terminology": {
            "ordinary": 1,
            "graph": 1,
            "search": 1,
            "reached": 3,
            "state": 5,
            "tested": 1,
            "see": 1,
            "work": 1,
            "belief": 3,
            "example": 1,
            "figure": 1,
            "action": 1,
            "sequence": 1,
            "suck": 3,
            "left": 2,
            "starting": 1,
            "initial": 1,
            "reach": 1,
            "right": 1,
            "consider": 1,
            "identical": 1,
            "superset": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para134",
          "content": "We can discard (prune) any such superset belief state. Why? Because a solution from {1, 3, 5, 7} must be a solution for each of the individual states 1, 3, 5, and 7, and thus it is a solution for any combination of these individual states, such as {5, 7}; therefore we don’t need to try to solve {1, 3, 5, 7}, we can concentrate on trying to solve the strictly easier belief state {5, 7}.",
          "sentence_count": 3,
          "char_count": 313,
          "prev_para_id": "chap4_para133",
          "next_para_id": "chap4_para135",
          "style_metadata": {
            "para_id": "chap4_para134",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 35.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 106,
            "sentence_count": 3
          },
          "terminology": {
            "discard": 1,
            "prune": 1,
            "superset": 1,
            "belief": 2,
            "state": 4,
            "solution": 3,
            "individual": 2,
            "combination": 1,
            "need": 1,
            "try": 1,
            "solve": 2,
            "concentrate": 1,
            "trying": 1,
            "easier": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para135",
          "content": "Conversely, if {1, 3, 5, 7} has already been generated and found to be solvable, then any\nsubset,\nsuch as {5, 7}, is guaranteed to be solvable. (If I have a solution that works when I’m very confused about what state I’m in, it will still work when I’m less confused.) This extra level of pruning may dramatically improve the efficiency of sensorless problem solving.",
          "sentence_count": 3,
          "char_count": 305,
          "prev_para_id": "chap4_para134",
          "next_para_id": "chap4_para136",
          "style_metadata": {
            "para_id": "chap4_para135",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.67,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 3
          },
          "terminology": {
            "generated": 1,
            "found": 1,
            "solvable": 2,
            "subset": 1,
            "guaranteed": 1,
            "solution": 1,
            "work": 2,
            "confused": 2,
            "state": 1,
            "extra": 1,
            "level": 1,
            "pruning": 1,
            "improve": 1,
            "efficiency": 1,
            "sensorless": 1,
            "problem": 1,
            "solving": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para136",
          "content": "Even with this improvement, however, sensorless problem-solving as we have described it is seldom feasible in practice. One issue is the vastness of the belief-state space—we saw in the previous chapter that often a search space of size\nN\nis too large, and now we have search spaces of size 2\nN\n. Furthermore, each element of the search space is a set of up to\nN\nelements. For large\nN\n, we won’t be able to represent even a single belief state without running out of memory space.",
          "sentence_count": 4,
          "char_count": 400,
          "prev_para_id": "chap4_para135",
          "next_para_id": "chap4_para137",
          "style_metadata": {
            "para_id": "chap4_para136",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 24.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore",
              "however"
            ],
            "word_count": 98,
            "sentence_count": 4
          },
          "terminology": {
            "improvement": 1,
            "sensorless": 1,
            "problem-solving": 1,
            "described": 1,
            "seldom": 1,
            "feasible": 1,
            "practice": 1,
            "issue": 1,
            "belief-state": 1,
            "space—we": 1,
            "saw": 1,
            "previous": 1,
            "chapter": 1,
            "search": 3,
            "space": 4,
            "size": 2,
            "large": 2,
            "element": 2,
            "set": 1,
            "able": 1,
            "represent": 1,
            "single": 1,
            "belief": 1,
            "state": 1,
            "running": 1,
            "memory": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para137",
          "content": "One solution is to represent the belief state by some more compact description. In English, we could say the agent knows “Nothing” in the initial state; after moving\nLeft,\nwe could\nsay, “Not in the rightmost column,” and so on.",
          "sentence_count": 2,
          "char_count": 191,
          "prev_para_id": "chap4_para136",
          "next_para_id": "chap4_para138",
          "style_metadata": {
            "para_id": "chap4_para137",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 2
          },
          "terminology": {
            "solution": 1,
            "represent": 1,
            "belief": 1,
            "state": 2,
            "compact": 1,
            "description": 1,
            "english": 1,
            "say": 2,
            "agent": 1,
            "know": 1,
            "nothing": 1,
            "initial": 1,
            "moving": 1,
            "left": 1,
            "column": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para138",
          "content": "Chapter 7\nexplains how to do this in a formal representation scheme.",
          "sentence_count": 1,
          "char_count": 58,
          "prev_para_id": "chap4_para137",
          "next_para_id": "chap4_para139",
          "style_metadata": {
            "para_id": "chap4_para138",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "chapter": 1,
            "explains": 1,
            "formal": 1,
            "representation": 1,
            "scheme": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para139",
          "content": "Another approach is to avoid the standard search algorithms, which treat belief states as black boxes just like any other problem state. Instead, we can look\ninside\nthe belief states and develop\nincremental belief-state search\nalgorithms that build up the solution one physical state at a time. For example, in the sensorless vacuum world, the initial belief state is {1, 2, 3, 4, 5, 6, 7, 8}, and we have to find an action sequence that works in all 8 states. We can do this by first finding a solution that works for state 1; then we check if it works for state 2; if not, go back and find a different solution for state 1, and so on.",
          "sentence_count": 4,
          "char_count": 522,
          "prev_para_id": "chap4_para138",
          "next_para_id": "chap4_para140",
          "style_metadata": {
            "para_id": "chap4_para139",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 141,
            "sentence_count": 4
          },
          "terminology": {
            "approach": 1,
            "standard": 1,
            "search": 2,
            "algorithm": 2,
            "treat": 1,
            "belief": 3,
            "state": 9,
            "black": 1,
            "box": 1,
            "problem": 1,
            "look": 1,
            "inside": 1,
            "develop": 1,
            "incremental": 1,
            "belief-state": 1,
            "build": 1,
            "solution": 3,
            "physical": 1,
            "time": 1,
            "example": 1,
            "sensorless": 1,
            "vacuum": 1,
            "world": 1,
            "initial": 1,
            "find": 2,
            "action": 1,
            "sequence": 1,
            "work": 3,
            "finding": 1,
            "check": 1,
            "different": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para140",
          "content": "Just as an\nAND–OR\nsearch has to find a solution for every branch at an\nAND\nnode, this algorithm has to find a solution for every state in the belief state; the difference is that\nAND–OR\nsearch can find a different solution for each branch, whereas an incremental belief-state search has to find\none\nsolution that works for\nall\nthe states.",
          "sentence_count": 1,
          "char_count": 288,
          "prev_para_id": "chap4_para139",
          "next_para_id": "chap4_para141",
          "style_metadata": {
            "para_id": "chap4_para140",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 65.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 1
          },
          "terminology": {
            "and–or": 2,
            "search": 3,
            "find": 4,
            "solution": 4,
            "branch": 2,
            "node": 1,
            "algorithm": 1,
            "state": 3,
            "belief": 1,
            "difference": 1,
            "different": 1,
            "incremental": 1,
            "belief-state": 1,
            "work": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para141",
          "content": "The main advantage of the incremental approach is that it is typically able to detect failure quickly—when a belief state is unsolvable, it is usually the case that a small subset of the\nbelief state, consisting of the first few states examined, is also unsolvable. In some cases, this leads to a speedup proportional to the size of the belief states, which may themselves be as large as the physical state space itself.",
          "sentence_count": 2,
          "char_count": 349,
          "prev_para_id": "chap4_para140",
          "next_para_id": "chap4_para142",
          "style_metadata": {
            "para_id": "chap4_para141",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 2
          },
          "terminology": {
            "main": 1,
            "advantage": 1,
            "incremental": 1,
            "approach": 1,
            "able": 1,
            "detect": 1,
            "failure": 1,
            "quickly—when": 1,
            "belief": 3,
            "state": 5,
            "unsolvable": 2,
            "case": 2,
            "small": 1,
            "subset": 1,
            "consisting": 1,
            "first": 1,
            "examined": 1,
            "lead": 1,
            "speedup": 1,
            "proportional": 1,
            "size": 1,
            "large": 1,
            "physical": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para142",
          "content": "4.4.2\nSearching in partially observable environments\nMany problems cannot be solved without sensing. For example, the sensorless 8-puzzle is impossible. On the other hand, a little bit of sensing can go a long way: we can solve 8- puzzles if we can see just the upper-left corner square. The solution involves moving each tile in turn into the observable square and keeping track of its location from then on.",
          "sentence_count": 4,
          "char_count": 343,
          "prev_para_id": "chap4_para141",
          "next_para_id": "chap4_para143",
          "style_metadata": {
            "para_id": "chap4_para142",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 4
          },
          "terminology": {
            "searching": 1,
            "observable": 2,
            "environment": 1,
            "many": 1,
            "problem": 1,
            "solved": 1,
            "sensing": 2,
            "example": 1,
            "sensorless": 1,
            "8-puzzle": 1,
            "impossible": 1,
            "hand": 1,
            "little": 1,
            "bit": 1,
            "long": 1,
            "way": 1,
            "solve": 1,
            "puzzle": 1,
            "see": 1,
            "upper-left": 1,
            "corner": 1,
            "square": 2,
            "solution": 1,
            "involves": 1,
            "moving": 1,
            "tile": 1,
            "turn": 1,
            "keeping": 1,
            "track": 1,
            "location": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para143",
          "content": "For a partially observable problem, the problem specification will specify a P\nERCEPT\n(\ns\n) function that returns the percept received by the agent in a given state. If sensing is nondeterministic, then we can use a P\nERCEPTS\nfunction that returns a set of possible percepts. For fully observable problems, P\nERCEPT\n(\ns\n) =\ns\nfor every state\ns\n, and for sensorless problems P\nERCEPT\n(\ns\n) =\nnull\n.",
          "sentence_count": 3,
          "char_count": 342,
          "prev_para_id": "chap4_para142",
          "next_para_id": "chap4_para144",
          "style_metadata": {
            "para_id": "chap4_para143",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 3
          },
          "terminology": {
            "observable": 2,
            "problem": 4,
            "specification": 1,
            "specify": 1,
            "function": 2,
            "return": 2,
            "percept": 2,
            "received": 1,
            "agent": 1,
            "given": 1,
            "state": 2,
            "sensing": 1,
            "nondeterministic": 1,
            "use": 1,
            "ercepts": 1,
            "set": 1,
            "possible": 1,
            "ercept": 2,
            "sensorless": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para143",
              "entity_text": "ERCEPTS",
              "entity_type": "ORG",
              "start_char": 218,
              "end_char": 225,
              "context": " sensing is nondeterministic, then we can use a P\nERCEPTS\nfunction that returns a set of possible percepts."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para144",
          "content": "Consider a local-sensing vacuum world, in which the agent has a position sensor that yields the percept\nL\nin the left square, and\nR\nin the right square, and a dirt sensor that yields\nDirty\nwhen the current square is dirty and\nClean\nwhen it is clean. Thus, the P\nERCEPT\nin state 1 is [\nL, Dirty\n]. With partial observability, it will usually be the case that several states produce the same percept; state 3 will also produce [\nL, Dirty\n]. Hence, given this initial percept, the initial belief state will be {1, 3}. We can think of the transition model between belief states for partially observable problems as occurring in three stages, as shown in\nFigure 4.15\n:\nDescription\nThe robot is placed in a maze-like environment with dark shaded and white blocks. The path formed by the white block is where the robot has to move. The dark shaded blocks depict an obstacle. In the percept bit value, the 1s indicate the obstacles and 0s indicate the open path. The four bits depict the north, east, west, and south directions. The robot is depicted by two concentric bold circles.",
          "sentence_count": 10,
          "char_count": 899,
          "prev_para_id": "chap4_para143",
          "next_para_id": "chap4_para145",
          "style_metadata": {
            "para_id": "chap4_para144",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.2,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 222,
            "sentence_count": 10
          },
          "terminology": {
            "consider": 1,
            "local-sensing": 1,
            "vacuum": 1,
            "world": 1,
            "agent": 1,
            "position": 1,
            "sensor": 2,
            "yield": 2,
            "left": 1,
            "square": 3,
            "right": 1,
            "dirt": 1,
            "dirty": 4,
            "current": 1,
            "clean": 2,
            "ercept": 1,
            "state": 5,
            "partial": 1,
            "observability": 1,
            "case": 1,
            "several": 1,
            "produce": 2,
            "percept": 2,
            "hence": 1,
            "given": 1,
            "initial": 2,
            "belief": 2,
            "think": 1,
            "transition": 1,
            "model": 1,
            "observable": 1,
            "problem": 1,
            "occurring": 1,
            "stage": 1,
            "shown": 1,
            "figure": 1,
            "description": 1,
            "robot": 3,
            "placed": 1,
            "maze-like": 1,
            "environment": 1,
            "dark": 2,
            "shaded": 2,
            "white": 2,
            "block": 3,
            "path": 2,
            "formed": 1,
            "move": 1,
            "depict": 2,
            "obstacle": 2,
            "bit": 2,
            "value": 1,
            "indicate": 2,
            "open": 1,
            "north": 1,
            "east": 1,
            "west": 1,
            "south": 1,
            "direction": 1,
            "depicted": 1,
            "concentric": 1,
            "bold": 1,
            "circle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para145",
          "content": "Part (“a”): Possible locations of the robot after E subscript 1 BaseLine equals 1011. The possible positions of the robot are shown at four blocks. Part (b): Possible locations of the robot after E subscript 1 BaseLine equals 1011, E subscript 2 BaseLine equals 1010. One possible position of the robot is depicted on the board.",
          "sentence_count": 4,
          "char_count": 273,
          "prev_para_id": "chap4_para144",
          "next_para_id": "chap4_para146",
          "style_metadata": {
            "para_id": "chap4_para145",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.75,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 4
          },
          "terminology": {
            "part": 2,
            "possible": 4,
            "location": 2,
            "robot": 4,
            "subscript": 3,
            "baseline": 3,
            "equal": 3,
            "position": 2,
            "shown": 1,
            "block": 1,
            "depicted": 1,
            "board": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para146",
          "content": "×\nFigure 4.15\nTwo examples of transitions in local-sensing vacuum worlds. (a) In the deterministic world,\nRight\nis applied in the initial belief state, resulting in a new predicted belief state with two possible physical states; for those states, the possible percepts are [\nR, Dirty\n] and [\nR, Clean\n]\n,\nleading to two belief states, each of which is a singleton. (b) In the slippery world,\nRight\nis applied in the initial belief state, giving a new belief state with four physical states; for those states, the possible percepts are [\nL, Dirty\n]\n,\n[R,\nDirty\n]\n,\nand [\nR, Clean\n]\n,\nleading to three belief states as shown.",
          "sentence_count": 3,
          "char_count": 533,
          "prev_para_id": "chap4_para145",
          "next_para_id": "chap4_para147",
          "style_metadata": {
            "para_id": "chap4_para146",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.67,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 137,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "example": 1,
            "transition": 1,
            "local-sensing": 1,
            "vacuum": 1,
            "world": 3,
            "deterministic": 1,
            "right": 2,
            "applied": 2,
            "initial": 2,
            "belief": 6,
            "state": 10,
            "resulting": 1,
            "new": 2,
            "predicted": 1,
            "possible": 3,
            "physical": 2,
            "percept": 2,
            "dirty": 3,
            "clean": 2,
            "leading": 2,
            "singleton": 1,
            "slippery": 1,
            "giving": 1,
            "shown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para147",
          "content": "•\nThe\nprediction\nstage computes the belief state resulting from the action, R\nESULT\n(\nb\n,\na\n), exactly as we did with sensorless problems. To emphasize that this is a prediction, we use the notation\nb\n^\n= R\nESULT\n(\nb\n,\na\n), where the “hat” over the\nb\nmeans “estimated,” and we also use P\nREDlCT\n(\nb\n,\na\n) as a synonym for R\nESULT\n(\nb\n,\na\n).",
          "sentence_count": 2,
          "char_count": 296,
          "prev_para_id": "chap4_para146",
          "next_para_id": "chap4_para148",
          "style_metadata": {
            "para_id": "chap4_para147",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 2
          },
          "terminology": {
            "prediction": 2,
            "stage": 1,
            "computes": 1,
            "belief": 1,
            "state": 1,
            "resulting": 1,
            "action": 1,
            "esult": 3,
            "problem": 1,
            "emphasize": 1,
            "use": 2,
            "notation": 1,
            "mean": 1,
            "estimated": 1,
            "redlct": 1,
            "synonym": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para148",
          "content": "•\nThe\npossible percepts\nstage computes the set of percepts that could be observed in the predicted belief state (using the letter\no\nfor observation):\nPOSSIBLE-PERCEPTS (\nb\n^\n)\n=\n{\no\n:\no\n=\nPERCEPT (\ns\n) and\ns\n∈\nb\n^\n}\n.",
          "sentence_count": 1,
          "char_count": 198,
          "prev_para_id": "chap4_para147",
          "next_para_id": "chap4_para149",
          "style_metadata": {
            "para_id": "chap4_para148",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 50.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 1
          },
          "terminology": {
            "possible": 1,
            "percept": 2,
            "stage": 1,
            "computes": 1,
            "set": 1,
            "observed": 1,
            "predicted": 1,
            "belief": 1,
            "state": 1,
            "using": 1,
            "letter": 1,
            "observation": 1,
            "possible-percepts": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para149",
          "content": "•\nThe\nupdate\nstage computes, for each possible percept, the belief state that would result from the percept. The updated belief state\nb\no\nis the set of states in\nb\n^\nthat could have produced the percept:\nb\no\n= UPDATE (\nb\n^\n,\na\n)\n=\n{\ns\n:\no\n=\nPERCEPT (\ns\n) and\ns\n∈\nb\n^\n}\n.",
          "sentence_count": 2,
          "char_count": 242,
          "prev_para_id": "chap4_para148",
          "next_para_id": "chap4_para150",
          "style_metadata": {
            "para_id": "chap4_para149",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 2
          },
          "terminology": {
            "update": 2,
            "stage": 1,
            "computes": 1,
            "possible": 1,
            "percept": 3,
            "belief": 2,
            "state": 3,
            "result": 1,
            "updated": 1,
            "set": 1,
            "produced": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para150",
          "content": "The agent needs to deal with\npossible\npercepts at planning time, because it won’t know the\nactual\npercepts until it executes the plan. Notice that nondeterminism in the physical environment can enlarge the belief state in the prediction stage, but each updated belief state\nb\no\ncan be no larger than the predicted belief state\nb\n^\n; observations can only help reduce uncertainty. Moreover, for deterministic sensing, the belief states for the different possible percepts will be disjoint, forming a\npartition\nof the original predicted belief state.",
          "sentence_count": 3,
          "char_count": 473,
          "prev_para_id": "chap4_para149",
          "next_para_id": "chap4_para151",
          "style_metadata": {
            "para_id": "chap4_para150",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 32.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 98,
            "sentence_count": 3
          },
          "terminology": {
            "agent": 1,
            "need": 1,
            "deal": 1,
            "possible": 2,
            "percept": 3,
            "planning": 1,
            "time": 1,
            "know": 1,
            "actual": 1,
            "executes": 1,
            "plan": 1,
            "notice": 1,
            "nondeterminism": 1,
            "physical": 1,
            "environment": 1,
            "enlarge": 1,
            "belief": 5,
            "state": 5,
            "prediction": 1,
            "stage": 1,
            "updated": 1,
            "larger": 1,
            "predicted": 2,
            "observation": 1,
            "help": 1,
            "reduce": 1,
            "uncertainty": 1,
            "deterministic": 1,
            "sensing": 1,
            "different": 1,
            "disjoint": 1,
            "forming": 1,
            "partition": 1,
            "original": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para151",
          "content": "Putting these three stages together, we obtain the possible belief states resulting from a given action and the subsequent possible percepts:\nRESULTS(\nb\n,\na\n)\n=\n{\nb\no\n:\nb\no\n= UPDATE\n(PREDICT (\nb\n,\na\n),\no\n) and\no\n∈\nPOSSIBLE-PERCEPTS (PREDICT(\nb\n,\na\n))}\n.",
          "sentence_count": 1,
          "char_count": 233,
          "prev_para_id": "chap4_para150",
          "next_para_id": "chap4_para152",
          "style_metadata": {
            "para_id": "chap4_para151",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 62.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 1
          },
          "terminology": {
            "putting": 1,
            "stage": 1,
            "obtain": 1,
            "possible": 2,
            "belief": 1,
            "state": 1,
            "resulting": 1,
            "given": 1,
            "action": 1,
            "subsequent": 1,
            "percept": 1,
            "result": 1,
            "update": 1,
            "predict": 2,
            "possible-percepts": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para152",
          "content": "(4\n.5)\n4.4.3\nSolving partially observable problems\nThe preceding section showed how to derive the R\nESULTS\nfunction for a nondeterministic belief-state problem from an underlying physical problem, given the P\nERCEPT\nfunction. With this formulation, the\nAND–OR\nsearch algorithm of\nFigure 4.11\ncan be applied directly to derive a solution.",
          "sentence_count": 2,
          "char_count": 299,
          "prev_para_id": "chap4_para151",
          "next_para_id": "chap4_para153",
          "style_metadata": {
            "para_id": "chap4_para152",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 2
          },
          "terminology": {
            "solving": 1,
            "observable": 1,
            "problem": 3,
            "preceding": 1,
            "section": 1,
            "showed": 1,
            "derive": 2,
            "esults": 1,
            "function": 2,
            "nondeterministic": 1,
            "belief-state": 1,
            "underlying": 1,
            "physical": 1,
            "given": 1,
            "formulation": 1,
            "search": 1,
            "algorithm": 1,
            "figure": 1,
            "applied": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para153",
          "content": "Figure 4.16\nshows part of the search tree for the local-sensing vacuum world, assuming an initial percept [\nL, Dirty\n]. The solution is the conditional plan\nDescription\nA square block with three rows and three columns depicts the maze. The rows are labeled 3, 2, and 1 from top to bottom. The columns are labeled 1, 2, and 3 from left to right. S is positioned at Row 1 Column 1. G is positioned at Row 3 Column 3. Red bold lines are marked at the border lines of column 1 of rows 2 and 3, row 2 of columns 1 and 2, and columns 2 and 3 of rows 2 and 3.",
          "sentence_count": 7,
          "char_count": 444,
          "prev_para_id": "chap4_para152",
          "next_para_id": "chap4_para154",
          "style_metadata": {
            "para_id": "chap4_para153",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.14,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 127,
            "sentence_count": 7
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "part": 1,
            "search": 1,
            "tree": 1,
            "local-sensing": 1,
            "vacuum": 1,
            "world": 1,
            "assuming": 1,
            "initial": 1,
            "percept": 1,
            "dirty": 1,
            "solution": 1,
            "conditional": 1,
            "plan": 1,
            "description": 1,
            "square": 1,
            "block": 1,
            "row": 7,
            "column": 7,
            "depicts": 1,
            "maze": 1,
            "labeled": 2,
            "top": 1,
            "bottom": 1,
            "right": 1,
            "positioned": 2,
            "red": 1,
            "bold": 1,
            "line": 2,
            "marked": 1,
            "border": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para154",
          "content": "×\nFigure 4.16\nThe first level of the\nAND–OR\nsearch tree for a problem in the local-sensing vacuum world;\nSuck\nis the first action in the solution.",
          "sentence_count": 1,
          "char_count": 126,
          "prev_para_id": "chap4_para153",
          "next_para_id": "chap4_para155",
          "style_metadata": {
            "para_id": "chap4_para154",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "first": 2,
            "level": 1,
            "search": 1,
            "tree": 1,
            "problem": 1,
            "local-sensing": 1,
            "vacuum": 1,
            "world": 1,
            "suck": 1,
            "action": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para155",
          "content": "[\nS\nu\nc\nk\n,\nR\ni\ng\nh\nt\n,\ni\nf\nR\ns\nt\na\nt\ne\n= {6}\nt\nh\ne\nn\nS\nu\nc\nk\ne\nl\ns\ne\n[ ]] .",
          "sentence_count": 1,
          "char_count": 76,
          "prev_para_id": "chap4_para154",
          "next_para_id": "chap4_para156",
          "style_metadata": {
            "para_id": "chap4_para155",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para156",
          "content": "Notice that, because we supplied a belief-state problem to the\nAND–OR\nsearch algorithm, it returned a conditional plan that tests the belief state rather than the actual state. This is as it should be: in a partially observable environment the agent won’t know the actual state.",
          "sentence_count": 2,
          "char_count": 235,
          "prev_para_id": "chap4_para155",
          "next_para_id": "chap4_para157",
          "style_metadata": {
            "para_id": "chap4_para156",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 2
          },
          "terminology": {
            "supplied": 1,
            "belief-state": 1,
            "problem": 1,
            "search": 1,
            "algorithm": 1,
            "returned": 1,
            "conditional": 1,
            "plan": 1,
            "test": 1,
            "belief": 1,
            "state": 3,
            "actual": 2,
            "observable": 1,
            "environment": 1,
            "agent": 1,
            "know": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para157",
          "content": "As in the case of standard search algorithms applied to sensorless problems, the\nAND–OR\nsearch algorithm treats belief states as black boxes, just like any other states. One can improve on this by checking for previously generated belief states that are subsets or supersets of the current state, just as for sensorless problems. One can also derive incremental search algorithms, analogous to those described for sensorless problems, that provide substantial speedups over the black-box approach.",
          "sentence_count": 3,
          "char_count": 425,
          "prev_para_id": "chap4_para156",
          "next_para_id": "chap4_para158",
          "style_metadata": {
            "para_id": "chap4_para157",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 3
          },
          "terminology": {
            "case": 1,
            "standard": 1,
            "search": 3,
            "algorithm": 2,
            "applied": 1,
            "sensorless": 3,
            "problem": 3,
            "and–or": 1,
            "treat": 1,
            "belief": 2,
            "state": 4,
            "black": 1,
            "box": 1,
            "improve": 1,
            "checking": 1,
            "generated": 1,
            "subset": 1,
            "supersets": 1,
            "current": 1,
            "derive": 1,
            "incremental": 1,
            "analogous": 1,
            "described": 1,
            "provide": 1,
            "substantial": 1,
            "speedup": 1,
            "black-box": 1,
            "approach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para158",
          "content": "4.4.4\nAn agent for partially observable environments\nAn agent for partially observable environments formulates a problem, calls a search algorithm (such as A\nND\n-O\nR\n-S\nEARCH\n) to solve it, and executes the solution. There are two main differences between this agent and the one for fully observable deterministic environments. First, the solution will be a conditional plan rather than a sequence; to execute an if–then–else expression, the agent will need to test the condition and execute the appropriate branch of the conditional. Second, the agent will need to maintain its belief state as it performs actions and receives percepts. This process resembles the prediction–observation–update process in\nEquation (4.5)\nbut is actually simpler because the percept is given by the environment rather than calculated by the agent. Given an initial belief state\nb,\nan action\na,\nand a percept\no,\nthe new belief state is:\nb\n′\n=\nUPDATE(PREDICT(\nb\n,\na\n),\no\n)\n.",
          "sentence_count": 6,
          "char_count": 824,
          "prev_para_id": "chap4_para157",
          "next_para_id": "chap4_para159",
          "style_metadata": {
            "para_id": "chap4_para158",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 180,
            "sentence_count": 6
          },
          "terminology": {
            "agent": 6,
            "observable": 3,
            "environment": 4,
            "formulates": 1,
            "problem": 1,
            "call": 1,
            "search": 1,
            "earch": 1,
            "solve": 1,
            "executes": 1,
            "solution": 2,
            "main": 1,
            "difference": 1,
            "deterministic": 1,
            "first": 1,
            "conditional": 2,
            "plan": 1,
            "sequence": 1,
            "execute": 2,
            "if–then–else": 1,
            "expression": 1,
            "need": 2,
            "test": 1,
            "condition": 1,
            "appropriate": 1,
            "branch": 1,
            "second": 1,
            "maintain": 1,
            "belief": 3,
            "state": 3,
            "performs": 1,
            "action": 2,
            "receives": 1,
            "percept": 2,
            "process": 2,
            "resembles": 1,
            "prediction–observation–update": 1,
            "equation": 1,
            "simpler": 1,
            "given": 2,
            "calculated": 1,
            "initial": 1,
            "new": 1,
            "update": 1,
            "predict": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para159",
          "content": "(\n4.6\n)\nConsider a\nkindergarten\nvacuum world wherein agents sense only the state of their current square, and any square may become dirty at any time unless the agent is actively cleaning it at that moment.",
          "sentence_count": 1,
          "char_count": 175,
          "prev_para_id": "chap4_para158",
          "next_para_id": "chap4_para160",
          "style_metadata": {
            "para_id": "chap4_para159",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 1
          },
          "terminology": {
            "consider": 1,
            "kindergarten": 1,
            "vacuum": 1,
            "world": 1,
            "wherein": 1,
            "agent": 2,
            "sense": 1,
            "state": 1,
            "current": 1,
            "square": 2,
            "become": 1,
            "dirty": 1,
            "time": 1,
            "cleaning": 1,
            "moment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para160",
          "content": "7\nFigure 4.17\nshows the belief state being maintained in this environment.",
          "sentence_count": 1,
          "char_count": 65,
          "prev_para_id": "chap4_para159",
          "next_para_id": "chap4_para161",
          "style_metadata": {
            "para_id": "chap4_para160",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "belief": 1,
            "state": 1,
            "maintained": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para161",
          "content": "Description\nState space 1: An arrow from a node labeled S points to a node labeled “a”. Two arrows from the node labeled “a” point to two unlabeled nodes. An arrow from the first unlabeled node points to a node labeled G. An arrow from the second unlabeled node points to a third unlabeled node which has a self-loop.",
          "sentence_count": 3,
          "char_count": 260,
          "prev_para_id": "chap4_para160",
          "next_para_id": "chap4_para162",
          "style_metadata": {
            "para_id": "chap4_para161",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 3
          },
          "terminology": {
            "description": 1,
            "state": 1,
            "space": 1,
            "arrow": 4,
            "node": 5,
            "labeled": 4,
            "point": 4,
            "unlabeled": 4,
            "second": 1,
            "third": 1,
            "self-loop": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para161",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 43,
              "end_char": 47,
              "context": "Description\nState space 1: An arrow from a node labeled S points to a node labeled “a”. Two arrow"
            },
            {
              "para_id": "chap4_para161",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 108,
              "end_char": 112,
              "context": "points to a node labeled “a”. Two arrows from the node labeled “a” point to two unlabeled nodes. An arro"
            },
            {
              "para_id": "chap4_para161",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 189,
              "end_char": 193,
              "context": "nlabeled nodes. An arrow from the first unlabeled node points to a node labeled G. An arrow from the sec"
            },
            {
              "para_id": "chap4_para161",
              "entity_text": "G. An",
              "entity_type": "PERSON",
              "start_char": 219,
              "end_char": 224,
              "context": "the first unlabeled node points to a node labeled G. An arrow from the second unlabeled node points to a "
            },
            {
              "para_id": "chap4_para161",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 257,
              "end_char": 261,
              "context": "ode labeled G. An arrow from the second unlabeled node points to a third unlabeled node which has a self"
            },
            {
              "para_id": "chap4_para161",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 290,
              "end_char": 294,
              "context": "second unlabeled node points to a third unlabeled node which has a self-loop."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para162",
          "content": "State space 2: An arrow from a node labeled S points to a node labeled “a”. Two arrows from the node labeled “a” point to two unlabeled nodes. An arrow from the first unlabeled node points to a third unlabeled node which has a self-loop. An arrow from the second unlabeled node points to a node labeled G.",
          "sentence_count": 4,
          "char_count": 248,
          "prev_para_id": "chap4_para161",
          "next_para_id": "chap4_para163",
          "style_metadata": {
            "para_id": "chap4_para162",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 4
          },
          "terminology": {
            "state": 1,
            "space": 1,
            "arrow": 4,
            "node": 5,
            "labeled": 4,
            "point": 4,
            "unlabeled": 4,
            "third": 1,
            "self-loop": 1,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para162",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 31,
              "end_char": 35,
              "context": "State space 2: An arrow from a node labeled S points to a node labeled “a”. Two arrow"
            },
            {
              "para_id": "chap4_para162",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 96,
              "end_char": 100,
              "context": "points to a node labeled “a”. Two arrows from the node labeled “a” point to two unlabeled nodes. An arro"
            },
            {
              "para_id": "chap4_para162",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 177,
              "end_char": 181,
              "context": "nlabeled nodes. An arrow from the first unlabeled node points to a third unlabeled node which has a self"
            },
            {
              "para_id": "chap4_para162",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 210,
              "end_char": 214,
              "context": " first unlabeled node points to a third unlabeled node which has a self-loop. An arrow from the second u"
            },
            {
              "para_id": "chap4_para162",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 273,
              "end_char": 277,
              "context": "s a self-loop. An arrow from the second unlabeled node points to a node labeled G."
            },
            {
              "para_id": "chap4_para162",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 290,
              "end_char": 294,
              "context": " arrow from the second unlabeled node points to a node labeled G."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para163",
          "content": "×\nFigure 4.17\nTwo prediction–update cycles of belief-state maintenance in the kindergarten vacuum world with local sensing.",
          "sentence_count": 1,
          "char_count": 109,
          "prev_para_id": "chap4_para162",
          "next_para_id": "chap4_para164",
          "style_metadata": {
            "para_id": "chap4_para163",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "prediction–update": 1,
            "cycle": 1,
            "belief-state": 1,
            "maintenance": 1,
            "kindergarten": 1,
            "vacuum": 1,
            "world": 1,
            "local": 1,
            "sensing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para164",
          "content": "In partially observable environments—which include the vast majority of real-world environments—maintaining one’s belief state is a core function of any intelligent system. This function goes under various names, including\nmonitoring\n,\nfiltering\n, and\nstate estimation\n.",
          "sentence_count": 2,
          "char_count": 240,
          "prev_para_id": "chap4_para163",
          "next_para_id": "chap4_para165",
          "style_metadata": {
            "para_id": "chap4_para164",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "observable": 1,
            "environments—which": 1,
            "include": 1,
            "vast": 1,
            "majority": 1,
            "real-world": 1,
            "environments—maintaining": 1,
            "belief": 1,
            "state": 2,
            "core": 1,
            "function": 2,
            "intelligent": 1,
            "system": 1,
            "go": 1,
            "various": 1,
            "name": 1,
            "including": 1,
            "monitoring": 1,
            "filtering": 1,
            "estimation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para165",
          "content": "Equation (4.6)\nis called a recursive state estimator because it computes the new belief state from the previous one rather than by examining the entire percept sequence. If the agent is not to “fall behind,” the computation has to happen as fast as percepts are coming in. As the environment becomes more complex, the agent will only have time to compute an approximate belief state, perhaps focusing on the implications of the percept for the aspects of the environment that are of current interest. Most work on this problem has been done for\nstochastic, continuous-state environments with the tools of probability theory, as explained in\nChapter 14\n.",
          "sentence_count": 4,
          "char_count": 550,
          "prev_para_id": "chap4_para164",
          "next_para_id": "chap4_para166",
          "style_metadata": {
            "para_id": "chap4_para165",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 120,
            "sentence_count": 4
          },
          "terminology": {
            "equation": 1,
            "called": 1,
            "recursive": 1,
            "state": 3,
            "estimator": 1,
            "computes": 1,
            "new": 1,
            "belief": 2,
            "previous": 1,
            "examining": 1,
            "entire": 1,
            "percept": 2,
            "sequence": 1,
            "agent": 2,
            "fall": 1,
            "computation": 1,
            "happen": 1,
            "coming": 1,
            "environment": 3,
            "becomes": 1,
            "complex": 1,
            "time": 1,
            "compute": 1,
            "approximate": 1,
            "focusing": 1,
            "implication": 1,
            "aspect": 1,
            "current": 1,
            "interest": 1,
            "work": 1,
            "problem": 1,
            "done": 1,
            "stochastic": 1,
            "continuous-state": 1,
            "tool": 1,
            "probability": 1,
            "theory": 1,
            "explained": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para166",
          "content": "In this section we will show an example in a discrete environment with deterministic sensors and nondeterministic actions. The example concerns a robot with a particular state estimation task called\nlocalization\n: working out where it is, given a map of the world and a sequence of percepts and actions. Our robot is placed in the maze-like environment of\nFigure 4.18\n. The robot is equipped with four sonar sensors that tell whether there is an obstacle—the outer wall or a dark shaded square in the figure—in each of the four compass directions. The percept is in the form of a bit vector, one bit for each of the directions north, east, south, and west in that order, so 1011 means there are obstacles to the north, south, and west, but not east.",
          "sentence_count": 5,
          "char_count": 621,
          "prev_para_id": "chap4_para165",
          "next_para_id": "chap4_para167",
          "style_metadata": {
            "para_id": "chap4_para166",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.2,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 146,
            "sentence_count": 5
          },
          "terminology": {
            "section": 1,
            "show": 1,
            "example": 2,
            "discrete": 1,
            "environment": 2,
            "deterministic": 1,
            "sensor": 2,
            "nondeterministic": 1,
            "action": 2,
            "concern": 1,
            "robot": 3,
            "particular": 1,
            "state": 1,
            "estimation": 1,
            "task": 1,
            "called": 1,
            "localization": 1,
            "working": 1,
            "given": 1,
            "map": 1,
            "world": 1,
            "sequence": 1,
            "percept": 2,
            "placed": 1,
            "maze-like": 1,
            "figure": 1,
            "equipped": 1,
            "sonar": 1,
            "tell": 1,
            "obstacle—the": 1,
            "outer": 1,
            "wall": 1,
            "dark": 1,
            "shaded": 1,
            "square": 1,
            "figure—in": 1,
            "compass": 1,
            "direction": 2,
            "form": 1,
            "bit": 2,
            "vector": 1,
            "east": 2,
            "south": 2,
            "west": 2,
            "order": 1,
            "mean": 1,
            "obstacle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para167",
          "content": "Description\nSeven long thin blocks are arranged at different levels, and the count of the block extends to n numbers. A path is traced with alternate upper and lower parts of the blocks. The path starts at S and ends at G.",
          "sentence_count": 3,
          "char_count": 182,
          "prev_para_id": "chap4_para166",
          "next_para_id": "chap4_para168",
          "style_metadata": {
            "para_id": "chap4_para167",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.33,
            "passive_voice_ratio": 0.022,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 3
          },
          "terminology": {
            "description": 1,
            "thin": 1,
            "block": 3,
            "arranged": 1,
            "different": 1,
            "level": 1,
            "count": 1,
            "extends": 1,
            "number": 1,
            "path": 2,
            "traced": 1,
            "alternate": 1,
            "upper": 1,
            "lower": 1,
            "part": 1,
            "start": 1,
            "end": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para168",
          "content": "×\nFigure 4.18\nPossible positions of the robot, ʘ, (a) after one observation,\nE\n1\n=\n1011, and (b) after moving one square and making a second observation,\nE\n2\n= 1010. When sensors are noiseless and the transition model is accurate, there is only one possible location for the robot consistent with this sequence of two observations.",
          "sentence_count": 2,
          "char_count": 283,
          "prev_para_id": "chap4_para167",
          "next_para_id": "chap4_para169",
          "style_metadata": {
            "para_id": "chap4_para168",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "possible": 2,
            "position": 1,
            "robot": 2,
            "observation": 3,
            "moving": 1,
            "square": 1,
            "making": 1,
            "second": 1,
            "sensor": 1,
            "noiseless": 1,
            "transition": 1,
            "model": 1,
            "accurate": 1,
            "location": 1,
            "consistent": 1,
            "sequence": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para169",
          "content": "We assume that the sensors give perfectly correct data, and that the robot has a correct map of the environment. But unfortunately, the robot’s navigational system is broken, so when it executes a\nRight\naction, it moves randomly to one of the adjacent squares. The robot’s task is to determine its current location.",
          "sentence_count": 3,
          "char_count": 265,
          "prev_para_id": "chap4_para168",
          "next_para_id": "chap4_para170",
          "style_metadata": {
            "para_id": "chap4_para169",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 3
          },
          "terminology": {
            "assume": 1,
            "sensor": 1,
            "give": 1,
            "correct": 2,
            "data": 1,
            "robot": 3,
            "map": 1,
            "environment": 1,
            "navigational": 1,
            "system": 1,
            "broken": 1,
            "executes": 1,
            "right": 1,
            "action": 1,
            "move": 1,
            "adjacent": 1,
            "square": 1,
            "task": 1,
            "determine": 1,
            "current": 1,
            "location": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para170",
          "content": "Suppose the robot has just been switched on, and it does not know where it is—its initial belief state\nb\nconsists of the set of all locations. The robot then receives the percept 1011 and does an update using the equation\nb\no\n= U\nPDATE\n(1011), yielding the 4 locations shown in\nFigure 4.18(a)\n. You can inspect the maze to see that those are the only four locations that yield the percept 1011.",
          "sentence_count": 3,
          "char_count": 329,
          "prev_para_id": "chap4_para169",
          "next_para_id": "chap4_para171",
          "style_metadata": {
            "para_id": "chap4_para170",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 84,
            "sentence_count": 3
          },
          "terminology": {
            "suppose": 1,
            "robot": 2,
            "switched": 1,
            "know": 1,
            "is—its": 1,
            "initial": 1,
            "belief": 1,
            "state": 1,
            "consists": 1,
            "set": 1,
            "location": 3,
            "receives": 1,
            "percept": 2,
            "update": 1,
            "using": 1,
            "equation": 1,
            "pdate": 1,
            "yielding": 1,
            "shown": 1,
            "figure": 1,
            "inspect": 1,
            "maze": 1,
            "see": 1,
            "yield": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para171",
          "content": "Next the robot executes a\nRight\naction, but the result is nondeterministic. The new belief state,\nb\na\n= P\nREDICT\n(\nb\no\n, Right\n), contains all the locations that are one step away from the locations in\nb\no\n. When the second percept, 1010, arrives, the robot does U\nPDATE\n(\nb\na\n, 1010) and finds that the belief state has collapsed down to the single location shown in\nFigure 4.18(b)\n. That’s the only location that could be the result of\nUPDATE (PREDICT (UPDATE (\nb\n, 1011),\nR\ni\ng\nh\nt\n), 1010)\n.",
          "sentence_count": 4,
          "char_count": 428,
          "prev_para_id": "chap4_para170",
          "next_para_id": "chap4_para172",
          "style_metadata": {
            "para_id": "chap4_para171",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 4
          },
          "terminology": {
            "next": 1,
            "robot": 2,
            "executes": 1,
            "right": 2,
            "action": 1,
            "result": 2,
            "nondeterministic": 1,
            "new": 1,
            "belief": 2,
            "state": 2,
            "redict": 1,
            "contains": 1,
            "location": 4,
            "step": 1,
            "second": 1,
            "percept": 1,
            "arrives": 1,
            "pdate": 1,
            "find": 1,
            "collapsed": 1,
            "single": 1,
            "shown": 1,
            "figure": 1,
            "update": 2,
            "predict": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para172",
          "content": "With nondeterministic actions the P\nREDICT\nstep grows the belief state, but the U\nPDATE\nstep shrinks it back down—as long as the percepts provide some useful identifying information. Sometimes the percepts don’t help much for localization: If there were one or more long east-west corridors, then a robot could receive a long sequence of 1010 percepts, but never know\nwhere in the corridor(s) it was. But for environments with reasonable variation in geography, localization often converges quickly to a single point, even when actions are nondeterministic.",
          "sentence_count": 3,
          "char_count": 476,
          "prev_para_id": "chap4_para171",
          "next_para_id": "chap4_para173",
          "style_metadata": {
            "para_id": "chap4_para172",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 101,
            "sentence_count": 3
          },
          "terminology": {
            "nondeterministic": 2,
            "action": 2,
            "redict": 1,
            "step": 2,
            "grows": 1,
            "belief": 1,
            "state": 1,
            "pdate": 1,
            "shrink": 1,
            "down—as": 1,
            "long": 3,
            "percept": 3,
            "provide": 1,
            "useful": 1,
            "identifying": 1,
            "information": 1,
            "help": 1,
            "much": 1,
            "localization": 2,
            "east-west": 1,
            "corridor": 2,
            "robot": 1,
            "receive": 1,
            "sequence": 1,
            "know": 1,
            "environment": 1,
            "reasonable": 1,
            "variation": 1,
            "geography": 1,
            "converges": 1,
            "single": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para173",
          "content": "What happens if the sensors are faulty? If we can reason only with Boolean logic, then we have to treat every sensor bit as being either correct or incorrect, which is the same as having no perceptual information at all. But we will see that probabilistic reasoning (\nChapter 12\n), allows us to extract useful information from a faulty sensor as long as it is wrong less than half the time.",
          "sentence_count": 3,
          "char_count": 321,
          "prev_para_id": "chap4_para172",
          "next_para_id": "chap4_para174",
          "style_metadata": {
            "para_id": "chap4_para173",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "happens": 1,
            "sensor": 3,
            "faulty": 2,
            "reason": 1,
            "boolean": 1,
            "logic": 1,
            "treat": 1,
            "bit": 1,
            "correct": 1,
            "incorrect": 1,
            "perceptual": 1,
            "information": 2,
            "see": 1,
            "probabilistic": 1,
            "reasoning": 1,
            "chapter": 1,
            "allows": 1,
            "extract": 1,
            "useful": 1,
            "half": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para174",
          "content": "4.5Online Search Agents and Unknown Environments\n4.5\nOnline Search Agents and Unknown Environments\nSo far we have concentrated on agents that use\noffline search\nalgorithms. They compute a complete solution before taking their first action. In contrast, an\nonline search\n8\nagent interleaves computation and action: first it takes an action, then it observes the environment and computes the next action. Online search is a good idea in dynamic or semi-dynamic environments, where there is a penalty for sitting around and computing too long. Online\nsearch is also helpful in nondeterministic domains because it allows the agent to focus its computational efforts on the contingencies that actually arise rather than those that\nmight\nhappen but probably won’t.",
          "sentence_count": 5,
          "char_count": 653,
          "prev_para_id": "chap4_para173",
          "next_para_id": "chap4_para175",
          "style_metadata": {
            "para_id": "chap4_para174",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 5
          },
          "terminology": {
            "search": 6,
            "agent": 5,
            "unknown": 2,
            "environment": 4,
            "online": 4,
            "concentrated": 1,
            "use": 1,
            "offline": 1,
            "compute": 1,
            "complete": 1,
            "solution": 1,
            "taking": 1,
            "first": 1,
            "action": 4,
            "contrast": 1,
            "interleaf": 1,
            "computation": 1,
            "take": 1,
            "observes": 1,
            "computes": 1,
            "good": 1,
            "idea": 1,
            "dynamic": 1,
            "semi-dynamic": 1,
            "penalty": 1,
            "sitting": 1,
            "computing": 1,
            "long": 1,
            "helpful": 1,
            "nondeterministic": 1,
            "domain": 1,
            "allows": 1,
            "focus": 1,
            "computational": 1,
            "effort": 1,
            "contingency": 1,
            "arise": 1,
            "happen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para174",
              "entity_text": "Search Agents and Unknown",
              "entity_type": "ORG",
              "start_char": 10,
              "end_char": 35,
              "context": "4.5Online Search Agents and Unknown Environments\n4.5\nOnline Search Agents and Unknown"
            },
            {
              "para_id": "chap4_para174",
              "entity_text": "n’t",
              "entity_type": "GPE",
              "start_char": 754,
              "end_char": 757,
              "context": "ather than those that\nmight\nhappen but probably won’t."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para175",
          "content": "Of course, there is a tradeoff: the more an agent plans ahead, the less often it will find itself up the creek without a paddle. In unknown environments, where the agent does not know what states exist or what its actions do, the agent must use its actions as experiments in order to learn about the environment.",
          "sentence_count": 2,
          "char_count": 256,
          "prev_para_id": "chap4_para174",
          "next_para_id": "chap4_para176",
          "style_metadata": {
            "para_id": "chap4_para175",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 2
          },
          "terminology": {
            "course": 1,
            "tradeoff": 1,
            "agent": 3,
            "plan": 1,
            "find": 1,
            "creek": 1,
            "paddle": 1,
            "unknown": 1,
            "environment": 2,
            "know": 1,
            "state": 1,
            "exist": 1,
            "action": 2,
            "use": 1,
            "experiment": 1,
            "order": 1,
            "learn": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para176",
          "content": "A canonical example of online search is the\nmapping problem\n: a robot is placed in an unknown building and must explore to build a map that can later be used for getting from\nA\nto\nB\n. Methods for escaping from labyrinths—required knowledge for aspiring heroes of antiquity—are also examples of online search algorithms. Spatial exploration is not the only form of online exploration, however. Consider a newborn baby: it has many possible actions but knows the outcomes of none of them, and it has experienced only a few of the possible states that it can reach.",
          "sentence_count": 4,
          "char_count": 471,
          "prev_para_id": "chap4_para175",
          "next_para_id": "chap4_para177",
          "style_metadata": {
            "para_id": "chap4_para176",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "canonical": 1,
            "example": 2,
            "online": 3,
            "search": 2,
            "mapping": 1,
            "problem": 1,
            "robot": 1,
            "placed": 1,
            "unknown": 1,
            "building": 1,
            "explore": 1,
            "build": 1,
            "map": 1,
            "used": 1,
            "getting": 1,
            "method": 1,
            "escaping": 1,
            "labyrinths—required": 1,
            "knowledge": 1,
            "aspiring": 1,
            "hero": 1,
            "antiquity—are": 1,
            "spatial": 1,
            "exploration": 2,
            "form": 1,
            "consider": 1,
            "newborn": 1,
            "baby": 1,
            "many": 1,
            "possible": 2,
            "action": 1,
            "know": 1,
            "outcome": 1,
            "experienced": 1,
            "state": 1,
            "reach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para176",
              "entity_text": "labyrinths",
              "entity_type": "GPE",
              "start_char": 210,
              "end_char": 220,
              "context": "r getting from\nA\nto\nB\n. Methods for escaping from labyrinths—required knowledge for aspiring heroes of antiqui"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para177",
          "content": "4.5.1\nOnline search problems\nAn online search problem is solved by interleaving computation, sensing, and acting. We’ll start by assuming a deterministic and fully observable environment (\nChapter 16\nrelaxes these assumptions) and stipulate that the agent knows only the following:\n•\nA\nCTIONS\n(\ns\n), the legal actions in state\ns\n;\n•\nc(s, a, s'\n), the cost of applying action\na\nin state s to arrive at state\ns'\n. Note that this cannot be used until the agent knows that\ns'\nis the outcome.",
          "sentence_count": 3,
          "char_count": 420,
          "prev_para_id": "chap4_para176",
          "next_para_id": "chap4_para178",
          "style_metadata": {
            "para_id": "chap4_para177",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.67,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 107,
            "sentence_count": 3
          },
          "terminology": {
            "online": 2,
            "search": 2,
            "problem": 2,
            "solved": 1,
            "interleaving": 1,
            "computation": 1,
            "sensing": 1,
            "acting": 1,
            "start": 1,
            "assuming": 1,
            "deterministic": 1,
            "observable": 1,
            "environment": 1,
            "chapter": 1,
            "relaxes": 1,
            "assumption": 1,
            "stipulate": 1,
            "agent": 2,
            "know": 2,
            "following": 1,
            "ctions": 1,
            "legal": 1,
            "action": 2,
            "state": 3,
            "cost": 1,
            "applying": 1,
            "arrive": 1,
            "note": 1,
            "used": 1,
            "outcome": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para178",
          "content": "•\nI\nS\n-G\nOAL\n(\ns\n), the goal test.",
          "sentence_count": 1,
          "char_count": 31,
          "prev_para_id": "chap4_para177",
          "next_para_id": "chap4_para179",
          "style_metadata": {
            "para_id": "chap4_para178",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "oal": 1,
            "goal": 1,
            "test": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para178",
              "entity_text": "OAL",
              "entity_type": "ORG",
              "start_char": 9,
              "end_char": 12,
              "context": "•\nI\nS\n-G\nOAL\n(\ns\n), the goal test."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para179",
          "content": "Note in particular that the agent\ncannot\ndetermine R\nESULT\n(\ns, a\n) except by actually being in\ns\nand doing\na.",
          "sentence_count": 1,
          "char_count": 97,
          "prev_para_id": "chap4_para178",
          "next_para_id": "chap4_para180",
          "style_metadata": {
            "para_id": "chap4_para179",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "note": 1,
            "particular": 1,
            "agent": 1,
            "determine": 1,
            "esult": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para180",
          "content": "For example, in the maze problem shown in\nFigure 4.19\n, the agent does not know that going\nUp\nfrom (1,1) leads to (1,2); nor, having done that, does it know that going\nDown\nwill take it back to (1,1). This degree of ignorance can be reduced in some applications—for example, a robot explorer might know how its movement actions work and be ignorant only of the locations of obstacles.",
          "sentence_count": 2,
          "char_count": 321,
          "prev_para_id": "chap4_para179",
          "next_para_id": "chap4_para181",
          "style_metadata": {
            "para_id": "chap4_para180",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 41.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 83,
            "sentence_count": 2
          },
          "terminology": {
            "example": 2,
            "maze": 1,
            "problem": 1,
            "shown": 1,
            "figure": 1,
            "agent": 1,
            "know": 3,
            "going": 2,
            "lead": 1,
            "done": 1,
            "take": 1,
            "degree": 1,
            "ignorance": 1,
            "reduced": 1,
            "applications—for": 1,
            "robot": 1,
            "explorer": 1,
            "movement": 1,
            "action": 1,
            "work": 1,
            "ignorant": 1,
            "location": 1,
            "obstacle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para181",
          "content": "Description\nThe first and the last nodes are labeled S and G, respectively. All the other nodes are unlabeled. For every two adjacent nodes, a third node is aligned below the mid of the two. To and from arrows connect the adjacent nodes. An arrow from node G points to the last node on the bottom row. An arrow from this node points to the node just above this, and then the flow progresses until the first node.",
          "sentence_count": 6,
          "char_count": 336,
          "prev_para_id": "chap4_para180",
          "next_para_id": "chap4_para182",
          "style_metadata": {
            "para_id": "chap4_para181",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.5,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 87,
            "sentence_count": 6
          },
          "terminology": {
            "description": 1,
            "last": 2,
            "node": 8,
            "labeled": 1,
            "unlabeled": 1,
            "adjacent": 2,
            "third": 1,
            "aligned": 1,
            "arrow": 3,
            "connect": 1,
            "point": 2,
            "bottom": 1,
            "row": 1,
            "flow": 1,
            "progress": 1,
            "first": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para181",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 252,
              "end_char": 256,
              "context": " arrows connect the adjacent nodes. An arrow from node G points to the last node on the bottom row. An a"
            },
            {
              "para_id": "chap4_para181",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 321,
              "end_char": 325,
              "context": "e last node on the bottom row. An arrow from this node points to the node just above this, and then the "
            },
            {
              "para_id": "chap4_para181",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 340,
              "end_char": 344,
              "context": "bottom row. An arrow from this node points to the node just above this, and then the flow progresses unt"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para182",
          "content": "×\nFigure 4.19\nA simple maze problem. The agent starts at\nS\nand must reach\nG\nbut knows nothing of the environment.",
          "sentence_count": 2,
          "char_count": 98,
          "prev_para_id": "chap4_para181",
          "next_para_id": "chap4_para183",
          "style_metadata": {
            "para_id": "chap4_para182",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "simple": 1,
            "maze": 1,
            "problem": 1,
            "agent": 1,
            "start": 1,
            "reach": 1,
            "know": 1,
            "nothing": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para183",
          "content": "Finally, the agent might have access to an admissible heuristic function\nh\n(\ns\n) that estimates the distance from the current state to a goal state. For example, in\nFigure 4.19\n, the agent might know the location of the goal and be able to use the Manhattan-distance heuristic (\npage 116\n).",
          "sentence_count": 2,
          "char_count": 245,
          "prev_para_id": "chap4_para182",
          "next_para_id": "chap4_para184",
          "style_metadata": {
            "para_id": "chap4_para183",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "agent": 2,
            "access": 1,
            "admissible": 1,
            "heuristic": 2,
            "function": 1,
            "estimate": 1,
            "distance": 1,
            "current": 1,
            "state": 2,
            "goal": 2,
            "example": 1,
            "figure": 1,
            "know": 1,
            "location": 1,
            "able": 1,
            "use": 1,
            "manhattan-distance": 1,
            "page": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para183",
              "entity_text": "Manhattan",
              "entity_type": "GPE",
              "start_char": 248,
              "end_char": 257,
              "context": "w the location of the goal and be able to use the Manhattan-distance heuristic (\npage 116\n)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para184",
          "content": "Typically, the agent’s objective is to reach a goal state while minimizing cost. (Another possible objective is simply to explore the entire environment.) The cost is the total path cost that the agent incurs as it travels. It is common to compare this cost with the path cost the agent would incur\nif it knew the search space in advance\n—that is, the optimal path in the known environment. In the language of online algorithms, this comparison is called the\ncompetitive ratio\n; we would like it to be as small as possible.",
          "sentence_count": 5,
          "char_count": 435,
          "prev_para_id": "chap4_para183",
          "next_para_id": "chap4_para185",
          "style_metadata": {
            "para_id": "chap4_para184",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 105,
            "sentence_count": 5
          },
          "terminology": {
            "agent": 3,
            "objective": 2,
            "reach": 1,
            "goal": 1,
            "state": 1,
            "minimizing": 1,
            "cost": 5,
            "possible": 2,
            "entire": 1,
            "environment": 2,
            "total": 1,
            "path": 3,
            "incurs": 1,
            "travel": 1,
            "common": 1,
            "compare": 1,
            "incur": 1,
            "knew": 1,
            "search": 1,
            "space": 1,
            "advance": 1,
            "optimal": 1,
            "known": 1,
            "language": 1,
            "online": 1,
            "algorithm": 1,
            "comparison": 1,
            "called": 1,
            "competitive": 1,
            "ratio": 1,
            "like": 1,
            "small": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para185",
          "content": "Online explorers are vulnerable to\ndead ends\n: states from which no goal state is reachable. If the agent doesn’t know what each action does, it might execute the “jump into bottomless pit” action, and thus never reach the goal. In general,\nno algorithm can avoid dead ends in all state spaces.",
          "sentence_count": 3,
          "char_count": 246,
          "prev_para_id": "chap4_para184",
          "next_para_id": "chap4_para186",
          "style_metadata": {
            "para_id": "chap4_para185",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 3
          },
          "terminology": {
            "online": 1,
            "explorer": 1,
            "vulnerable": 1,
            "dead": 2,
            "end": 2,
            "state": 3,
            "goal": 2,
            "reachable": 1,
            "agent": 1,
            "know": 1,
            "action": 2,
            "execute": 1,
            "jump": 1,
            "bottomless": 1,
            "pit": 1,
            "reach": 1,
            "general": 1,
            "algorithm": 1,
            "avoid": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para186",
          "content": "Consider the two dead-end state spaces in\nFigure 4.20(a)\n. An online search algorithm that has visited states\nS\nand\nA\ncannot tell if it is in the top state space or the bottom one; the two look identical based on what the agent has seen. Therefore, there\nis no way it could know how to choose the correct action in both state spaces. This is an example of an\nadversary argument\n—we can imagine an adversary constructing the state space while the agent explores it and putting the goals and dead ends wherever it chooses, as in\nFigure 4.20(b)\n.",
          "sentence_count": 4,
          "char_count": 454,
          "prev_para_id": "chap4_para185",
          "next_para_id": "chap4_para187",
          "style_metadata": {
            "para_id": "chap4_para186",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 28.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 113,
            "sentence_count": 4
          },
          "terminology": {
            "consider": 1,
            "dead-end": 1,
            "state": 5,
            "space": 4,
            "figure": 2,
            "online": 1,
            "search": 1,
            "algorithm": 1,
            "visited": 1,
            "tell": 1,
            "top": 1,
            "bottom": 1,
            "look": 1,
            "identical": 1,
            "based": 1,
            "agent": 2,
            "seen": 1,
            "way": 1,
            "know": 1,
            "choose": 1,
            "correct": 1,
            "action": 1,
            "example": 1,
            "adversary": 2,
            "argument": 1,
            "—we": 1,
            "imagine": 1,
            "constructing": 1,
            "explores": 1,
            "putting": 1,
            "goal": 1,
            "dead": 1,
            "end": 1,
            "wherever": 1,
            "chooses": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para187",
          "content": "Description\nPart (“a”): Six nodes labeled 8, 9, 2, 2, 4, and 3 are connected using double-headed arrows labeled 1. Node 2 is shaded in red.",
          "sentence_count": 2,
          "char_count": 115,
          "prev_para_id": "chap4_para186",
          "next_para_id": "chap4_para188",
          "style_metadata": {
            "para_id": "chap4_para187",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.027,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "node": 1,
            "labeled": 2,
            "connected": 1,
            "using": 1,
            "double-headed": 1,
            "arrow": 1,
            "shaded": 1,
            "red": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para187",
              "entity_text": "Node 2",
              "entity_type": "PERSON",
              "start_char": 115,
              "end_char": 121,
              "context": "e connected using double-headed arrows labeled 1. Node 2 is shaded in red."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para188",
          "content": "Part (b): Six nodes labeled 8, 9, 3, 2, 4, and 3 are connected using double-headed arrows labeled 1. Note: Digit 3 in the third node is encircled. Node 2 is shaded in red.",
          "sentence_count": 3,
          "char_count": 138,
          "prev_para_id": "chap4_para187",
          "next_para_id": "chap4_para189",
          "style_metadata": {
            "para_id": "chap4_para188",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.044,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "node": 2,
            "labeled": 2,
            "connected": 1,
            "using": 1,
            "double-headed": 1,
            "arrow": 1,
            "note": 1,
            "digit": 1,
            "third": 1,
            "encircled": 1,
            "shaded": 1,
            "red": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para188",
              "entity_text": "Node 2",
              "entity_type": "PERSON",
              "start_char": 147,
              "end_char": 153,
              "context": " 1. Note: Digit 3 in the third node is encircled. Node 2 is shaded in red."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para189",
          "content": "Part (c): Six nodes labeled 8, 9, 3, 4, 4, and 3 are connected using double-headed arrows labeled 1. Note: The digit 4 in the fourth node is encircled. Node 3 is shaded in red.",
          "sentence_count": 3,
          "char_count": 142,
          "prev_para_id": "chap4_para188",
          "next_para_id": "chap4_para190",
          "style_metadata": {
            "para_id": "chap4_para189",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.33,
            "passive_voice_ratio": 0.043,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "node": 2,
            "labeled": 2,
            "connected": 1,
            "using": 1,
            "double-headed": 1,
            "arrow": 1,
            "note": 1,
            "digit": 1,
            "fourth": 1,
            "encircled": 1,
            "shaded": 1,
            "red": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para190",
          "content": "Part (d): Six nodes labeled 8, 9, 5, 4, 4, and 3 are connected using double-headed arrows labeled 1. Note: The digit 5 in the third node is encircled. Node 4 is shaded in red.",
          "sentence_count": 3,
          "char_count": 141,
          "prev_para_id": "chap4_para189",
          "next_para_id": "chap4_para191",
          "style_metadata": {
            "para_id": "chap4_para190",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.33,
            "passive_voice_ratio": 0.043,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "node": 2,
            "labeled": 2,
            "connected": 1,
            "using": 1,
            "double-headed": 1,
            "arrow": 1,
            "note": 1,
            "digit": 1,
            "third": 1,
            "encircled": 1,
            "shaded": 1,
            "red": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para190",
              "entity_text": "Node 4",
              "entity_type": "PERSON",
              "start_char": 151,
              "end_char": 157,
              "context": "Note: The digit 5 in the third node is encircled. Node 4 is shaded in red."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para191",
          "content": "Part (e): Six nodes labeled 8, 9, 5, 5, 4, and 3 are connected using double-headed arrows labeled 1. Note: The digit 5 in the fourth node is encircled. Node 4 is shaded in red.",
          "sentence_count": 3,
          "char_count": 142,
          "prev_para_id": "chap4_para190",
          "next_para_id": "chap4_para192",
          "style_metadata": {
            "para_id": "chap4_para191",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.33,
            "passive_voice_ratio": 0.043,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 3
          },
          "terminology": {
            "part": 1,
            "node": 2,
            "labeled": 2,
            "connected": 1,
            "using": 1,
            "double-headed": 1,
            "arrow": 1,
            "note": 1,
            "digit": 1,
            "fourth": 1,
            "encircled": 1,
            "shaded": 1,
            "red": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para191",
              "entity_text": "Node 4",
              "entity_type": "PERSON",
              "start_char": 152,
              "end_char": 158,
              "context": "ote: The digit 5 in the fourth node is encircled. Node 4 is shaded in red."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para192",
          "content": "×\nFigure 4.20\n(a) Two state spaces that might lead an online search agent into a dead end. Any given agent will fail in at least one of these spaces. (b) A two-dimensional environment that can cause an online search agent to follow an arbitrarily inefficient route to the goal. Whichever choice the agent makes, the adversary blocks that route with another long, thin wall, so that the path followed is much longer than the best possible path.",
          "sentence_count": 4,
          "char_count": 368,
          "prev_para_id": "chap4_para191",
          "next_para_id": "chap4_para193",
          "style_metadata": {
            "para_id": "chap4_para192",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 89,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "state": 1,
            "space": 2,
            "lead": 1,
            "online": 2,
            "search": 2,
            "agent": 4,
            "dead": 1,
            "end": 1,
            "given": 1,
            "fail": 1,
            "least": 1,
            "two-dimensional": 1,
            "environment": 1,
            "cause": 1,
            "follow": 1,
            "inefficient": 1,
            "route": 2,
            "goal": 1,
            "choice": 1,
            "make": 1,
            "adversary": 1,
            "block": 1,
            "long": 1,
            "thin": 1,
            "wall": 1,
            "path": 2,
            "followed": 1,
            "longer": 1,
            "best": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para193",
          "content": "Dead ends are a real difficulty for robot exploration—staircases, ramps, cliffs, one-way streets, and even natural terrain all present states from which some actions are\nirreversible\n—there is no way to return to the previous state. The exploration algorithm we will present is only guaranteed to work in state spaces that are\nsafely explorable\n—that is, some goal state is reachable from every reachable state. State spaces with only reversible actions, such as\nmazes and 8-puzzles, are clearly safely explorable (if they have any solution at all). We will cover the subject of safe exploration in more depth in\nSection 23.3.2\n.",
          "sentence_count": 4,
          "char_count": 535,
          "prev_para_id": "chap4_para192",
          "next_para_id": "chap4_para194",
          "style_metadata": {
            "para_id": "chap4_para193",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 4
          },
          "terminology": {
            "dead": 1,
            "end": 1,
            "real": 1,
            "difficulty": 1,
            "robot": 1,
            "exploration—staircases": 1,
            "ramp": 1,
            "cliff": 1,
            "one-way": 1,
            "street": 1,
            "natural": 1,
            "terrain": 1,
            "present": 2,
            "state": 6,
            "action": 2,
            "irreversible": 1,
            "—there": 1,
            "way": 1,
            "return": 1,
            "previous": 1,
            "exploration": 2,
            "algorithm": 1,
            "guaranteed": 1,
            "work": 1,
            "space": 2,
            "explorable": 2,
            "goal": 1,
            "reachable": 2,
            "reversible": 1,
            "maze": 1,
            "8-puzzles": 1,
            "solution": 1,
            "cover": 1,
            "subject": 1,
            "safe": 1,
            "depth": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para194",
          "content": "Even in safely explorable environments, no bounded competitive ratio can be guaranteed if there are paths of unbounded cost. This is easy to show in environments with irreversible actions, but in fact it remains true for the reversible case as well, as\nFigure 4.20(b)\nshows. For this reason, it is common to characterize the performance of online search algorithms in terms of the size of the entire state space rather than just the depth of the shallowest goal.",
          "sentence_count": 3,
          "char_count": 387,
          "prev_para_id": "chap4_para193",
          "next_para_id": "chap4_para195",
          "style_metadata": {
            "para_id": "chap4_para194",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 3
          },
          "terminology": {
            "explorable": 1,
            "environment": 2,
            "bounded": 1,
            "competitive": 1,
            "ratio": 1,
            "guaranteed": 1,
            "path": 1,
            "unbounded": 1,
            "cost": 1,
            "easy": 1,
            "show": 2,
            "irreversible": 1,
            "action": 1,
            "fact": 1,
            "remains": 1,
            "true": 1,
            "reversible": 1,
            "case": 1,
            "reason": 1,
            "common": 1,
            "characterize": 1,
            "performance": 1,
            "online": 1,
            "search": 1,
            "algorithm": 1,
            "term": 1,
            "size": 1,
            "entire": 1,
            "state": 1,
            "space": 1,
            "depth": 1,
            "shallowest": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para195",
          "content": "4.5.2\nOnline search agents\nAfter each action, an online agent in an observable environment receives a percept telling it what state it has reached; from this information, it can augment its map of the environment. The updated map is then used to plan where to go next. This interleaving of planning and action means that online search algorithms are quite different from the offline search algorithms we have seen previously: offline algorithms explore their\nmodel\nof the state space, while online algorithms explore the real world. For example, A* can expand a node in one part of the space and then immediately expand a node in a distant part of the space, because node expansion involves simulated rather than real actions.",
          "sentence_count": 4,
          "char_count": 610,
          "prev_para_id": "chap4_para194",
          "next_para_id": "chap4_para196",
          "style_metadata": {
            "para_id": "chap4_para195",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 133,
            "sentence_count": 4
          },
          "terminology": {
            "online": 4,
            "search": 3,
            "agent": 2,
            "action": 3,
            "observable": 1,
            "environment": 2,
            "receives": 1,
            "percept": 1,
            "telling": 1,
            "state": 2,
            "reached": 1,
            "information": 1,
            "augment": 1,
            "map": 2,
            "updated": 1,
            "used": 1,
            "plan": 1,
            "next": 1,
            "interleaving": 1,
            "planning": 1,
            "mean": 1,
            "algorithm": 3,
            "different": 1,
            "offline": 2,
            "seen": 1,
            "explore": 1,
            "model": 1,
            "space": 3,
            "real": 2,
            "world": 1,
            "example": 1,
            "expand": 2,
            "part": 2,
            "node": 2,
            "distant": 1,
            "expansion": 1,
            "involves": 1,
            "simulated": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para196",
          "content": "An online algorithm, on the other hand, can discover successors only for a state that it physically occupies. To avoid traveling all the way to a distant state to expand the next node, it seems better to expand nodes in a\nlocal\norder. Depth-first search has exactly this property because (except when the algorithm is backtracking) the next node expanded is a child of the previous node expanded.",
          "sentence_count": 3,
          "char_count": 331,
          "prev_para_id": "chap4_para195",
          "next_para_id": "chap4_para197",
          "style_metadata": {
            "para_id": "chap4_para196",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "online": 1,
            "algorithm": 2,
            "hand": 1,
            "discover": 1,
            "successor": 1,
            "state": 2,
            "occupies": 1,
            "traveling": 1,
            "way": 1,
            "distant": 1,
            "expand": 2,
            "next": 2,
            "node": 4,
            "seems": 1,
            "local": 1,
            "order": 1,
            "depth-first": 1,
            "search": 1,
            "property": 1,
            "backtracking": 1,
            "expanded": 2,
            "previous": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para196",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 341,
              "end_char": 345,
              "context": "cept when the algorithm is backtracking) the next node expanded is a child of the previous node expanded"
            },
            {
              "para_id": "chap4_para196",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 382,
              "end_char": 386,
              "context": "the next node expanded is a child of the previous node expanded."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para197",
          "content": "An online depth-first exploration agent (for deterministic but unknown actions) is shown in\nFigure 4.21\n. This agent stores its map in a table,\nresult\n[\ns, a\n], that records the state resulting from executing action\na\nin state\ns\n. (For nondeterministic actions, the agent could record a set\nof states under\nresults\n[\ns, a\n].) Whenever the current state has unexplored actions, the agent tries one of those actions. The difficulty comes when the agent has tried all the actions in a state. In offline depth-first search, the state is simply dropped from the queue; in an online search, the agent has to backtrack in the physical world. In depth-first search, this means going back to the state from which the agent most recently entered the current state. To achieve that, the algorithm keeps another table that lists, for each state, the predecessor states to which the agent has not yet backtracked. If the agent has run out of states to which it can backtrack, then its search is complete.",
          "sentence_count": 9,
          "char_count": 833,
          "prev_para_id": "chap4_para196",
          "next_para_id": "chap4_para198",
          "style_metadata": {
            "para_id": "chap4_para197",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.11,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 199,
            "sentence_count": 9
          },
          "terminology": {
            "online": 2,
            "depth-first": 3,
            "exploration": 1,
            "agent": 9,
            "deterministic": 1,
            "unknown": 1,
            "action": 6,
            "shown": 1,
            "figure": 1,
            "store": 1,
            "map": 1,
            "table": 2,
            "result": 2,
            "record": 2,
            "state": 11,
            "resulting": 1,
            "executing": 1,
            "nondeterministic": 1,
            "set": 1,
            "current": 2,
            "unexplored": 1,
            "try": 1,
            "difficulty": 1,
            "come": 1,
            "tried": 1,
            "offline": 1,
            "search": 4,
            "dropped": 1,
            "queue": 1,
            "physical": 1,
            "world": 1,
            "mean": 1,
            "going": 1,
            "entered": 1,
            "achieve": 1,
            "algorithm": 1,
            "keep": 1,
            "list": 1,
            "predecessor": 1,
            "backtracked": 1,
            "run": 1,
            "backtrack": 1,
            "complete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para198",
          "content": "×\nFigure 4.21\nAn online search agent that uses depth-first exploration. The agent can safely explore only in state spaces in which every action can be “undone” by some other action.",
          "sentence_count": 2,
          "char_count": 153,
          "prev_para_id": "chap4_para197",
          "next_para_id": "chap4_para199",
          "style_metadata": {
            "para_id": "chap4_para198",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "online": 1,
            "search": 1,
            "agent": 2,
            "us": 1,
            "depth-first": 1,
            "exploration": 1,
            "state": 1,
            "space": 1,
            "action": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para199",
          "content": "We recommend that the reader trace through the progress of O\nNLINE\n-DFS-A\nGENT\nwhen applied to the maze given in\nFigure 4.19\n. It is fairly easy to see that the agent will, in the worst case, end up traversing every link in the state space exactly twice. For exploration, this is optimal; for finding a goal, on the other hand, the agent’s competitive ratio could be arbitrarily bad if it goes off on a long excursion when there is a goal right next to the initial state. An online variant of iterative deepening solves this problem; for an environment that is a uniform tree, the competitive ratio of such an agent is a small constant.",
          "sentence_count": 4,
          "char_count": 526,
          "prev_para_id": "chap4_para198",
          "next_para_id": "chap4_para200",
          "style_metadata": {
            "para_id": "chap4_para199",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 130,
            "sentence_count": 4
          },
          "terminology": {
            "recommend": 1,
            "reader": 1,
            "trace": 1,
            "progress": 1,
            "nline": 1,
            "-dfs-a": 1,
            "gent": 1,
            "applied": 1,
            "maze": 1,
            "given": 1,
            "figure": 1,
            "easy": 1,
            "see": 1,
            "agent": 3,
            "worst": 1,
            "case": 1,
            "end": 1,
            "traversing": 1,
            "link": 1,
            "state": 2,
            "space": 1,
            "exploration": 1,
            "optimal": 1,
            "finding": 1,
            "goal": 2,
            "hand": 1,
            "competitive": 2,
            "ratio": 2,
            "bad": 1,
            "go": 1,
            "long": 1,
            "excursion": 1,
            "next": 1,
            "initial": 1,
            "online": 1,
            "variant": 1,
            "iterative": 1,
            "deepening": 1,
            "solves": 1,
            "problem": 1,
            "environment": 1,
            "uniform": 1,
            "tree": 1,
            "small": 1,
            "constant": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para200",
          "content": "Because of its method of backtracking, O\nNLINE\n-DFS-A\nGENT\nworks only in state spaces where the actions are reversible. There are slightly more complex algorithms that work in general state spaces, but no such algorithm has a bounded competitive ratio.",
          "sentence_count": 2,
          "char_count": 216,
          "prev_para_id": "chap4_para199",
          "next_para_id": "chap4_para201",
          "style_metadata": {
            "para_id": "chap4_para200",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "method": 1,
            "backtracking": 1,
            "nline": 1,
            "-dfs-a": 1,
            "gent": 1,
            "work": 2,
            "state": 2,
            "space": 2,
            "action": 1,
            "reversible": 1,
            "complex": 1,
            "algorithm": 2,
            "general": 1,
            "bounded": 1,
            "competitive": 1,
            "ratio": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para201",
          "content": "4.5.3\nOnline local search\nLike depth-first search,\nhill-climbing search\nhas the property of locality in its node expansions. In fact, because it keeps just one current state in memory, hill-climbing search is\nalready\nan online search algorithm! Unfortunately, the basic algorithm is not very good for exploration because it leaves the agent sitting at local maxima with nowhere to go. Moreover, random restarts cannot be used, because the agent cannot teleport itself to a new start state.",
          "sentence_count": 4,
          "char_count": 419,
          "prev_para_id": "chap4_para200",
          "next_para_id": "chap4_para202",
          "style_metadata": {
            "para_id": "chap4_para201",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 22.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "moreover"
            ],
            "word_count": 89,
            "sentence_count": 4
          },
          "terminology": {
            "online": 2,
            "local": 2,
            "search": 5,
            "depth-first": 1,
            "hill-climbing": 2,
            "property": 1,
            "locality": 1,
            "node": 1,
            "expansion": 1,
            "fact": 1,
            "keep": 1,
            "current": 1,
            "state": 2,
            "memory": 1,
            "algorithm": 1,
            "basic": 1,
            "good": 1,
            "exploration": 1,
            "leaf": 1,
            "agent": 2,
            "sitting": 1,
            "maximum": 1,
            "random": 1,
            "restarts": 1,
            "used": 1,
            "new": 1,
            "start": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para201",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 108,
              "end_char": 112,
              "context": "imbing search\nhas the property of locality in its node expansions. In fact, because it keeps just one cu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para202",
          "content": "Instead of random restarts, one might consider using a\nrandom walk\nto explore the environment. A random walk simply selects at random one of the available actions from the current state; preference can be given to actions that have not yet been tried. It is easy to prove that a random walk will\neventually\nfind a goal or complete its exploration, provided that the space is finite and safely explorable.",
          "sentence_count": 3,
          "char_count": 339,
          "prev_para_id": "chap4_para201",
          "next_para_id": "chap4_para203",
          "style_metadata": {
            "para_id": "chap4_para202",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "random": 5,
            "restarts": 1,
            "consider": 1,
            "using": 1,
            "walk": 3,
            "environment": 1,
            "selects": 1,
            "available": 1,
            "action": 2,
            "current": 1,
            "state": 1,
            "preference": 1,
            "given": 1,
            "tried": 1,
            "easy": 1,
            "prove": 1,
            "find": 1,
            "goal": 1,
            "complete": 1,
            "exploration": 1,
            "provided": 1,
            "space": 1,
            "finite": 1,
            "explorable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para203",
          "content": "9\nOn the other hand, the process can be very slow.",
          "sentence_count": 1,
          "char_count": 41,
          "prev_para_id": "chap4_para202",
          "next_para_id": "chap4_para204",
          "style_metadata": {
            "para_id": "chap4_para203",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "hand": 1,
            "process": 1,
            "slow": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para204",
          "content": "Figure 4.22\nshows an environment in which a random walk will take exponentially many steps to find the goal, because, for each state in the top row except S, backward progress is twice as likely as forward progress. The example is contrived, of course, but there are many real-world state spaces whose topology causes these kinds of “traps” for random walks.",
          "sentence_count": 2,
          "char_count": 299,
          "prev_para_id": "chap4_para203",
          "next_para_id": "chap4_para205",
          "style_metadata": {
            "para_id": "chap4_para204",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "environment": 1,
            "random": 2,
            "walk": 2,
            "take": 1,
            "many": 2,
            "step": 1,
            "find": 1,
            "goal": 1,
            "state": 2,
            "top": 1,
            "row": 1,
            "backward": 1,
            "progress": 2,
            "likely": 1,
            "forward": 1,
            "example": 1,
            "contrived": 1,
            "course": 1,
            "real-world": 1,
            "space": 1,
            "topology": 1,
            "cause": 1,
            "kind": 1,
            "trap": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para204",
              "entity_text": "S",
              "entity_type": "PERSON",
              "start_char": 155,
              "end_char": 156,
              "context": "al, because, for each state in the top row except S, backward progress is twice as likely as forward "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para205",
          "content": "×\nFigure 4.22\nAn environment in which a random walk will take exponentially many steps to find the goal.",
          "sentence_count": 1,
          "char_count": 88,
          "prev_para_id": "chap4_para204",
          "next_para_id": "chap4_para206",
          "style_metadata": {
            "para_id": "chap4_para205",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "environment": 1,
            "random": 1,
            "walk": 1,
            "take": 1,
            "many": 1,
            "step": 1,
            "find": 1,
            "goal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para206",
          "content": "Augmenting hill climbing with\nmemory\nrather than randomness turns out to be a more effective approach. The basic idea is to store a “current best estimate”\nH\n(\ns\n) of the cost to reach the goal from each state that has been visited.",
          "sentence_count": 2,
          "char_count": 195,
          "prev_para_id": "chap4_para205",
          "next_para_id": "chap4_para207",
          "style_metadata": {
            "para_id": "chap4_para206",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "augmenting": 1,
            "hill": 1,
            "climbing": 1,
            "memory": 1,
            "randomness": 1,
            "turn": 1,
            "effective": 1,
            "approach": 1,
            "basic": 1,
            "idea": 1,
            "store": 1,
            "current": 1,
            "best": 1,
            "estimate": 1,
            "cost": 1,
            "reach": 1,
            "goal": 1,
            "state": 1,
            "visited": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para207",
          "content": "H\n(\ns\n) starts out being just the heuristic estimate\nh\n(\ns\n) and is updated as the agent gains experience in the state space.",
          "sentence_count": 1,
          "char_count": 106,
          "prev_para_id": "chap4_para206",
          "next_para_id": "chap4_para208",
          "style_metadata": {
            "para_id": "chap4_para207",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "start": 1,
            "heuristic": 1,
            "estimate": 1,
            "updated": 1,
            "agent": 1,
            "gain": 1,
            "experience": 1,
            "state": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para208",
          "content": "Figure 4.23\nshows a simple example in a one-dimensional state space. In (a), the agent seems to be stuck in a flat local minimum at the red state. Rather than staying where it is, the agent should follow what seems to be the best path to the goal given the current cost estimates for its neighbors. The estimated cost to reach the goal through a neighbor\ns'\nis the cost to get to\ns'\nplus the estimated cost to get to a goal from there—that is,\nc\n(\ns, a, s'\n) +\nH\n(\ns'\n). In the example, there are two actions, with estimated costs 1 + 9 to the left and 1 + 2 to the right, so it seems best to move right.",
          "sentence_count": 5,
          "char_count": 491,
          "prev_para_id": "chap4_para207",
          "next_para_id": "chap4_para209",
          "style_metadata": {
            "para_id": "chap4_para208",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 146,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "simple": 1,
            "example": 2,
            "one-dimensional": 1,
            "state": 2,
            "space": 1,
            "agent": 2,
            "seems": 3,
            "stuck": 1,
            "flat": 1,
            "local": 1,
            "minimum": 1,
            "red": 1,
            "staying": 1,
            "follow": 1,
            "best": 2,
            "path": 1,
            "goal": 3,
            "given": 1,
            "current": 1,
            "cost": 5,
            "estimate": 1,
            "neighbor": 2,
            "estimated": 3,
            "reach": 1,
            "get": 2,
            "action": 1,
            "left": 1,
            "right": 2,
            "move": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para209",
          "content": "×\nFigure 4.23\nFive iterations of LRTA* on a one-dimensional state space. Each state is labeled with\nH\n(\ns\n), the current cost estimate to reach a goal, and every link has an action cost of 1. The red state marks the location of the agent, and the updated cost estimates at each iteration have a double circle.",
          "sentence_count": 3,
          "char_count": 257,
          "prev_para_id": "chap4_para208",
          "next_para_id": "chap4_para210",
          "style_metadata": {
            "para_id": "chap4_para209",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.67,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "iteration": 2,
            "one-dimensional": 1,
            "state": 3,
            "space": 1,
            "labeled": 1,
            "current": 1,
            "cost": 3,
            "estimate": 2,
            "reach": 1,
            "goal": 1,
            "link": 1,
            "action": 1,
            "red": 1,
            "mark": 1,
            "location": 1,
            "agent": 1,
            "updated": 1,
            "double": 1,
            "circle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para210",
          "content": "In (b) it is clear that the cost estimate of 2 for the red state in (a) was overly optimistic. Since the best move cost 1 and led to a state that is at least 2 steps from a goal, the red state must be at least 3 steps from a goal, so its\nH\nshould be updated accordingly, as shown in\nFigure 4.23(b)\n. Continuing this process, the agent will move back and forth twice more, updating\nH\neach time and “flattening out” the local minimum until it escapes to the right.",
          "sentence_count": 3,
          "char_count": 376,
          "prev_para_id": "chap4_para209",
          "next_para_id": "chap4_para211",
          "style_metadata": {
            "para_id": "chap4_para210",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 109,
            "sentence_count": 3
          },
          "terminology": {
            "clear": 1,
            "cost": 2,
            "estimate": 1,
            "red": 2,
            "state": 3,
            "optimistic": 1,
            "best": 1,
            "move": 2,
            "led": 1,
            "least": 2,
            "step": 2,
            "goal": 2,
            "updated": 1,
            "shown": 1,
            "figure": 1,
            "continuing": 1,
            "process": 1,
            "agent": 1,
            "forth": 1,
            "updating": 1,
            "time": 1,
            "flattening": 1,
            "local": 1,
            "minimum": 1,
            "escape": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para211",
          "content": "An agent implementing this scheme, which is called learning real-time A* (\nLRTA\n*), is shown in\nFigure 4.24\n. Like O\nNLINE\n-DFS-A\nGENT\n, it builds a map of the environment in the\nresult\ntable. It updates the cost estimate for the state it has just left and then chooses the “apparently best” move according to its current cost estimates. One important detail is that actions that have not yet been tried in a state\ns\nare always assumed to lead immediately to the goal with the least possible cost, namely\nh\n(\ns\n). This\noptimism under uncertainty\nencourages the agent to explore new, possibly promising paths.",
          "sentence_count": 5,
          "char_count": 517,
          "prev_para_id": "chap4_para210",
          "next_para_id": "chap4_para212",
          "style_metadata": {
            "para_id": "chap4_para211",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.4,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 122,
            "sentence_count": 5
          },
          "terminology": {
            "agent": 2,
            "implementing": 1,
            "scheme": 1,
            "called": 1,
            "learning": 1,
            "real-time": 1,
            "lrta": 1,
            "shown": 1,
            "figure": 1,
            "nline": 1,
            "-dfs-a": 1,
            "gent": 1,
            "build": 1,
            "map": 1,
            "environment": 1,
            "result": 1,
            "table": 1,
            "update": 1,
            "cost": 3,
            "estimate": 2,
            "state": 2,
            "left": 1,
            "chooses": 1,
            "best": 1,
            "move": 1,
            "according": 1,
            "current": 1,
            "important": 1,
            "detail": 1,
            "action": 1,
            "tried": 1,
            "assumed": 1,
            "lead": 1,
            "goal": 1,
            "least": 1,
            "possible": 1,
            "optimism": 1,
            "uncertainty": 1,
            "encourages": 1,
            "new": 1,
            "promising": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para212",
          "content": "×\nFigure 4.24\nLRTA*-A\nGENT\nselects an action according to the values of neighboring states, which are updated as the agent moves about the state space.",
          "sentence_count": 1,
          "char_count": 130,
          "prev_para_id": "chap4_para211",
          "next_para_id": "chap4_para213",
          "style_metadata": {
            "para_id": "chap4_para212",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 30,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "lrta": 1,
            "gent": 1,
            "selects": 1,
            "action": 1,
            "according": 1,
            "value": 1,
            "neighboring": 1,
            "state": 2,
            "updated": 1,
            "agent": 1,
            "move": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para213",
          "content": "An LRTA* agent is guaranteed to find a goal in any finite, safely explorable environment. Unlike A*, however, it is not complete for infinite state spaces—there are cases where it can be led infinitely astray. It can explore an environment of\nn\nstates in\nO\n(\nn\n2\n) steps in the worst case, but often does much better. The LRTA* agent is just one of a large family of online agents that one can define by specifying the action selection rule and the update rule in different ways. We discuss this family, developed originally for stochastic environments, in\nChapter 23\n.",
          "sentence_count": 5,
          "char_count": 477,
          "prev_para_id": "chap4_para212",
          "next_para_id": "chap4_para214",
          "style_metadata": {
            "para_id": "chap4_para213",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 115,
            "sentence_count": 5
          },
          "terminology": {
            "lrta": 2,
            "agent": 3,
            "guaranteed": 1,
            "find": 1,
            "goal": 1,
            "finite": 1,
            "explorable": 1,
            "environment": 3,
            "complete": 1,
            "infinite": 1,
            "state": 2,
            "spaces—there": 1,
            "case": 2,
            "led": 1,
            "astray": 1,
            "step": 1,
            "much": 1,
            "better": 1,
            "large": 1,
            "family": 2,
            "online": 1,
            "define": 1,
            "specifying": 1,
            "action": 1,
            "selection": 1,
            "rule": 2,
            "update": 1,
            "different": 1,
            "way": 1,
            "discus": 1,
            "developed": 1,
            "stochastic": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para214",
          "content": "4.5.4\nLearning in online search\nThe initial ignorance of online search agents provides several opportunities for learning. First, the agents learn a “map” of the environment—more precisely, the outcome of each action in each state—simply by recording each of their experiences. Second, the local search agents acquire more accurate estimates of the cost of each state by using local updating rules, as in LRTA*. In\nChapter 23\n, we show that these updates eventually converge to\nexact\nvalues for every state, provided that the agent explores the state space in the right way. Once exact values are known, optimal decisions can be taken simply by moving to the lowest-cost successor—that is, pure hill climbing is then an optimal strategy.",
          "sentence_count": 5,
          "char_count": 625,
          "prev_para_id": "chap4_para213",
          "next_para_id": "chap4_para215",
          "style_metadata": {
            "para_id": "chap4_para214",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 5
          },
          "terminology": {
            "learning": 2,
            "online": 2,
            "search": 3,
            "initial": 1,
            "ignorance": 1,
            "agent": 4,
            "provides": 1,
            "several": 1,
            "opportunity": 1,
            "first": 1,
            "learn": 1,
            "map": 1,
            "outcome": 1,
            "action": 1,
            "state—simply": 1,
            "recording": 1,
            "experience": 1,
            "second": 1,
            "local": 2,
            "acquire": 1,
            "accurate": 1,
            "estimate": 1,
            "cost": 1,
            "state": 3,
            "using": 1,
            "updating": 1,
            "rule": 1,
            "lrta": 1,
            "chapter": 1,
            "show": 1,
            "update": 1,
            "converge": 1,
            "exact": 2,
            "value": 2,
            "provided": 1,
            "explores": 1,
            "space": 1,
            "right": 1,
            "way": 1,
            "known": 1,
            "optimal": 2,
            "decision": 1,
            "taken": 1,
            "moving": 1,
            "lowest-cost": 1,
            "successor—that": 1,
            "pure": 1,
            "hill": 1,
            "climbing": 1,
            "strategy": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para215",
          "content": "If you followed our suggestion to trace the behavior of O\nNLINE\n-DFS-A\nGENT\nin the environment of\nFigure 4.19\n, you will have noticed that the agent is not very bright. For example, after it has seen that the\nUp\naction goes from (1,1) to (1,2), the agent still has no idea that the\nDown\naction goes back to (1,1) or that the\nUp\naction also goes from (2,1) to (2,2), from (2,2) to (2,3), and so on. In general, we would like the agent to learn that\nUp\nincreases the\ny\n-coordinate unless there is a wall in the way, that\nDown\nreduces it, and so on.",
          "sentence_count": 3,
          "char_count": 456,
          "prev_para_id": "chap4_para214",
          "next_para_id": "chap4_para216",
          "style_metadata": {
            "para_id": "chap4_para215",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 133,
            "sentence_count": 3
          },
          "terminology": {
            "followed": 1,
            "suggestion": 1,
            "trace": 1,
            "behavior": 1,
            "nline": 1,
            "-dfs-a": 1,
            "gent": 1,
            "environment": 1,
            "figure": 1,
            "noticed": 1,
            "agent": 3,
            "bright": 1,
            "example": 1,
            "seen": 1,
            "action": 3,
            "go": 3,
            "idea": 1,
            "general": 1,
            "like": 1,
            "learn": 1,
            "increase": 1,
            "-coordinate": 1,
            "way": 1,
            "reduces": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para216",
          "content": "For this to happen, we need two things. First, we need a formal and explicitly manipulable representation for these kinds of general rules; so far, we have hidden the information inside\nthe black box called the R\nESULT\nfunction.",
          "sentence_count": 2,
          "char_count": 193,
          "prev_para_id": "chap4_para215",
          "next_para_id": "chap4_para217",
          "style_metadata": {
            "para_id": "chap4_para216",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "happen": 1,
            "thing": 1,
            "need": 1,
            "formal": 1,
            "manipulable": 1,
            "representation": 1,
            "kind": 1,
            "general": 1,
            "rule": 1,
            "hidden": 1,
            "information": 1,
            "black": 1,
            "box": 1,
            "called": 1,
            "esult": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para217",
          "content": "Chapters 8\nto\n11\nare devoted to this issue. Second, we need algorithms that can construct suitable general rules from the specific observations made by the agent. These are covered in\nChapter 19\n.",
          "sentence_count": 3,
          "char_count": 168,
          "prev_para_id": "chap4_para216",
          "next_para_id": "chap4_para218",
          "style_metadata": {
            "para_id": "chap4_para217",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 3
          },
          "terminology": {
            "chapter": 2,
            "devoted": 1,
            "issue": 1,
            "second": 1,
            "need": 1,
            "algorithm": 1,
            "construct": 1,
            "suitable": 1,
            "general": 1,
            "rule": 1,
            "specific": 1,
            "observation": 1,
            "made": 1,
            "agent": 1,
            "covered": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para218",
          "content": "If we anticipate that we will be called upon to solve multiple similar problems in the future then it makes sense to invest time (and memory) to make those future searches easier. There are several ways to do this, all falling under the heading of\nincremental search\n. We could keep the search tree in memory and reuse the parts of it that are unchanged in the new problem. We could keep the heuristic\nh\nvalues and update them as we gain new information—either because the world has changed or because we have computed a better estimate. Or we could keep the best-path\ng\nvalues, using them to piece together a new solution, and updating them when the world changes.",
          "sentence_count": 5,
          "char_count": 552,
          "prev_para_id": "chap4_para217",
          "next_para_id": "chap4_para219",
          "style_metadata": {
            "para_id": "chap4_para218",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 129,
            "sentence_count": 5
          },
          "terminology": {
            "anticipate": 1,
            "called": 1,
            "solve": 1,
            "multiple": 1,
            "similar": 1,
            "problem": 2,
            "future": 2,
            "make": 2,
            "sense": 1,
            "invest": 1,
            "time": 1,
            "memory": 2,
            "search": 3,
            "several": 1,
            "way": 1,
            "falling": 1,
            "heading": 1,
            "incremental": 1,
            "keep": 3,
            "tree": 1,
            "reuse": 1,
            "part": 1,
            "unchanged": 1,
            "new": 3,
            "heuristic": 1,
            "value": 2,
            "update": 1,
            "gain": 1,
            "information—either": 1,
            "world": 2,
            "changed": 1,
            "computed": 1,
            "estimate": 1,
            "best-path": 1,
            "using": 1,
            "piece": 1,
            "solution": 1,
            "updating": 1,
            "change": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para219",
          "content": "Summary\nSummary\nThis chapter has examined search algorithms for problems in partially observable, nondeterministic, unknown, and continuous environments.",
          "sentence_count": 1,
          "char_count": 138,
          "prev_para_id": "chap4_para218",
          "next_para_id": "chap4_para220",
          "style_metadata": {
            "para_id": "chap4_para219",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 1
          },
          "terminology": {
            "summary": 2,
            "chapter": 1,
            "examined": 1,
            "search": 1,
            "algorithm": 1,
            "problem": 1,
            "observable": 1,
            "nondeterministic": 1,
            "unknown": 1,
            "continuous": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para220",
          "content": "•\nLocal search\nmethods such as\nhill climbing\nkeep only a small number of states in memory. They have been applied to optimization problems, where the idea is to find a high-scoring state, without worrying about the path to the state. Several stochastic local search algorithms have been developed, including\nsimulated annealing\n, which returns optimal solutions when given an appropriate cooling schedule.",
          "sentence_count": 3,
          "char_count": 349,
          "prev_para_id": "chap4_para219",
          "next_para_id": "chap4_para221",
          "style_metadata": {
            "para_id": "chap4_para220",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 3
          },
          "terminology": {
            "local": 2,
            "search": 2,
            "method": 1,
            "hill": 1,
            "climbing": 1,
            "keep": 1,
            "small": 1,
            "number": 1,
            "state": 3,
            "memory": 1,
            "applied": 1,
            "optimization": 1,
            "problem": 1,
            "idea": 1,
            "find": 1,
            "high-scoring": 1,
            "worrying": 1,
            "path": 1,
            "several": 1,
            "stochastic": 1,
            "algorithm": 1,
            "developed": 1,
            "including": 1,
            "simulated": 1,
            "annealing": 1,
            "return": 1,
            "optimal": 1,
            "solution": 1,
            "given": 1,
            "appropriate": 1,
            "cooling": 1,
            "schedule": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para221",
          "content": "•\nMany local search methods apply also to problems in continuous spaces.",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap4_para220",
          "next_para_id": "chap4_para222",
          "style_metadata": {
            "para_id": "chap4_para221",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "many": 1,
            "local": 1,
            "search": 1,
            "method": 1,
            "problem": 1,
            "continuous": 1,
            "space": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para222",
          "content": "Linear programming\nand\nconvex optimization\nproblems obey certain restrictions on the shape of the state space and the nature of the objective function, and admit polynomial-time algorithms that are often extremely efficient in practice. For some mathematically well-formed problems, we can find the maximum using calculus to find where the gradient is zero; for other problems we have to make do with the empirical gradient, which measures the difference in fitness between two nearby points.",
          "sentence_count": 2,
          "char_count": 421,
          "prev_para_id": "chap4_para221",
          "next_para_id": "chap4_para223",
          "style_metadata": {
            "para_id": "chap4_para222",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 2
          },
          "terminology": {
            "linear": 1,
            "programming": 1,
            "convex": 1,
            "optimization": 1,
            "problem": 3,
            "obey": 1,
            "certain": 1,
            "restriction": 1,
            "shape": 1,
            "state": 1,
            "space": 1,
            "nature": 1,
            "objective": 1,
            "function": 1,
            "polynomial-time": 1,
            "algorithm": 1,
            "efficient": 1,
            "practice": 1,
            "well-formed": 1,
            "find": 2,
            "maximum": 1,
            "using": 1,
            "calculus": 1,
            "gradient": 2,
            "zero": 1,
            "make": 1,
            "empirical": 1,
            "measure": 1,
            "difference": 1,
            "fitness": 1,
            "nearby": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para222",
              "entity_text": "Linear",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 6,
              "context": "Linear programming\nand\nconvex optimization\nproblems obey"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para223",
          "content": "•\nAn\nevolutionary algorithm\nis a stochastic hill-climbing search in which a population of states is maintained. New states are generated by\nmutation\nand by\ncrossover\n, which combines pairs of states.",
          "sentence_count": 2,
          "char_count": 175,
          "prev_para_id": "chap4_para222",
          "next_para_id": "chap4_para224",
          "style_metadata": {
            "para_id": "chap4_para223",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.029,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 2
          },
          "terminology": {
            "evolutionary": 1,
            "algorithm": 1,
            "stochastic": 1,
            "hill-climbing": 1,
            "search": 1,
            "population": 1,
            "state": 3,
            "maintained": 1,
            "new": 1,
            "generated": 1,
            "mutation": 1,
            "crossover": 1,
            "combine": 1,
            "pair": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para224",
          "content": "•\nIn\nnondeterministic\nenvironments, agents can apply\nAND–OR\nsearch to generate\ncontingent\nplans that reach the goal regardless of which outcomes occur during execution.",
          "sentence_count": 1,
          "char_count": 152,
          "prev_para_id": "chap4_para223",
          "next_para_id": "chap4_para225",
          "style_metadata": {
            "para_id": "chap4_para224",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "nondeterministic": 1,
            "environment": 1,
            "agent": 1,
            "apply": 1,
            "and–or": 1,
            "search": 1,
            "generate": 1,
            "contingent": 1,
            "plan": 1,
            "reach": 1,
            "goal": 1,
            "regardless": 1,
            "occur": 1,
            "execution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para225",
          "content": "•\nWhen the environment is partially observable, the\nbelief state\nrepresents the set of possible states that the agent might be in.",
          "sentence_count": 1,
          "char_count": 112,
          "prev_para_id": "chap4_para224",
          "next_para_id": "chap4_para226",
          "style_metadata": {
            "para_id": "chap4_para225",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "environment": 1,
            "observable": 1,
            "belief": 1,
            "state": 2,
            "represents": 1,
            "set": 1,
            "possible": 1,
            "agent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para226",
          "content": "•\nStandard search algorithms can be applied directly to belief-state space to solve\nsensorless problems\n, and belief-state\nAND–OR\nsearch can solve general partially observable problems. Incremental algorithms that construct solutions state by state within a belief state are often more efficient.",
          "sentence_count": 2,
          "char_count": 260,
          "prev_para_id": "chap4_para225",
          "next_para_id": "chap4_para227",
          "style_metadata": {
            "para_id": "chap4_para226",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "standard": 1,
            "search": 2,
            "algorithm": 2,
            "applied": 1,
            "belief-state": 2,
            "space": 1,
            "solve": 2,
            "sensorless": 1,
            "problem": 2,
            "and–or": 1,
            "general": 1,
            "observable": 1,
            "incremental": 1,
            "construct": 1,
            "solution": 1,
            "state": 3,
            "belief": 1,
            "efficient": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para227",
          "content": "•\nExploration problems\narise when the agent has no idea about the states and actions of its environment. For safely explorable environments,\nonline search\nagents can build a map and find a goal if one exists. Updating heuristic estimates from experience provides an effective method to escape from local minima.",
          "sentence_count": 3,
          "char_count": 266,
          "prev_para_id": "chap4_para226",
          "next_para_id": "chap4_para228",
          "style_metadata": {
            "para_id": "chap4_para227",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 3
          },
          "terminology": {
            "exploration": 1,
            "problem": 1,
            "arise": 1,
            "agent": 2,
            "idea": 1,
            "state": 1,
            "action": 1,
            "environment": 2,
            "explorable": 1,
            "online": 1,
            "search": 1,
            "build": 1,
            "map": 1,
            "find": 1,
            "goal": 1,
            "exists": 1,
            "updating": 1,
            "heuristic": 1,
            "estimate": 1,
            "experience": 1,
            "provides": 1,
            "effective": 1,
            "method": 1,
            "escape": 1,
            "local": 1,
            "minimum": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para228",
          "content": "Bibliographical and Historical Notes\nBibliographical and Historical Notes\nLocal search techniques have a long history in mathematics and computer science. Indeed, the Newton–Raphson method (Newton, 1671; Raphson, 1690) can be seen as a very efficient local search method for continuous spaces in which gradient information is available. Brent (1973) is a classic reference for optimization algorithms that do not require such information. Beam search, which we have presented as a local search algorithm, originated as a bounded-width variant of dynamic programming for speech recognition in the H\nARPY\nsystem (Lowerre, 1976). A related algorithm is analyzed in depth by Pearl (1984, Ch. 5).",
          "sentence_count": 6,
          "char_count": 593,
          "prev_para_id": "chap4_para227",
          "next_para_id": "chap4_para229",
          "style_metadata": {
            "para_id": "chap4_para228",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.83,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 125,
            "sentence_count": 6
          },
          "terminology": {
            "bibliographical": 2,
            "historical": 2,
            "note": 2,
            "local": 3,
            "search": 4,
            "technique": 1,
            "long": 1,
            "history": 1,
            "mathematics": 1,
            "computer": 1,
            "science": 1,
            "newton–raphson": 1,
            "method": 2,
            "newton": 1,
            "raphson": 1,
            "seen": 1,
            "efficient": 1,
            "continuous": 1,
            "space": 1,
            "gradient": 1,
            "information": 2,
            "available": 1,
            "brent": 1,
            "classic": 1,
            "reference": 1,
            "optimization": 1,
            "require": 1,
            "beam": 1,
            "presented": 1,
            "algorithm": 1,
            "originated": 1,
            "bounded-width": 1,
            "variant": 1,
            "dynamic": 1,
            "programming": 1,
            "speech": 1,
            "recognition": 1,
            "arpy": 1,
            "system": 1,
            "lowerre": 1,
            "related": 1,
            "analyzed": 1,
            "depth": 1,
            "pearl": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para228",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 167,
              "end_char": 173,
              "context": " in mathematics and computer science. Indeed, the Newton–Raphson method (Newton, 1671; Raphson, 1690) can "
            },
            {
              "para_id": "chap4_para228",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 190,
              "end_char": 196,
              "context": "puter science. Indeed, the Newton–Raphson method (Newton, 1671; Raphson, 1690) can be seen as a very effic"
            },
            {
              "para_id": "chap4_para228",
              "entity_text": "Raphson",
              "entity_type": "PERSON",
              "start_char": 204,
              "end_char": 211,
              "context": " Indeed, the Newton–Raphson method (Newton, 1671; Raphson, 1690) can be seen as a very efficient local sear"
            },
            {
              "para_id": "chap4_para228",
              "entity_text": "Lowerre",
              "entity_type": "ORG",
              "start_char": 611,
              "end_char": 618,
              "context": "ming for speech recognition in the H\nARPY\nsystem (Lowerre, 1976). A related algorithm is analyzed in depth "
            },
            {
              "para_id": "chap4_para228",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 671,
              "end_char": 676,
              "context": "976). A related algorithm is analyzed in depth by Pearl (1984, Ch. 5)."
            },
            {
              "para_id": "chap4_para228",
              "entity_text": "Ch",
              "entity_type": "PERSON",
              "start_char": 684,
              "end_char": 686,
              "context": "ed algorithm is analyzed in depth by Pearl (1984, Ch. 5)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para229",
          "content": "The topic of local search was reinvigorated in the early 1990s by surprisingly good results for large constraint-satisfaction problems such as\nn\n-queens (Minton\net al.",
          "sentence_count": 1,
          "char_count": 145,
          "prev_para_id": "chap4_para228",
          "next_para_id": "chap4_para230",
          "style_metadata": {
            "para_id": "chap4_para229",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 1
          },
          "terminology": {
            "topic": 1,
            "local": 1,
            "search": 1,
            "reinvigorated": 1,
            "good": 1,
            "result": 1,
            "large": 1,
            "constraint-satisfaction": 1,
            "problem": 1,
            "-queens": 1,
            "minton": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para229",
              "entity_text": "Minton",
              "entity_type": "PERSON",
              "start_char": 154,
              "end_char": 160,
              "context": "nstraint-satisfaction problems such as\nn\n-queens (Minton\net al."
            },
            {
              "para_id": "chap4_para229",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 164,
              "end_char": 166,
              "context": "atisfaction problems such as\nn\n-queens (Minton\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para230",
          "content": ", 1992) and Boolean satisfiability (Selman\net al.",
          "sentence_count": 1,
          "char_count": 43,
          "prev_para_id": "chap4_para229",
          "next_para_id": "chap4_para231",
          "style_metadata": {
            "para_id": "chap4_para230",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "boolean": 1,
            "satisfiability": 1,
            "selman": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para230",
              "entity_text": "Selman",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 42,
              "context": ", 1992) and Boolean satisfiability (Selman\net al."
            },
            {
              "para_id": "chap4_para230",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 46,
              "end_char": 48,
              "context": ", 1992) and Boolean satisfiability (Selman\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para231",
          "content": ", 1992) and by the incorporation of randomness, multiple simultaneous searches, and other improvements. This renaissance of what Christos Papadimitriou has called “New Age” algorithms also sparked increased interest among theoretical computer scientists (Koutsoupias and Papadimitriou, 1992; Aldous and Vazirani, 1994).",
          "sentence_count": 2,
          "char_count": 279,
          "prev_para_id": "chap4_para230",
          "next_para_id": "chap4_para232",
          "style_metadata": {
            "para_id": "chap4_para231",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 2
          },
          "terminology": {
            "incorporation": 1,
            "randomness": 1,
            "simultaneous": 1,
            "search": 1,
            "improvement": 1,
            "renaissance": 1,
            "christos": 1,
            "papadimitriou": 1,
            "called": 1,
            "new": 1,
            "age": 1,
            "algorithm": 1,
            "sparked": 1,
            "increased": 1,
            "interest": 1,
            "theoretical": 1,
            "computer": 1,
            "scientist": 1,
            "koutsoupias": 1,
            "aldous": 1,
            "vazirani": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para231",
              "entity_text": "Christos Papadimitriou",
              "entity_type": "PERSON",
              "start_char": 129,
              "end_char": 151,
              "context": " and other improvements. This renaissance of what Christos Papadimitriou has called “New Age” algorithms also sparked incr"
            },
            {
              "para_id": "chap4_para231",
              "entity_text": "New Age",
              "entity_type": "WORK_OF_ART",
              "start_char": 164,
              "end_char": 171,
              "context": "ssance of what Christos Papadimitriou has called “New Age” algorithms also sparked increased interest among"
            },
            {
              "para_id": "chap4_para231",
              "entity_text": "Koutsoupias",
              "entity_type": "PERSON",
              "start_char": 255,
              "end_char": 266,
              "context": "d interest among theoretical computer scientists (Koutsoupias and Papadimitriou, 1992; Aldous and Vazirani, 199"
            },
            {
              "para_id": "chap4_para231",
              "entity_text": "Papadimitriou",
              "entity_type": "PERSON",
              "start_char": 271,
              "end_char": 284,
              "context": " theoretical computer scientists (Koutsoupias and Papadimitriou, 1992; Aldous and Vazirani, 1994)."
            },
            {
              "para_id": "chap4_para231",
              "entity_text": "Vazirani",
              "entity_type": "PERSON",
              "start_char": 303,
              "end_char": 311,
              "context": " (Koutsoupias and Papadimitriou, 1992; Aldous and Vazirani, 1994)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para232",
          "content": "In the field of operations research, a variant of hill climbing called\ntabu search\nhas gained popularity (Glover and Laguna, 1997). This algorithm maintains a tabu list of\nk\npreviously visited states that cannot be revisited; as well as improving efficiency when searching graphs, this list can allow the algorithm to escape from some local minima.",
          "sentence_count": 2,
          "char_count": 297,
          "prev_para_id": "chap4_para231",
          "next_para_id": "chap4_para233",
          "style_metadata": {
            "para_id": "chap4_para232",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 2
          },
          "terminology": {
            "field": 1,
            "operation": 1,
            "research": 1,
            "variant": 1,
            "hill": 1,
            "climbing": 1,
            "called": 1,
            "tabu": 2,
            "search": 1,
            "gained": 1,
            "popularity": 1,
            "glover": 1,
            "laguna": 1,
            "algorithm": 2,
            "maintains": 1,
            "list": 2,
            "visited": 1,
            "state": 1,
            "revisited": 1,
            "improving": 1,
            "efficiency": 1,
            "searching": 1,
            "graph": 1,
            "escape": 1,
            "local": 1,
            "minimum": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para232",
              "entity_text": "Glover",
              "entity_type": "PRODUCT",
              "start_char": 106,
              "end_char": 112,
              "context": "limbing called\ntabu search\nhas gained popularity (Glover and Laguna, 1997). This algorithm maintains a tab"
            },
            {
              "para_id": "chap4_para232",
              "entity_text": "Laguna",
              "entity_type": "GPE",
              "start_char": 117,
              "end_char": 123,
              "context": "led\ntabu search\nhas gained popularity (Glover and Laguna, 1997). This algorithm maintains a tabu list of\nk"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para233",
          "content": "Another useful improvement on hill climbing is the S\nTAGE\nalgorithm (Boyan and Moore, 1998). The idea is to use the local maxima found by random-restart hill climbing to get an idea of the overall shape of the landscape. The algorithm fits a smooth quadratic surface to the set of local maxima and then calculates the global maximum of that surface analytically. This becomes the new restart point. Gomes\net al.",
          "sentence_count": 5,
          "char_count": 344,
          "prev_para_id": "chap4_para232",
          "next_para_id": "chap4_para234",
          "style_metadata": {
            "para_id": "chap4_para233",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 79,
            "sentence_count": 5
          },
          "terminology": {
            "useful": 1,
            "improvement": 1,
            "hill": 2,
            "climbing": 2,
            "tage": 1,
            "algorithm": 2,
            "boyan": 1,
            "moore": 1,
            "idea": 2,
            "use": 1,
            "local": 2,
            "maximum": 3,
            "found": 1,
            "get": 1,
            "overall": 1,
            "shape": 1,
            "landscape": 1,
            "fit": 1,
            "quadratic": 1,
            "surface": 2,
            "set": 1,
            "calculates": 1,
            "global": 1,
            "becomes": 1,
            "new": 1,
            "restart": 1,
            "point": 1,
            "gomes": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para233",
              "entity_text": "maxima",
              "entity_type": "PRODUCT",
              "start_char": 122,
              "end_char": 128,
              "context": "an and Moore, 1998). The idea is to use the local maxima found by random-restart hill climbing to get an i"
            },
            {
              "para_id": "chap4_para233",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 408,
              "end_char": 410,
              "context": "lly. This becomes the new restart point. Gomes\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para234",
          "content": "(1998) showed that the run times of systematic backtracking algorithms often have a\nheavy-tailed distribution\n, which means that the probability of a very long run time is more than would be predicted if the run times were exponentially distributed. When the run time distribution is heavy-tailed, random restarts find a solution faster, on average, than a single run to completion. Hoos and Stützle (2004) provide a book-length coverage of the topic.",
          "sentence_count": 3,
          "char_count": 382,
          "prev_para_id": "chap4_para233",
          "next_para_id": "chap4_para235",
          "style_metadata": {
            "para_id": "chap4_para234",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 3
          },
          "terminology": {
            "showed": 1,
            "run": 5,
            "systematic": 1,
            "backtracking": 1,
            "algorithm": 1,
            "heavy-tailed": 2,
            "distribution": 2,
            "mean": 1,
            "probability": 1,
            "time": 3,
            "predicted": 1,
            "distributed": 1,
            "random": 1,
            "restarts": 1,
            "find": 1,
            "solution": 1,
            "average": 1,
            "single": 1,
            "completion": 1,
            "hoos": 1,
            "stützle": 1,
            "provide": 1,
            "book-length": 1,
            "coverage": 1,
            "topic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para234",
              "entity_text": "Stützle",
              "entity_type": "PERSON",
              "start_char": 392,
              "end_char": 399,
              "context": "verage, than a single run to completion. Hoos and Stützle (2004) provide a book-length coverage of the topi"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para235",
          "content": "Simulated annealing was first described by Kirkpatrick\net al.",
          "sentence_count": 1,
          "char_count": 54,
          "prev_para_id": "chap4_para234",
          "next_para_id": "chap4_para236",
          "style_metadata": {
            "para_id": "chap4_para235",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 10,
            "sentence_count": 1
          },
          "terminology": {
            "simulated": 1,
            "annealing": 1,
            "first": 1,
            "described": 1,
            "kirkpatrick": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para235",
              "entity_text": "Kirkpatrick",
              "entity_type": "GPE",
              "start_char": 43,
              "end_char": 54,
              "context": "Simulated annealing was first described by Kirkpatrick\net al."
            },
            {
              "para_id": "chap4_para235",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 58,
              "end_char": 60,
              "context": "d annealing was first described by Kirkpatrick\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para236",
          "content": "(1983), who borrowed directly from the\nMetropolis algorithm\n(which is used to simulate complex systems in physics (Metropolis\net al.",
          "sentence_count": 1,
          "char_count": 116,
          "prev_para_id": "chap4_para235",
          "next_para_id": "chap4_para237",
          "style_metadata": {
            "para_id": "chap4_para236",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.038,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 1
          },
          "terminology": {
            "borrowed": 1,
            "metropolis": 2,
            "algorithm": 1,
            "used": 1,
            "simulate": 1,
            "complex": 1,
            "system": 1,
            "physic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para236",
              "entity_text": "Metropolis",
              "entity_type": "PERSON",
              "start_char": 39,
              "end_char": 49,
              "context": "(1983), who borrowed directly from the\nMetropolis algorithm\n(which is used to simulate complex syst"
            },
            {
              "para_id": "chap4_para236",
              "entity_text": "Metropolis",
              "entity_type": "PERSON",
              "start_char": 115,
              "end_char": 125,
              "context": "h is used to simulate complex systems in physics (Metropolis\net al."
            },
            {
              "para_id": "chap4_para236",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 129,
              "end_char": 131,
              "context": "imulate complex systems in physics (Metropolis\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para237",
          "content": ",1953) and was supposedly invented at a Los Alamos dinner party). Simulated annealing is now a field in itself, with hundreds of papers published every year.",
          "sentence_count": 2,
          "char_count": 132,
          "prev_para_id": "chap4_para236",
          "next_para_id": "chap4_para238",
          "style_metadata": {
            "para_id": "chap4_para237",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 2
          },
          "terminology": {
            ",1953": 1,
            "invented": 1,
            "los": 1,
            "alamo": 1,
            "dinner": 1,
            "party": 1,
            "simulated": 1,
            "annealing": 1,
            "field": 1,
            "hundred": 1,
            "paper": 1,
            "published": 1,
            "year": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para237",
              "entity_text": "Los Alamos",
              "entity_type": "GPE",
              "start_char": 40,
              "end_char": 50,
              "context": ",1953) and was supposedly invented at a Los Alamos dinner party). Simulated annealing is now a field"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para238",
          "content": "Finding optimal solutions in continuous spaces is the subject matter of several fields, including\noptimization theory\n,\noptimal control theory\n, and the\ncalculus of variations\n. The basic techniques are explained well by Bishop (1995); Press\net al.",
          "sentence_count": 2,
          "char_count": 217,
          "prev_para_id": "chap4_para237",
          "next_para_id": "chap4_para239",
          "style_metadata": {
            "para_id": "chap4_para238",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "finding": 1,
            "optimal": 2,
            "solution": 1,
            "continuous": 1,
            "space": 1,
            "subject": 1,
            "several": 1,
            "field": 1,
            "including": 1,
            "optimization": 1,
            "theory": 2,
            "control": 1,
            "calculus": 1,
            "variation": 1,
            "basic": 1,
            "technique": 1,
            "explained": 1,
            "bishop": 1,
            "press": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para238",
              "entity_text": "Bishop",
              "entity_type": "ORG",
              "start_char": 221,
              "end_char": 227,
              "context": "ions\n. The basic techniques are explained well by Bishop (1995); Press\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para239",
          "content": "(2007) cover a wide range of algorithms and provide working software.",
          "sentence_count": 1,
          "char_count": 59,
          "prev_para_id": "chap4_para238",
          "next_para_id": "chap4_para240",
          "style_metadata": {
            "para_id": "chap4_para239",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 14,
            "sentence_count": 1
          },
          "terminology": {
            "cover": 1,
            "wide": 1,
            "range": 1,
            "algorithm": 1,
            "working": 1,
            "software": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para240",
          "content": "Researchers have taken inspiration for search and optimization algorithms from a wide variety of fields of study: metallurgy (simulated annealing); biology (genetic algorithms); neuroscience (neural networks); mountaineering (hill climbing); economics (market-based algorithms (Dias\net al.",
          "sentence_count": 1,
          "char_count": 256,
          "prev_para_id": "chap4_para239",
          "next_para_id": "chap4_para241",
          "style_metadata": {
            "para_id": "chap4_para240",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 51.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 1
          },
          "terminology": {
            "researcher": 1,
            "taken": 1,
            "inspiration": 1,
            "search": 1,
            "optimization": 1,
            "wide": 1,
            "variety": 1,
            "field": 1,
            "study": 1,
            "simulated": 1,
            "annealing": 1,
            "biology": 1,
            "genetic": 1,
            "algorithm": 2,
            "neuroscience": 1,
            "neural": 1,
            "network": 1,
            "mountaineering": 1,
            "hill": 1,
            "climbing": 1,
            "economics": 1,
            "market-based": 1,
            "dia": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para240",
              "entity_text": "Dias",
              "entity_type": "PERSON",
              "start_char": 278,
              "end_char": 282,
              "context": "ll climbing); economics (market-based algorithms (Dias\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para241",
          "content": ", 2006)); physics (particle swarms (Li and Yao, 2012) and spin glasses (Mézard\net al.",
          "sentence_count": 1,
          "char_count": 72,
          "prev_para_id": "chap4_para240",
          "next_para_id": "chap4_para242",
          "style_metadata": {
            "para_id": "chap4_para241",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 1
          },
          "terminology": {
            "physic": 1,
            "particle": 1,
            "swarm": 1,
            "yao": 1,
            "spin": 1,
            "glass": 1,
            "mézard": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para241",
              "entity_text": "Li",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 38,
              "context": ", 2006)); physics (particle swarms (Li and Yao, 2012) and spin glasses (Mézard\net al."
            },
            {
              "para_id": "chap4_para241",
              "entity_text": "Yao",
              "entity_type": "PERSON",
              "start_char": 43,
              "end_char": 46,
              "context": ", 2006)); physics (particle swarms (Li and Yao, 2012) and spin glasses (Mézard\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para242",
          "content": ", 1987)); animal behavior (reinforcement learning, grey wolf optimizers (Mirjalili and Lewis, 2014)); ornithology (Cuckoo search (Yang and Deb, 2014)); entomology (ant colony (Dorigo\net al.",
          "sentence_count": 1,
          "char_count": 165,
          "prev_para_id": "chap4_para241",
          "next_para_id": "chap4_para243",
          "style_metadata": {
            "para_id": "chap4_para242",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 1
          },
          "terminology": {
            "animal": 1,
            "behavior": 1,
            "reinforcement": 1,
            "learning": 1,
            "grey": 1,
            "wolf": 1,
            "optimizers": 1,
            "mirjalili": 1,
            "lewis": 1,
            "ornithology": 1,
            "cuckoo": 1,
            "search": 1,
            "yang": 1,
            "deb": 1,
            "entomology": 1,
            "ant": 1,
            "colony": 1,
            "dorigo": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para242",
              "entity_text": "grey wolf",
              "entity_type": "PERSON",
              "start_char": 51,
              "end_char": 60,
              "context": " 1987)); animal behavior (reinforcement learning, grey wolf optimizers (Mirjalili and Lewis, 2014)); ornithol"
            },
            {
              "para_id": "chap4_para242",
              "entity_text": "Mirjalili and Lewis",
              "entity_type": "ORG",
              "start_char": 73,
              "end_char": 92,
              "context": "or (reinforcement learning, grey wolf optimizers (Mirjalili and Lewis, 2014)); ornithology (Cuckoo search (Yang and Deb"
            },
            {
              "para_id": "chap4_para242",
              "entity_text": "Cuckoo",
              "entity_type": "ORG",
              "start_char": 115,
              "end_char": 121,
              "context": "mizers (Mirjalili and Lewis, 2014)); ornithology (Cuckoo search (Yang and Deb, 2014)); entomology (ant col"
            },
            {
              "para_id": "chap4_para242",
              "entity_text": "Yang",
              "entity_type": "PERSON",
              "start_char": 130,
              "end_char": 134,
              "context": "li and Lewis, 2014)); ornithology (Cuckoo search (Yang and Deb, 2014)); entomology (ant colony (Dorigo\ne"
            },
            {
              "para_id": "chap4_para242",
              "entity_text": "Dorigo",
              "entity_type": "ORG",
              "start_char": 176,
              "end_char": 182,
              "context": "ch (Yang and Deb, 2014)); entomology (ant colony (Dorigo\net al."
            },
            {
              "para_id": "chap4_para242",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 186,
              "end_char": 188,
              "context": "nd Deb, 2014)); entomology (ant colony (Dorigo\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para243",
          "content": ", 2008), bee colony (Karaboga and Basturk, 2007), firefly (Yang, 2009) and glowworm (Krishnanand and Ghose, 2009) optimization); and others.",
          "sentence_count": 1,
          "char_count": 121,
          "prev_para_id": "chap4_para242",
          "next_para_id": "chap4_para244",
          "style_metadata": {
            "para_id": "chap4_para243",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 1
          },
          "terminology": {
            "bee": 1,
            "colony": 1,
            "karaboga": 1,
            "basturk": 1,
            "firefly": 1,
            "yang": 1,
            "glowworm": 1,
            "krishnanand": 1,
            "ghose": 1,
            "optimization": 1,
            "others": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para243",
              "entity_text": "bee colony",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 19,
              "context": ", 2008), bee colony (Karaboga and Basturk, 2007), firefly (Yang, 2009"
            },
            {
              "para_id": "chap4_para243",
              "entity_text": "Karaboga",
              "entity_type": "PERSON",
              "start_char": 21,
              "end_char": 29,
              "context": ", 2008), bee colony (Karaboga and Basturk, 2007), firefly (Yang, 2009) and glow"
            },
            {
              "para_id": "chap4_para243",
              "entity_text": "Basturk",
              "entity_type": "GPE",
              "start_char": 34,
              "end_char": 41,
              "context": ", 2008), bee colony (Karaboga and Basturk, 2007), firefly (Yang, 2009) and glowworm (Krishn"
            },
            {
              "para_id": "chap4_para243",
              "entity_text": "Yang",
              "entity_type": "PERSON",
              "start_char": 59,
              "end_char": 63,
              "context": "bee colony (Karaboga and Basturk, 2007), firefly (Yang, 2009) and glowworm (Krishnanand and Ghose, 2009)"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para244",
          "content": "Linear programming\n(LP) was first studied systematically by the mathematician Leonid Kantorovich (1939). It was one of the first applications of computers; the\nsimplex algorithm\n(Dantzig, 1949) is still used despite worst-case exponential complexity. Karmarkar (1984) developed the far more efficient family of\ninterior-point\nmethods, which was shown to have polynomial complexity for the more general class of convex optimization problems by Nesterov and Nemirovski (1994). Excellent introductions to convex optimization are provided by Ben-Tal and Nemirovski (2001) and Boyd and Vandenberghe (2004).",
          "sentence_count": 4,
          "char_count": 524,
          "prev_para_id": "chap4_para243",
          "next_para_id": "chap4_para245",
          "style_metadata": {
            "para_id": "chap4_para244",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "linear": 1,
            "programming": 1,
            "first": 2,
            "studied": 1,
            "mathematician": 1,
            "leonid": 1,
            "kantorovich": 1,
            "application": 1,
            "computer": 1,
            "simplex": 1,
            "algorithm": 1,
            "dantzig": 1,
            "used": 1,
            "worst-case": 1,
            "exponential": 1,
            "complexity": 2,
            "karmarkar": 1,
            "developed": 1,
            "efficient": 1,
            "family": 1,
            "interior-point": 1,
            "method": 1,
            "shown": 1,
            "polynomial": 1,
            "general": 1,
            "class": 1,
            "convex": 2,
            "optimization": 2,
            "problem": 1,
            "nesterov": 1,
            "nemirovski": 2,
            "excellent": 1,
            "introduction": 1,
            "provided": 1,
            "ben-tal": 1,
            "boyd": 1,
            "vandenberghe": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para244",
              "entity_text": "Linear",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 6,
              "context": "Linear programming\n(LP) was first studied systematically"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Leonid Kantorovich",
              "entity_type": "PERSON",
              "start_char": 78,
              "end_char": 96,
              "context": "first studied systematically by the mathematician Leonid Kantorovich (1939). It was one of the first applications of c"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "simplex algorithm\n",
              "entity_type": "PERSON",
              "start_char": 160,
              "end_char": 178,
              "context": "s one of the first applications of computers; the\nsimplex algorithm\n(Dantzig, 1949) is still used despite worst-case e"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Dantzig",
              "entity_type": "ORG",
              "start_char": 179,
              "end_char": 186,
              "context": "applications of computers; the\nsimplex algorithm\n(Dantzig, 1949) is still used despite worst-case exponenti"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Karmarkar",
              "entity_type": "PERSON",
              "start_char": 251,
              "end_char": 260,
              "context": "l used despite worst-case exponential complexity. Karmarkar (1984) developed the far more efficient family of"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Nesterov",
              "entity_type": "PERSON",
              "start_char": 443,
              "end_char": 451,
              "context": " general class of convex optimization problems by Nesterov and Nemirovski (1994). Excellent introductions to"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Nemirovski",
              "entity_type": "PERSON",
              "start_char": 456,
              "end_char": 466,
              "context": "s of convex optimization problems by Nesterov and Nemirovski (1994). Excellent introductions to convex optimiz"
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Ben-Tal",
              "entity_type": "PERSON",
              "start_char": 538,
              "end_char": 545,
              "context": "roductions to convex optimization are provided by Ben-Tal and Nemirovski (2001) and Boyd and Vandenberghe ("
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Nemirovski",
              "entity_type": "PERSON",
              "start_char": 550,
              "end_char": 560,
              "context": "o convex optimization are provided by Ben-Tal and Nemirovski (2001) and Boyd and Vandenberghe (2004)."
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Boyd",
              "entity_type": "PERSON",
              "start_char": 572,
              "end_char": 576,
              "context": "are provided by Ben-Tal and Nemirovski (2001) and Boyd and Vandenberghe (2004)."
            },
            {
              "para_id": "chap4_para244",
              "entity_text": "Vandenberghe",
              "entity_type": "PERSON",
              "start_char": 581,
              "end_char": 593,
              "context": "ded by Ben-Tal and Nemirovski (2001) and Boyd and Vandenberghe (2004)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para245",
          "content": "Work by Sewall Wright (1931) on the concept of a\nfitness landscape\nwas an important precursor to the development of genetic algorithms. In the 1950s, several statisticians, including Box (1957) and Friedman (1959), used evolutionary techniques for optimization problems, but it wasn’t until Rechenberg (1965) introduced\nevolution strategies\nto solve optimization problems for airfoils that the approach gained popularity. In the 1960s and 1970s, John Holland (1975) championed genetic algorithms, both as a useful optimization tool and as a method to expand our understanding of adaptation (Holland, 1995).",
          "sentence_count": 3,
          "char_count": 523,
          "prev_para_id": "chap4_para244",
          "next_para_id": "chap4_para246",
          "style_metadata": {
            "para_id": "chap4_para245",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 112,
            "sentence_count": 3
          },
          "terminology": {
            "work": 1,
            "sewall": 1,
            "wright": 1,
            "concept": 1,
            "fitness": 1,
            "landscape": 1,
            "important": 1,
            "precursor": 1,
            "development": 1,
            "genetic": 2,
            "several": 1,
            "statistician": 1,
            "including": 1,
            "box": 1,
            "friedman": 1,
            "used": 1,
            "evolutionary": 1,
            "technique": 1,
            "optimization": 3,
            "problem": 2,
            "rechenberg": 1,
            "introduced": 1,
            "evolution": 1,
            "strategy": 1,
            "solve": 1,
            "airfoil": 1,
            "approach": 1,
            "gained": 1,
            "popularity": 1,
            "john": 1,
            "holland": 2,
            "championed": 1,
            "algorithm": 1,
            "useful": 1,
            "tool": 1,
            "method": 1,
            "expand": 1,
            "understanding": 1,
            "adaptation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para245",
              "entity_text": "Sewall Wright",
              "entity_type": "PERSON",
              "start_char": 8,
              "end_char": 21,
              "context": "Work by Sewall Wright (1931) on the concept of a\nfitness landscape\nwas "
            },
            {
              "para_id": "chap4_para245",
              "entity_text": "Box",
              "entity_type": "PERSON",
              "start_char": 183,
              "end_char": 186,
              "context": "s. In the 1950s, several statisticians, including Box (1957) and Friedman (1959), used evolutionary tec"
            },
            {
              "para_id": "chap4_para245",
              "entity_text": "Friedman",
              "entity_type": "PERSON",
              "start_char": 198,
              "end_char": 206,
              "context": ", several statisticians, including Box (1957) and Friedman (1959), used evolutionary techniques for optimiza"
            },
            {
              "para_id": "chap4_para245",
              "entity_text": "Rechenberg",
              "entity_type": "PERSON",
              "start_char": 291,
              "end_char": 301,
              "context": "es for optimization problems, but it wasn’t until Rechenberg (1965) introduced\nevolution strategies\nto solve o"
            },
            {
              "para_id": "chap4_para245",
              "entity_text": "John Holland",
              "entity_type": "PERSON",
              "start_char": 446,
              "end_char": 458,
              "context": "proach gained popularity. In the 1960s and 1970s, John Holland (1975) championed genetic algorithms, both as a u"
            },
            {
              "para_id": "chap4_para245",
              "entity_text": "Holland",
              "entity_type": "GPE",
              "start_char": 591,
              "end_char": 598,
              "context": "method to expand our understanding of adaptation (Holland, 1995)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para246",
          "content": "The\nartificial life\nmovement (Langton, 1995) took this idea one step further, viewing the products of genetic algorithms as\norganisms\nrather than solutions to problems. The Baldwin effect discussed in the chapter was proposed roughly simultaneously by Conwy Lloyd Morgan (1896) and James (Baldwin, 1896). Computer simulations have helped to clarify its implications (Hinton and Nowlan, 1987; Ackley and Littman, 1991; Morgan and Griffiths, 2015). Smith and Szathmáry (1999), Ridley (2004), and Carroll (2007) provide general background on evolution.",
          "sentence_count": 4,
          "char_count": 475,
          "prev_para_id": "chap4_para245",
          "next_para_id": "chap4_para247",
          "style_metadata": {
            "para_id": "chap4_para246",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.75,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 107,
            "sentence_count": 4
          },
          "terminology": {
            "artificial": 1,
            "life": 1,
            "movement": 1,
            "langton": 1,
            "took": 1,
            "idea": 1,
            "step": 1,
            "viewing": 1,
            "product": 1,
            "genetic": 1,
            "algorithm": 1,
            "organism": 1,
            "solution": 1,
            "problem": 1,
            "baldwin": 2,
            "effect": 1,
            "discussed": 1,
            "chapter": 1,
            "proposed": 1,
            "conwy": 1,
            "lloyd": 1,
            "morgan": 2,
            "james": 1,
            "computer": 1,
            "simulation": 1,
            "helped": 1,
            "clarify": 1,
            "implication": 1,
            "hinton": 1,
            "nowlan": 1,
            "littman": 1,
            "griffith": 1,
            "smith": 1,
            "szathmáry": 1,
            "ridley": 1,
            "carroll": 1,
            "provide": 1,
            "general": 1,
            "background": 1,
            "evolution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para246",
              "entity_text": "Langton",
              "entity_type": "GPE",
              "start_char": 30,
              "end_char": 37,
              "context": "The\nartificial life\nmovement (Langton, 1995) took this idea one step further, viewing t"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Baldwin",
              "entity_type": "PERSON",
              "start_char": 173,
              "end_char": 180,
              "context": "\norganisms\nrather than solutions to problems. The Baldwin effect discussed in the chapter was proposed roug"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Conwy Lloyd Morgan",
              "entity_type": "ORG",
              "start_char": 252,
              "end_char": 270,
              "context": "he chapter was proposed roughly simultaneously by Conwy Lloyd Morgan (1896) and James (Baldwin, 1896). Computer simula"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "James",
              "entity_type": "PERSON",
              "start_char": 282,
              "end_char": 287,
              "context": "y simultaneously by Conwy Lloyd Morgan (1896) and James (Baldwin, 1896). Computer simulations have helped"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Baldwin",
              "entity_type": "GPE",
              "start_char": 289,
              "end_char": 296,
              "context": "taneously by Conwy Lloyd Morgan (1896) and James (Baldwin, 1896). Computer simulations have helped to clari"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Hinton and",
              "entity_type": "ORG",
              "start_char": 367,
              "end_char": 377,
              "context": "ulations have helped to clarify its implications (Hinton and Nowlan, 1987; Ackley and Littman, 1991; Morgan an"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Nowlan",
              "entity_type": "ORG",
              "start_char": 378,
              "end_char": 384,
              "context": "ve helped to clarify its implications (Hinton and Nowlan, 1987; Ackley and Littman, 1991; Morgan and Griff"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Ackley",
              "entity_type": "ORG",
              "start_char": 392,
              "end_char": 398,
              "context": "larify its implications (Hinton and Nowlan, 1987; Ackley and Littman, 1991; Morgan and Griffiths, 2015). S"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Littman",
              "entity_type": "ORG",
              "start_char": 403,
              "end_char": 410,
              "context": "implications (Hinton and Nowlan, 1987; Ackley and Littman, 1991; Morgan and Griffiths, 2015). Smith and Sza"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Morgan",
              "entity_type": "PERSON",
              "start_char": 418,
              "end_char": 424,
              "context": "inton and Nowlan, 1987; Ackley and Littman, 1991; Morgan and Griffiths, 2015). Smith and Szathmáry (1999),"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Smith",
              "entity_type": "PERSON",
              "start_char": 447,
              "end_char": 452,
              "context": "y and Littman, 1991; Morgan and Griffiths, 2015). Smith and Szathmáry (1999), Ridley (2004), and Carroll "
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Szathmáry",
              "entity_type": "GPE",
              "start_char": 457,
              "end_char": 466,
              "context": "man, 1991; Morgan and Griffiths, 2015). Smith and Szathmáry (1999), Ridley (2004), and Carroll (2007) provide"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Ridley",
              "entity_type": "ORG",
              "start_char": 475,
              "end_char": 481,
              "context": "and Griffiths, 2015). Smith and Szathmáry (1999), Ridley (2004), and Carroll (2007) provide general backgr"
            },
            {
              "para_id": "chap4_para246",
              "entity_text": "Carroll",
              "entity_type": "ORG",
              "start_char": 494,
              "end_char": 501,
              "context": "). Smith and Szathmáry (1999), Ridley (2004), and Carroll (2007) provide general background on evolution."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para247",
          "content": "Most comparisons of genetic algorithms to other approaches (especially stochastic hill climbing) have found that the genetic algorithms are slower to converge (O’Reilly and Oppacher, 1994; Mitchell\net al.",
          "sentence_count": 1,
          "char_count": 177,
          "prev_para_id": "chap4_para246",
          "next_para_id": "chap4_para248",
          "style_metadata": {
            "para_id": "chap4_para247",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 1
          },
          "terminology": {
            "comparison": 1,
            "genetic": 2,
            "algorithm": 2,
            "approach": 1,
            "stochastic": 1,
            "hill": 1,
            "climbing": 1,
            "found": 1,
            "slower": 1,
            "converge": 1,
            "mitchell": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para247",
              "entity_text": "Oppacher",
              "entity_type": "ORG",
              "start_char": 173,
              "end_char": 181,
              "context": "c algorithms are slower to converge (O’Reilly and Oppacher, 1994; Mitchell\net al."
            },
            {
              "para_id": "chap4_para247",
              "entity_text": "Mitchell",
              "entity_type": "PERSON",
              "start_char": 189,
              "end_char": 197,
              "context": " slower to converge (O’Reilly and Oppacher, 1994; Mitchell\net al."
            },
            {
              "para_id": "chap4_para247",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 201,
              "end_char": 203,
              "context": "onverge (O’Reilly and Oppacher, 1994; Mitchell\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para248",
          "content": ", 1996; Juels and Wattenberg, 1996; Baluja, 1997). Such findings are not universally popular within the GA community, but recent attempts within that community to understand population-based search as an approximate form of Bayesian learning (see\nChapter 21\n) might help close the gap between the field and its critics (Pelikan\net al.,\n1999). The theory of\nquadratic dynamical systems\nmay also explain the performance of GAs (Rabani\net al.,\n1998). There are some impressive practical applications of GAs, in areas as diverse as antenna design (Lohn\net al.,\n2001), computer-aided design (Renner and Ekart, 2003), climate models (Stanislawska\net al.,\n2015), medicine (Ghaheri\net al.,\n2015), and designing deep neural networks (Miikkulainen\net al.,\n2019).",
          "sentence_count": 4,
          "char_count": 653,
          "prev_para_id": "chap4_para247",
          "next_para_id": "chap4_para249",
          "style_metadata": {
            "para_id": "chap4_para248",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 153,
            "sentence_count": 4
          },
          "terminology": {
            "juels": 1,
            "wattenberg": 1,
            "baluja": 1,
            "finding": 1,
            "popular": 1,
            "community": 2,
            "recent": 1,
            "attempt": 1,
            "understand": 1,
            "population-based": 1,
            "search": 1,
            "approximate": 1,
            "form": 1,
            "bayesian": 1,
            "learning": 1,
            "see": 1,
            "chapter": 1,
            "help": 1,
            "close": 1,
            "gap": 1,
            "field": 1,
            "critic": 1,
            "pelikan": 1,
            "al.": 5,
            "theory": 1,
            "quadratic": 1,
            "dynamical": 1,
            "system": 1,
            "explain": 1,
            "performance": 1,
            "gas": 2,
            "rabani": 1,
            "impressive": 1,
            "practical": 1,
            "application": 1,
            "area": 1,
            "diverse": 1,
            "antenna": 1,
            "design": 2,
            "lohn": 1,
            "computer-aided": 1,
            "renner": 1,
            "ekart": 1,
            "climate": 1,
            "model": 1,
            "stanislawska": 1,
            "medicine": 1,
            "ghaheri": 1,
            "designing": 1,
            "deep": 1,
            "neural": 1,
            "network": 1,
            "miikkulainen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para248",
              "entity_text": "Juels",
              "entity_type": "GPE",
              "start_char": 8,
              "end_char": 13,
              "context": ", 1996; Juels and Wattenberg, 1996; Baluja, 1997). Such finding"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Wattenberg",
              "entity_type": "GPE",
              "start_char": 18,
              "end_char": 28,
              "context": ", 1996; Juels and Wattenberg, 1996; Baluja, 1997). Such findings are not unive"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Baluja",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 42,
              "context": ", 1996; Juels and Wattenberg, 1996; Baluja, 1997). Such findings are not universally popular"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "GA",
              "entity_type": "ORG",
              "start_char": 104,
              "end_char": 106,
              "context": "h findings are not universally popular within the GA community, but recent attempts within that commun"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 331,
              "end_char": 334,
              "context": "gap between the field and its critics (Pelikan\net al.,\n1999). The theory of\nquadratic dynamical systems"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Rabani",
              "entity_type": "PERSON",
              "start_char": 426,
              "end_char": 432,
              "context": " systems\nmay also explain the performance of GAs (Rabani\net al.,\n1998). There are some impressive practica"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 436,
              "end_char": 439,
              "context": "ay also explain the performance of GAs (Rabani\net al.,\n1998). There are some impressive practical appli"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 552,
              "end_char": 555,
              "context": "s, in areas as diverse as antenna design (Lohn\net al.,\n2001), computer-aided design (Renner and Ekart, "
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Renner",
              "entity_type": "ORG",
              "start_char": 587,
              "end_char": 593,
              "context": "esign (Lohn\net al.,\n2001), computer-aided design (Renner and Ekart, 2003), climate models (Stanislawska\net"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Ekart",
              "entity_type": "ORG",
              "start_char": 598,
              "end_char": 603,
              "context": "\net al.,\n2001), computer-aided design (Renner and Ekart, 2003), climate models (Stanislawska\net al.,\n2015"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Stanislawska",
              "entity_type": "ORG",
              "start_char": 628,
              "end_char": 640,
              "context": " design (Renner and Ekart, 2003), climate models (Stanislawska\net al.,\n2015), medicine (Ghaheri\net al.,\n2015), a"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 644,
              "end_char": 647,
              "context": "and Ekart, 2003), climate models (Stanislawska\net al.,\n2015), medicine (Ghaheri\net al.,\n2015), and desi"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Ghaheri",
              "entity_type": "PERSON",
              "start_char": 666,
              "end_char": 673,
              "context": "ate models (Stanislawska\net al.,\n2015), medicine (Ghaheri\net al.,\n2015), and designing deep neural networks"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 677,
              "end_char": 680,
              "context": "(Stanislawska\net al.,\n2015), medicine (Ghaheri\net al.,\n2015), and designing deep neural networks (Miikk"
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "Miikkulainen",
              "entity_type": "PERSON",
              "start_char": 725,
              "end_char": 737,
              "context": "t al.,\n2015), and designing deep neural networks (Miikkulainen\net al.,\n2019)."
            },
            {
              "para_id": "chap4_para248",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 741,
              "end_char": 744,
              "context": "d designing deep neural networks (Miikkulainen\net al.,\n2019)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para249",
          "content": "The field of\ngenetic programming\nis a subfield of genetic algorithms in which the representations are programs rather than bit strings. The programs are represented in the form of syntax trees, either in a standard programming language or in specially designed formats to represent electronic circuits, robot controllers, and so on. Crossover involves splicing together subtrees in such a way that the offspring are guaranteed to be well-formed expressions.",
          "sentence_count": 3,
          "char_count": 391,
          "prev_para_id": "chap4_para248",
          "next_para_id": "chap4_para250",
          "style_metadata": {
            "para_id": "chap4_para249",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 75,
            "sentence_count": 3
          },
          "terminology": {
            "field": 1,
            "genetic": 2,
            "programming": 2,
            "subfield": 1,
            "algorithm": 1,
            "representation": 1,
            "program": 2,
            "bit": 1,
            "string": 1,
            "represented": 1,
            "form": 1,
            "syntax": 1,
            "tree": 1,
            "standard": 1,
            "language": 1,
            "designed": 1,
            "format": 1,
            "represent": 1,
            "electronic": 1,
            "circuit": 1,
            "robot": 1,
            "controller": 1,
            "crossover": 1,
            "involves": 1,
            "splicing": 1,
            "subtrees": 1,
            "way": 1,
            "offspring": 1,
            "guaranteed": 1,
            "well-formed": 1,
            "expression": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para250",
          "content": "Interest in genetic programming was spurred by the work of John Koza (1992, 1994), but it goes back at least to early experiments with machine code by Friedberg (1958) and with finite-state automata by Fogel\net al.",
          "sentence_count": 1,
          "char_count": 179,
          "prev_para_id": "chap4_para249",
          "next_para_id": "chap4_para251",
          "style_metadata": {
            "para_id": "chap4_para250",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 44.0,
            "passive_voice_ratio": 0.023,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 1
          },
          "terminology": {
            "interest": 1,
            "genetic": 1,
            "programming": 1,
            "spurred": 1,
            "work": 1,
            "john": 1,
            "koza": 1,
            "go": 1,
            "least": 1,
            "early": 1,
            "experiment": 1,
            "machine": 1,
            "code": 1,
            "friedberg": 1,
            "finite-state": 1,
            "automaton": 1,
            "fogel": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para250",
              "entity_text": "John Koza",
              "entity_type": "PERSON",
              "start_char": 59,
              "end_char": 68,
              "context": "in genetic programming was spurred by the work of John Koza (1992, 1994), but it goes back at least to early "
            },
            {
              "para_id": "chap4_para250",
              "entity_text": "Friedberg",
              "entity_type": "ORG",
              "start_char": 151,
              "end_char": 160,
              "context": "t least to early experiments with machine code by Friedberg (1958) and with finite-state automata by Fogel\net"
            },
            {
              "para_id": "chap4_para250",
              "entity_text": "Fogel",
              "entity_type": "PERSON",
              "start_char": 202,
              "end_char": 207,
              "context": "riedberg (1958) and with finite-state automata by Fogel\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para251",
          "content": "(1966). As with genetic algorithms, there is debate about the effectiveness of the technique. Koza\net al.",
          "sentence_count": 3,
          "char_count": 90,
          "prev_para_id": "chap4_para250",
          "next_para_id": "chap4_para252",
          "style_metadata": {
            "para_id": "chap4_para251",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 23,
            "sentence_count": 3
          },
          "terminology": {
            "genetic": 1,
            "algorithm": 1,
            "debate": 1,
            "effectiveness": 1,
            "technique": 1,
            "koza": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para252",
          "content": "(1999) describe experiments in the use of genetic programming to design circuit devices.",
          "sentence_count": 1,
          "char_count": 76,
          "prev_para_id": "chap4_para251",
          "next_para_id": "chap4_para253",
          "style_metadata": {
            "para_id": "chap4_para252",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "describe": 1,
            "experiment": 1,
            "use": 1,
            "genetic": 1,
            "programming": 1,
            "design": 1,
            "circuit": 1,
            "device": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para253",
          "content": "The journals\nEvolutionary Computation\nand\nIEEE Transactions on Evolutionary Computation\ncover evolutionary algorithms; articles are also found in\nComplex Systems\n,\nAdaptive Behavior,\nand\nArtificial Life.",
          "sentence_count": 1,
          "char_count": 187,
          "prev_para_id": "chap4_para252",
          "next_para_id": "chap4_para254",
          "style_metadata": {
            "para_id": "chap4_para253",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "journal": 1,
            "evolutionary": 3,
            "computation": 2,
            "ieee": 1,
            "transaction": 1,
            "cover": 1,
            "algorithm": 1,
            "article": 1,
            "found": 1,
            "complex": 1,
            "system": 1,
            "adaptive": 1,
            "behavior": 1,
            "artificial": 1,
            "life": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para253",
              "entity_text": "IEEE Transactions on Evolutionary Computation",
              "entity_type": "ORG",
              "start_char": 42,
              "end_char": 87,
              "context": "The journals\nEvolutionary Computation\nand\nIEEE Transactions on Evolutionary Computation\ncover evolutionary algorithms; articles are also "
            },
            {
              "para_id": "chap4_para253",
              "entity_text": "Complex Systems",
              "entity_type": "ORG",
              "start_char": 146,
              "end_char": 161,
              "context": "olutionary algorithms; articles are also found in\nComplex Systems\n,\nAdaptive Behavior,\nand\nArtificial Life."
            },
            {
              "para_id": "chap4_para253",
              "entity_text": "Adaptive Behavior",
              "entity_type": "ORG",
              "start_char": 164,
              "end_char": 181,
              "context": "hms; articles are also found in\nComplex Systems\n,\nAdaptive Behavior,\nand\nArtificial Life."
            },
            {
              "para_id": "chap4_para253",
              "entity_text": "Artificial Life",
              "entity_type": "ORG",
              "start_char": 187,
              "end_char": 202,
              "context": "found in\nComplex Systems\n,\nAdaptive Behavior,\nand\nArtificial Life."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para254",
          "content": "The main conference is the\nGenetic and Evolutionary\nComputation Conference\n(GECCO). Good overview texts on genetic algorithms include those by Mitchell (1996), Fogel (2000), Langdon and Poli (2002), and Poli\net al.",
          "sentence_count": 2,
          "char_count": 187,
          "prev_para_id": "chap4_para253",
          "next_para_id": "chap4_para255",
          "style_metadata": {
            "para_id": "chap4_para254",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "main": 1,
            "conference": 2,
            "genetic": 2,
            "evolutionary": 1,
            "computation": 1,
            "gecco": 1,
            "good": 1,
            "overview": 1,
            "text": 1,
            "algorithm": 1,
            "include": 1,
            "mitchell": 1,
            "fogel": 1,
            "langdon": 1,
            "poli": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para254",
              "entity_text": "GECCO",
              "entity_type": "ORG",
              "start_char": 76,
              "end_char": 81,
              "context": "\nGenetic and Evolutionary\nComputation Conference\n(GECCO). Good overview texts on genetic algorithms inclu"
            },
            {
              "para_id": "chap4_para254",
              "entity_text": "Mitchell",
              "entity_type": "PERSON",
              "start_char": 143,
              "end_char": 151,
              "context": "view texts on genetic algorithms include those by Mitchell (1996), Fogel (2000), Langdon and Poli (2002), an"
            },
            {
              "para_id": "chap4_para254",
              "entity_text": "Fogel",
              "entity_type": "PERSON",
              "start_char": 160,
              "end_char": 165,
              "context": "etic algorithms include those by Mitchell (1996), Fogel (2000), Langdon and Poli (2002), and Poli\net al."
            },
            {
              "para_id": "chap4_para254",
              "entity_text": "Langdon",
              "entity_type": "GPE",
              "start_char": 174,
              "end_char": 181,
              "context": "s include those by Mitchell (1996), Fogel (2000), Langdon and Poli (2002), and Poli\net al."
            },
            {
              "para_id": "chap4_para254",
              "entity_text": "Poli",
              "entity_type": "PERSON",
              "start_char": 186,
              "end_char": 190,
              "context": "ose by Mitchell (1996), Fogel (2000), Langdon and Poli (2002), and Poli\net al."
            },
            {
              "para_id": "chap4_para254",
              "entity_text": "Poli",
              "entity_type": "PERSON",
              "start_char": 203,
              "end_char": 207,
              "context": "1996), Fogel (2000), Langdon and Poli (2002), and Poli\net al."
            },
            {
              "para_id": "chap4_para254",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 211,
              "end_char": 213,
              "context": "ogel (2000), Langdon and Poli (2002), and Poli\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para255",
          "content": "(2008).",
          "sentence_count": 1,
          "char_count": 7,
          "prev_para_id": "chap4_para254",
          "next_para_id": "chap4_para256",
          "style_metadata": {
            "para_id": "chap4_para255",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para256",
          "content": "The unpredictability and partial observability of real environments were recognized early on in robotics projects that used planning techniques, including Shakey (Fikes\net al.,\n1972) and F\nREDDY\n(Michie, 1972). The problems received more attention after the publication of McDermott’s (1978a) influential article\nPlanning and Acting.",
          "sentence_count": 2,
          "char_count": 293,
          "prev_para_id": "chap4_para255",
          "next_para_id": "chap4_para257",
          "style_metadata": {
            "para_id": "chap4_para256",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.5,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 2
          },
          "terminology": {
            "unpredictability": 1,
            "partial": 1,
            "observability": 1,
            "real": 1,
            "environment": 1,
            "recognized": 1,
            "early": 1,
            "robotics": 1,
            "project": 1,
            "used": 1,
            "planning": 2,
            "technique": 1,
            "including": 1,
            "shakey": 1,
            "fikes": 1,
            "al.": 1,
            "reddy": 1,
            "michie": 1,
            "problem": 1,
            "received": 1,
            "attention": 1,
            "publication": 1,
            "mcdermott": 1,
            "influential": 1,
            "article": 1,
            "acting": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para256",
              "entity_text": "Shakey (Fikes\net al.",
              "entity_type": "WORK_OF_ART",
              "start_char": 155,
              "end_char": 175,
              "context": "projects that used planning techniques, including Shakey (Fikes\net al.,\n1972) and F\nREDDY\n(Michie, 1972). The problems r"
            },
            {
              "para_id": "chap4_para256",
              "entity_text": "F\nREDDY",
              "entity_type": "PRODUCT",
              "start_char": 187,
              "end_char": 194,
              "context": "niques, including Shakey (Fikes\net al.,\n1972) and F\nREDDY\n(Michie, 1972). The problems received more attent"
            },
            {
              "para_id": "chap4_para256",
              "entity_text": "Michie",
              "entity_type": "PERSON",
              "start_char": 196,
              "end_char": 202,
              "context": "ncluding Shakey (Fikes\net al.,\n1972) and F\nREDDY\n(Michie, 1972). The problems received more attention afte"
            },
            {
              "para_id": "chap4_para256",
              "entity_text": "McDermott",
              "entity_type": "PERSON",
              "start_char": 273,
              "end_char": 282,
              "context": " received more attention after the publication of McDermott’s (1978a) influential article\nPlanning and Acting"
            },
            {
              "para_id": "chap4_para256",
              "entity_text": "Planning and Acting",
              "entity_type": "WORK_OF_ART",
              "start_char": 313,
              "end_char": 332,
              "context": "cation of McDermott’s (1978a) influential article\nPlanning and Acting."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para257",
          "content": "The first work to make explicit use of\nAND–OR\ntrees seems to have been Slagle’s S\nAINT\nprogram for symbolic integration, mentioned in\nChapter 1\n. Amarel (1967) applied the idea to propositional theorem proving, a topic discussed in\nChapter 7\n, and introduced a search algorithm similar to A\nND\n-O\nR\n-G\nRAPH\n-S\nEARCH\n. The algorithm was further developed by Nilsson (1971), who also described AO*—which, as its name suggests, finds optimal solutions. AO* was further improved by Martelli and Montanari (1973).",
          "sentence_count": 4,
          "char_count": 439,
          "prev_para_id": "chap4_para256",
          "next_para_id": "chap4_para258",
          "style_metadata": {
            "para_id": "chap4_para257",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 4
          },
          "terminology": {
            "first": 1,
            "work": 1,
            "make": 1,
            "explicit": 1,
            "use": 1,
            "and–or": 1,
            "tree": 1,
            "seems": 1,
            "slagle": 1,
            "aint": 1,
            "program": 1,
            "symbolic": 1,
            "integration": 1,
            "mentioned": 1,
            "chapter": 2,
            "amarel": 1,
            "applied": 1,
            "idea": 1,
            "propositional": 1,
            "theorem": 1,
            "proving": 1,
            "topic": 1,
            "discussed": 1,
            "introduced": 1,
            "search": 1,
            "algorithm": 2,
            "similar": 1,
            "raph": 1,
            "earch": 1,
            "developed": 1,
            "nilsson": 1,
            "described": 1,
            "—which": 1,
            "name": 1,
            "suggests": 1,
            "find": 1,
            "optimal": 1,
            "solution": 1,
            "improved": 1,
            "martelli": 1,
            "montanari": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para257",
              "entity_text": "Slagle’s S\nAINT",
              "entity_type": "PERSON",
              "start_char": 71,
              "end_char": 86,
              "context": "e explicit use of\nAND–OR\ntrees seems to have been Slagle’s S\nAINT\nprogram for symbolic integration, mentioned in\nCh"
            },
            {
              "para_id": "chap4_para257",
              "entity_text": "RAPH",
              "entity_type": "ORG",
              "start_char": 302,
              "end_char": 306,
              "context": "oduced a search algorithm similar to A\nND\n-O\nR\n-G\nRAPH\n-S\nEARCH\n. The algorithm was further developed by"
            },
            {
              "para_id": "chap4_para257",
              "entity_text": "Nilsson",
              "entity_type": "ORG",
              "start_char": 357,
              "end_char": 364,
              "context": "-S\nEARCH\n. The algorithm was further developed by Nilsson (1971), who also described AO*—which, as its name"
            },
            {
              "para_id": "chap4_para257",
              "entity_text": "Martelli",
              "entity_type": "PERSON",
              "start_char": 478,
              "end_char": 486,
              "context": "ds optimal solutions. AO* was further improved by Martelli and Montanari (1973)."
            },
            {
              "para_id": "chap4_para257",
              "entity_text": "Montanari",
              "entity_type": "ORG",
              "start_char": 491,
              "end_char": 500,
              "context": "lutions. AO* was further improved by Martelli and Montanari (1973)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para258",
          "content": "AO* is a top-down algorithm; a bottom-up generalization of A* is A*LD, for A* Lightest Derivation (Felzenszwalb and McAllester, 2007). Interest in\nAND–OR\nsearch underwent a revival in the early 2000s, with new algorithms for finding cyclic solutions (Jimenez and Torras, 2000; Hansen and Zilberstein, 2001) and new techniques inspired by dynamic programming (Bonet and Geffner, 2005).",
          "sentence_count": 2,
          "char_count": 330,
          "prev_para_id": "chap4_para257",
          "next_para_id": "chap4_para259",
          "style_metadata": {
            "para_id": "chap4_para258",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 2
          },
          "terminology": {
            "top-down": 1,
            "algorithm": 2,
            "bottom-up": 1,
            "generalization": 1,
            "lightest": 1,
            "derivation": 1,
            "felzenszwalb": 1,
            "mcallester": 1,
            "interest": 1,
            "search": 1,
            "underwent": 1,
            "revival": 1,
            "new": 2,
            "finding": 1,
            "cyclic": 1,
            "solution": 1,
            "jimenez": 1,
            "torras": 1,
            "hansen": 1,
            "technique": 1,
            "inspired": 1,
            "dynamic": 1,
            "programming": 1,
            "bonet": 1,
            "geffner": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para258",
              "entity_text": "AO",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 2,
              "context": "AO* is a top-down algorithm; a bottom-up generalizat"
            },
            {
              "para_id": "chap4_para258",
              "entity_text": "McAllester",
              "entity_type": "PERSON",
              "start_char": 116,
              "end_char": 126,
              "context": "*LD, for A* Lightest Derivation (Felzenszwalb and McAllester, 2007). Interest in\nAND–OR\nsearch underwent a rev"
            },
            {
              "para_id": "chap4_para258",
              "entity_text": "Torras",
              "entity_type": "PERSON",
              "start_char": 263,
              "end_char": 269,
              "context": "orithms for finding cyclic solutions (Jimenez and Torras, 2000; Hansen and Zilberstein, 2001) and new tech"
            },
            {
              "para_id": "chap4_para258",
              "entity_text": "Hansen",
              "entity_type": "PERSON",
              "start_char": 277,
              "end_char": 283,
              "context": "nding cyclic solutions (Jimenez and Torras, 2000; Hansen and Zilberstein, 2001) and new techniques inspire"
            },
            {
              "para_id": "chap4_para258",
              "entity_text": "Zilberstein",
              "entity_type": "GPE",
              "start_char": 288,
              "end_char": 299,
              "context": "c solutions (Jimenez and Torras, 2000; Hansen and Zilberstein, 2001) and new techniques inspired by dynamic pro"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para259",
          "content": "The idea of transforming partially observable problems into belief-state problems originated with Astrom (1965) for the much more complex case of probabilistic uncertainty (see\nChapter 16\n). Erdmann and Mason (1988) studied the problem of robotic manipulation without sensors, using a continuous form of belief-state search. They showed that it was possible to orient a part on a table from an arbitrary initial position by a well-designed sequence of tilting actions. More practical methods, based on a series of precisely oriented diagonal barriers across a conveyor belt, use the same algorithmic insights (Wiegley\net al.,\n1996).",
          "sentence_count": 4,
          "char_count": 541,
          "prev_para_id": "chap4_para258",
          "next_para_id": "chap4_para260",
          "style_metadata": {
            "para_id": "chap4_para259",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 111,
            "sentence_count": 4
          },
          "terminology": {
            "idea": 1,
            "transforming": 1,
            "observable": 1,
            "problem": 3,
            "belief-state": 2,
            "originated": 1,
            "much": 1,
            "complex": 1,
            "case": 1,
            "probabilistic": 1,
            "uncertainty": 1,
            "see": 1,
            "chapter": 1,
            "erdmann": 1,
            "mason": 1,
            "studied": 1,
            "robotic": 1,
            "manipulation": 1,
            "sensor": 1,
            "using": 1,
            "continuous": 1,
            "form": 1,
            "search": 1,
            "showed": 1,
            "possible": 1,
            "orient": 1,
            "part": 1,
            "table": 1,
            "arbitrary": 1,
            "initial": 1,
            "position": 1,
            "well-designed": 1,
            "sequence": 1,
            "tilting": 1,
            "action": 1,
            "practical": 1,
            "method": 1,
            "based": 1,
            "series": 1,
            "oriented": 1,
            "diagonal": 1,
            "barrier": 1,
            "conveyor": 1,
            "belt": 1,
            "use": 1,
            "algorithmic": 1,
            "insight": 1,
            "wiegley": 1,
            "al.": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para259",
              "entity_text": "Erdmann",
              "entity_type": "ORG",
              "start_char": 191,
              "end_char": 198,
              "context": "e of probabilistic uncertainty (see\nChapter 16\n). Erdmann and Mason (1988) studied the problem of robotic m"
            },
            {
              "para_id": "chap4_para259",
              "entity_text": "Mason",
              "entity_type": "ORG",
              "start_char": 203,
              "end_char": 208,
              "context": "listic uncertainty (see\nChapter 16\n). Erdmann and Mason (1988) studied the problem of robotic manipulatio"
            },
            {
              "para_id": "chap4_para259",
              "entity_text": "Wiegley",
              "entity_type": "PERSON",
              "start_char": 610,
              "end_char": 617,
              "context": "conveyor belt, use the same algorithmic insights (Wiegley\net al.,\n1996)."
            },
            {
              "para_id": "chap4_para259",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 621,
              "end_char": 624,
              "context": "lt, use the same algorithmic insights (Wiegley\net al.,\n1996)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para260",
          "content": "The belief-state approach was reinvented in the context of sensorless and partially observable search problems by Genesereth and Nourbakhsh (1993). Additional work was done on sensorless problems in the logic-based planning community (Goldman and Boddy, 1996; Smith and Weld, 1998). This work has emphasized concise representations for belief states, as explained in\nChapter 11\n. Bonet and Geffner (2000) introduced the first effective heuristics for belief-state search; these were refined by Bryce\net al.",
          "sentence_count": 4,
          "char_count": 436,
          "prev_para_id": "chap4_para259",
          "next_para_id": "chap4_para261",
          "style_metadata": {
            "para_id": "chap4_para260",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.023,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 4
          },
          "terminology": {
            "belief-state": 2,
            "approach": 1,
            "reinvented": 1,
            "context": 1,
            "sensorless": 2,
            "observable": 1,
            "search": 2,
            "problem": 2,
            "genesereth": 1,
            "nourbakhsh": 1,
            "additional": 1,
            "work": 2,
            "done": 1,
            "logic-based": 1,
            "planning": 1,
            "community": 1,
            "goldman": 1,
            "boddy": 1,
            "smith": 1,
            "weld": 1,
            "emphasized": 1,
            "concise": 1,
            "representation": 1,
            "belief": 1,
            "state": 1,
            "explained": 1,
            "chapter": 1,
            "bonet": 1,
            "geffner": 1,
            "introduced": 1,
            "first": 1,
            "effective": 1,
            "heuristic": 1,
            "refined": 1,
            "bryce": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para260",
              "entity_text": "Genesereth",
              "entity_type": "PERSON",
              "start_char": 114,
              "end_char": 124,
              "context": "rless and partially observable search problems by Genesereth and Nourbakhsh (1993). Additional work was done o"
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Nourbakhsh",
              "entity_type": "PERSON",
              "start_char": 129,
              "end_char": 139,
              "context": "ally observable search problems by Genesereth and Nourbakhsh (1993). Additional work was done on sensorless pr"
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Goldman",
              "entity_type": "ORG",
              "start_char": 235,
              "end_char": 242,
              "context": "s problems in the logic-based planning community (Goldman and Boddy, 1996; Smith and Weld, 1998). This work"
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Boddy",
              "entity_type": "GPE",
              "start_char": 247,
              "end_char": 252,
              "context": "n the logic-based planning community (Goldman and Boddy, 1996; Smith and Weld, 1998). This work has empha"
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Smith",
              "entity_type": "PERSON",
              "start_char": 260,
              "end_char": 265,
              "context": "ased planning community (Goldman and Boddy, 1996; Smith and Weld, 1998). This work has emphasized concise"
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Weld",
              "entity_type": "PERSON",
              "start_char": 270,
              "end_char": 274,
              "context": "ing community (Goldman and Boddy, 1996; Smith and Weld, 1998). This work has emphasized concise represen"
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Geffner",
              "entity_type": "PERSON",
              "start_char": 390,
              "end_char": 397,
              "context": "ef states, as explained in\nChapter 11\n. Bonet and Geffner (2000) introduced the first effective heuristics "
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "Bryce",
              "entity_type": "PERSON",
              "start_char": 494,
              "end_char": 499,
              "context": "cs for belief-state search; these were refined by Bryce\net al."
            },
            {
              "para_id": "chap4_para260",
              "entity_text": "al",
              "entity_type": "ORG",
              "start_char": 503,
              "end_char": 505,
              "context": "lief-state search; these were refined by Bryce\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para261",
          "content": "(2006). The incremental approach to belief-state search, in which solutions are constructed incrementally for subsets of states within each belief state, was studied in the planning literature by Kurien\net al.",
          "sentence_count": 2,
          "char_count": 180,
          "prev_para_id": "chap4_para260",
          "next_para_id": "chap4_para262",
          "style_metadata": {
            "para_id": "chap4_para261",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.027,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "incremental": 1,
            "approach": 1,
            "belief-state": 1,
            "search": 1,
            "solution": 1,
            "constructed": 1,
            "subset": 1,
            "state": 2,
            "belief": 1,
            "studied": 1,
            "planning": 1,
            "literature": 1,
            "kurien": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para261",
              "entity_text": "Kurien",
              "entity_type": "PERSON",
              "start_char": 196,
              "end_char": 202,
              "context": " state, was studied in the planning literature by Kurien\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para262",
          "content": "(2002); several new incremental algorithms were introduced for nondeterministic, partially observable problems by Russell and Wolfe (2005). Additional references for planning in stochastic, partially observable environments appear in\nChapter 16\n.",
          "sentence_count": 2,
          "char_count": 218,
          "prev_para_id": "chap4_para261",
          "next_para_id": "chap4_para263",
          "style_metadata": {
            "para_id": "chap4_para262",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.026,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 39,
            "sentence_count": 2
          },
          "terminology": {
            "several": 1,
            "new": 1,
            "incremental": 1,
            "algorithm": 1,
            "introduced": 1,
            "nondeterministic": 1,
            "observable": 2,
            "problem": 1,
            "russell": 1,
            "wolfe": 1,
            "additional": 1,
            "reference": 1,
            "planning": 1,
            "stochastic": 1,
            "environment": 1,
            "appear": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para262",
              "entity_text": "Russell",
              "entity_type": "PERSON",
              "start_char": 114,
              "end_char": 121,
              "context": "ondeterministic, partially observable problems by Russell and Wolfe (2005). Additional references for plann"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para263",
          "content": "Algorithms for exploring unknown state spaces have been of interest for many centuries. Depth-first search in a reversible maze can be implemented by keeping one’s left hand on the wall; loops can be avoided by marking each junction. The more general problem of exploring\nEulerian graphs\n(i.e., graphs in which each node has equal numbers of incoming and outgoing edges) was solved by an algorithm due to Hierholzer (1873).",
          "sentence_count": 3,
          "char_count": 357,
          "prev_para_id": "chap4_para262",
          "next_para_id": "chap4_para264",
          "style_metadata": {
            "para_id": "chap4_para263",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.67,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 3
          },
          "terminology": {
            "exploring": 2,
            "unknown": 1,
            "state": 1,
            "space": 1,
            "interest": 1,
            "many": 1,
            "century": 1,
            "depth-first": 1,
            "search": 1,
            "reversible": 1,
            "maze": 1,
            "implemented": 1,
            "keeping": 1,
            "left": 1,
            "hand": 1,
            "wall": 1,
            "loop": 1,
            "avoided": 1,
            "marking": 1,
            "junction": 1,
            "general": 1,
            "problem": 1,
            "eulerian": 1,
            "graph": 2,
            "i.e.": 1,
            "node": 1,
            "equal": 1,
            "number": 1,
            "incoming": 1,
            "outgoing": 1,
            "edge": 1,
            "solved": 1,
            "algorithm": 1,
            "due": 1,
            "hierholzer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para263",
              "entity_text": "Hierholzer",
              "entity_type": "PERSON",
              "start_char": 405,
              "end_char": 415,
              "context": "outgoing edges) was solved by an algorithm due to Hierholzer (1873)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para264",
          "content": "The first thorough algorithmic study of the exploration problem for arbitrary graphs was carried out by Deng and Papadimitriou (1990), who developed a completely general algorithm but showed that no bounded competitive ratio is possible for exploring a general graph. Papadimitriou and Yannakakis (1991) examined the question of finding paths to a goal in geometric path-planning environments (where all actions are reversible). They showed that\na small competitive ratio is achievable with square obstacles, but with general rectangular obstacles no bounded ratio can be achieved. (See\nFigure 4.20\n.)\nIn a dynamic environment, the state of the world can spontaneously change without any action by the agent. For example, the agent can plan an optimal driving route from A to B, but an accident or unusually bad rush hour traffic can spoil the plan. Incremental search algorithms such as Lifelong Planning A* (Koenig\net al.",
          "sentence_count": 7,
          "char_count": 784,
          "prev_para_id": "chap4_para263",
          "next_para_id": "chap4_para265",
          "style_metadata": {
            "para_id": "chap4_para264",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.71,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 166,
            "sentence_count": 7
          },
          "terminology": {
            "thorough": 1,
            "algorithmic": 1,
            "study": 1,
            "exploration": 1,
            "problem": 1,
            "arbitrary": 1,
            "graph": 2,
            "carried": 1,
            "deng": 1,
            "papadimitriou": 2,
            "developed": 1,
            "general": 3,
            "algorithm": 2,
            "showed": 2,
            "bounded": 2,
            "competitive": 2,
            "ratio": 3,
            "possible": 1,
            "exploring": 1,
            "yannakakis": 1,
            "examined": 1,
            "question": 1,
            "finding": 1,
            "path": 1,
            "goal": 1,
            "geometric": 1,
            "path-planning": 1,
            "environment": 2,
            "action": 2,
            "reversible": 1,
            "small": 1,
            "achievable": 1,
            "square": 1,
            "obstacle": 2,
            "rectangular": 1,
            "achieved": 1,
            "see": 1,
            "figure": 1,
            "dynamic": 1,
            "state": 1,
            "world": 1,
            "change": 1,
            "agent": 2,
            "example": 1,
            "plan": 2,
            "optimal": 1,
            "driving": 1,
            "route": 1,
            "accident": 1,
            "bad": 1,
            "rush": 1,
            "hour": 1,
            "traffic": 1,
            "spoil": 1,
            "incremental": 1,
            "search": 1,
            "planning": 1,
            "koenig": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para264",
              "entity_text": "Deng",
              "entity_type": "PERSON",
              "start_char": 104,
              "end_char": 108,
              "context": "n problem for arbitrary graphs was carried out by Deng and Papadimitriou (1990), who developed a complet"
            },
            {
              "para_id": "chap4_para264",
              "entity_text": "Papadimitriou",
              "entity_type": "PERSON",
              "start_char": 113,
              "end_char": 126,
              "context": " for arbitrary graphs was carried out by Deng and Papadimitriou (1990), who developed a completely general algori"
            },
            {
              "para_id": "chap4_para264",
              "entity_text": "Yannakakis",
              "entity_type": "GPE",
              "start_char": 286,
              "end_char": 296,
              "context": " for exploring a general graph. Papadimitriou and Yannakakis (1991) examined the question of finding paths to "
            },
            {
              "para_id": "chap4_para264",
              "entity_text": "Lifelong Planning A*",
              "entity_type": "ORG",
              "start_char": 888,
              "end_char": 908,
              "context": "l the plan. Incremental search algorithms such as Lifelong Planning A* (Koenig\net al."
            },
            {
              "para_id": "chap4_para264",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 920,
              "end_char": 922,
              "context": "lgorithms such as Lifelong Planning A* (Koenig\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para265",
          "content": ", 2004) and D* Lite (Koenig and Likhachev, 2002) deal with this situation.",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap4_para264",
          "next_para_id": "chap4_para266",
          "style_metadata": {
            "para_id": "chap4_para265",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "lite": 1,
            "koenig": 1,
            "likhachev": 1,
            "deal": 1,
            "situation": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para265",
              "entity_text": "Likhachev",
              "entity_type": "ORG",
              "start_char": 32,
              "end_char": 41,
              "context": ", 2004) and D* Lite (Koenig and Likhachev, 2002) deal with this situation."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para266",
          "content": "The LRTA* algorithm was developed by Korf (1990) as part of an investigation into\nrealtime search\nfor environments in which the agent must act after searching for only a fixed amount of time (a common situation in two-player games). LRTA\n*\nis in fact a special case of reinforcement learning algorithms for stochastic environments (Barto\net al.",
          "sentence_count": 2,
          "char_count": 293,
          "prev_para_id": "chap4_para265",
          "next_para_id": "chap4_para267",
          "style_metadata": {
            "para_id": "chap4_para266",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.5,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 2
          },
          "terminology": {
            "lrta": 2,
            "algorithm": 2,
            "developed": 1,
            "korf": 1,
            "part": 1,
            "investigation": 1,
            "realtime": 1,
            "search": 1,
            "environment": 2,
            "agent": 1,
            "act": 1,
            "searching": 1,
            "fixed": 1,
            "amount": 1,
            "time": 1,
            "common": 1,
            "situation": 1,
            "two-player": 1,
            "game": 1,
            "fact": 1,
            "special": 1,
            "case": 1,
            "reinforcement": 1,
            "learning": 1,
            "stochastic": 1,
            "barto": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para266",
              "entity_text": "Korf",
              "entity_type": "PERSON",
              "start_char": 37,
              "end_char": 41,
              "context": "The LRTA* algorithm was developed by Korf (1990) as part of an investigation into\nrealtime "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para267",
          "content": ", 1995). Its policy of optimism under uncertainty—always head for the closest unvisited state—can result in an exploration pattern that is less efficient in the uninformed case than simple depth-first search (Koenig, 2000). Dasgupta\net al.",
          "sentence_count": 3,
          "char_count": 205,
          "prev_para_id": "chap4_para266",
          "next_para_id": "chap4_para268",
          "style_metadata": {
            "para_id": "chap4_para267",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 43,
            "sentence_count": 3
          },
          "terminology": {
            "policy": 1,
            "optimism": 1,
            "uncertainty—always": 1,
            "head": 1,
            "closest": 1,
            "unvisited": 1,
            "state—can": 1,
            "result": 1,
            "exploration": 1,
            "pattern": 1,
            "efficient": 1,
            "uninformed": 1,
            "case": 1,
            "simple": 1,
            "depth-first": 1,
            "search": 1,
            "koenig": 1,
            "dasgupta": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para267",
              "entity_text": "Koenig",
              "entity_type": "GPE",
              "start_char": 209,
              "end_char": 215,
              "context": "e uninformed case than simple depth-first search (Koenig, 2000). Dasgupta\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para268",
          "content": "(1994) show that online iterative deepening search is optimally efficient for finding a goal in a uniform tree with no heuristic information.",
          "sentence_count": 1,
          "char_count": 120,
          "prev_para_id": "chap4_para267",
          "next_para_id": "chap4_para269",
          "style_metadata": {
            "para_id": "chap4_para268",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "show": 1,
            "online": 1,
            "iterative": 1,
            "deepening": 1,
            "search": 1,
            "efficient": 1,
            "finding": 1,
            "goal": 1,
            "uniform": 1,
            "tree": 1,
            "heuristic": 1,
            "information": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para269",
          "content": "Several informed variants on the LRTA\n*\ntheme have been developed with different methods for searching and updating within the known portion of the graph (Pemberton and Korf, 1992). As yet, there is no good theoretical understanding of how to find goals with optimal efficiency when using heuristic information. Sturtevant and Bulitko (2016) provide an analysis of some pitfalls that occur in practice.",
          "sentence_count": 3,
          "char_count": 342,
          "prev_para_id": "chap4_para268",
          "next_para_id": "chap4_para270",
          "style_metadata": {
            "para_id": "chap4_para269",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 3
          },
          "terminology": {
            "several": 1,
            "informed": 1,
            "variant": 1,
            "lrta": 1,
            "theme": 1,
            "developed": 1,
            "different": 1,
            "method": 1,
            "searching": 1,
            "updating": 1,
            "known": 1,
            "portion": 1,
            "graph": 1,
            "pemberton": 1,
            "korf": 1,
            "good": 1,
            "theoretical": 1,
            "understanding": 1,
            "find": 1,
            "goal": 1,
            "optimal": 1,
            "efficiency": 1,
            "using": 1,
            "heuristic": 1,
            "information": 1,
            "sturtevant": 1,
            "bulitko": 1,
            "provide": 1,
            "analysis": 1,
            "pitfall": 1,
            "occur": 1,
            "practice": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para269",
              "entity_text": "Pemberton",
              "entity_type": "ORG",
              "start_char": 155,
              "end_char": 164,
              "context": "d updating within the known portion of the graph (Pemberton and Korf, 1992). As yet, there is no good theoret"
            },
            {
              "para_id": "chap4_para269",
              "entity_text": "Korf",
              "entity_type": "ORG",
              "start_char": 169,
              "end_char": 173,
              "context": "hin the known portion of the graph (Pemberton and Korf, 1992). As yet, there is no good theoretical unde"
            },
            {
              "para_id": "chap4_para269",
              "entity_text": "Bulitko",
              "entity_type": "PERSON",
              "start_char": 327,
              "end_char": 334,
              "context": " when using heuristic information. Sturtevant and Bulitko (2016) provide an analysis of some pitfalls that "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para270",
          "content": "1\nLuby\net al.",
          "sentence_count": 1,
          "char_count": 12,
          "prev_para_id": "chap4_para269",
          "next_para_id": "chap4_para271",
          "style_metadata": {
            "para_id": "chap4_para270",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 5.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 5,
            "sentence_count": 1
          },
          "terminology": {
            "luby": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para271",
          "content": "(1993) suggest restarting after a fixed number of steps and show that this can be\nmuch\nmore efficient than letting each search continue indefinitely.",
          "sentence_count": 1,
          "char_count": 128,
          "prev_para_id": "chap4_para270",
          "next_para_id": "chap4_para272",
          "style_metadata": {
            "para_id": "chap4_para271",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 1
          },
          "terminology": {
            "suggest": 1,
            "restarting": 1,
            "fixed": 1,
            "number": 1,
            "step": 1,
            "show": 1,
            "much": 1,
            "efficient": 1,
            "letting": 1,
            "search": 1,
            "continue": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para272",
          "content": "2\nKnowledge of vectors, matrices, and derivatives is useful for this section (see\nAppendix A\n).",
          "sentence_count": 1,
          "char_count": 83,
          "prev_para_id": "chap4_para271",
          "next_para_id": "chap4_para273",
          "style_metadata": {
            "para_id": "chap4_para272",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "knowledge": 1,
            "vector": 1,
            "matrix": 1,
            "derivative": 1,
            "useful": 1,
            "section": 1,
            "see": 1,
            "appendix": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para273",
          "content": "3\nIn general, the Newton–Raphson update can be seen as fitting a quadratic surface to\nf\nat\nx\nand then moving directly to the minimum of that surface—which is also the minimum of\nf\nif\nf\nis quadratic.",
          "sentence_count": 1,
          "char_count": 170,
          "prev_para_id": "chap4_para272",
          "next_para_id": "chap4_para274",
          "style_metadata": {
            "para_id": "chap4_para273",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 40,
            "sentence_count": 1
          },
          "terminology": {
            "general": 1,
            "newton–raphson": 1,
            "update": 1,
            "seen": 1,
            "fitting": 1,
            "quadratic": 2,
            "surface": 1,
            "moving": 1,
            "minimum": 2,
            "surface—which": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para273",
              "entity_text": "Newton",
              "entity_type": "GPE",
              "start_char": 18,
              "end_char": 24,
              "context": "3\nIn general, the Newton–Raphson update can be seen as fitting a quadratic"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para274",
          "content": "4\nA set of points\nS\nis convex if the line joining any two points in\nS\nis also contained in\nS\n. A\nconvex function\nis one for which the space “above” it forms a convex set; by definition, convex functions have no local (as opposed to global) minima.",
          "sentence_count": 2,
          "char_count": 207,
          "prev_para_id": "chap4_para273",
          "next_para_id": "chap4_para275",
          "style_metadata": {
            "para_id": "chap4_para274",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 2
          },
          "terminology": {
            "set": 2,
            "point": 2,
            "convex": 4,
            "line": 1,
            "joining": 1,
            "contained": 1,
            "function": 2,
            "space": 1,
            "form": 1,
            "definition": 1,
            "local": 1,
            "opposed": 1,
            "global": 1,
            "minimum": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para275",
          "content": "5\nWe assume that most readers face similar problems and can sympathize with our agent. We apologize to owners of modern, efficient cleaning appliances who cannot take advantage of this pedagogical device.",
          "sentence_count": 2,
          "char_count": 174,
          "prev_para_id": "chap4_para274",
          "next_para_id": "chap4_para276",
          "style_metadata": {
            "para_id": "chap4_para275",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 2
          },
          "terminology": {
            "assume": 1,
            "reader": 1,
            "face": 1,
            "similar": 1,
            "problem": 1,
            "sympathize": 1,
            "agent": 1,
            "apologize": 1,
            "owner": 1,
            "modern": 1,
            "efficient": 1,
            "cleaning": 1,
            "appliance": 1,
            "take": 1,
            "advantage": 1,
            "pedagogical": 1,
            "device": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para276",
          "content": "6\nIn a fully observable environment, each belief state contains one physical state. Thus, we can view the algorithms in\nChapter 3\nas searching in a belief-state space of singleton belief states.",
          "sentence_count": 2,
          "char_count": 166,
          "prev_para_id": "chap4_para275",
          "next_para_id": "chap4_para277",
          "style_metadata": {
            "para_id": "chap4_para276",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 2
          },
          "terminology": {
            "observable": 1,
            "environment": 1,
            "belief": 2,
            "state": 3,
            "contains": 1,
            "physical": 1,
            "view": 1,
            "algorithm": 1,
            "chapter": 1,
            "searching": 1,
            "belief-state": 1,
            "space": 1,
            "singleton": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para276",
              "entity_text": "singleton",
              "entity_type": "GPE",
              "start_char": 170,
              "end_char": 179,
              "context": "Chapter 3\nas searching in a belief-state space of singleton belief states."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para277",
          "content": "7\nThe usual apologies to those who are unfamiliar with the effect of small children on the environment.",
          "sentence_count": 1,
          "char_count": 87,
          "prev_para_id": "chap4_para276",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap4_para277",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "usual": 1,
            "apology": 1,
            "unfamiliar": 1,
            "effect": 1,
            "small": 1,
            "child": 1,
            "environment": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap4_para278",
          "content": "8\nThe term “online” here refers to algorithms that must process input as it is received rather than waiting for the entire input data set to become available. This usage of “online” is unrelated to the concept of “having an Internet connection.”\n9\nRandom walks are complete on infinite one-dimensional and two-dimensional grids. On a three-dimensional grid, the probability that the walk ever returns to the starting point is only about 0.3405 (Hughes, 1995).",
          "sentence_count": 3,
          "char_count": 389,
          "prev_para_id": "chap4_para277",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap4_para278",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.023,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 87,
            "sentence_count": 3
          },
          "terminology": {
            "term": 1,
            "online": 2,
            "refers": 1,
            "algorithm": 1,
            "process": 1,
            "input": 2,
            "received": 1,
            "waiting": 1,
            "entire": 1,
            "data": 1,
            "set": 1,
            "become": 1,
            "available": 1,
            "usage": 1,
            "unrelated": 1,
            "concept": 1,
            "internet": 1,
            "connection.": 1,
            "random": 1,
            "walk": 2,
            "complete": 1,
            "infinite": 1,
            "one-dimensional": 1,
            "two-dimensional": 1,
            "grid": 2,
            "three-dimensional": 1,
            "probability": 1,
            "return": 1,
            "starting": 1,
            "point": 1,
            "hughes": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap4_para278",
              "entity_text": "Hughes",
              "entity_type": "ORG",
              "start_char": 445,
              "end_char": 451,
              "context": "turns to the starting point is only about 0.3405 (Hughes, 1995)."
            }
          ],
          "cultural_words": []
        }
      ],
      "para_count": 278,
      "char_count": 95372
    },
    {
      "chapter_num": 5,
      "title": "Chapter 5: CHAPTER",
      "paragraphs": [
        {
          "para_id": "chap5_para1",
          "content": "5\nCONSTRAINT SATISFACTION PROBLEMS\nIn which we see how treating states as more than just little black boxes leads to new search methods and a deeper understanding of problem structure.",
          "sentence_count": 1,
          "char_count": 157,
          "prev_para_id": "None",
          "next_para_id": "chap5_para2",
          "style_metadata": {
            "para_id": "chap5_para1",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "constraint": 1,
            "satisfaction": 1,
            "problem": 2,
            "see": 1,
            "treating": 1,
            "state": 1,
            "little": 1,
            "black": 1,
            "box": 1,
            "lead": 1,
            "new": 1,
            "search": 1,
            "method": 1,
            "understanding": 1,
            "structure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para2",
          "content": "Chapters 3\nand\n4\nexplored the idea that problems can be solved by searching the state space: a graph where the nodes are states and the edges between them are actions. We saw that domain-specific heuristics could estimate the cost of reaching the goal from a given state, but that from the point of view of the search algorithm, each state is atomic, or indivisible—a black box with no internal structure. For each problem we need domain-specific code to describe the transitions between states.",
          "sentence_count": 3,
          "char_count": 415,
          "prev_para_id": "chap5_para1",
          "next_para_id": "chap5_para3",
          "style_metadata": {
            "para_id": "chap5_para2",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 3
          },
          "terminology": {
            "chapter": 1,
            "explored": 1,
            "idea": 1,
            "problem": 2,
            "solved": 1,
            "searching": 1,
            "state": 5,
            "space": 1,
            "graph": 1,
            "node": 1,
            "edge": 1,
            "action": 1,
            "saw": 1,
            "domain-specific": 2,
            "heuristic": 1,
            "estimate": 1,
            "cost": 1,
            "reaching": 1,
            "goal": 1,
            "given": 1,
            "point": 1,
            "view": 1,
            "search": 1,
            "algorithm": 1,
            "atomic": 1,
            "indivisible—a": 1,
            "black": 1,
            "box": 1,
            "internal": 1,
            "structure": 1,
            "need": 1,
            "code": 1,
            "describe": 1,
            "transition": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para3",
          "content": "In this chapter we break open the black box by using a\nfactored representation\nfor each state: a set of\nvariables\n, each of which has a\nvalue\n. A problem is solved when each variable has a value that satisfies all the constraints on the variable. A problem described this way is called a\nconstraint satisfaction problem\n, or\nCSP\n.",
          "sentence_count": 3,
          "char_count": 279,
          "prev_para_id": "chap5_para2",
          "next_para_id": "chap5_para4",
          "style_metadata": {
            "para_id": "chap5_para3",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.33,
            "passive_voice_ratio": 0.031,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 3
          },
          "terminology": {
            "chapter": 1,
            "break": 1,
            "open": 1,
            "black": 1,
            "box": 1,
            "using": 1,
            "factored": 1,
            "representation": 1,
            "state": 1,
            "set": 1,
            "variable": 3,
            "value": 2,
            "problem": 3,
            "solved": 1,
            "satisfies": 1,
            "constraint": 2,
            "described": 1,
            "way": 1,
            "called": 1,
            "satisfaction": 1,
            "csp": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para3",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 325,
              "end_char": 328,
              "context": " is called a\nconstraint satisfaction problem\n, or\nCSP\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para4",
          "content": "CSP search algorithms take advantage of the structure of states and use\ngeneral\nrather than domain-specific heuristics to enable the solution of complex problems. The main idea is to eliminate large portions of the search space all at once by identifying variable/value combinations that violate the constraints. CSPs have the additional advantage that the actions and transition model can be deduced from the problem description.",
          "sentence_count": 3,
          "char_count": 368,
          "prev_para_id": "chap5_para3",
          "next_para_id": "chap5_para5",
          "style_metadata": {
            "para_id": "chap5_para4",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 3
          },
          "terminology": {
            "csp": 1,
            "search": 2,
            "algorithm": 1,
            "take": 1,
            "advantage": 2,
            "structure": 1,
            "state": 1,
            "use": 1,
            "general": 1,
            "domain-specific": 1,
            "heuristic": 1,
            "enable": 1,
            "solution": 1,
            "complex": 1,
            "problem": 2,
            "main": 1,
            "idea": 1,
            "eliminate": 1,
            "large": 1,
            "portion": 1,
            "space": 1,
            "identifying": 1,
            "variable/value": 1,
            "combination": 1,
            "violate": 1,
            "constraint": 1,
            "csps": 1,
            "additional": 1,
            "action": 1,
            "transition": 1,
            "model": 1,
            "deduced": 1,
            "description": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para4",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 3,
              "context": "CSP search algorithms take advantage of the structure"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para5",
          "content": "5.1Defining Constraint Satisfaction Problems\n5.1\nDefining Constraint Satisfaction Problems\nA constraint satisfaction problem consists of three components,\nX\n,\nD\n, and\nC\n:\nX\nis a set of variables, (\nX\n1\n,\n...,\nX\nn\n}.",
          "sentence_count": 1,
          "char_count": 196,
          "prev_para_id": "chap5_para4",
          "next_para_id": "chap5_para6",
          "style_metadata": {
            "para_id": "chap5_para5",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 42,
            "sentence_count": 1
          },
          "terminology": {
            "5.1defining": 1,
            "constraint": 3,
            "satisfaction": 3,
            "problem": 3,
            "defining": 1,
            "consists": 1,
            "component": 1,
            "set": 1,
            "variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para6",
          "content": "D\nis a set of domains, {\nD\n1\n,...,\nD\nn\n}, one for each variable.",
          "sentence_count": 1,
          "char_count": 55,
          "prev_para_id": "chap5_para5",
          "next_para_id": "chap5_para7",
          "style_metadata": {
            "para_id": "chap5_para6",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 22,
            "sentence_count": 1
          },
          "terminology": {
            "set": 1,
            "domain": 1,
            "variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para7",
          "content": "C\nis a set of constraints that specify allowable combinations of values.",
          "sentence_count": 1,
          "char_count": 62,
          "prev_para_id": "chap5_para6",
          "next_para_id": "chap5_para8",
          "style_metadata": {
            "para_id": "chap5_para7",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "set": 1,
            "constraint": 1,
            "specify": 1,
            "allowable": 1,
            "combination": 1,
            "value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para8",
          "content": "A domain,\nD\ni\n, consists of a set of allowable values, {\nv\n1\n,...,\nv\nk\n}, for variable\nX\ni\n. For example, a Boolean variable would have the domain {\ntrue, false\n}. Different variables can have different domains of different sizes. Each constraint\nC\nj\nconsists of a pair 〈\nscope, rel\n〉, where\nscope\nis a tuple of variables that participate in the constraint and\nrel\nis a\nrelation\nthat defines the values that those variables can take on. A relation can be represented as an explicit set of all tuples of values that satisfy the constraint, or as a function that can compute whether a tuple is a member of the relation. For example, if\nX\n1\nand\nX\n2\nboth have the domain {1,2,3}, then the constraint saying that\nX\n1\nmust be greater than\nX\n2\ncan be written as 〈(\nX\n1\n,\nX\n2\n), {(3,1), (3,2), (2,1)}〉 or as 〈(\nX\n1\n,\nX\n2\n),\nX\n1\n>\nX\n2\n〉.",
          "sentence_count": 6,
          "char_count": 710,
          "prev_para_id": "chap5_para7",
          "next_para_id": "chap5_para9",
          "style_metadata": {
            "para_id": "chap5_para8",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 208,
            "sentence_count": 6
          },
          "terminology": {
            "domain": 4,
            "consists": 2,
            "set": 2,
            "allowable": 1,
            "value": 3,
            "variable": 5,
            "example": 2,
            "boolean": 1,
            "true": 1,
            "false": 1,
            "different": 3,
            "size": 1,
            "constraint": 4,
            "pair": 1,
            "scope": 2,
            "rel": 2,
            "tuple": 2,
            "participate": 1,
            "relation": 3,
            "defines": 1,
            "take": 1,
            "represented": 1,
            "explicit": 1,
            "tuples": 1,
            "satisfy": 1,
            "function": 1,
            "compute": 1,
            "member": 1,
            "saying": 1,
            "greater": 1,
            "written": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para8",
              "entity_text": "rel\n〉",
              "entity_type": "PERSON",
              "start_char": 279,
              "end_char": 284,
              "context": ". Each constraint\nC\nj\nconsists of a pair 〈\nscope, rel\n〉, where\nscope\nis a tuple of variables that partici"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para9",
          "content": "CSPs deal with\nassignments\nof values to variables, {\nX\ni\n=\nv\ni\n,\nX\nj\n=\nv\nj\n,...}. An assignment that does not violate any constraints is called a\nconsistent\nor legal assignment. A\ncomplete assignment\nis one in which every variable is assigned a value, and a\nsolution\nto a CSP is a consistent, complete assignment. A\npartial assignment\nis one that leaves some variables unassigned, and a\npartial solution\nis a partial assignment that is consistent. Solving a CSP is an NP-complete problem in general, although there are important subclasses of CSPs that can be solved very efficiently.",
          "sentence_count": 5,
          "char_count": 506,
          "prev_para_id": "chap5_para8",
          "next_para_id": "chap5_para10",
          "style_metadata": {
            "para_id": "chap5_para9",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 5
          },
          "terminology": {
            "csps": 2,
            "deal": 1,
            "assignment": 7,
            "value": 2,
            "variable": 3,
            "violate": 1,
            "constraint": 1,
            "called": 1,
            "consistent": 3,
            "legal": 1,
            "complete": 2,
            "assigned": 1,
            "solution": 2,
            "csp": 2,
            "partial": 3,
            "leaf": 1,
            "unassigned": 1,
            "solving": 1,
            "np-complete": 1,
            "problem": 1,
            "general": 1,
            "important": 1,
            "subclass": 1,
            "solved": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para9",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 272,
              "end_char": 275,
              "context": "variable is assigned a value, and a\nsolution\nto a CSP is a consistent, complete assignment. A\npartial a"
            },
            {
              "para_id": "chap5_para9",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 458,
              "end_char": 461,
              "context": " partial assignment that is consistent. Solving a CSP is an NP-complete problem in general, although th"
            },
            {
              "para_id": "chap5_para9",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 468,
              "end_char": 470,
              "context": "ssignment that is consistent. Solving a CSP is an NP-complete problem in general, although there are i"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para10",
          "content": "5.1.1\nExample problem: Map coloring\nSuppose that, having tired of Romania, we are looking at a map of Australia showing each of its states and territories (\nFigure 5.1(a)\n). We are given the task of coloring each region either red, green, or blue in such a way that no two neighboring regions have the same color. To formulate this as a CSP, we define the variables to be the regions:\nDescription\nThe game tree has five rows of boxes. Each box has nine squares arranged in three rows and three columns.",
          "sentence_count": 4,
          "char_count": 417,
          "prev_para_id": "chap5_para9",
          "next_para_id": "chap5_para11",
          "style_metadata": {
            "para_id": "chap5_para10",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 4
          },
          "terminology": {
            "example": 1,
            "problem": 1,
            "map": 2,
            "coloring": 2,
            "tired": 1,
            "romania": 1,
            "looking": 1,
            "showing": 1,
            "state": 1,
            "territory": 1,
            "figure": 1,
            "given": 1,
            "task": 1,
            "region": 3,
            "red": 1,
            "green": 1,
            "blue": 1,
            "way": 1,
            "neighboring": 1,
            "color": 1,
            "formulate": 1,
            "csp": 1,
            "define": 1,
            "variable": 1,
            "description": 1,
            "game": 1,
            "tree": 1,
            "row": 2,
            "box": 2,
            "square": 1,
            "arranged": 1,
            "column": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para10",
              "entity_text": "Suppose",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 43,
              "context": "5.1.1\nExample problem: Map coloring\nSuppose that, having tired of Romania, we are looking at "
            },
            {
              "para_id": "chap5_para10",
              "entity_text": "Romania",
              "entity_type": "GPE",
              "start_char": 66,
              "end_char": 73,
              "context": "oblem: Map coloring\nSuppose that, having tired of Romania, we are looking at a map of Australia showing eac"
            },
            {
              "para_id": "chap5_para10",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 102,
              "end_char": 111,
              "context": "ving tired of Romania, we are looking at a map of Australia showing each of its states and territories (\nFigu"
            },
            {
              "para_id": "chap5_para10",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 337,
              "end_char": 340,
              "context": "gions have the same color. To formulate this as a CSP, we define the variables to be the regions:\nDescr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para11",
          "content": "The first row is labeled MAX (x) and has one square box with nine empty squares.",
          "sentence_count": 1,
          "char_count": 65,
          "prev_para_id": "chap5_para10",
          "next_para_id": "chap5_para12",
          "style_metadata": {
            "para_id": "chap5_para11",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.053,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "row": 1,
            "labeled": 1,
            "max": 1,
            "square": 2,
            "box": 1,
            "empty": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para11",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 25,
              "end_char": 28,
              "context": "The first row is labeled MAX (x) and has one square box with nine empty square"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para12",
          "content": "The second row is labeled MIN (o) and has nine boxes. The boxes in the second row show the nine possible squares the x can be placed.",
          "sentence_count": 2,
          "char_count": 107,
          "prev_para_id": "chap5_para11",
          "next_para_id": "chap5_para13",
          "style_metadata": {
            "para_id": "chap5_para12",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.032,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 2
          },
          "terminology": {
            "second": 2,
            "row": 2,
            "labeled": 1,
            "min": 1,
            "box": 2,
            "show": 1,
            "possible": 1,
            "square": 1,
            "placed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para12",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 29,
              "context": "The second row is labeled MIN (o) and has nine boxes. The boxes in the second r"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para13",
          "content": "The third row is labeled MAX (x) and shows the possibilities of placing an o after placing the x in the top left square of the first box in the second row. The first box in the third row has the x in the first column of the first row and an o in the second column. The other boxes in the third row show the other possible squares the o can be placed, given that an x is already placed in the top left square in each box.",
          "sentence_count": 3,
          "char_count": 332,
          "prev_para_id": "chap5_para12",
          "next_para_id": "chap5_para14",
          "style_metadata": {
            "para_id": "chap5_para13",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.67,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 95,
            "sentence_count": 3
          },
          "terminology": {
            "third": 3,
            "row": 5,
            "labeled": 1,
            "max": 1,
            "show": 2,
            "possibility": 1,
            "placing": 2,
            "top": 2,
            "left": 2,
            "square": 3,
            "first": 1,
            "box": 4,
            "second": 2,
            "column": 2,
            "possible": 1,
            "placed": 2,
            "given": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para13",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 25,
              "end_char": 28,
              "context": "The third row is labeled MAX (x) and shows the possibilities of placing an o a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para14",
          "content": "The fourth row is labeled MIN (o) and shows the possibilities of placing an x after placing an x and o in the top left and top mid squares. The first box in the fourth row has an x and an o in the first and second columns of the first row. The other boxes in the fourth row show the other possible squares the x can be placed, given that an x and an o are already placed in the top left and top mid squares in each box.",
          "sentence_count": 3,
          "char_count": 330,
          "prev_para_id": "chap5_para13",
          "next_para_id": "chap5_para15",
          "style_metadata": {
            "para_id": "chap5_para14",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.01,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 3
          },
          "terminology": {
            "fourth": 3,
            "row": 4,
            "labeled": 1,
            "min": 1,
            "show": 2,
            "possibility": 1,
            "placing": 2,
            "top": 4,
            "left": 2,
            "mid": 2,
            "square": 3,
            "box": 3,
            "second": 1,
            "column": 1,
            "possible": 1,
            "placed": 2,
            "given": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para14",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 29,
              "context": "The fourth row is labeled MIN (o) and shows the possibilities of placing an x a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para15",
          "content": "The rows continue this way and the last row is labeled TERMINAL. The last row shows three boxes representing three possible ends. The first box has a utility value of negative 1. The first box is filled column-wise as follows. Column 1: x, blank, blank. Column 2: o, o, o. Column 3: x, x, blank. The second box has a utility value of 0. The second box is filled row-wise as follows. Row 1: x, o, x. Row 2: o, o, x. Row 3: x, x, o. The third box has a utility value of positive 1. The third box is filled row-wise as follows. Row 1: x, o, x. Row 2: blank, x, blank. Row 3: x, o, o.",
          "sentence_count": 17,
          "char_count": 461,
          "prev_para_id": "chap5_para14",
          "next_para_id": "chap5_para16",
          "style_metadata": {
            "para_id": "chap5_para15",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.18,
            "passive_voice_ratio": 0.026,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 156,
            "sentence_count": 17
          },
          "terminology": {
            "row": 9,
            "continue": 1,
            "way": 1,
            "last": 2,
            "labeled": 1,
            "terminal": 1,
            "show": 1,
            "box": 7,
            "representing": 1,
            "possible": 1,
            "end": 1,
            "utility": 3,
            "value": 3,
            "negative": 1,
            "first": 1,
            "filled": 3,
            "column-wise": 1,
            "follows": 3,
            "column": 3,
            "blank": 5,
            "second": 2,
            "row-wise": 2,
            "third": 2,
            "positive": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para15",
              "entity_text": "TERMINAL",
              "entity_type": "ORG",
              "start_char": 55,
              "end_char": 63,
              "context": "ows continue this way and the last row is labeled TERMINAL. The last row shows three boxes representing thre"
            },
            {
              "para_id": "chap5_para15",
              "entity_text": "x. Row 2: o, o",
              "entity_type": "PERSON",
              "start_char": 396,
              "end_char": 410,
              "context": "d box is filled row-wise as follows. Row 1: x, o, x. Row 2: o, o, x. Row 3: x, x, o. The third box has a utility v"
            },
            {
              "para_id": "chap5_para15",
              "entity_text": "x. Row",
              "entity_type": "PERSON",
              "start_char": 412,
              "end_char": 418,
              "context": "row-wise as follows. Row 1: x, o, x. Row 2: o, o, x. Row 3: x, x, o. The third box has a utility value of "
            },
            {
              "para_id": "chap5_para15",
              "entity_text": "x. Row 2:",
              "entity_type": "PERSON",
              "start_char": 538,
              "end_char": 547,
              "context": "d box is filled row-wise as follows. Row 1: x, o, x. Row 2: blank, x, blank. Row 3: x, o, o."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para16",
          "content": "×\nFigure 5.1\n(a) The principal states and territories of Australia. Coloring this map can be viewed as a constraint satisfaction problem (CSP). The goal is to assign colors to each region so that no neighboring regions have the same color. (b) The map-coloring problem represented as a constraint graph.",
          "sentence_count": 4,
          "char_count": 256,
          "prev_para_id": "chap5_para15",
          "next_para_id": "chap5_para17",
          "style_metadata": {
            "para_id": "chap5_para16",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 60,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "principal": 1,
            "state": 1,
            "territory": 1,
            "australia": 1,
            "coloring": 1,
            "map": 1,
            "viewed": 1,
            "constraint": 2,
            "satisfaction": 1,
            "problem": 2,
            "csp": 1,
            "goal": 1,
            "assign": 1,
            "color": 2,
            "region": 2,
            "neighboring": 1,
            "map-coloring": 1,
            "represented": 1,
            "graph": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para16",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 57,
              "end_char": 66,
              "context": "e 5.1\n(a) The principal states and territories of Australia. Coloring this map can be viewed as a constraint "
            },
            {
              "para_id": "chap5_para16",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 138,
              "end_char": 141,
              "context": "n be viewed as a constraint satisfaction problem (CSP). The goal is to assign colors to each region so "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para17",
          "content": "χ\n= {\nW\nA\n,\nN\nT\n,\nQ\n,\nN\nS\nW\n,\nV\n,\nS\nA\n,\nT\n}\n.",
          "sentence_count": 1,
          "char_count": 45,
          "prev_para_id": "chap5_para16",
          "next_para_id": "chap5_para18",
          "style_metadata": {
            "para_id": "chap5_para17",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 23,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para18",
          "content": "The domain of every variable is the set\nD\ni\n= {\nred, green, blue\n}. The constraints require neighboring regions to have distinct colors. Since there are nine places where regions border, there are nine constraints:\nC\n=\n{\nS\nA\n≠\nW\nA\n,\nS\nA\n≠\nN\nT\n,\nS\nA\n≠\nQ\n,\nS\nA\n≠\nN\nS\nW\n,\nS\nA\n≠\nV\n,\nW\nA\n≠\nN\nT\n,\nN\nT\n≠\nQ\n,\nQ\n≠\nN\nS\nW\n,\nN\nS\nW\n≠\nV\n}\n.",
          "sentence_count": 3,
          "char_count": 295,
          "prev_para_id": "chap5_para17",
          "next_para_id": "chap5_para19",
          "style_metadata": {
            "para_id": "chap5_para18",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 99,
            "sentence_count": 3
          },
          "terminology": {
            "domain": 1,
            "variable": 1,
            "set": 1,
            "red": 1,
            "green": 1,
            "blue": 1,
            "constraint": 2,
            "require": 1,
            "neighboring": 1,
            "region": 2,
            "distinct": 1,
            "color": 1,
            "place": 1,
            "border": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para19",
          "content": "Here we are using abbreviations;\nSA ≠ WA\nis a shortcut for 〈(\nSA, WA\n),\nSA\n≠\nWA\n〉, where\nSA ≠ WA\ncan be fully enumerated in turn as\n{\n(\nr\ne\nd\n,\ng\nr\ne\ne\nn\n), (\nr\ne\nd\n,\nb\nl\nu\ne\n), (\ng\nr\ne\ne\nn\n,\nr\ne\nd\n), (\ng\nr\ne\ne\nn\n,\nb\nl\nu\ne\n), (\nb\nl\nu\ne\n,\nr\ne\nd\n), (\nb\nl\nu\ne\n,\ng\nr\ne\ne\nn\n)}\n.",
          "sentence_count": 1,
          "char_count": 253,
          "prev_para_id": "chap5_para18",
          "next_para_id": "chap5_para20",
          "style_metadata": {
            "para_id": "chap5_para19",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 110.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 110,
            "sentence_count": 1
          },
          "terminology": {
            "using": 1,
            "abbreviation": 1,
            "shortcut": 1,
            "enumerated": 1,
            "turn": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para19",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 33,
              "end_char": 35,
              "context": "Here we are using abbreviations;\nSA ≠ WA\nis a shortcut for 〈(\nSA, WA\n),\nSA\n≠\nWA\n〉, wh"
            },
            {
              "para_id": "chap5_para19",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 72,
              "end_char": 74,
              "context": "eviations;\nSA ≠ WA\nis a shortcut for 〈(\nSA, WA\n),\nSA\n≠\nWA\n〉, where\nSA ≠ WA\ncan be fully enumerated in "
            },
            {
              "para_id": "chap5_para19",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 89,
              "end_char": 91,
              "context": "A\nis a shortcut for 〈(\nSA, WA\n),\nSA\n≠\nWA\n〉, where\nSA ≠ WA\ncan be fully enumerated in turn as\n{\n(\nr\ne\nd"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para20",
          "content": "There are many possible solutions to this problem, such as\n{\nW\nA\n=\nr\ne\nd\n,\nN\nT\n=\ng\nr\ne\ne\nn\n,\nQ\n=\nr\ne\nd\n,\nN\nS\nW\n=\ng\nr\ne\ne\nn\n,\nV\n=\nr\ne\nd\n,\nS\nA\n=\nb\nl\nu\ne\n,\nT\n=\nr\ne\nd\n}\n.",
          "sentence_count": 1,
          "char_count": 157,
          "prev_para_id": "chap5_para19",
          "next_para_id": "chap5_para21",
          "style_metadata": {
            "para_id": "chap5_para20",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 65.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 1
          },
          "terminology": {
            "many": 1,
            "possible": 1,
            "solution": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para21",
          "content": "It can be helpful to visualize a CSP as a\nconstraint graph\n, as shown in\nFigure 5.1(b)\n. The nodes of the graph correspond to variables of the problem, and an edge connects any two variables that participate in a constraint.",
          "sentence_count": 2,
          "char_count": 187,
          "prev_para_id": "chap5_para20",
          "next_para_id": "chap5_para22",
          "style_metadata": {
            "para_id": "chap5_para21",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 2
          },
          "terminology": {
            "helpful": 1,
            "visualize": 1,
            "csp": 1,
            "constraint": 2,
            "graph": 2,
            "shown": 1,
            "figure": 1,
            "node": 1,
            "correspond": 1,
            "variable": 2,
            "problem": 1,
            "edge": 1,
            "connects": 1,
            "participate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para21",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 33,
              "end_char": 36,
              "context": "It can be helpful to visualize a CSP as a\nconstraint graph\n, as shown in\nFigure 5.1(b)"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para22",
          "content": "Why formulate a problem as a CSP? One reason is that the CSPs yield a natural representation for a wide variety of problems; it is often easy to formulate a problem as a CSP. Another is that years of development work have gone into making CSP solvers fast and efficient. A third is that a CSP solver can quickly prune large swathes of the search space that an atomic state-space searcher cannot. For example, once we have chosen {\nSA\n=\nblue\n} in the Australia problem, we can conclude that none of the five neighboring variables can take on the value\nblue\n. A search procedure that does not use constraints would have to consider 3\n5\n= 243 assignments for the five neighboring variables; with constraints we have only 2\n5\n= 32 assignments to consider, a reduction of 87%.",
          "sentence_count": 6,
          "char_count": 640,
          "prev_para_id": "chap5_para21",
          "next_para_id": "chap5_para23",
          "style_metadata": {
            "para_id": "chap5_para22",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 154,
            "sentence_count": 6
          },
          "terminology": {
            "formulate": 2,
            "problem": 4,
            "csp": 4,
            "reason": 1,
            "csps": 1,
            "yield": 1,
            "natural": 1,
            "representation": 1,
            "wide": 1,
            "variety": 1,
            "easy": 1,
            "year": 1,
            "development": 1,
            "work": 1,
            "gone": 1,
            "making": 1,
            "solver": 2,
            "efficient": 1,
            "third": 1,
            "prune": 1,
            "large": 1,
            "swathe": 1,
            "search": 2,
            "space": 1,
            "atomic": 1,
            "state-space": 1,
            "searcher": 1,
            "example": 1,
            "chosen": 1,
            "blue": 2,
            "australia": 1,
            "conclude": 1,
            "none": 1,
            "neighboring": 2,
            "variable": 2,
            "take": 1,
            "value": 1,
            "procedure": 1,
            "use": 1,
            "constraint": 2,
            "consider": 2,
            "assignment": 2,
            "reduction": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para22",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 29,
              "end_char": 32,
              "context": "Why formulate a problem as a CSP? One reason is that the CSPs yield a natural repr"
            },
            {
              "para_id": "chap5_para22",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 170,
              "end_char": 173,
              "context": "ems; it is often easy to formulate a problem as a CSP. Another is that years of development work have g"
            },
            {
              "para_id": "chap5_para22",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 239,
              "end_char": 242,
              "context": "t years of development work have gone into making CSP solvers fast and efficient. A third is that a CSP"
            },
            {
              "para_id": "chap5_para22",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 289,
              "end_char": 292,
              "context": "CSP solvers fast and efficient. A third is that a CSP solver can quickly prune large swathes of the sea"
            },
            {
              "para_id": "chap5_para22",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 450,
              "end_char": 459,
              "context": "example, once we have chosen {\nSA\n=\nblue\n} in the Australia problem, we can conclude that none of the five ne"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para23",
          "content": "In atomic state-space search we can only ask: is this specific state a goal? No? What about this one? With CSPs, once we find out that a partial assignment violates a constraint, we can immediately discard further refinements of the partial assignment. Furthermore, we can see\nwhy\nthe assignment is not a solution—we see which variables violate a constraint—so we can focus attention on the variables that matter. As a result, many problems that are intractable for atomic state-space search can be solved quickly when formulated as a CSP.",
          "sentence_count": 6,
          "char_count": 453,
          "prev_para_id": "chap5_para22",
          "next_para_id": "chap5_para24",
          "style_metadata": {
            "para_id": "chap5_para23",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 16.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "furthermore"
            ],
            "word_count": 100,
            "sentence_count": 6
          },
          "terminology": {
            "atomic": 2,
            "state-space": 2,
            "search": 2,
            "ask": 1,
            "specific": 1,
            "state": 1,
            "goal": 1,
            "csps": 1,
            "find": 1,
            "partial": 2,
            "assignment": 3,
            "violates": 1,
            "constraint": 1,
            "discard": 1,
            "refinement": 1,
            "see": 2,
            "solution—we": 1,
            "variable": 2,
            "violate": 1,
            "constraint—so": 1,
            "focus": 1,
            "attention": 1,
            "result": 1,
            "many": 1,
            "problem": 1,
            "intractable": 1,
            "solved": 1,
            "formulated": 1,
            "csp": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para23",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 535,
              "end_char": 538,
              "context": "search can be solved quickly when formulated as a CSP."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para24",
          "content": "5.1.2\nExample problem: Job-shop scheduling\nFactories have the problem of scheduling a day’s worth of jobs, subject to various constraints. In practice, many of these problems are solved with CSP techniques. Consider the problem of scheduling the assembly of a car. The whole job is composed of tasks, and we can model each task as a variable, where the value of each variable is the time that the task starts, expressed as an integer number of minutes. Constraints can assert that one task must occur before another—for example, a wheel must be installed before the hubcap is put on—and that only so many tasks can go on at once. Constraints can also specify that a task takes a certain amount of time to complete.",
          "sentence_count": 6,
          "char_count": 593,
          "prev_para_id": "chap5_para23",
          "next_para_id": "chap5_para25",
          "style_metadata": {
            "para_id": "chap5_para24",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.17,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 139,
            "sentence_count": 6
          },
          "terminology": {
            "example": 2,
            "problem": 4,
            "job-shop": 1,
            "scheduling": 3,
            "factory": 1,
            "day": 1,
            "job": 2,
            "subject": 1,
            "various": 1,
            "constraint": 3,
            "practice": 1,
            "many": 2,
            "solved": 1,
            "csp": 1,
            "technique": 1,
            "consider": 1,
            "assembly": 1,
            "car": 1,
            "whole": 1,
            "composed": 1,
            "task": 6,
            "variable": 2,
            "value": 1,
            "time": 2,
            "start": 1,
            "expressed": 1,
            "integer": 1,
            "number": 1,
            "minute": 1,
            "assert": 1,
            "occur": 1,
            "another—for": 1,
            "wheel": 1,
            "installed": 1,
            "hubcap": 1,
            "put": 1,
            "specify": 1,
            "take": 1,
            "certain": 1,
            "amount": 1,
            "complete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para24",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 191,
              "end_char": 194,
              "context": " practice, many of these problems are solved with CSP techniques. Consider the problem of scheduling th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para25",
          "content": "We consider a small part of the car assembly, consisting of 15 tasks: install axles (front and back), affix all four wheels (right and left, front and back), tighten nuts for each wheel, affix hubcaps, and inspect the final assembly. We can represent the tasks with 15 variables:\nχ\n=\n{\nA\nx\nl\ne\nF\n,\nA\nx\nl\ne\nB\n,\nW\nh\ne\ne\nl\nR\nF\n,\nW\nh\ne\ne\nl\nL\nF\n,\nW\nh\ne\ne\nl\nR\nB\n,\nW\nh\ne\ne\nl\nL\nB\n,\nN\nu\nt\ns\nR\nF\n,\nN\nu\nt\ns\nL\nF\n,\nN\nu\nt\ns\nR\nB\n,\nN\nu\nt\ns\nL\nB\n,\nC\na\np\nR\nF\n,\nC\na\np\nL\nF\n,\nC\na\np\nR\nB\n,\nC\na\np\nL\nB\n,\nI\nn\ns\np\ne\nc\nt\n}\n.",
          "sentence_count": 2,
          "char_count": 448,
          "prev_para_id": "chap5_para24",
          "next_para_id": "chap5_para26",
          "style_metadata": {
            "para_id": "chap5_para25",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 84.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 169,
            "sentence_count": 2
          },
          "terminology": {
            "consider": 1,
            "small": 1,
            "part": 1,
            "car": 1,
            "assembly": 2,
            "consisting": 1,
            "task": 2,
            "install": 1,
            "axle": 1,
            "front": 2,
            "wheel": 2,
            "left": 1,
            "tighten": 1,
            "nut": 1,
            "affix": 1,
            "hubcap": 1,
            "inspect": 1,
            "final": 1,
            "represent": 1,
            "variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para25",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 294,
              "end_char": 295,
              "context": "resent the tasks with 15 variables:\nχ\n=\n{\nA\nx\nl\ne\nF\n,\nA\nx\nl\ne\nB\n,\nW\nh\ne\ne\nl\nR\nF\n,\nW\nh\ne\ne\nl\nL\nF\n,\nW\nh"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para26",
          "content": "Next, we represent\nprecedence constraints\nbetween individual tasks. Whenever a task\nT\n1\nmust occur before task\nT\n2\n, and task\nT\n1\ntakes duration\nd\n1\nto complete, we add an arithmetic constraint of the form\nT\n1\n+\nd\n1\n≤\nT\n2\n:\nIn our example, the axles have to be in place before the wheels are put on, and it takes 10 minutes to install an axle, so we write\nA\nx\nl\ne\nF\n+ 10\n≤\nW\nh\ne\ne\nl\nR\nF\n;\nA\nx\nl\ne\nF\n+ 10\n≤\nW\nh\ne\ne\nl\nL\nF\n;\nA\nx\nl\ne\nB\n+ 10\n≤\nW\nh\ne\ne\nl\nR\nB\n;\nA\nx\nl\ne\nB\n+ 10\n≤\nW\nh\ne\ne\nl\nL\nB\n.",
          "sentence_count": 2,
          "char_count": 437,
          "prev_para_id": "chap5_para25",
          "next_para_id": "chap5_para27",
          "style_metadata": {
            "para_id": "chap5_para26",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 72.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 145,
            "sentence_count": 2
          },
          "terminology": {
            "next": 1,
            "represent": 1,
            "precedence": 1,
            "constraint": 2,
            "individual": 1,
            "task": 4,
            "occur": 1,
            "take": 2,
            "duration": 1,
            "complete": 1,
            "arithmetic": 1,
            "form": 1,
            "example": 1,
            "axle": 2,
            "place": 1,
            "wheel": 1,
            "put": 1,
            "minute": 1,
            "write": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para26",
              "entity_text": "F\n+",
              "entity_type": "PRODUCT",
              "start_char": 364,
              "end_char": 367,
              "context": "0 minutes to install an axle, so we write\nA\nx\nl\ne\nF\n+ 10\n≤\nW\nh\ne\ne\nl\nR\nF\n;\nA\nx\nl\ne\nF\n+ 10\n≤\nW\nh\ne\ne\nl\nL"
            },
            {
              "para_id": "chap5_para26",
              "entity_text": "F\n+",
              "entity_type": "PRODUCT",
              "start_char": 397,
              "end_char": 400,
              "context": "we write\nA\nx\nl\ne\nF\n+ 10\n≤\nW\nh\ne\ne\nl\nR\nF\n;\nA\nx\nl\ne\nF\n+ 10\n≤\nW\nh\ne\ne\nl\nL\nF\n;\nA\nx\nl\ne\nB\n+ 10\n≤\nW\nh\ne\ne\nl\nR"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para27",
          "content": "Next we say that for each wheel, we must affix the wheel (which takes 1 minute), then tighten the nuts (2 minutes), and finally attach the hubcap (1 minute, but not represented yet):\nW\nh\ne\ne\nl\nR\nF\n+\n1\n≤\nN\nu\nt\ns\nR\nF\n;\nN\nu\nt\ns\nR\nF\n+\n2\n≤\nC\na\np\nR\nF\n;\nW\nh\ne\ne\nl\nL\nF\n+\n1\n≤\nN\nu\nt\ns\nL\nF\n;\nN\nu\nt\ns\nL\nF\n+\n2\n≤\nC\na\np\nL\nF\n;\nW\nh\ne\ne\nl\nR\nB\n+\n1\n≤\nN\nu\nt\ns\nR\nB\n;\nN\nu\nt\ns\nR\nB\n+\n2\n≤\nC\na\np\nR\nB\n;\nW\nh\ne\ne\nl\nL\nB\n+\n1\n≤\nN\nu\nt\ns\nL\nB\n;\nN\nu\nt\ns\nL\nB\n+\n2\n≤\nC\na\np\nL\nB\n.",
          "sentence_count": 1,
          "char_count": 406,
          "prev_para_id": "chap5_para26",
          "next_para_id": "chap5_para28",
          "style_metadata": {
            "para_id": "chap5_para27",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 172.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 172,
            "sentence_count": 1
          },
          "terminology": {
            "next": 1,
            "say": 1,
            "wheel": 2,
            "affix": 1,
            "take": 1,
            "minute": 3,
            "tighten": 1,
            "nut": 1,
            "attach": 1,
            "hubcap": 1,
            "represented": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para27",
              "entity_text": "F\n+\n1\n≤\nN",
              "entity_type": "PRODUCT",
              "start_char": 195,
              "end_char": 204,
              "context": " (1 minute, but not represented yet):\nW\nh\ne\ne\nl\nR\nF\n+\n1\n≤\nN\nu\nt\ns\nR\nF\n;\nN\nu\nt\ns\nR\nF\n+\n2\n≤\nC\na\np\nR\nF\n;\nW\nh\ne\ne"
            },
            {
              "para_id": "chap5_para27",
              "entity_text": "F\n+\n2\n≤",
              "entity_type": "PRODUCT",
              "start_char": 227,
              "end_char": 234,
              "context": "yet):\nW\nh\ne\ne\nl\nR\nF\n+\n1\n≤\nN\nu\nt\ns\nR\nF\n;\nN\nu\nt\ns\nR\nF\n+\n2\n≤\nC\na\np\nR\nF\n;\nW\nh\ne\ne\nl\nL\nF\n+\n1\n≤\nN\nu\nt\ns\nL\nF\n;\nN\nu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para28",
          "content": "Suppose we have four workers to install wheels, but they have to share one tool that helps put the axle in place. We need a\ndisjunctive constraint\nto say that\nAxle\nF\nand\nAxle\nB\nmust not overlap in time; either one comes first or the other does:\n(\nA\nx\nl\ne\nF\n+ 10\n≤\nA\nx\nl\ne\nB\n)\no\nr\n(\nA\nx\nl\ne\nB\n+ 10\n≤\nA\nx\nl\ne\nF\n)\n.",
          "sentence_count": 2,
          "char_count": 273,
          "prev_para_id": "chap5_para27",
          "next_para_id": "chap5_para29",
          "style_metadata": {
            "para_id": "chap5_para28",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 2
          },
          "terminology": {
            "suppose": 1,
            "worker": 1,
            "install": 1,
            "wheel": 1,
            "share": 1,
            "tool": 1,
            "help": 1,
            "put": 1,
            "axle": 3,
            "place": 1,
            "need": 1,
            "disjunctive": 1,
            "constraint": 1,
            "say": 1,
            "overlap": 1,
            "time": 1,
            "come": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para28",
              "entity_text": "F\n+",
              "entity_type": "PRODUCT",
              "start_char": 255,
              "end_char": 258,
              "context": "ther one comes first or the other does:\n(\nA\nx\nl\ne\nF\n+ 10\n≤\nA\nx\nl\ne\nB\n)\no\nr\n(\nA\nx\nl\ne\nB\n+ 10\n≤\nA\nx\nl\ne\nF"
            },
            {
              "para_id": "chap5_para28",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 307,
              "end_char": 308,
              "context": "+ 10\n≤\nA\nx\nl\ne\nB\n)\no\nr\n(\nA\nx\nl\ne\nB\n+ 10\n≤\nA\nx\nl\ne\nF\n)\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para29",
          "content": "This looks like a more complicated constraint, combining arithmetic and logic. But it still reduces to a set of pairs of values that\nAxle\nF\nand\nAxle\nB\ncan take on.",
          "sentence_count": 2,
          "char_count": 139,
          "prev_para_id": "chap5_para28",
          "next_para_id": "chap5_para30",
          "style_metadata": {
            "para_id": "chap5_para29",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 2
          },
          "terminology": {
            "look": 1,
            "complicated": 1,
            "constraint": 1,
            "combining": 1,
            "arithmetic": 1,
            "logic": 1,
            "reduces": 1,
            "set": 1,
            "pair": 1,
            "value": 1,
            "axle": 2,
            "take": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para30",
          "content": "We also need to assert that the inspection comes last and takes 3 minutes. For every variable except\nInspect\nwe add a constraint of the form\nX\n+\nd\nX\n≤\nInspect\n. Finally, suppose there is a requirement to get the whole assembly done in 30 minutes. We can achieve that by limiting the domain of all variables:\nD\ni\n= {0,1,2,3,\n…\n,30}\n.",
          "sentence_count": 4,
          "char_count": 283,
          "prev_para_id": "chap5_para29",
          "next_para_id": "chap5_para31",
          "style_metadata": {
            "para_id": "chap5_para30",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 4
          },
          "terminology": {
            "need": 1,
            "assert": 1,
            "inspection": 1,
            "come": 1,
            "last": 1,
            "take": 1,
            "minute": 2,
            "variable": 2,
            "inspect": 2,
            "add": 1,
            "constraint": 1,
            "form": 1,
            "suppose": 1,
            "requirement": 1,
            "get": 1,
            "whole": 1,
            "assembly": 1,
            "done": 1,
            "achieve": 1,
            "limiting": 1,
            "domain": 1,
            ",30": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para31",
          "content": "This particular problem is trivial to solve, but CSPs have been successfully applied to jobshop scheduling problems like this with thousands of variables.",
          "sentence_count": 1,
          "char_count": 132,
          "prev_para_id": "chap5_para30",
          "next_para_id": "chap5_para32",
          "style_metadata": {
            "para_id": "chap5_para31",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "particular": 1,
            "problem": 2,
            "trivial": 1,
            "solve": 1,
            "csps": 1,
            "applied": 1,
            "jobshop": 1,
            "scheduling": 1,
            "thousand": 1,
            "variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para32",
          "content": "5.1.3\nVariations on the CSP formalism\nThe simplest kind of CSP involves variables that have\ndiscrete\n,\nfinite domains\n. Map-coloring problems and scheduling with time limits are both of this kind. The 8-queens problem (\nFigure 4.3\n) can also be viewed as a finite-domain CSP, where the variables\nQ\n1\n,...,\nQ\n8\ncorrespond to the queens in columns 1 to 8, and the domain of each variable specifies the possible row numbers for the queen in that column,\nD\ni\n= {1,2,3,4,5,6,7,8}. The constraints say that no two queens can be in the same row or diagonal.",
          "sentence_count": 4,
          "char_count": 468,
          "prev_para_id": "chap5_para31",
          "next_para_id": "chap5_para33",
          "style_metadata": {
            "para_id": "chap5_para32",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 110,
            "sentence_count": 4
          },
          "terminology": {
            "variation": 1,
            "csp": 3,
            "formalism": 1,
            "simplest": 1,
            "kind": 2,
            "involves": 1,
            "variable": 3,
            "discrete": 1,
            "finite": 1,
            "domain": 2,
            "map-coloring": 1,
            "problem": 2,
            "scheduling": 1,
            "time": 1,
            "limit": 1,
            "8-queens": 1,
            "figure": 1,
            "viewed": 1,
            "finite-domain": 1,
            "correspond": 1,
            "queen": 3,
            "column": 2,
            "specifies": 1,
            "possible": 1,
            "row": 2,
            "number": 1,
            "constraint": 1,
            "say": 1,
            "diagonal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para32",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 24,
              "end_char": 27,
              "context": "5.1.3\nVariations on the CSP formalism\nThe simplest kind of CSP involves varia"
            },
            {
              "para_id": "chap5_para32",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 59,
              "end_char": 62,
              "context": "iations on the CSP formalism\nThe simplest kind of CSP involves variables that have\ndiscrete\n,\nfinite do"
            },
            {
              "para_id": "chap5_para32",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 271,
              "end_char": 274,
              "context": "igure 4.3\n) can also be viewed as a finite-domain CSP, where the variables\nQ\n1\n,...,\nQ\n8\ncorrespond to "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para33",
          "content": "A discrete domain can be\ninfinite\n, such as the set of integers or strings. (If we didn’t put a deadline on the job-scheduling problem, there would be an infinite number of start times for each variable.) With infinite domains, we must use implicit constraints like\nT\n1\n+\nd\n1\n≤\nT\n2\nrather than explicit tuples of values. Special solution algorithms (which we do not discuss here) exist for\nlinear constraints\non integer variables—that is, constraints, such as the one just given, in which each variable appears only in linear form. It can be shown that no algorithm exists for solving general\nnonlinear constraints\non integer variables—the problem is undecidable.",
          "sentence_count": 5,
          "char_count": 567,
          "prev_para_id": "chap5_para32",
          "next_para_id": "chap5_para34",
          "style_metadata": {
            "para_id": "chap5_para33",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 5
          },
          "terminology": {
            "discrete": 1,
            "domain": 2,
            "infinite": 3,
            "set": 1,
            "integer": 3,
            "string": 1,
            "put": 1,
            "deadline": 1,
            "job-scheduling": 1,
            "problem": 2,
            "number": 1,
            "start": 1,
            "time": 1,
            "variable": 2,
            "use": 1,
            "implicit": 1,
            "constraint": 4,
            "explicit": 1,
            "tuples": 1,
            "value": 1,
            "special": 1,
            "solution": 1,
            "discus": 1,
            "exist": 1,
            "linear": 2,
            "given": 1,
            "appears": 1,
            "form": 1,
            "shown": 1,
            "algorithm": 1,
            "exists": 1,
            "solving": 1,
            "general": 1,
            "nonlinear": 1,
            "variables—the": 1,
            "undecidable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para34",
          "content": "Constraint satisfaction problems with\ncontinuous domains\nare common in the real world and are widely studied in the field of operations research. For example, the scheduling of experiments on the Hubble Space Telescope requires very precise timing of observations; the start and finish of each observation and maneuver are continuous-valued variables that must obey a variety of astronomical, precedence, and power constraints. The best-known category of continuous-domain CSPs is that of\nlinear programming\nproblems, where constraints must be linear equalities or inequalities. Linear programming problems can be solved in time polynomial in the number of variables. Problems with different types of constraints and objective functions have also been studied—quadratic programming, second-order conic programming, and so on. These problems constitute an important area of applied mathematics.",
          "sentence_count": 6,
          "char_count": 773,
          "prev_para_id": "chap5_para33",
          "next_para_id": "chap5_para35",
          "style_metadata": {
            "para_id": "chap5_para34",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 138,
            "sentence_count": 6
          },
          "terminology": {
            "constraint": 4,
            "satisfaction": 1,
            "problem": 5,
            "continuous": 1,
            "domain": 1,
            "common": 1,
            "real": 1,
            "world": 1,
            "studied": 1,
            "field": 1,
            "operation": 1,
            "research": 1,
            "example": 1,
            "scheduling": 1,
            "experiment": 1,
            "hubble": 1,
            "space": 1,
            "telescope": 1,
            "requires": 1,
            "precise": 1,
            "timing": 1,
            "observation": 2,
            "start": 1,
            "finish": 1,
            "continuous-valued": 1,
            "variable": 2,
            "obey": 1,
            "variety": 1,
            "astronomical": 1,
            "precedence": 1,
            "power": 1,
            "best-known": 1,
            "category": 1,
            "continuous-domain": 1,
            "csps": 1,
            "programming": 4,
            "linear": 2,
            "equality": 1,
            "inequality": 1,
            "solved": 1,
            "time": 1,
            "polynomial": 1,
            "number": 1,
            "different": 1,
            "type": 1,
            "objective": 1,
            "function": 1,
            "studied—quadratic": 1,
            "second-order": 1,
            "conic": 1,
            "constitute": 1,
            "important": 1,
            "area": 1,
            "applied": 1,
            "mathematics": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para34",
              "entity_text": "Linear",
              "entity_type": "ORG",
              "start_char": 579,
              "end_char": 585,
              "context": "raints must be linear equalities or inequalities. Linear programming problems can be solved in time polyno"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para35",
          "content": "In addition to examining the types of variables that can appear in CSPs, it is useful to look at the types of constraints. The simplest type is the\nunary constraint\n, which restricts the value of a single variable. For example, in the map-coloring problem it could be the case that South Australians won’t tolerate the color green; we can express that with the unary constraint 〈(\nSA\n),\nSA\n≠\ngreen\n〉. (The initial specification of the domain of a variable can also be seen as a unary constraint.)\nA\nbinary constraint\nrelates two variables. For example,\nSA ≠ NSW\nis a binary constraint. A\nbinary CSP\nis one with only unary and binary constraints; it can be represented as a constraint graph, as in\nFigure 5.1(b)\n.",
          "sentence_count": 7,
          "char_count": 601,
          "prev_para_id": "chap5_para34",
          "next_para_id": "chap5_para36",
          "style_metadata": {
            "para_id": "chap5_para35",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 7
          },
          "terminology": {
            "addition": 1,
            "examining": 1,
            "type": 3,
            "variable": 4,
            "appear": 1,
            "csps": 1,
            "useful": 1,
            "look": 1,
            "constraint": 8,
            "simplest": 1,
            "unary": 4,
            "restricts": 1,
            "value": 1,
            "single": 1,
            "example": 2,
            "map-coloring": 1,
            "problem": 1,
            "case": 1,
            "south": 1,
            "australian": 1,
            "tolerate": 1,
            "color": 1,
            "green": 2,
            "express": 1,
            "initial": 1,
            "specification": 1,
            "domain": 1,
            "seen": 1,
            "binary": 4,
            "relates": 1,
            "nsw": 1,
            "csp": 1,
            "represented": 1,
            "graph": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para35",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 387,
              "end_char": 389,
              "context": "n express that with the unary constraint 〈(\nSA\n),\nSA\n≠\ngreen\n〉. (The initial specification of the doma"
            },
            {
              "para_id": "chap5_para35",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 553,
              "end_char": 555,
              "context": "ry constraint\nrelates two variables. For example,\nSA ≠ NSW\nis a binary constraint. A\nbinary CSP\nis one"
            },
            {
              "para_id": "chap5_para35",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 595,
              "end_char": 598,
              "context": "xample,\nSA ≠ NSW\nis a binary constraint. A\nbinary CSP\nis one with only unary and binary constraints; it"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para36",
          "content": "We can also define higher-order constraints. The ternary constraint\nBetween\n(\nX, Y, Z\n), for example, can be defined as 〈(\nX, Y, Z\n),\nX\n<\nY\n<\nZ\nor\nX\n>\nY\n>\nZ\n〉.",
          "sentence_count": 2,
          "char_count": 140,
          "prev_para_id": "chap5_para35",
          "next_para_id": "chap5_para37",
          "style_metadata": {
            "para_id": "chap5_para36",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 48,
            "sentence_count": 2
          },
          "terminology": {
            "define": 1,
            "higher-order": 1,
            "constraint": 2,
            "ternary": 1,
            "example": 1,
            "defined": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para37",
          "content": "A constraint involving an arbitrary number of variables is called a\nglobal constraint\n. (The name is traditional but confusing because a global constraint need not involve\nall\nthe variables in a problem). One of the most common global constraints is\nAlldiff\n, which says that all of the variables involved in the constraint must have different values. In Sudoku problems (see\nSection 5.2.6\n), all variables in a row, column, or 3 × 3 box must satisfy an\nAlldiff\nconstraint.",
          "sentence_count": 4,
          "char_count": 403,
          "prev_para_id": "chap5_para36",
          "next_para_id": "chap5_para38",
          "style_metadata": {
            "para_id": "chap5_para37",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 90,
            "sentence_count": 4
          },
          "terminology": {
            "constraint": 6,
            "involving": 1,
            "arbitrary": 1,
            "number": 1,
            "variable": 4,
            "called": 1,
            "global": 3,
            "name": 1,
            "traditional": 1,
            "confusing": 1,
            "need": 1,
            "involve": 1,
            "problem": 2,
            "common": 1,
            "alldiff": 2,
            "say": 1,
            "involved": 1,
            "different": 1,
            "value": 1,
            "sudoku": 1,
            "see": 1,
            "section": 1,
            "row": 1,
            "column": 1,
            "box": 1,
            "satisfy": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para38",
          "content": "Another example is provided by\ncryptarithmetic\npuzzles (\nFigure 5.2(a)\n). Each letter in a cryptarithmetic puzzle represents a different digit. For the case in\nFigure 5.2(a)\n, this would be represented as the global constraint\nAlldiff\n(\nF, T, U, W, R, O\n). The addition constraints on the four columns of the puzzle can be written as the following n-ary constraints:\nDescription\nUp and down triangles represent MAX and MIN nodes, respectively. The first level of the game tree is labeled MAX and the MAX node is labeled \"A\". Node \"A\" is marked 3 and has three child nodes. The second level is labeled MIN and the three child nodes are MIN nodes that are labeled B, C, and D. An arrow labeled “a” subscript 1 from node “a” points to node B. Paths labeled “a” subscript 2 and “a” subscript 3 from node “a” connect to nodes C and D, respectively. The three nodes each have three child nodes that are MAX nodes. Node B is marked 3, C is marked 2, and D is marked 2. The three child nodes of B are marked 3, 12, and 8. Paths labeled b subscript 1, b subscript 2, and b subscript 3 connect node B to nodes 3, 12, and 8, respectively. The three child nodes of C are marked 2, 4, and 6. Paths labeled c subscript 1, c subscript 2, and c subscript 3 connect node C to nodes 2, 4, and 6, respectively. The three child nodes of D are marked 14, 5, and 2. Paths labeled d subscript 1, d subscript 2, and d subscript 3 connect node D to nodes 14, 5, and 2, respectively.",
          "sentence_count": 16,
          "char_count": 1188,
          "prev_para_id": "chap5_para37",
          "next_para_id": "chap5_para39",
          "style_metadata": {
            "para_id": "chap5_para38",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.62,
            "passive_voice_ratio": 0.023,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 346,
            "sentence_count": 16
          },
          "terminology": {
            "example": 1,
            "provided": 1,
            "cryptarithmetic": 2,
            "puzzle": 3,
            "figure": 2,
            "letter": 1,
            "represents": 1,
            "different": 1,
            "digit": 1,
            "case": 1,
            "represented": 1,
            "global": 1,
            "constraint": 3,
            "alldiff": 1,
            "addition": 1,
            "column": 1,
            "written": 1,
            "following": 1,
            "n-ary": 1,
            "description": 1,
            "triangle": 1,
            "represent": 1,
            "max": 4,
            "min": 3,
            "node": 22,
            "first": 1,
            "level": 2,
            "game": 1,
            "tree": 1,
            "labeled": 9,
            "marked": 7,
            "child": 6,
            "second": 1,
            "subscript": 12,
            "point": 1,
            "path": 4,
            "connect": 4,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para38",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 237,
              "end_char": 238,
              "context": "be represented as the global constraint\nAlldiff\n(\nF, T, U, W, R, O\n). The addition constraints on the"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "U, W",
              "entity_type": "ORG",
              "start_char": 243,
              "end_char": 247,
              "context": "resented as the global constraint\nAlldiff\n(\nF, T, U, W, R, O\n). The addition constraints on the four col"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 411,
              "end_char": 414,
              "context": "ints:\nDescription\nUp and down triangles represent MAX and MIN nodes, respectively. The first level of t"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 419,
              "end_char": 422,
              "context": "scription\nUp and down triangles represent MAX and MIN nodes, respectively. The first level of the game "
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 488,
              "end_char": 491,
              "context": "vely. The first level of the game tree is labeled MAX and the MAX node is labeled \"A\". Node \"A\" is mark"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 500,
              "end_char": 503,
              "context": "rst level of the game tree is labeled MAX and the MAX node is labeled \"A\". Node \"A\" is marked 3 and has"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 525,
              "end_char": 529,
              "context": "e is labeled MAX and the MAX node is labeled \"A\". Node \"A\" is marked 3 and has three child nodes. The se"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 601,
              "end_char": 604,
              "context": "as three child nodes. The second level is labeled MIN and the three child nodes are MIN nodes that are "
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 635,
              "end_char": 638,
              "context": "evel is labeled MIN and the three child nodes are MIN nodes that are labeled B, C, and D. An arrow labe"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 713,
              "end_char": 717,
              "context": ", C, and D. An arrow labeled “a” subscript 1 from node “a” points to node B. Paths labeled “a” subscript"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 897,
              "end_char": 900,
              "context": " three nodes each have three child nodes that are MAX nodes. Node B is marked 3, C is marked 2, and D i"
            },
            {
              "para_id": "chap5_para38",
              "entity_text": "Node B",
              "entity_type": "PERSON",
              "start_char": 908,
              "end_char": 914,
              "context": "s each have three child nodes that are MAX nodes. Node B is marked 3, C is marked 2, and D is marked 2. Th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para39",
          "content": "×\nFigure 5.2\n(a) A cryptarithmetic problem. Each letter stands for a distinct digit; the aim is to find a substitution of digits for letters such that the resulting sum is arithmetically correct, with the added restriction that no leading zeroes are allowed. (b) The constraint hypergraph for the cryptarithmetic problem, showing the\nAlldiff\nconstraint (square box at the top) as well as the column addition constraints (four square boxes in the middle). The variables\nC\n1\n,\nC\n2\n, and\nC\n3\nrepresent the carry digits for the three columns from right to left.",
          "sentence_count": 4,
          "char_count": 475,
          "prev_para_id": "chap5_para38",
          "next_para_id": "chap5_para40",
          "style_metadata": {
            "para_id": "chap5_para39",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 111,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "cryptarithmetic": 2,
            "problem": 2,
            "letter": 2,
            "stand": 1,
            "distinct": 1,
            "digit": 3,
            "aim": 1,
            "find": 1,
            "substitution": 1,
            "resulting": 1,
            "sum": 1,
            "correct": 1,
            "added": 1,
            "restriction": 1,
            "leading": 1,
            "zero": 1,
            "allowed": 1,
            "constraint": 3,
            "showing": 1,
            "alldiff": 1,
            "square": 2,
            "box": 2,
            "top": 1,
            "column": 2,
            "addition": 1,
            "middle": 1,
            "variable": 1,
            "represent": 1,
            "carry": 1,
            "left": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para40",
          "content": "O\n+\nO\n=\nR\n+\n10\n⋅\nC\n1\nC\n1\n+\nW\n+\nW\n=\nU\n+10\n⋅\nC\n2\nC\n2\n+\nT\n+\nT\n=\nO\n+\n10\n⋅\nC\n3\nC\n3\n=\nF\n,\nwhere\nC\n1\n,\nC\n2\n, and\nC\n3\nare auxiliary variables representing the digit carried over into the tens, hundreds, or thousands column. These constraints can be represented in a\nconstraint hypergraph\n, such as the one shown in\nFigure 5.2(b)\n. A hypergraph consists of ordinary nodes (the circles in the figure) and hypernodes (the squares), which represent\nn\n-ary constraints—constraints involving\nn\nvariables.",
          "sentence_count": 3,
          "char_count": 441,
          "prev_para_id": "chap5_para39",
          "next_para_id": "chap5_para41",
          "style_metadata": {
            "para_id": "chap5_para40",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 119,
            "sentence_count": 3
          },
          "terminology": {
            "+10": 1,
            "auxiliary": 1,
            "variable": 2,
            "representing": 1,
            "digit": 1,
            "carried": 1,
            "ten": 1,
            "hundred": 1,
            "thousand": 1,
            "column": 1,
            "constraint": 2,
            "represented": 1,
            "hypergraph": 2,
            "shown": 1,
            "figure": 2,
            "consists": 1,
            "ordinary": 1,
            "node": 1,
            "circle": 1,
            "hypernodes": 1,
            "square": 1,
            "represent": 1,
            "-ary": 1,
            "constraints—constraints": 1,
            "involving": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para40",
              "entity_text": "F",
              "entity_type": "PRODUCT",
              "start_char": 80,
              "end_char": 81,
              "context": "\nW\n=\nU\n+10\n⋅\nC\n2\nC\n2\n+\nT\n+\nT\n=\nO\n+\n10\n⋅\nC\n3\nC\n3\n=\nF\n,\nwhere\nC\n1\n,\nC\n2\n, and\nC\n3\nare auxiliary variabl"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para41",
          "content": "Alternatively, as Exercise\n5.",
          "sentence_count": 1,
          "char_count": 27,
          "prev_para_id": "chap5_para40",
          "next_para_id": "chap5_para42",
          "style_metadata": {
            "para_id": "chap5_para41",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 6,
            "sentence_count": 1
          },
          "terminology": {
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para42",
          "content": "NARY\nasks you to prove, every finite-domain constraint can be reduced to a set of binary constraints if enough auxiliary variables are introduced. This means that we could transform any CSP into one with only binary constraints—which certainly makes the life of the algorithm designer simpler. Another way to convert an\nn\n-ary CSP to a binary one is the\ndual graph\ntransformation: create a new graph in which there will be one variable for each constraint in the original graph, and one binary constraint for each pair of constraints in the original graph that share variables.",
          "sentence_count": 3,
          "char_count": 486,
          "prev_para_id": "chap5_para41",
          "next_para_id": "chap5_para43",
          "style_metadata": {
            "para_id": "chap5_para42",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 3
          },
          "terminology": {
            "nary": 1,
            "asks": 1,
            "prove": 1,
            "finite-domain": 1,
            "constraint": 5,
            "reduced": 1,
            "set": 1,
            "binary": 4,
            "auxiliary": 1,
            "variable": 3,
            "introduced": 1,
            "mean": 1,
            "transform": 1,
            "csp": 2,
            "constraints—which": 1,
            "make": 1,
            "life": 1,
            "algorithm": 1,
            "designer": 1,
            "simpler": 1,
            "way": 1,
            "convert": 1,
            "-ary": 1,
            "dual": 1,
            "graph": 4,
            "transformation": 1,
            "create": 1,
            "new": 1,
            "original": 2,
            "pair": 1,
            "share": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para42",
              "entity_text": "NARY",
              "entity_type": "GPE",
              "start_char": 0,
              "end_char": 4,
              "context": "NARY\nasks you to prove, every finite-domain constraint"
            },
            {
              "para_id": "chap5_para42",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 186,
              "end_char": 189,
              "context": "ntroduced. This means that we could transform any CSP into one with only binary constraints—which certa"
            },
            {
              "para_id": "chap5_para42",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 327,
              "end_char": 330,
              "context": "esigner simpler. Another way to convert an\nn\n-ary CSP to a binary one is the\ndual graph\ntransformation:"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para43",
          "content": "For example, consider a CSP with the variables\nχ\n= {\nX, Y, Z\n}, each with the domain {1,2,3,4,5}, and with the two constraints\nC\n1\n: 〈(\nX ,Y, Z\n),\nX\n+\nY\n=\nZ\n〉 and\nC\n2\n: 〈(\nX, Y\n),\nX\n+1 =\nY\n〉. Then the dual graph would have the variables\nχ\n= {\nC\n1\n,\nC\n2\n}, where the domain of the\nC\n1\nvariable in the dual graph is the set of {(\nx\ni\n,\ny\nj\n,\nz\nk\n)} tuples from the\nC\n1\nconstraint in the original problem, and similarly the domain of\nC\n2\nis the set of {(\nx\ni\n,\ny\nj\n)} tuples. The dual graph has the binary constraint 〈(\nC\n1\n,\nC\n2\n),\nR\n1\n〉, where\nR\n1\nis a new relation that defines the constraint between\nC\n1\nand\nC\n2\n; in this case it would be\nR\n1\n= {((1,2,3), (1,2)), ((2,3,5), (2,3))}.",
          "sentence_count": 3,
          "char_count": 589,
          "prev_para_id": "chap5_para42",
          "next_para_id": "chap5_para44",
          "style_metadata": {
            "para_id": "chap5_para43",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 71.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 215,
            "sentence_count": 3
          },
          "terminology": {
            "example": 1,
            "consider": 1,
            "csp": 1,
            "variable": 3,
            "domain": 3,
            "constraint": 4,
            "dual": 3,
            "graph": 3,
            "set": 2,
            "tuples": 2,
            "original": 1,
            "problem": 1,
            "binary": 1,
            "new": 1,
            "relation": 1,
            "defines": 1,
            "case": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para43",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 24,
              "end_char": 27,
              "context": "For example, consider a CSP with the variables\nχ\n= {\nX, Y, Z\n}, each with the"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para44",
          "content": "There are however two reasons why we might prefer a global constraint such as\nAlldiff\nrather than a set of binary constraints. First, it is easier and less error-prone to write the problem description using\nAlldiff\n. Second, it is possible to design special-purpose inference algorithms for global constraints that are more efficient than operating with primitive constraints. We describe these inference algorithms in\nSection 5.2.5\n.",
          "sentence_count": 4,
          "char_count": 374,
          "prev_para_id": "chap5_para43",
          "next_para_id": "chap5_para45",
          "style_metadata": {
            "para_id": "chap5_para44",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 17.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 71,
            "sentence_count": 4
          },
          "terminology": {
            "reason": 1,
            "prefer": 1,
            "global": 2,
            "constraint": 4,
            "alldiff": 2,
            "set": 1,
            "binary": 1,
            "easier": 1,
            "error-prone": 1,
            "write": 1,
            "problem": 1,
            "description": 1,
            "using": 1,
            "second": 1,
            "possible": 1,
            "design": 1,
            "special-purpose": 1,
            "inference": 2,
            "algorithm": 2,
            "efficient": 1,
            "operating": 1,
            "primitive": 1,
            "describe": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para45",
          "content": "The constraints we have described so far have all been absolute constraints, violation of which rules out a potential solution. Many real-world CSPs include\npreference constraints\nindicating which solutions are preferred. For example, in a university class-scheduling problem there are absolute constraints that no professor can teach two classes at the same time. But we also may allow preference constraints: Prof. R might prefer teaching in the morning, whereas Prof. N prefers teaching in the afternoon. A schedule that has Prof. R teaching at 2 p.m. would still be an allowable solution (unless Prof. R happens to be the department chair) but would not be an optimal one.",
          "sentence_count": 5,
          "char_count": 571,
          "prev_para_id": "chap5_para44",
          "next_para_id": "chap5_para46",
          "style_metadata": {
            "para_id": "chap5_para45",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 119,
            "sentence_count": 5
          },
          "terminology": {
            "constraint": 5,
            "described": 1,
            "absolute": 2,
            "violation": 1,
            "rule": 1,
            "potential": 1,
            "solution": 3,
            "many": 1,
            "real-world": 1,
            "csps": 1,
            "include": 1,
            "preference": 2,
            "indicating": 1,
            "preferred": 1,
            "example": 1,
            "university": 1,
            "class-scheduling": 1,
            "problem": 1,
            "professor": 1,
            "teach": 1,
            "class": 1,
            "time": 1,
            "allow": 1,
            "prof.": 4,
            "prefer": 1,
            "teaching": 3,
            "morning": 1,
            "whereas": 1,
            "prefers": 1,
            "afternoon": 1,
            "schedule": 1,
            "p.m.": 1,
            "allowable": 1,
            "happens": 1,
            "department": 1,
            "chair": 1,
            "optimal": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para46",
          "content": "Preference constraints can often be encoded as costs on individual variable assignments—for example, assigning an afternoon slot for Prof. R costs 2 points against the overall objective function, whereas a morning slot costs 1. With this formulation, CSPs with preferences can be solved with optimization search methods, either path-based or local. We call such a problem a\nconstrained optimization problem\n, or COP. Linear programs are one class of COPs.",
          "sentence_count": 4,
          "char_count": 388,
          "prev_para_id": "chap5_para45",
          "next_para_id": "chap5_para47",
          "style_metadata": {
            "para_id": "chap5_para46",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 77,
            "sentence_count": 4
          },
          "terminology": {
            "preference": 2,
            "constraint": 1,
            "encoded": 1,
            "cost": 3,
            "individual": 1,
            "variable": 1,
            "assignments—for": 1,
            "example": 1,
            "assigning": 1,
            "afternoon": 1,
            "slot": 2,
            "prof.": 1,
            "point": 1,
            "overall": 1,
            "objective": 1,
            "function": 1,
            "morning": 1,
            "formulation": 1,
            "csps": 1,
            "solved": 1,
            "optimization": 2,
            "search": 1,
            "method": 1,
            "path-based": 1,
            "local": 1,
            "call": 1,
            "problem": 2,
            "constrained": 1,
            "cop": 2,
            "linear": 1,
            "program": 1,
            "class": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para46",
              "entity_text": "COP",
              "entity_type": "ORG",
              "start_char": 412,
              "end_char": 415,
              "context": "a problem a\nconstrained optimization problem\n, or COP. Linear programs are one class of COPs."
            },
            {
              "para_id": "chap5_para46",
              "entity_text": "Linear",
              "entity_type": "ORG",
              "start_char": 417,
              "end_char": 423,
              "context": "blem a\nconstrained optimization problem\n, or COP. Linear programs are one class of COPs."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para47",
          "content": "5.2Constraint Propagation: Inference in CSPs\n5.2\nConstraint Propagation: Inference in CSPs\nAn atomic state-space search algorithm makes progress in only one way: by expanding a node to visit the successors. A CSP algorithm has choices. It can generate successors by choosing a new variable assignment, or it can do a specific type of inference called\nconstraint propagation\n: using the constraints to reduce the number of legal values for a variable, which\nin turn can reduce the legal values for another variable, and so on. The idea is that this will leave fewer choices to consider when we make the next choice of a variable assignment. Constraint propagation may be intertwined with search, or it may be done as a preprocessing step, before search starts. Sometimes this preprocessing can solve the whole problem, so no search is required at all.",
          "sentence_count": 6,
          "char_count": 717,
          "prev_para_id": "chap5_para46",
          "next_para_id": "chap5_para48",
          "style_metadata": {
            "para_id": "chap5_para47",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.83,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 155,
            "sentence_count": 6
          },
          "terminology": {
            "propagation": 4,
            "inference": 3,
            "csps": 2,
            "constraint": 4,
            "atomic": 1,
            "state-space": 1,
            "search": 4,
            "algorithm": 2,
            "make": 2,
            "way": 1,
            "expanding": 1,
            "node": 1,
            "visit": 1,
            "successor": 2,
            "csp": 1,
            "choice": 3,
            "generate": 1,
            "choosing": 1,
            "new": 1,
            "variable": 4,
            "assignment": 2,
            "specific": 1,
            "type": 1,
            "called": 1,
            "using": 1,
            "reduce": 2,
            "number": 1,
            "legal": 2,
            "value": 2,
            "turn": 1,
            "idea": 1,
            "leave": 1,
            "fewer": 1,
            "consider": 1,
            "next": 1,
            "intertwined": 1,
            "done": 1,
            "preprocessing": 2,
            "step": 1,
            "start": 1,
            "solve": 1,
            "whole": 1,
            "problem": 1,
            "required": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para47",
              "entity_text": "5.2Constraint Propagation: Inference",
              "entity_type": "ORG",
              "start_char": 0,
              "end_char": 36,
              "context": "5.2Constraint Propagation: Inference in CSPs\n5.2\nConstraint Propagation: Inference in "
            },
            {
              "para_id": "chap5_para47",
              "entity_text": "Constraint Propagation: Inference",
              "entity_type": "ORG",
              "start_char": 49,
              "end_char": 82,
              "context": "5.2Constraint Propagation: Inference in CSPs\n5.2\nConstraint Propagation: Inference in CSPs\nAn atomic state-space search algorithm ma"
            },
            {
              "para_id": "chap5_para47",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 177,
              "end_char": 181,
              "context": "hm makes progress in only one way: by expanding a node to visit the successors. A CSP algorithm has choi"
            },
            {
              "para_id": "chap5_para47",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 209,
              "end_char": 212,
              "context": "y: by expanding a node to visit the successors. A CSP algorithm has choices. It can generate successors"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para48",
          "content": "The key idea is\nlocal consistency\n. If we treat each variable as a node in a graph (see\nFigure 5.1(b)\n) and each binary constraint as an edge, then the process of enforcing local consistency in each part of the graph causes inconsistent values to be eliminated throughout the graph. There are different types of local consistency, which we now cover in turn.",
          "sentence_count": 3,
          "char_count": 299,
          "prev_para_id": "chap5_para47",
          "next_para_id": "chap5_para49",
          "style_metadata": {
            "para_id": "chap5_para48",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 3
          },
          "terminology": {
            "key": 1,
            "idea": 1,
            "local": 3,
            "consistency": 3,
            "treat": 1,
            "variable": 1,
            "node": 1,
            "graph": 3,
            "see": 1,
            "figure": 1,
            "binary": 1,
            "constraint": 1,
            "edge": 1,
            "process": 1,
            "enforcing": 1,
            "part": 1,
            "cause": 1,
            "inconsistent": 1,
            "value": 1,
            "eliminated": 1,
            "different": 1,
            "type": 1,
            "cover": 1,
            "turn": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para49",
          "content": "5.2.1\nNode consistency\nA single variable (corresponding to a node in the CSP graph) is\nnode-consistent\nif all the values in the variable’s domain satisfy the variable’s unary constraints. For example, in the variant of the Australia map-coloring problem (\nFigure 5.1\n) where South Australians dislike green, the variable\nSA\nstarts with domain {\nred,green,blue\n}\n,\nand we can make it node consistent by eliminating\ngreen,\nleaving\nSA\nwith the reduced domain {\nred, blue\n}. We say that a graph is node-consistent if every variable in the graph is node-consistent.",
          "sentence_count": 3,
          "char_count": 486,
          "prev_para_id": "chap5_para48",
          "next_para_id": "chap5_para50",
          "style_metadata": {
            "para_id": "chap5_para49",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 110,
            "sentence_count": 3
          },
          "terminology": {
            "node": 3,
            "consistency": 1,
            "single": 1,
            "variable": 5,
            "corresponding": 1,
            "csp": 1,
            "graph": 3,
            "node-consistent": 3,
            "value": 1,
            "domain": 3,
            "satisfy": 1,
            "unary": 1,
            "constraint": 1,
            "example": 1,
            "variant": 1,
            "australia": 1,
            "map-coloring": 1,
            "problem": 1,
            "figure": 1,
            "south": 1,
            "australian": 1,
            "dislike": 1,
            "green": 3,
            "start": 1,
            "red": 2,
            "blue": 2,
            "make": 1,
            "consistent": 1,
            "eliminating": 1,
            "leaving": 1,
            "reduced": 1,
            "say": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para49",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 6,
              "end_char": 10,
              "context": "5.2.1\nNode consistency\nA single variable (corresponding to a"
            },
            {
              "para_id": "chap5_para49",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 73,
              "end_char": 76,
              "context": "A single variable (corresponding to a node in the CSP graph) is\nnode-consistent\nif all the values in th"
            },
            {
              "para_id": "chap5_para49",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 223,
              "end_char": 232,
              "context": "y constraints. For example, in the variant of the Australia map-coloring problem (\nFigure 5.1\n) where South A"
            },
            {
              "para_id": "chap5_para49",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 321,
              "end_char": 323,
              "context": "ere South Australians dislike green, the variable\nSA\nstarts with domain {\nred,green,blue\n}\n,\nand we ca"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para50",
          "content": "It is easy to eliminate all the unary constraints in a CSP by reducing the domain of variables with unary constraints at the start of the solving process. As mentioned earlier, it is also possible to transform all\nn\n-ary constraints into binary ones. Because of this, some CSP solvers work with only binary constraints, expecting the user to eliminate the other constraints ahead of time. We make that assumption for the rest of this chapter, except where noted.",
          "sentence_count": 4,
          "char_count": 386,
          "prev_para_id": "chap5_para49",
          "next_para_id": "chap5_para51",
          "style_metadata": {
            "para_id": "chap5_para50",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 87,
            "sentence_count": 4
          },
          "terminology": {
            "easy": 1,
            "eliminate": 2,
            "unary": 2,
            "constraint": 5,
            "csp": 2,
            "reducing": 1,
            "domain": 1,
            "variable": 1,
            "start": 1,
            "solving": 1,
            "process": 1,
            "mentioned": 1,
            "possible": 1,
            "transform": 1,
            "-ary": 1,
            "binary": 2,
            "one": 1,
            "solver": 1,
            "work": 1,
            "expecting": 1,
            "user": 1,
            "time": 1,
            "make": 1,
            "assumption": 1,
            "rest": 1,
            "chapter": 1,
            "noted": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para50",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 55,
              "end_char": 58,
              "context": " easy to eliminate all the unary constraints in a CSP by reducing the domain of variables with unary co"
            },
            {
              "para_id": "chap5_para50",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 273,
              "end_char": 276,
              "context": "nstraints into binary ones. Because of this, some CSP solvers work with only binary constraints, expect"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para51",
          "content": "5.2.2\nArc consistency\nA variable in a CSP is\narc-consistent\n1\nif every value in its domain satisfies the variable’s binary constraints. More formally,\nX\ni\nis arc-consistent with respect to another variable\nX\nj\nif for every value in the current domain\nD\ni\nthere is some value in the domain\nD\nj\nthat satisfies the binary constraint on the arc (\nX\ni\n,\nX\nj\n). A graph is arc-consistent if every variable is arc-consistent with every other variable. For example, consider the constraint\nY\n=\nX\n2\nwhere the domain of both\nX\nand\nY\nis the set of decimal digits. We can write this constraint explicitly as\n〈\n(\nX\n,\nY\n),{(0,0), (1,1), (2,4), (3,9)}\n〉\n.",
          "sentence_count": 5,
          "char_count": 561,
          "prev_para_id": "chap5_para50",
          "next_para_id": "chap5_para52",
          "style_metadata": {
            "para_id": "chap5_para51",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 146,
            "sentence_count": 5
          },
          "terminology": {
            "arc": 2,
            "consistency": 1,
            "variable": 5,
            "csp": 1,
            "arc-consistent": 4,
            "value": 3,
            "domain": 4,
            "satisfies": 2,
            "binary": 2,
            "constraint": 4,
            "respect": 1,
            "current": 1,
            "graph": 1,
            "example": 1,
            "consider": 1,
            "set": 1,
            "decimal": 1,
            "digit": 1,
            "write": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para51",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 38,
              "end_char": 41,
              "context": "5.2.2\nArc consistency\nA variable in a CSP is\narc-consistent\n1\nif every value in its domain "
            },
            {
              "para_id": "chap5_para51",
              "entity_text": "〈",
              "entity_type": "PERSON",
              "start_char": 596,
              "end_char": 597,
              "context": "igits. We can write this constraint explicitly as\n〈\n(\nX\n,\nY\n),{(0,0), (1,1), (2,4), (3,9)}\n〉\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para52",
          "content": "To make\nX\narc-consistent with respect to\nY\n, we reduce\nX\n’s domain to {0,1,2,3}. If we also make\nY\narc-consistent with respect to\nX\n, then\nY\n’s domain becomes {0,1,4,9}, and the whole CSP is arc-consistent. On the other hand, arc consistency can do nothing for the Australia map-coloring problem. Consider the following inequality constraint on (\nSA, WA\n):\n{(\nr\ne\nd\n,\ng\nr\ne\ne\nn\n), (\nr\ne\nd\n,\nb\nl\nu\ne\n), (\ng\nr\ne\ne\nn\n,\nr\ne\nd\n), (\ng\nr\ne\ne\nn\n,\nb\nl\nu\ne\n), (\nb\nl\nu\ne\n,\nr\ne\nd\n), (\nb\nl\nu\ne\n,\ng\nr\ne\ne\nn\n)}\n.",
          "sentence_count": 4,
          "char_count": 449,
          "prev_para_id": "chap5_para51",
          "next_para_id": "chap5_para53",
          "style_metadata": {
            "para_id": "chap5_para52",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 4
          },
          "terminology": {
            "make": 2,
            "arc-consistent": 3,
            "respect": 2,
            "reduce": 1,
            "domain": 2,
            "becomes": 1,
            "whole": 1,
            "csp": 1,
            "hand": 1,
            "arc": 1,
            "consistency": 1,
            "nothing": 1,
            "australia": 1,
            "map-coloring": 1,
            "problem": 1,
            "consider": 1,
            "following": 1,
            "inequality": 1,
            "constraint": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para52",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 184,
              "end_char": 187,
              "context": "then\nY\n’s domain becomes {0,1,4,9}, and the whole CSP is arc-consistent. On the other hand, arc consist"
            },
            {
              "para_id": "chap5_para52",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 265,
              "end_char": 274,
              "context": "ther hand, arc consistency can do nothing for the Australia map-coloring problem. Consider the following ineq"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para53",
          "content": "No matter what value you choose for\nSA\n(or for\nWA\n), there is a valid value for the other variable. So applying arc consistency has no effect on the domains of either variable.",
          "sentence_count": 2,
          "char_count": 147,
          "prev_para_id": "chap5_para52",
          "next_para_id": "chap5_para54",
          "style_metadata": {
            "para_id": "chap5_para53",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "matter": 1,
            "value": 2,
            "choose": 1,
            "valid": 1,
            "variable": 2,
            "applying": 1,
            "arc": 1,
            "consistency": 1,
            "effect": 1,
            "domain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para54",
          "content": "The most popular algorithm for enforcing arc consistency is called AC-3 (see\nFigure 5.3\n). To make every variable arc-consistent, the AC-3 algorithm maintains a queue of arcs to consider. Initially, the queue contains all the arcs in the CSP. (Each binary constraint becomes two arcs, one in each direction.) AC-3 then pops off an arbitrary arc (\nX\ni\n,\nX\nj\n) from the queue\nand makes\nX\ni\narc-consistent with respect to\nX\nj\n. If this leaves\nD\ni\nunchanged, the algorithm just moves on to the next arc. But if this revises\nD\ni\n(makes the domain smaller), then we add to the queue all arcs (\nX\nk\n,\nX\ni\n) where\nX\nk\nis a neighbor of\nX\ni\n. We need to do that because the change in\nD\ni\nmight enable further reductions in\nD\nk\n, even if we have previously considered\nX\nk\n. If\nD\ni\nis revised down to nothing, then we know the whole CSP has no consistent solution, and AC-3 can immediately return failure. Otherwise, we keep checking, trying to remove values from the domains of variables until no more arcs are in the queue. At that point, we are left with a CSP that is equivalent to the original CSP—they both have the same solutions—but the arc-consistent CSP will be faster to search because its variables have smaller domains. In some cases, it solves the problem completely (by reducing every domain to size 1) and in others it proves that no solution exists (by reducing some domain to size 0).",
          "sentence_count": 12,
          "char_count": 1169,
          "prev_para_id": "chap5_para53",
          "next_para_id": "chap5_para55",
          "style_metadata": {
            "para_id": "chap5_para54",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.67,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 296,
            "sentence_count": 12
          },
          "terminology": {
            "popular": 1,
            "algorithm": 3,
            "enforcing": 1,
            "arc": 6,
            "consistency": 1,
            "called": 1,
            "ac-3": 4,
            "see": 1,
            "figure": 1,
            "make": 3,
            "variable": 3,
            "arc-consistent": 3,
            "maintains": 1,
            "queue": 5,
            "consider": 1,
            "contains": 1,
            "csp": 4,
            "binary": 1,
            "constraint": 1,
            "becomes": 1,
            "direction": 1,
            "pop": 1,
            "arbitrary": 1,
            "respect": 1,
            "leaf": 1,
            "unchanged": 1,
            "move": 1,
            "revise": 1,
            "domain": 5,
            "smaller": 2,
            "add": 1,
            "neighbor": 1,
            "need": 1,
            "change": 1,
            "enable": 1,
            "reduction": 1,
            "considered": 1,
            "revised": 1,
            "nothing": 1,
            "know": 1,
            "whole": 1,
            "consistent": 1,
            "solution": 2,
            "return": 1,
            "failure": 1,
            "keep": 1,
            "checking": 1,
            "trying": 1,
            "remove": 1,
            "value": 1,
            "point": 1,
            "left": 1,
            "equivalent": 1,
            "original": 1,
            "csp—they": 1,
            "solutions—but": 1,
            "search": 1,
            "case": 1,
            "solves": 1,
            "problem": 1,
            "reducing": 2,
            "size": 2,
            "others": 1,
            "prof": 1,
            "exists": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para54",
              "entity_text": "AC-3",
              "entity_type": "PRODUCT",
              "start_char": 67,
              "end_char": 71,
              "context": "algorithm for enforcing arc consistency is called AC-3 (see\nFigure 5.3\n). To make every variable arc-con"
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "the AC-3 algorithm",
              "entity_type": "ORG",
              "start_char": 130,
              "end_char": 148,
              "context": "ure 5.3\n). To make every variable arc-consistent, the AC-3 algorithm maintains a queue of arcs to consider. Initially,"
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 238,
              "end_char": 241,
              "context": "Initially, the queue contains all the arcs in the CSP. (Each binary constraint becomes two arcs, one in"
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 821,
              "end_char": 824,
              "context": "s revised down to nothing, then we know the whole CSP has no consistent solution, and AC-3 can immediat"
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "AC-3",
              "entity_type": "GPE",
              "start_char": 857,
              "end_char": 861,
              "context": "now the whole CSP has no consistent solution, and AC-3 can immediately return failure. Otherwise, we kee"
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 1048,
              "end_char": 1051,
              "context": "e in the queue. At that point, we are left with a CSP that is equivalent to the original CSP—they both "
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 1087,
              "end_char": 1090,
              "context": "eft with a CSP that is equivalent to the original CSP—they both have the same solutions—but the arc-con"
            },
            {
              "para_id": "chap5_para54",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 1148,
              "end_char": 1151,
              "context": "th have the same solutions—but the arc-consistent CSP will be faster to search because its variables ha"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para55",
          "content": "Description\nThe game tree is a binary tree. The first level of the game tree is labeled to move \"A\" and the node is labeled (1, 2, 6). The two child nodes of (1, 2, 6) are labeled (1, 2, 6) and (0, 5, 2) and are in the second level. The second level is labeled to move B. An arrow from the node (1, 2, 6) in level “A” points to node (1, 2, 6) in level B. The two child nodes of (1, 2, 6) in level B are labeled (1, 2, 6) with a cross and (6, 1, 2) in the third level. The two child nodes of (0, 5, 2) in level B are labeled (0, 5, 2) and (5, 4, 5) in the third level. The third level is labeled to move C. The two child nodes of (1, 2, 6) with a cross are labeled (1, 2, 6) and (4, 2, 3) in the fourth level. The two child nodes of (6, 1, 2) in the level C are labeled (6, 1, 2) and (4, 7, 1) in the fourth level. The two child nodes of (0, 5, 2) in level C are labeled (0, 5, 2) and (5, 1, 1) in the fourth level. The two child nodes of (5, 4, 5) in level C are labeled (5, 4, 5) and (7, 7, 1) in the fourth level. The fourth level is labeled to move \"A\".",
          "sentence_count": 12,
          "char_count": 815,
          "prev_para_id": "chap5_para54",
          "next_para_id": "chap5_para56",
          "style_metadata": {
            "para_id": "chap5_para55",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.58,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 355,
            "sentence_count": 12
          },
          "terminology": {
            "description": 1,
            "game": 2,
            "tree": 3,
            "binary": 1,
            "level": 18,
            "labeled": 12,
            "move": 3,
            "node": 9,
            "child": 7,
            "second": 2,
            "arrow": 1,
            "point": 1,
            "cross": 2,
            "third": 3,
            "fourth": 5,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para55",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 328,
              "end_char": 332,
              "context": "ow from the node (1, 2, 6) in level “A” points to node (1, 2, 6) in level B. The two child nodes of (1, "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para56",
          "content": "×\nFigure 5.3\nThe arc-consistency algorithm AC-3. After applying AC-3, either every arc is arc-consistent, or some variable has an empty domain, indicating that the CSP cannot be solved. The name “AC-3” was used by the algorithm’s inventor (Mackworth, 1977) because it was the third version developed in the paper.",
          "sentence_count": 3,
          "char_count": 266,
          "prev_para_id": "chap5_para55",
          "next_para_id": "chap5_para57",
          "style_metadata": {
            "para_id": "chap5_para56",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.33,
            "passive_voice_ratio": 0.016,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "arc-consistency": 1,
            "algorithm": 2,
            "ac-3": 3,
            "applying": 1,
            "arc": 1,
            "arc-consistent": 1,
            "variable": 1,
            "empty": 1,
            "domain": 1,
            "indicating": 1,
            "csp": 1,
            "solved": 1,
            "name": 1,
            "used": 1,
            "inventor": 1,
            "mackworth": 1,
            "third": 1,
            "version": 1,
            "developed": 1,
            "paper": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para56",
              "entity_text": "AC-3",
              "entity_type": "GPE",
              "start_char": 64,
              "end_char": 68,
              "context": "he arc-consistency algorithm AC-3. After applying AC-3, either every arc is arc-consistent, or some vari"
            },
            {
              "para_id": "chap5_para56",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 164,
              "end_char": 167,
              "context": "variable has an empty domain, indicating that the CSP cannot be solved. The name “AC-3” was used by the"
            },
            {
              "para_id": "chap5_para56",
              "entity_text": "AC-3",
              "entity_type": "PRODUCT",
              "start_char": 196,
              "end_char": 200,
              "context": "dicating that the CSP cannot be solved. The name “AC-3” was used by the algorithm’s inventor (Mackworth,"
            },
            {
              "para_id": "chap5_para56",
              "entity_text": "Mackworth",
              "entity_type": "PERSON",
              "start_char": 240,
              "end_char": 249,
              "context": "name “AC-3” was used by the algorithm’s inventor (Mackworth, 1977) because it was the third version developed"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para57",
          "content": "The complexity of AC-3 can be analyzed as follows. Assume a CSP with\nn\nvariables, each with domain size at most\nd\n, and with\nc\nbinary constraints (arcs). Each arc (\nX\nk\n,\nX\ni\n) can be inserted in the queue only\nd\ntimes because\nX\ni\nhas at most\nd\nvalues to delete. Checking consistency of an arc can be done in\nO\n(\nd\n2\n) time, so we get\nO\n(\ncd\n3\n) total worst-case time.",
          "sentence_count": 4,
          "char_count": 315,
          "prev_para_id": "chap5_para56",
          "next_para_id": "chap5_para58",
          "style_metadata": {
            "para_id": "chap5_para57",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 4
          },
          "terminology": {
            "complexity": 1,
            "ac-3": 1,
            "analyzed": 1,
            "follows": 1,
            "assume": 1,
            "csp": 1,
            "variable": 1,
            "domain": 1,
            "size": 1,
            "binary": 1,
            "constraint": 1,
            "arc": 1,
            "inserted": 1,
            "queue": 1,
            "time": 3,
            "value": 1,
            "delete": 1,
            "checking": 1,
            "consistency": 1,
            "done": 1,
            "get": 1,
            "total": 1,
            "worst-case": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para57",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 60,
              "end_char": 63,
              "context": "xity of AC-3 can be analyzed as follows. Assume a CSP with\nn\nvariables, each with domain size at most\nd"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para58",
          "content": "5.2.3\nPath consistency\nSuppose we are to color the map of Australia with just two colors, red and blue. Arc consistency does nothing because every constraint can be satisfied individually with red at one end and blue at the other. But clearly there is no solution to the problem: because Western Australia, Northern Territory, and South Australia all touch each other, we need at least three colors for them alone.",
          "sentence_count": 3,
          "char_count": 347,
          "prev_para_id": "chap5_para57",
          "next_para_id": "chap5_para59",
          "style_metadata": {
            "para_id": "chap5_para58",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 3
          },
          "terminology": {
            "path": 1,
            "consistency": 2,
            "suppose": 1,
            "color": 3,
            "map": 1,
            "australia": 3,
            "red": 2,
            "blue": 2,
            "arc": 1,
            "nothing": 1,
            "constraint": 1,
            "satisfied": 1,
            "end": 1,
            "solution": 1,
            "problem": 1,
            "western": 1,
            "northern": 1,
            "territory": 1,
            "south": 1,
            "touch": 1,
            "need": 1,
            "least": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para58",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 58,
              "end_char": 67,
              "context": "th consistency\nSuppose we are to color the map of Australia with just two colors, red and blue. Arc consisten"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para59",
          "content": "Arc consistency tightens down the domains (unary constraints) using the arcs (binary constraints). To make progress on problems like map coloring, we need a stronger notion of consistency.",
          "sentence_count": 2,
          "char_count": 161,
          "prev_para_id": "chap5_para58",
          "next_para_id": "chap5_para60",
          "style_metadata": {
            "para_id": "chap5_para59",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 2
          },
          "terminology": {
            "arc": 2,
            "consistency": 2,
            "tightens": 1,
            "domain": 1,
            "unary": 1,
            "constraint": 2,
            "using": 1,
            "binary": 1,
            "make": 1,
            "progress": 1,
            "problem": 1,
            "map": 1,
            "coloring": 1,
            "need": 1,
            "stronger": 1,
            "notion": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para60",
          "content": "Path consistency\ntightens the binary constraints by using implicit constraints that are inferred by looking at triples of variables.",
          "sentence_count": 1,
          "char_count": 115,
          "prev_para_id": "chap5_para59",
          "next_para_id": "chap5_para61",
          "style_metadata": {
            "para_id": "chap5_para60",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "path": 1,
            "consistency": 1,
            "tightens": 1,
            "binary": 1,
            "constraint": 2,
            "using": 1,
            "implicit": 1,
            "inferred": 1,
            "looking": 1,
            "triple": 1,
            "variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para61",
          "content": "A two-variable set {\nX\ni\n,\nX\nj\n} is path-consistent with respect to a third variable\nX\nm\nif, for every assignment {\nX\ni\n=\na, X\nj\n=\nb\n} consistent with the constraints (if any) on {\nX\ni\n,\nX\nj\n}, there is an assignment to\nX\nm\nthat satisfies the constraints on {\nX\ni\n,\nX\nm\n} and {\nX\nm\n,\nX\nj\n}. The name refers to the overall consistency of the path from\nX\ni\nto\nX\nj\nwith\nX\nm\nin the middle.",
          "sentence_count": 2,
          "char_count": 336,
          "prev_para_id": "chap5_para60",
          "next_para_id": "chap5_para62",
          "style_metadata": {
            "para_id": "chap5_para61",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 52.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 104,
            "sentence_count": 2
          },
          "terminology": {
            "two-variable": 1,
            "set": 1,
            "path-consistent": 1,
            "respect": 1,
            "third": 1,
            "variable": 1,
            "assignment": 2,
            "consistent": 1,
            "constraint": 2,
            "satisfies": 1,
            "name": 1,
            "refers": 1,
            "overall": 1,
            "consistency": 1,
            "path": 1,
            "middle": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para62",
          "content": "Let’s see how path consistency fares in coloring the Australia map with two colors. We will make the set {\nWA\n,\nSA\n} path-consistent with respect to\nNT\n. We start by enumerating the consistent assignments to the set. In this case, there are only two: {\nWA = red, SA = blue\n} and {\nWA = blue, SA = red\n}. We can see that with both of these assignments\nNT\ncan be neither\nred\nnor\nblue\n(because it would conflict with either\nWA\nor\nSA\n). Because there is no valid choice for\nNT\n, we eliminate both assignments, and we end up with no valid assignments for {\nWA\n,\nSA\n}. Therefore, we know that there can be no solution to this problem.",
          "sentence_count": 7,
          "char_count": 526,
          "prev_para_id": "chap5_para61",
          "next_para_id": "chap5_para63",
          "style_metadata": {
            "para_id": "chap5_para62",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 20.57,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 144,
            "sentence_count": 7
          },
          "terminology": {
            "let": 1,
            "see": 2,
            "path": 1,
            "consistency": 1,
            "fare": 1,
            "coloring": 1,
            "australia": 1,
            "map": 1,
            "color": 1,
            "make": 1,
            "set": 2,
            "path-consistent": 1,
            "respect": 1,
            "start": 1,
            "enumerating": 1,
            "consistent": 1,
            "assignment": 4,
            "case": 1,
            "red": 3,
            "blue": 3,
            "conflict": 1,
            "valid": 2,
            "choice": 1,
            "eliminate": 1,
            "end": 1,
            "know": 1,
            "solution": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para62",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 53,
              "end_char": 62,
              "context": "’s see how path consistency fares in coloring the Australia map with two colors. We will make the set {\nWA\n,\n"
            },
            {
              "para_id": "chap5_para62",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 263,
              "end_char": 265,
              "context": "et. In this case, there are only two: {\nWA = red, SA = blue\n} and {\nWA = blue, SA = red\n}. We can see "
            },
            {
              "para_id": "chap5_para62",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 292,
              "end_char": 294,
              "context": "nly two: {\nWA = red, SA = blue\n} and {\nWA = blue, SA = red\n}. We can see that with both of these assig"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para63",
          "content": "5.2.4\nK\n-consistency\nStronger forms of propagation can be defined with the notion of\nk\n-consistency\n. A CSP is\nk\n-consistent if, for any set of\nk –\n1 variables and for any consistent assignment to those variables, a consistent value can always be assigned to any\nk\nth variable. 1-consistency says that, given the empty set, we can make any set of one variable consistent: this is what we called node consistency. 2-consistency is the same as arc consistency. For binary constraint graphs, 3-consistency is the same as path consistency.",
          "sentence_count": 5,
          "char_count": 456,
          "prev_para_id": "chap5_para62",
          "next_para_id": "chap5_para64",
          "style_metadata": {
            "para_id": "chap5_para63",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.4,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 102,
            "sentence_count": 5
          },
          "terminology": {
            "-consistency": 2,
            "stronger": 1,
            "form": 1,
            "propagation": 1,
            "defined": 1,
            "notion": 1,
            "csp": 1,
            "-consistent": 1,
            "set": 3,
            "variable": 4,
            "consistent": 3,
            "assignment": 1,
            "value": 1,
            "assigned": 1,
            "1-consistency": 1,
            "say": 1,
            "given": 1,
            "empty": 1,
            "make": 1,
            "called": 1,
            "node": 1,
            "consistency": 3,
            "2-consistency": 1,
            "arc": 1,
            "binary": 1,
            "constraint": 1,
            "graph": 1,
            "3-consistency": 1,
            "path": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para63",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 104,
              "end_char": 107,
              "context": " be defined with the notion of\nk\n-consistency\n. A CSP is\nk\n-consistent if, for any set of\nk –\n1 variabl"
            },
            {
              "para_id": "chap5_para63",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 395,
              "end_char": 399,
              "context": "f one variable consistent: this is what we called node consistency. 2-consistency is the same as arc con"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para64",
          "content": "A CSP is\nstrongly\nk\n-consistent\nif it is\nk\n-consistent and is also (\nk\n– 1)-consistent, (\nk\n– 2)-consistent, ... all the way down to 1-consistent. Now suppose we have a CSP with\nn\nnodes and make it strongly\nn\n-consistent (i.e., strongly\nk\n-consistent for\nk = n\n). We can then solve the problem as follows: First, we choose a consistent value for\nX\n1\n. We are then guaranteed to be able to choose a value for\nX\n2\nbecause the graph is 2-consistent, for\nX\n3\nbecause it is 3-consistent, and so on. For each variable\nX\ni\n, we need only search through the\nd\nvalues in the domain to find a value consistent with\nX\n1\n,...,\nX\ni\n–1\n. The total run time is only\nO\n(\nn\n2\nd\n).",
          "sentence_count": 6,
          "char_count": 567,
          "prev_para_id": "chap5_para63",
          "next_para_id": "chap5_para65",
          "style_metadata": {
            "para_id": "chap5_para64",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 160,
            "sentence_count": 6
          },
          "terminology": {
            "csp": 2,
            "-consistent": 6,
            "way": 1,
            "1-consistent": 1,
            "suppose": 1,
            "node": 1,
            "make": 1,
            "i.e.": 1,
            "solve": 1,
            "problem": 1,
            "follows": 1,
            "choose": 2,
            "consistent": 2,
            "value": 4,
            "guaranteed": 1,
            "able": 1,
            "graph": 1,
            "2-consistent": 1,
            "3-consistent": 1,
            "variable": 1,
            "need": 1,
            "search": 1,
            "domain": 1,
            "total": 1,
            "run": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para64",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 2,
              "end_char": 5,
              "context": "A CSP is\nstrongly\nk\n-consistent\nif it is\nk\n-consistent "
            },
            {
              "para_id": "chap5_para64",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 169,
              "end_char": 172,
              "context": "e way down to 1-consistent. Now suppose we have a CSP with\nn\nnodes and make it strongly\nn\n-consistent ("
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para65",
          "content": "Of course, there is no free lunch: constraint satisfaction is NP-complete in general, and any algorithm for establishing\nn\n-consistency must take time exponential in\nn\nin the worst case. Worse,\nn\n-consistency also requires space that is exponential in\nn\n. In practice, determining the appropriate level of consistency checking is mostly an empirical science. Computing 2-consistency is common, and 3-consistency less common.",
          "sentence_count": 4,
          "char_count": 369,
          "prev_para_id": "chap5_para64",
          "next_para_id": "chap5_para66",
          "style_metadata": {
            "para_id": "chap5_para65",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 4
          },
          "terminology": {
            "course": 1,
            "free": 1,
            "lunch": 1,
            "constraint": 1,
            "satisfaction": 1,
            "np-complete": 1,
            "general": 1,
            "algorithm": 1,
            "establishing": 1,
            "-consistency": 2,
            "take": 1,
            "time": 1,
            "exponential": 2,
            "worst": 1,
            "case": 1,
            "worse": 1,
            "requires": 1,
            "space": 1,
            "practice": 1,
            "determining": 1,
            "appropriate": 1,
            "level": 1,
            "consistency": 1,
            "checking": 1,
            "empirical": 1,
            "science": 1,
            "computing": 1,
            "2-consistency": 1,
            "common": 2,
            "3-consistency": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para65",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 62,
              "end_char": 64,
              "context": "here is no free lunch: constraint satisfaction is NP-complete in general, and any algorithm for establ"
            },
            {
              "para_id": "chap5_para65",
              "entity_text": "Computing 2-consistency",
              "entity_type": "PERSON",
              "start_char": 359,
              "end_char": 382,
              "context": "sistency checking is mostly an empirical science. Computing 2-consistency is common, and 3-consistency less common."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para66",
          "content": "5.2.5\nGlobal constraints\nRemember that a\nglobal constraint\nis one involving an arbitrary number of variables (but not necessarily all variables). Global constraints occur frequently in real problems and can be handled by special-purpose algorithms that are more efficient than the general-purpose methods described so far. For example, the\nAlldiff\nconstraint says that all the variables involved must have distinct values (as in the cryptarithmetic problem above and Sudoku puzzles below). One simple form of inconsistency detection for\nAlldiff\nconstraints works as follows: if\nm\nvariables are involved in the constraint, and if they have\nn\npossible distinct values altogether, and\nm > n,\nthen the constraint cannot be satisfied.",
          "sentence_count": 4,
          "char_count": 634,
          "prev_para_id": "chap5_para65",
          "next_para_id": "chap5_para67",
          "style_metadata": {
            "para_id": "chap5_para66",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 124,
            "sentence_count": 4
          },
          "terminology": {
            "global": 3,
            "constraint": 7,
            "remember": 1,
            "involving": 1,
            "arbitrary": 1,
            "number": 1,
            "variable": 4,
            "occur": 1,
            "real": 1,
            "problem": 2,
            "handled": 1,
            "special-purpose": 1,
            "algorithm": 1,
            "efficient": 1,
            "general-purpose": 1,
            "method": 1,
            "described": 1,
            "example": 1,
            "alldiff": 2,
            "say": 1,
            "involved": 2,
            "distinct": 2,
            "value": 2,
            "cryptarithmetic": 1,
            "sudoku": 1,
            "puzzle": 1,
            "simple": 1,
            "form": 1,
            "inconsistency": 1,
            "detection": 1,
            "work": 1,
            "follows": 1,
            "possible": 1,
            "satisfied": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para66",
              "entity_text": "Sudoku",
              "entity_type": "ORG",
              "start_char": 467,
              "end_char": 473,
              "context": "lues (as in the cryptarithmetic problem above and Sudoku puzzles below). One simple form of inconsistency "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para67",
          "content": "This leads to the following simple algorithm: First, remove any variable in the constraint that has a singleton domain, and delete that variable’s value from the domains of the remaining variables. Repeat as long as there are singleton variables. If at any point an empty domain is produced or there are more variables than domain values left, then an inconsistency has been detected.",
          "sentence_count": 3,
          "char_count": 322,
          "prev_para_id": "chap5_para66",
          "next_para_id": "chap5_para68",
          "style_metadata": {
            "para_id": "chap5_para67",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 72,
            "sentence_count": 3
          },
          "terminology": {
            "lead": 1,
            "following": 1,
            "simple": 1,
            "first": 1,
            "remove": 1,
            "variable": 5,
            "constraint": 1,
            "singleton": 2,
            "domain": 4,
            "delete": 1,
            "value": 2,
            "remaining": 1,
            "repeat": 1,
            "long": 1,
            "point": 1,
            "empty": 1,
            "produced": 1,
            "left": 1,
            "inconsistency": 1,
            "detected": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para68",
          "content": "This method can detect the inconsistency in the assignment {\nWA = red, NSW = red\n} for\nFigure 5.1\n. Notice that the variables\nSA, NT\n, and\nQ\nare effectively connected by an\nAlldiff\nconstraint because each pair must have two different colors. After applying AC-3 with the partial assignment, the domains of\nSA, NT\n, and\nQ\nare all reduced to {\ngreen, blue\n}. That is, we have three variables and only two colors, so the\nAlldiff\nconstraint is violated. Thus, a simple consistency procedure for a higher-order constraint is sometimes more effective than applying arc consistency to an equivalent set of binary constraints.",
          "sentence_count": 5,
          "char_count": 529,
          "prev_para_id": "chap5_para67",
          "next_para_id": "chap5_para69",
          "style_metadata": {
            "para_id": "chap5_para68",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.0,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 120,
            "sentence_count": 5
          },
          "terminology": {
            "method": 1,
            "detect": 1,
            "inconsistency": 1,
            "assignment": 2,
            "red": 2,
            "nsw": 1,
            "figure": 1,
            "notice": 1,
            "variable": 2,
            "connected": 1,
            "alldiff": 2,
            "constraint": 4,
            "pair": 1,
            "different": 1,
            "color": 2,
            "applying": 2,
            "ac-3": 1,
            "partial": 1,
            "domain": 1,
            "reduced": 1,
            "green": 1,
            "blue": 1,
            "violated": 1,
            "simple": 1,
            "consistency": 2,
            "procedure": 1,
            "higher-order": 1,
            "effective": 1,
            "arc": 1,
            "equivalent": 1,
            "set": 1,
            "binary": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para68",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 126,
              "end_char": 128,
              "context": " red\n} for\nFigure 5.1\n. Notice that the variables\nSA, NT\n, and\nQ\nare effectively connected by an\nAlldi"
            },
            {
              "para_id": "chap5_para68",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 306,
              "end_char": 308,
              "context": " AC-3 with the partial assignment, the domains of\nSA, NT\n, and\nQ\nare all reduced to {\ngreen, blue\n}. T"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para69",
          "content": "Another important higher-order constraint is the\nresource constraint\n, sometimes called the\nAtmost\nconstraint. For example, in a scheduling problem, let\nP\n1\n,...,\nP\n4\ndenote the numbers of personnel assigned to each of four tasks. The constraint that no more than 10 personnel are assigned in total is written as\nAtmost\n(10,\nP\n1\n,\nP\n2\n,\nP\n3\n,\nP\n4\n). We can detect an inconsistency simply by checking the sum of the minimum values of the current domains; for example, if each variable has the domain {3,4,5,6}, the\nAtmost\nconstraint cannot be satisfied. We can also enforce consistency by deleting the maximum value of any domain if it is not consistent with the minimum values of the other domains. Thus, if each variable in our example has the domain {2,3,4,5,6}, the values 5 and 6 can be deleted from each domain.",
          "sentence_count": 6,
          "char_count": 696,
          "prev_para_id": "chap5_para68",
          "next_para_id": "chap5_para70",
          "style_metadata": {
            "para_id": "chap5_para69",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 169,
            "sentence_count": 6
          },
          "terminology": {
            "important": 1,
            "higher-order": 1,
            "constraint": 5,
            "resource": 1,
            "called": 1,
            "atmost": 3,
            "example": 3,
            "scheduling": 1,
            "problem": 1,
            "let": 1,
            "denote": 1,
            "number": 1,
            "personnel": 2,
            "assigned": 2,
            "task": 1,
            "total": 1,
            "written": 1,
            "detect": 1,
            "inconsistency": 1,
            "checking": 1,
            "sum": 1,
            "minimum": 2,
            "value": 4,
            "current": 1,
            "domain": 6,
            "variable": 2,
            "satisfied": 1,
            "enforce": 1,
            "consistency": 1,
            "deleting": 1,
            "maximum": 1,
            "consistent": 1,
            "deleted": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para70",
          "content": "For large resource-limited problems with integer values—such as logistical problems involving moving thousands of people in hundreds of vehicles—it is usually not possible to represent the domain of each variable as a large set of integers and gradually reduce that set by consistency-checking methods. Instead, domains are represented by upper and lower bounds and are managed by\nbounds propagation\n. For example, in an airline-scheduling problem, let’s suppose there are two flights,\nF\n1\nand\nF\n2\n, for which the planes have capacities 165 and 385, respectively. The initial domains for the numbers of passengers on flights\nF\n1\nand\nF\n2\nare then\nD\n1\n= [0,165] and\nD\n2\n= [0,385]\n.",
          "sentence_count": 4,
          "char_count": 589,
          "prev_para_id": "chap5_para69",
          "next_para_id": "chap5_para71",
          "style_metadata": {
            "para_id": "chap5_para70",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 4
          },
          "terminology": {
            "large": 2,
            "resource-limited": 1,
            "problem": 3,
            "integer": 2,
            "values—such": 1,
            "logistical": 1,
            "involving": 1,
            "moving": 1,
            "thousand": 1,
            "people": 1,
            "hundred": 1,
            "vehicles—it": 1,
            "possible": 1,
            "represent": 1,
            "domain": 3,
            "variable": 1,
            "set": 2,
            "reduce": 1,
            "consistency-checking": 1,
            "method": 1,
            "represented": 1,
            "upper": 1,
            "lower": 1,
            "bound": 2,
            "managed": 1,
            "propagation": 1,
            "example": 1,
            "airline-scheduling": 1,
            "let": 1,
            "suppose": 1,
            "flight": 2,
            "plane": 1,
            "capacity": 1,
            "initial": 1,
            "number": 1,
            "passenger": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para70",
              "entity_text": "F\n1",
              "entity_type": "PRODUCT",
              "start_char": 486,
              "end_char": 489,
              "context": "ing problem, let’s suppose there are two flights,\nF\n1\nand\nF\n2\n, for which the planes have capacities 16"
            },
            {
              "para_id": "chap5_para70",
              "entity_text": "F\n2",
              "entity_type": "PRODUCT",
              "start_char": 494,
              "end_char": 497,
              "context": "lem, let’s suppose there are two flights,\nF\n1\nand\nF\n2\n, for which the planes have capacities 165 and 38"
            },
            {
              "para_id": "chap5_para70",
              "entity_text": "F\n1",
              "entity_type": "PRODUCT",
              "start_char": 625,
              "end_char": 628,
              "context": " domains for the numbers of passengers on flights\nF\n1\nand\nF\n2\nare then\nD\n1\n= [0,165] and\nD\n2\n= [0,385]\n"
            },
            {
              "para_id": "chap5_para70",
              "entity_text": "F\n2",
              "entity_type": "PRODUCT",
              "start_char": 633,
              "end_char": 636,
              "context": " for the numbers of passengers on flights\nF\n1\nand\nF\n2\nare then\nD\n1\n= [0,165] and\nD\n2\n= [0,385]\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para71",
          "content": "Now suppose we have the additional constraint that the two flights together must carry 420 people:\nF\n1\n+\nF\n2\n= 420. Propagating bounds constraints, we reduce the domains to\nD\n1\n= [35,165] and\nD\n2\n= [255,385]\n.",
          "sentence_count": 2,
          "char_count": 185,
          "prev_para_id": "chap5_para70",
          "next_para_id": "chap5_para72",
          "style_metadata": {
            "para_id": "chap5_para71",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 47,
            "sentence_count": 2
          },
          "terminology": {
            "suppose": 1,
            "additional": 1,
            "constraint": 2,
            "flight": 1,
            "carry": 1,
            "people": 1,
            "propagating": 1,
            "bound": 1,
            "reduce": 1,
            "domain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para71",
              "entity_text": "F\n1\n+\nF\n2",
              "entity_type": "PRODUCT",
              "start_char": 99,
              "end_char": 108,
              "context": "t the two flights together must carry 420 people:\nF\n1\n+\nF\n2\n= 420. Propagating bounds constraints, we reduce "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para72",
          "content": "We say that a CSP is\nbounds-consistent\nif for every variable\nX\n, and for both the lower-bound and upper-bound values of\nX\n, there exists some value of\nY\nthat satisfies the constraint between\nX\nand\nY\nfor every variable\nY\n. This kind of bounds propagation is widely used in practical constraint problems.",
          "sentence_count": 2,
          "char_count": 262,
          "prev_para_id": "chap5_para71",
          "next_para_id": "chap5_para73",
          "style_metadata": {
            "para_id": "chap5_para72",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 56,
            "sentence_count": 2
          },
          "terminology": {
            "say": 1,
            "csp": 1,
            "bounds-consistent": 1,
            "variable": 2,
            "lower-bound": 1,
            "upper-bound": 1,
            "value": 2,
            "exists": 1,
            "satisfies": 1,
            "constraint": 2,
            "kind": 1,
            "bound": 1,
            "propagation": 1,
            "used": 1,
            "practical": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para72",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 14,
              "end_char": 17,
              "context": "We say that a CSP is\nbounds-consistent\nif for every variable\nX\n, an"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para73",
          "content": "5.2.6\nSudoku\nThe popular\nSudoku\npuzzle has introduced millions of people to constraint satisfaction problems, although they may not realize it. A Sudoku board consists of 81 squares, some of which are initially filled with digits from 1 to 9. The puzzle is to fill in all the remaining squares such that no digit appears twice in any row, column, or 3 × 3 box (see\nFigure 5.4\n). A row, column, or box is called a\nunit\n.",
          "sentence_count": 4,
          "char_count": 349,
          "prev_para_id": "chap5_para72",
          "next_para_id": "chap5_para74",
          "style_metadata": {
            "para_id": "chap5_para73",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 88,
            "sentence_count": 4
          },
          "terminology": {
            "sudoku": 3,
            "popular": 1,
            "puzzle": 2,
            "introduced": 1,
            "million": 1,
            "people": 1,
            "constraint": 1,
            "satisfaction": 1,
            "problem": 1,
            "realize": 1,
            "board": 1,
            "consists": 1,
            "square": 2,
            "filled": 1,
            "digit": 2,
            "fill": 1,
            "remaining": 1,
            "appears": 1,
            "row": 2,
            "column": 2,
            "box": 2,
            "see": 1,
            "figure": 1,
            "called": 1,
            "unit": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para73",
              "entity_text": "Sudoku",
              "entity_type": "ORG",
              "start_char": 146,
              "end_char": 152,
              "context": "ion problems, although they may not realize it. A Sudoku board consists of 81 squares, some of which are i"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para74",
          "content": "The Sudoku puzzles that appear in newspapers and puzzle books have the property that there is exactly one solution. Although some can be tricky to solve by hand, taking tens of minutes, a CSP solver can handle thousands of puzzles per second.",
          "sentence_count": 2,
          "char_count": 201,
          "prev_para_id": "chap5_para73",
          "next_para_id": "chap5_para75",
          "style_metadata": {
            "para_id": "chap5_para74",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "sudoku": 1,
            "puzzle": 3,
            "appear": 1,
            "newspaper": 1,
            "book": 1,
            "property": 1,
            "solution": 1,
            "tricky": 1,
            "solve": 1,
            "hand": 1,
            "taking": 1,
            "ten": 1,
            "minute": 1,
            "csp": 1,
            "solver": 1,
            "handle": 1,
            "thousand": 1,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para74",
              "entity_text": "Sudoku",
              "entity_type": "PERSON",
              "start_char": 4,
              "end_char": 10,
              "context": "The Sudoku puzzles that appear in newspapers and puzzle book"
            },
            {
              "para_id": "chap5_para74",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 188,
              "end_char": 191,
              "context": "ricky to solve by hand, taking tens of minutes, a CSP solver can handle thousands of puzzles per second"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para75",
          "content": "A Sudoku puzzle can be considered a CSP with 81 variables, one for each square. We use the variable names\nA1\nthrough\nA9\nfor the top row (left to right), down to\n11\nthrough\n19\nfor the bottom row. The empty squares have the domain {1,2,3,4,5,6,7,8,9} and the pre-filled squares have a domain consisting of a single value. In addition, there are 27 different\nAlldiff\nconstraints, one for each unit (row, column, and box of 9 squares):\nA\nl\nl\nd\ni\nf\nf\n(\nA\n1,\nA\n2,\nA\n3,\nA\n4,\nA\n5,\nA\n6,\nA\n7,\nA\n8,\nA\n9)\nA\nl\nl\nd\ni\nf\nf\n(\nB\n1,\nB\n2,\nB\n3,\nB\n4,\nB\n5,\nB\n6,\nB\n7,\nB\n8,\nB\n9)\n…\nA\nl\nl\nd\ni\nf\nf\n(\nA\n1,\nB\n1,\nC\n1,\nD\n1,\nE\n1,\nF\n1,\nG\n1,\nH\n1,\nI\n1)\nA\nl\nl\nd\ni\nf\nf\n(\nA\n2,\nB\n2,\nC\n2,\nD\n2,\nE\n2,\nF\n2,\nG\n2,\nH\n2,\nI\n2)\n…\nA\nl\nl\nd\ni\nf\nf\n(\nA\n1,\nA\n2,\nA\n3,\nB\n1,\nB\n2,\nB\n3,\nC\n1,\nC\n2,\nC\n3)\nA\nl\nl\nd\ni\nf\nf\n(\nA\n4,\nA\n5,\nA\n6,\nB\n4,\nB\n5,\nB\n6,\nC\n4,\nC\n5,\nC\n6)\n…\nLet us see how far arc consistency can take us. Assume that the\nAlldiff\nconstraints have been expanded into binary constraints (such as\nA1\n≠\nA2\n) so that we can apply the AC-3 algorithm directly. Consider variable\nE6\nfrom\nFigure 5.4(a)\n—the empty square between the 2 and the 8 in the middle box. From the constraints in the box, we can remove 1, 2, 7, and 8 from\nE6\n’s domain. From the constraints in its column, we can eliminate 5, 6, 2, 8, 9, and 3 (although 2 and 8 were already removed). That leaves\nE6\nwith a domain of {4}; in other words, we know the answer for\nE6.",
          "sentence_count": 9,
          "char_count": 1213,
          "prev_para_id": "chap5_para74",
          "next_para_id": "chap5_para76",
          "style_metadata": {
            "para_id": "chap5_para75",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 49.56,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 446,
            "sentence_count": 9
          },
          "terminology": {
            "sudoku": 1,
            "puzzle": 1,
            "considered": 1,
            "csp": 1,
            "variable": 3,
            "square": 5,
            "use": 1,
            "name": 1,
            "top": 1,
            "row": 3,
            "left": 1,
            "right": 1,
            "bottom": 1,
            "empty": 2,
            "domain": 4,
            "pre-filled": 1,
            "consisting": 1,
            "single": 1,
            "value": 1,
            "addition": 1,
            "different": 1,
            "alldiff": 2,
            "constraint": 5,
            "unit": 1,
            "column": 2,
            "box": 3,
            "let": 1,
            "see": 1,
            "arc": 1,
            "consistency": 1,
            "take": 1,
            "assume": 1,
            "expanded": 1,
            "binary": 1,
            "apply": 1,
            "ac-3": 1,
            "algorithm": 1,
            "figure": 1,
            "—the": 1,
            "middle": 1,
            "remove": 1,
            "eliminate": 1,
            "removed": 1,
            "leaf": 1,
            "word": 1,
            "know": 1,
            "answer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para75",
              "entity_text": "Sudoku",
              "entity_type": "ORG",
              "start_char": 2,
              "end_char": 8,
              "context": "A Sudoku puzzle can be considered a CSP with 81 variables,"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 36,
              "end_char": 39,
              "context": "A Sudoku puzzle can be considered a CSP with 81 variables, one for each square. We use th"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "F\n1",
              "entity_type": "PRODUCT",
              "start_char": 597,
              "end_char": 600,
              "context": ",\nB\n9)\n…\nA\nl\nl\nd\ni\nf\nf\n(\nA\n1,\nB\n1,\nC\n1,\nD\n1,\nE\n1,\nF\n1,\nG\n1,\nH\n1,\nI\n1)\nA\nl\nl\nd\ni\nf\nf\n(\nA\n2,\nB\n2,\nC\n2,\nD\n"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "F\n2",
              "entity_type": "PRODUCT",
              "start_char": 658,
              "end_char": 661,
              "context": "\n1,\nI\n1)\nA\nl\nl\nd\ni\nf\nf\n(\nA\n2,\nB\n2,\nC\n2,\nD\n2,\nE\n2,\nF\n2,\nG\n2,\nH\n2,\nI\n2)\n…\nA\nl\nl\nd\ni\nf\nf\n(\nA\n1,\nA\n2,\nA\n3,\n"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "AC-3",
              "entity_type": "PRODUCT",
              "start_char": 975,
              "end_char": 979,
              "context": "aints (such as\nA1\n≠\nA2\n) so that we can apply the AC-3 algorithm directly. Consider variable\nE6\nfrom\nFig"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "E6",
              "entity_type": "PRODUCT",
              "start_char": 1018,
              "end_char": 1020,
              "context": "ly the AC-3 algorithm directly. Consider variable\nE6\nfrom\nFigure 5.4(a)\n—the empty square between the "
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "E6",
              "entity_type": "PRODUCT",
              "start_char": 1168,
              "end_char": 1170,
              "context": "nts in the box, we can remove 1, 2, 7, and 8 from\nE6\n’s domain. From the constraints in its column, we"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "E6",
              "entity_type": "PRODUCT",
              "start_char": 1309,
              "end_char": 1311,
              "context": "though 2 and 8 were already removed). That leaves\nE6\nwith a domain of {4}; in other words, we know the"
            },
            {
              "para_id": "chap5_para75",
              "entity_text": "E6",
              "entity_type": "PRODUCT",
              "start_char": 1373,
              "end_char": 1375,
              "context": "in of {4}; in other words, we know the answer for\nE6."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para76",
          "content": "Now consider variable\n16\n—the square in the bottom middle box surrounded by 1, 3, and 3. Applying arc consistency in its column, we eliminate 5, 6, 2, 4 (since we now know\nE6\nmust be 4), 8, 9, and 3. We eliminate 1 by arc consistency with\nI5,\nand we are left with only the value 7 in the domain of\nI6.",
          "sentence_count": 3,
          "char_count": 246,
          "prev_para_id": "chap5_para75",
          "next_para_id": "chap5_para77",
          "style_metadata": {
            "para_id": "chap5_para76",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "consider": 1,
            "variable": 1,
            "—the": 1,
            "square": 1,
            "bottom": 1,
            "middle": 1,
            "box": 1,
            "surrounded": 1,
            "applying": 1,
            "arc": 2,
            "consistency": 2,
            "column": 1,
            "eliminate": 2,
            "know": 1,
            "left": 1,
            "value": 1,
            "domain": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para76",
              "entity_text": "E6",
              "entity_type": "PRODUCT",
              "start_char": 172,
              "end_char": 174,
              "context": "olumn, we eliminate 5, 6, 2, 4 (since we now know\nE6\nmust be 4), 8, 9, and 3. We eliminate 1 by arc co"
            },
            {
              "para_id": "chap5_para76",
              "entity_text": "I6",
              "entity_type": "PRODUCT",
              "start_char": 298,
              "end_char": 300,
              "context": "e are left with only the value 7 in the domain of\nI6."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para77",
          "content": "Now there are 8 known values in column 6, so arc consistency can infer that\nA6\nmust be 1. Inference continues along these lines, and eventually, AC-3 can solve the entire puzzle—all the variables have their domains reduced to a single value, as shown in\nFigure 5.4(b)\n.",
          "sentence_count": 2,
          "char_count": 226,
          "prev_para_id": "chap5_para76",
          "next_para_id": "chap5_para78",
          "style_metadata": {
            "para_id": "chap5_para77",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 2
          },
          "terminology": {
            "known": 1,
            "value": 2,
            "column": 1,
            "arc": 1,
            "consistency": 1,
            "infer": 1,
            "inference": 1,
            "continues": 1,
            "line": 1,
            "ac-3": 1,
            "solve": 1,
            "entire": 1,
            "puzzle—all": 1,
            "variable": 1,
            "domain": 1,
            "reduced": 1,
            "single": 1,
            "shown": 1,
            "figure": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para78",
          "content": "Description\nUp and down triangles represent MAX and MIN nodes, respectively. At the top level, a max node is present and the level is labeled Player. The next level is labeled Opponent and a MIN node is labeled m. The nodes in the player and opponent levels are connected. After many levels, the next level is represented by another level labeled Player and a node present is a MAX node. This node is connected to the MAX node of the player level at the top by a dashed line. The last level is labeled Opponent and a MIN node is labeled n. The nodes in the last player and opponent levels are connected.",
          "sentence_count": 6,
          "char_count": 492,
          "prev_para_id": "chap5_para77",
          "next_para_id": "chap5_para79",
          "style_metadata": {
            "para_id": "chap5_para78",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 20.33,
            "passive_voice_ratio": 0.057,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 122,
            "sentence_count": 6
          },
          "terminology": {
            "description": 1,
            "triangle": 1,
            "represent": 1,
            "max": 4,
            "min": 3,
            "node": 10,
            "top": 2,
            "level": 10,
            "present": 2,
            "labeled": 6,
            "player": 5,
            "next": 1,
            "opponent": 4,
            "connected": 3,
            "many": 1,
            "represented": 1,
            "dashed": 1,
            "line": 1,
            "last": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para78",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 44,
              "end_char": 47,
              "context": "Description\nUp and down triangles represent MAX and MIN nodes, respectively. At the top level, a "
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 52,
              "end_char": 55,
              "context": "scription\nUp and down triangles represent MAX and MIN nodes, respectively. At the top level, a max node"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "max node",
              "entity_type": "PERSON",
              "start_char": 97,
              "end_char": 105,
              "context": " and MIN nodes, respectively. At the top level, a max node is present and the level is labeled Player. The n"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "Player",
              "entity_type": "PERSON",
              "start_char": 142,
              "end_char": 148,
              "context": "l, a max node is present and the level is labeled Player. The next level is labeled Opponent and a MIN nod"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "Opponent",
              "entity_type": "ORG",
              "start_char": 176,
              "end_char": 184,
              "context": "evel is labeled Player. The next level is labeled Opponent and a MIN node is labeled m. The nodes in the pla"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 191,
              "end_char": 194,
              "context": " Player. The next level is labeled Opponent and a MIN node is labeled m. The nodes in the player and op"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "Player",
              "entity_type": "PERSON",
              "start_char": 347,
              "end_char": 353,
              "context": "ext level is represented by another level labeled Player and a node present is a MAX node. This node is co"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 378,
              "end_char": 381,
              "context": "ther level labeled Player and a node present is a MAX node. This node is connected to the MAX node of t"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 418,
              "end_char": 421,
              "context": "sent is a MAX node. This node is connected to the MAX node of the player level at the top by a dashed l"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "Opponent",
              "entity_type": "ORG",
              "start_char": 502,
              "end_char": 510,
              "context": "e top by a dashed line. The last level is labeled Opponent and a MIN node is labeled n. The nodes in the las"
            },
            {
              "para_id": "chap5_para78",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 517,
              "end_char": 520,
              "context": "ed line. The last level is labeled Opponent and a MIN node is labeled n. The nodes in the last player a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para79",
          "content": "×\nFigure 5.4\n(a) A Sudoku puzzle and (b) its solution.",
          "sentence_count": 1,
          "char_count": 46,
          "prev_para_id": "chap5_para78",
          "next_para_id": "chap5_para80",
          "style_metadata": {
            "para_id": "chap5_para79",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "sudoku": 1,
            "puzzle": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para79",
              "entity_text": "Sudoku",
              "entity_type": "ORG",
              "start_char": 19,
              "end_char": 25,
              "context": "×\nFigure 5.4\n(a) A Sudoku puzzle and (b) its solution."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para80",
          "content": "Of course, Sudoku would soon lose its appeal if every puzzle could be solved by a mechanical application of AC-3, and indeed AC-3 works only for the easiest Sudoku puzzles. Slightly harder ones can be solved by PC-2, but at a greater computational cost: there are 255,960 different path constraints to consider in a Sudoku puzzle. To solve the hardest puzzles and to make efficient progress, we will have to be more clever.",
          "sentence_count": 3,
          "char_count": 351,
          "prev_para_id": "chap5_para79",
          "next_para_id": "chap5_para81",
          "style_metadata": {
            "para_id": "chap5_para80",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 81,
            "sentence_count": 3
          },
          "terminology": {
            "course": 1,
            "sudoku": 3,
            "lose": 1,
            "appeal": 1,
            "puzzle": 4,
            "solved": 2,
            "mechanical": 1,
            "application": 1,
            "ac-3": 2,
            "work": 1,
            "easiest": 1,
            "harder": 1,
            "one": 1,
            "pc-2": 1,
            "greater": 1,
            "computational": 1,
            "cost": 1,
            "different": 1,
            "path": 1,
            "constraint": 1,
            "consider": 1,
            "solve": 1,
            "hardest": 1,
            "make": 1,
            "efficient": 1,
            "progress": 1,
            "clever": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para80",
              "entity_text": "Sudoku",
              "entity_type": "PERSON",
              "start_char": 11,
              "end_char": 17,
              "context": "Of course, Sudoku would soon lose its appeal if every puzzle could "
            },
            {
              "para_id": "chap5_para80",
              "entity_text": "AC-3",
              "entity_type": "GPE",
              "start_char": 108,
              "end_char": 112,
              "context": "le could be solved by a mechanical application of AC-3, and indeed AC-3 works only for the easiest Sudok"
            },
            {
              "para_id": "chap5_para80",
              "entity_text": "Sudoku",
              "entity_type": "PERSON",
              "start_char": 157,
              "end_char": 163,
              "context": " AC-3, and indeed AC-3 works only for the easiest Sudoku puzzles. Slightly harder ones can be solved by PC"
            },
            {
              "para_id": "chap5_para80",
              "entity_text": "PC-2",
              "entity_type": "ORG",
              "start_char": 211,
              "end_char": 215,
              "context": "ku puzzles. Slightly harder ones can be solved by PC-2, but at a greater computational cost: there are 2"
            },
            {
              "para_id": "chap5_para80",
              "entity_text": "Sudoku",
              "entity_type": "ORG",
              "start_char": 316,
              "end_char": 322,
              "context": "5,960 different path constraints to consider in a Sudoku puzzle. To solve the hardest puzzles and to make "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para81",
          "content": "Indeed, the appeal of Sudoku puzzles for the human solver is the need to be resourceful in applying more complex inference strategies. Aficionados give them colorful names, such as “naked triples.” That strategy works as follows: in any unit (row, column or box), find three squares that each have a domain that contains the same three numbers or a subset of those numbers. For example, the three domains might be {1,8}, {3,8}, and {1,3,8}. From that we don’t know which square contains 1, 3, or 8, but we do know that the three numbers must be distributed among the three squares. Therefore we can remove 1, 3, and 8 from the domains of every\nother\nsquare in the unit.",
          "sentence_count": 5,
          "char_count": 553,
          "prev_para_id": "chap5_para80",
          "next_para_id": "chap5_para82",
          "style_metadata": {
            "para_id": "chap5_para81",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 29.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 149,
            "sentence_count": 5
          },
          "terminology": {
            "appeal": 1,
            "sudoku": 1,
            "puzzle": 1,
            "human": 1,
            "need": 1,
            "resourceful": 1,
            "applying": 1,
            "complex": 1,
            "inference": 1,
            "strategy": 2,
            "aficionado": 1,
            "give": 1,
            "colorful": 1,
            "name": 1,
            "naked": 1,
            "triples.": 1,
            "work": 1,
            "follows": 1,
            "unit": 2,
            "row": 1,
            "column": 1,
            "box": 1,
            "find": 1,
            "square": 4,
            "domain": 3,
            "contains": 2,
            "number": 3,
            "subset": 1,
            "example": 1,
            "know": 2,
            "distributed": 1,
            "remove": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para81",
              "entity_text": "Sudoku",
              "entity_type": "ORG",
              "start_char": 22,
              "end_char": 28,
              "context": "Indeed, the appeal of Sudoku puzzles for the human solver is the need to be re"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para82",
          "content": "It is interesting to note how far we can go without saying much that is specific to Sudoku. We do of course have to say that there are 81 variables, that their domains are the digits 1 to 9, and that there are 27\nAlldiff\nconstraints. But beyond that, all the strategies—arc consistency, path consistency, and so on—apply generally to all CSPs, not just to Sudoku problems. Even naked triples is really a strategy for enforcing consistency of\nAlldiff\nconstraints and is not specific to Sudoku\nper se\n. This is the power of the CSP formalism: for each new problem area, we only need to define the problem in terms of constraints; then the general constraintsolving mechanisms can take over.",
          "sentence_count": 5,
          "char_count": 574,
          "prev_para_id": "chap5_para81",
          "next_para_id": "chap5_para83",
          "style_metadata": {
            "para_id": "chap5_para82",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.8,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 134,
            "sentence_count": 5
          },
          "terminology": {
            "interesting": 1,
            "note": 1,
            "saying": 1,
            "much": 1,
            "specific": 2,
            "sudoku": 2,
            "course": 1,
            "say": 1,
            "variable": 1,
            "domain": 1,
            "digit": 1,
            "alldiff": 2,
            "constraint": 3,
            "strategies—arc": 1,
            "consistency": 3,
            "path": 1,
            "csps": 1,
            "problem": 3,
            "naked": 1,
            "triple": 1,
            "strategy": 1,
            "enforcing": 1,
            "power": 1,
            "csp": 1,
            "formalism": 1,
            "new": 1,
            "area": 1,
            "need": 1,
            "define": 1,
            "term": 1,
            "general": 1,
            "constraintsolving": 1,
            "mechanism": 1,
            "take": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para82",
              "entity_text": "Sudoku",
              "entity_type": "PERSON",
              "start_char": 84,
              "end_char": 90,
              "context": "we can go without saying much that is specific to Sudoku. We do of course have to say that there are 81 va"
            },
            {
              "para_id": "chap5_para82",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 526,
              "end_char": 529,
              "context": "cific to Sudoku\nper se\n. This is the power of the CSP formalism: for each new problem area, we only nee"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para83",
          "content": "5.3Backtracking Search for CSPs\n5.3\nBacktracking Search for CSPs\nSometimes we can finish the constraint propagation process and still have variables with multiple possible values. In that case we have to\nsearch\nfor a solution. In this section we cover backtracking search algorithms that work on partial assignments; in the next section we look at local search algorithms over complete assignments.",
          "sentence_count": 3,
          "char_count": 343,
          "prev_para_id": "chap5_para82",
          "next_para_id": "chap5_para84",
          "style_metadata": {
            "para_id": "chap5_para83",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 65,
            "sentence_count": 3
          },
          "terminology": {
            "5.3backtracking": 1,
            "search": 5,
            "csps": 2,
            "backtracking": 2,
            "finish": 1,
            "constraint": 1,
            "propagation": 1,
            "process": 1,
            "variable": 1,
            "multiple": 1,
            "possible": 1,
            "value": 1,
            "case": 1,
            "solution": 1,
            "section": 2,
            "cover": 1,
            "algorithm": 2,
            "work": 1,
            "partial": 1,
            "assignment": 2,
            "look": 1,
            "local": 1,
            "complete": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para84",
          "content": "Consider how a standard depth-limited search (from\nChapter 3\n) could solve CSPs. A state would be a partial assignment, and an action would extend the assignment, adding, say,\nNSW = red\nor\nSA = blue\nfor the Australia map-coloring problem. For a CSP with\nn\nvariables of domain size\nd\nwe would end up with a search tree where all the complete assignments (and thus all the solutions) are leaf nodes at depth\nn\n. But notice that the branching factor at the top level would be\nnd\nbecause any of\nd\nvalues can be assigned to any of\nn\nvariables. At the next level, the branching factor is (\nn\n– 1)\nd\n, and so on for\nn\nlevels. So the tree has\nn\n! ·\nd\nn\nleaves, even though there are only\nd\nn\npossible complete assignments!",
          "sentence_count": 7,
          "char_count": 605,
          "prev_para_id": "chap5_para83",
          "next_para_id": "chap5_para85",
          "style_metadata": {
            "para_id": "chap5_para84",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.43,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 157,
            "sentence_count": 7
          },
          "terminology": {
            "consider": 1,
            "standard": 1,
            "depth-limited": 1,
            "search": 2,
            "chapter": 1,
            "solve": 1,
            "csps": 1,
            "state": 1,
            "partial": 1,
            "assignment": 4,
            "action": 1,
            "extend": 1,
            "adding": 1,
            "say": 1,
            "nsw": 1,
            "red": 1,
            "blue": 1,
            "map-coloring": 1,
            "problem": 1,
            "csp": 1,
            "variable": 2,
            "domain": 1,
            "size": 1,
            "end": 1,
            "tree": 2,
            "complete": 2,
            "solution": 1,
            "leaf": 2,
            "node": 1,
            "depth": 1,
            "branching": 2,
            "factor": 2,
            "top": 1,
            "level": 3,
            "value": 1,
            "assigned": 1,
            "possible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para84",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 189,
              "end_char": 191,
              "context": " extend the assignment, adding, say,\nNSW = red\nor\nSA = blue\nfor the Australia map-coloring problem. Fo"
            },
            {
              "para_id": "chap5_para84",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 207,
              "end_char": 216,
              "context": "ment, adding, say,\nNSW = red\nor\nSA = blue\nfor the Australia map-coloring problem. For a CSP with\nn\nvariables "
            },
            {
              "para_id": "chap5_para84",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 245,
              "end_char": 248,
              "context": "lue\nfor the Australia map-coloring problem. For a CSP with\nn\nvariables of domain size\nd\nwe would end up"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para85",
          "content": "We can get back that factor of\nn\n! by recognizing a crucial property of CSPs:\ncommutativity\n. A problem is commutative if the order of application of any given set of actions does not matter. In CSPs, it makes no difference if we first assign\nNSW = red\nand then\nSA = blue,\nor the other way around. Therefore, we need only consider a\nsingle\nvariable at each node in the search tree. At the root we might make a choice between\nSA\n=\nred\n,\nSA\n=\ngreen\n, and\nSA = blue,\nbut we would never choose between\nNSW = red\nand\nSA = blue.",
          "sentence_count": 6,
          "char_count": 438,
          "prev_para_id": "chap5_para84",
          "next_para_id": "chap5_para86",
          "style_metadata": {
            "para_id": "chap5_para85",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 19.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 117,
            "sentence_count": 6
          },
          "terminology": {
            "get": 1,
            "factor": 1,
            "recognizing": 1,
            "crucial": 1,
            "property": 1,
            "csps": 2,
            "commutativity": 1,
            "problem": 1,
            "commutative": 1,
            "order": 1,
            "application": 1,
            "given": 1,
            "set": 1,
            "action": 1,
            "make": 2,
            "difference": 1,
            "first": 1,
            "assign": 1,
            "red": 3,
            "blue": 3,
            "way": 1,
            "need": 1,
            "consider": 1,
            "single": 1,
            "variable": 1,
            "node": 1,
            "search": 1,
            "tree": 1,
            "root": 1,
            "choice": 1,
            "green": 1,
            "choose": 1,
            "nsw": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para85",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 262,
              "end_char": 264,
              "context": " difference if we first assign\nNSW = red\nand then\nSA = blue,\nor the other way around. Therefore, we ne"
            },
            {
              "para_id": "chap5_para85",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 436,
              "end_char": 438,
              "context": "he root we might make a choice between\nSA\n=\nred\n,\nSA\n=\ngreen\n, and\nSA = blue,\nbut we would never choos"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para86",
          "content": "With this restriction, the number of leaves is\nd\nn\n,\nas we would hope. At each level of the tree we do have to choose which variable we will deal with, but we never have to backtrack over that choice.",
          "sentence_count": 2,
          "char_count": 164,
          "prev_para_id": "chap5_para85",
          "next_para_id": "chap5_para87",
          "style_metadata": {
            "para_id": "chap5_para86",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 45,
            "sentence_count": 2
          },
          "terminology": {
            "restriction": 1,
            "number": 1,
            "leaf": 1,
            "hope": 1,
            "level": 1,
            "tree": 1,
            "choose": 1,
            "variable": 1,
            "deal": 1,
            "backtrack": 1,
            "choice": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para87",
          "content": "Figure 5.5\nshows a backtracking search procedure for CSPs. It repeatedly chooses an unassigned variable, and then tries all values in the domain of that variable in turn, trying to extend each one into a solution via a recursive call. If the call succeeds, the solution is returned, and if it fails, the assignment is restored to the previous state, and we try the next value. If no value works then we return failure. Part of the search tree for the Australia problem is shown in\nFigure 5.6\n, where we have assigned variables in the order\nWA, NT, Q,....",
          "sentence_count": 5,
          "char_count": 459,
          "prev_para_id": "chap5_para86",
          "next_para_id": "chap5_para88",
          "style_metadata": {
            "para_id": "chap5_para87",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.8,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 2,
            "show": 1,
            "backtracking": 1,
            "search": 2,
            "procedure": 1,
            "csps": 1,
            "chooses": 1,
            "unassigned": 1,
            "variable": 3,
            "try": 2,
            "value": 3,
            "domain": 1,
            "turn": 1,
            "trying": 1,
            "extend": 1,
            "solution": 2,
            "recursive": 1,
            "call": 2,
            "succeeds": 1,
            "returned": 1,
            "fails": 1,
            "assignment": 1,
            "restored": 1,
            "previous": 1,
            "state": 1,
            "work": 1,
            "return": 1,
            "failure": 1,
            "part": 1,
            "tree": 1,
            "australia": 1,
            "problem": 1,
            "shown": 1,
            "assigned": 1,
            "order": 1,
            "....": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para87",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 451,
              "end_char": 460,
              "context": "e return failure. Part of the search tree for the Australia problem is shown in\nFigure 5.6\n, where we have as"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para88",
          "content": "Description\nPart (“a”): The blacks are in the following positions. King, e 8. Queen, g 2. Rooks, \"a\" 8 and h 8. Bishop, c 8. Knights d 4 and g 8. Pawns, \"a\" 7, b 7, c 7, d 6, e 5, f 7, g 7, and h 7. The whites are in the following positions. King, e 1. Queen, d 1. Rooks, \"a\" 1 and h 1. Bishop, c 4. Knight c3. Pawns, \"a\" 2, b 2, c 2, e 4, f 2, and h 2. Part (b): All the pieces are in the same positions as in part (“a”), except the white rook at h 1 moves to g 1.",
          "sentence_count": 15,
          "char_count": 355,
          "prev_para_id": "chap5_para87",
          "next_para_id": "chap5_para89",
          "style_metadata": {
            "para_id": "chap5_para88",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 10.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 159,
            "sentence_count": 15
          },
          "terminology": {
            "description": 1,
            "part": 3,
            "black": 1,
            "following": 2,
            "position": 3,
            "king": 2,
            "queen": 2,
            "rook": 3,
            "knight": 2,
            "pawn": 2,
            "white": 2,
            "bishop": 1,
            "piece": 1,
            "move": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para88",
              "entity_text": "Bishop",
              "entity_type": "ORG",
              "start_char": 112,
              "end_char": 118,
              "context": "ons. King, e 8. Queen, g 2. Rooks, \"a\" 8 and h 8. Bishop, c 8. Knights d 4 and g 8. Pawns, \"a\" 7, b 7, c 7"
            },
            {
              "para_id": "chap5_para88",
              "entity_text": "Knights d 4",
              "entity_type": "ORG",
              "start_char": 125,
              "end_char": 136,
              "context": "8. Queen, g 2. Rooks, \"a\" 8 and h 8. Bishop, c 8. Knights d 4 and g 8. Pawns, \"a\" 7, b 7, c 7, d 6, e 5, f 7, g"
            },
            {
              "para_id": "chap5_para88",
              "entity_text": "Bishop",
              "entity_type": "ORG",
              "start_char": 287,
              "end_char": 293,
              "context": "ons. King, e 1. Queen, d 1. Rooks, \"a\" 1 and h 1. Bishop, c 4. Knight c3. Pawns, \"a\" 2, b 2, c 2, e 4, f 2"
            },
            {
              "para_id": "chap5_para88",
              "entity_text": "Knight c3.",
              "entity_type": "PERSON",
              "start_char": 300,
              "end_char": 310,
              "context": "1. Queen, d 1. Rooks, \"a\" 1 and h 1. Bishop, c 4. Knight c3. Pawns, \"a\" 2, b 2, c 2, e 4, f 2, and h 2. Part ("
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para89",
          "content": "×\nFigure 5.5\nA simple backtracking algorithm for constraint satisfaction problems. The algorithm is modeled on the recursive depth-first search of\nChapter 3\n. The functions S\nELECT\n-U\nNASSIGNED\n-V\nARIABLE\nand O\nRDER\n-D\nOMAIN\n-V\nALUES\nimplement the generalpurpose heuristics discussed in\nSection 5.3.1\n. The I\nNFERENCE\nfunction can optionally impose arc-, path-, or\nk\n-consistency, as desired. If a value choice leads to failure (noticed either by I\nNFERENCE\nor by B\nACKTRACK\n), then value assignments (including those made by I\nNFERENCE\n) are retracted and a new value is tried.",
          "sentence_count": 5,
          "char_count": 510,
          "prev_para_id": "chap5_para88",
          "next_para_id": "chap5_para90",
          "style_metadata": {
            "para_id": "chap5_para89",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.2,
            "passive_voice_ratio": 0.019,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "simple": 1,
            "backtracking": 1,
            "algorithm": 2,
            "constraint": 1,
            "satisfaction": 1,
            "problem": 1,
            "modeled": 1,
            "recursive": 1,
            "depth-first": 1,
            "search": 1,
            "chapter": 1,
            "function": 2,
            "elect": 1,
            "nassigned": 1,
            "ariable": 1,
            "rder": 1,
            "omain": 1,
            "alues": 1,
            "implement": 1,
            "generalpurpose": 1,
            "heuristic": 1,
            "discussed": 1,
            "section": 1,
            "nference": 3,
            "impose": 1,
            "arc-": 1,
            "path-": 1,
            "-consistency": 1,
            "desired": 1,
            "value": 3,
            "choice": 1,
            "lead": 1,
            "failure": 1,
            "noticed": 1,
            "acktrack": 1,
            "assignment": 1,
            "including": 1,
            "made": 1,
            "retracted": 1,
            "new": 1,
            "tried": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para89",
              "entity_text": "OMAIN",
              "entity_type": "ORG",
              "start_char": 219,
              "end_char": 224,
              "context": "ons S\nELECT\n-U\nNASSIGNED\n-V\nARIABLE\nand O\nRDER\n-D\nOMAIN\n-V\nALUES\nimplement the generalpurpose heuristics "
            },
            {
              "para_id": "chap5_para89",
              "entity_text": "ALUES",
              "entity_type": "ORG",
              "start_char": 228,
              "end_char": 233,
              "context": "CT\n-U\nNASSIGNED\n-V\nARIABLE\nand O\nRDER\n-D\nOMAIN\n-V\nALUES\nimplement the generalpurpose heuristics discussed"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para90",
          "content": "Description\nThe blacks are in the following positions. King, g 7. Bishop, \"a\" 2. Pawns, g 6, f 5, e 4, and b 4. The whites are in the following positions. King, d 2. Rook, h 2. Pawns, c 2 and b 3.",
          "sentence_count": 8,
          "char_count": 155,
          "prev_para_id": "chap5_para89",
          "next_para_id": "chap5_para91",
          "style_metadata": {
            "para_id": "chap5_para90",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.12,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 8
          },
          "terminology": {
            "description": 1,
            "black": 1,
            "following": 2,
            "position": 2,
            "king": 2,
            "bishop": 1,
            "pawn": 2,
            "white": 1,
            "rook": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para90",
              "entity_text": "Bishop",
              "entity_type": "ORG",
              "start_char": 66,
              "end_char": 72,
              "context": "blacks are in the following positions. King, g 7. Bishop, \"a\" 2. Pawns, g 6, f 5, e 4, and b 4. The whites"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para91",
          "content": "×\nFigure 5.6\nPart of the search tree for the map-coloring problem in\nFigure 5.1\n.",
          "sentence_count": 1,
          "char_count": 70,
          "prev_para_id": "chap5_para90",
          "next_para_id": "chap5_para92",
          "style_metadata": {
            "para_id": "chap5_para91",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 2,
            "part": 1,
            "search": 1,
            "tree": 1,
            "map-coloring": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para92",
          "content": "Notice that B\nACKTRACKING\n-S\nEARCH\nkeeps only a single representation of a state (assignment) and alters that representation rather than creating new ones (see\npage 98\n).",
          "sentence_count": 1,
          "char_count": 149,
          "prev_para_id": "chap5_para91",
          "next_para_id": "chap5_para93",
          "style_metadata": {
            "para_id": "chap5_para92",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 1
          },
          "terminology": {
            "acktracking": 1,
            "earch": 1,
            "keep": 1,
            "single": 1,
            "representation": 2,
            "state": 1,
            "assignment": 1,
            "alters": 1,
            "creating": 1,
            "new": 1,
            "one": 1,
            "see": 1,
            "page": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para93",
          "content": "Whereas the uninformed search algorithms of\nChapter 3\ncould be improved only by supplying them with\ndomain-specific\nheuristics, it turns out that backtracking search can be improved using\ndomain-independent\nheuristics that take advantage of the factored representation of CSPs. In the following four sections we show how this is done:\n•\n(5.3.1) Which variable should be assigned next (S\nELECT\n-U\nNASSIGNED\n-V\nARIABLE\n), and in what order should its values be tried (O\nRDER\n-D\nOMAIN\n-V\nALUES\n)?",
          "sentence_count": 2,
          "char_count": 433,
          "prev_para_id": "chap5_para92",
          "next_para_id": "chap5_para94",
          "style_metadata": {
            "para_id": "chap5_para93",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 90,
            "sentence_count": 2
          },
          "terminology": {
            "whereas": 1,
            "uninformed": 1,
            "search": 2,
            "algorithm": 1,
            "chapter": 1,
            "improved": 2,
            "supplying": 1,
            "domain-specific": 1,
            "heuristic": 2,
            "turn": 1,
            "backtracking": 1,
            "using": 1,
            "domain-independent": 1,
            "take": 1,
            "advantage": 1,
            "factored": 1,
            "representation": 1,
            "csps": 1,
            "following": 1,
            "section": 1,
            "show": 1,
            "done": 1,
            "variable": 1,
            "assigned": 1,
            "next": 1,
            "elect": 1,
            "nassigned": 1,
            "ariable": 1,
            "order": 1,
            "value": 1,
            "tried": 1,
            "rder": 1,
            "omain": 1,
            "alues": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para93",
              "entity_text": "OMAIN",
              "entity_type": "ORG",
              "start_char": 476,
              "end_char": 481,
              "context": " what order should its values be tried (O\nRDER\n-D\nOMAIN\n-V\nALUES\n)?"
            },
            {
              "para_id": "chap5_para93",
              "entity_text": "ALUES",
              "entity_type": "ORG",
              "start_char": 485,
              "end_char": 490,
              "context": "er should its values be tried (O\nRDER\n-D\nOMAIN\n-V\nALUES\n)?"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para94",
          "content": "•\n(5.3.2) What inferences should be performed at each step in the search (I\nNFERENCE\n)?",
          "sentence_count": 1,
          "char_count": 75,
          "prev_para_id": "chap5_para93",
          "next_para_id": "chap5_para95",
          "style_metadata": {
            "para_id": "chap5_para94",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 1
          },
          "terminology": {
            "inference": 1,
            "performed": 1,
            "step": 1,
            "search": 1,
            "nference": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para95",
          "content": "•\n(5.3.3) Can we B\nACKTRACK\nmore than one step when appropriate?",
          "sentence_count": 1,
          "char_count": 56,
          "prev_para_id": "chap5_para94",
          "next_para_id": "chap5_para96",
          "style_metadata": {
            "para_id": "chap5_para95",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "acktrack": 1,
            "step": 1,
            "appropriate": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para96",
          "content": "•\n(5.3.4) Can we save and reuse partial results from the search?",
          "sentence_count": 1,
          "char_count": 54,
          "prev_para_id": "chap5_para95",
          "next_para_id": "chap5_para97",
          "style_metadata": {
            "para_id": "chap5_para96",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "save": 1,
            "reuse": 1,
            "partial": 1,
            "result": 1,
            "search": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para97",
          "content": "5.3.1\nVariable and value ordering\nThe backtracking algorithm contains the line\nv\na\nr\n←\nSELECT-UNASSIGNED-VARIABLE(\nc\ns\np\n,\na\ns\ns\ni\ng\nn\nm\ne\nn\nt\n)\n.",
          "sentence_count": 1,
          "char_count": 138,
          "prev_para_id": "chap5_para96",
          "next_para_id": "chap5_para98",
          "style_metadata": {
            "para_id": "chap5_para97",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 1
          },
          "terminology": {
            "variable": 1,
            "value": 1,
            "ordering": 1,
            "backtracking": 1,
            "algorithm": 1,
            "contains": 1,
            "line": 1,
            "select-unassigned-variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para97",
              "entity_text": "←\nSELECT-UNASSIGNED-VARIABLE",
              "entity_type": "ORG",
              "start_char": 85,
              "end_char": 113,
              "context": "he backtracking algorithm contains the line\nv\na\nr\n←\nSELECT-UNASSIGNED-VARIABLE(\nc\ns\np\n,\na\ns\ns\ni\ng\nn\nm\ne\nn\nt\n)\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para98",
          "content": "The simplest strategy for S\nELECT\n-U\nNASSIGNED\n-V\nARIABLE\nis static ordering: choose the variables in order, {\nX\n1\n,\nX\n2\n,...}. The next simplest is to choose randomly. Neither strategy is optimal. For example, after the assignments for\nWA = red\nand\nNT = green\nin\nFigure 5.6\n, there is only one possible value for\nSA\n, so it makes sense to assign\nSA = blue\nnext rather than assigning\nQ\n. in fact, after\nSA\nis assigned, the choices for\nQ\n,\nNSW\n, and\nV\nare all forced.",
          "sentence_count": 5,
          "char_count": 404,
          "prev_para_id": "chap5_para97",
          "next_para_id": "chap5_para99",
          "style_metadata": {
            "para_id": "chap5_para98",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.2,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 106,
            "sentence_count": 5
          },
          "terminology": {
            "simplest": 2,
            "strategy": 2,
            "elect": 1,
            "nassigned": 1,
            "ariable": 1,
            "static": 1,
            "ordering": 1,
            "choose": 2,
            "variable": 1,
            "order": 1,
            "next": 2,
            "optimal": 1,
            "example": 1,
            "assignment": 1,
            "red": 1,
            "green": 1,
            "figure": 1,
            "possible": 1,
            "value": 1,
            "make": 1,
            "sense": 1,
            "assign": 1,
            "blue": 1,
            "assigning": 1,
            "fact": 1,
            "assigned": 1,
            "choice": 1,
            "forced": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para98",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 347,
              "end_char": 349,
              "context": "ssible value for\nSA\n, so it makes sense to assign\nSA = blue\nnext rather than assigning\nQ\n. in fact, af"
            },
            {
              "para_id": "chap5_para98",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 403,
              "end_char": 405,
              "context": "lue\nnext rather than assigning\nQ\n. in fact, after\nSA\nis assigned, the choices for\nQ\n,\nNSW\n, and\nV\nare "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para99",
          "content": "This intuitive idea—choosing the variable with the fewest “legal” values—is called the\nminimum-remaining-values\n(MRV) heuristic. It also has been called the “most constrained variable” or “fail-first” heuristic, the latter because it picks a variable that is most likely to cause a failure soon, thereby pruning the search tree. If some variable\nX\nhas no legal values left, the MRV heuristic will select\nX\nand failure will be detected immediately—avoiding pointless searches through other variables. The MRV heuristic usually performs better than a random or static ordering, sometimes by orders of magnitude, although the results vary depending on the problem.",
          "sentence_count": 4,
          "char_count": 569,
          "prev_para_id": "chap5_para98",
          "next_para_id": "chap5_para100",
          "style_metadata": {
            "para_id": "chap5_para99",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 116,
            "sentence_count": 4
          },
          "terminology": {
            "intuitive": 1,
            "idea—choosing": 1,
            "variable": 5,
            "fewest": 1,
            "legal": 2,
            "values—is": 1,
            "called": 2,
            "minimum-remaining-values": 1,
            "heuristic": 4,
            "constrained": 1,
            "fail-first": 1,
            "latter": 1,
            "pick": 1,
            "likely": 1,
            "cause": 1,
            "failure": 2,
            "pruning": 1,
            "search": 2,
            "tree": 1,
            "value": 1,
            "left": 1,
            "mrv": 1,
            "select": 1,
            "detected": 1,
            "immediately—avoiding": 1,
            "pointless": 1,
            "performs": 1,
            "better": 1,
            "random": 1,
            "static": 1,
            "ordering": 1,
            "order": 1,
            "magnitude": 1,
            "result": 1,
            "vary": 1,
            "depending": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para99",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 378,
              "end_char": 381,
              "context": " If some variable\nX\nhas no legal values left, the MRV heuristic will select\nX\nand failure will be detec"
            },
            {
              "para_id": "chap5_para99",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 504,
              "end_char": 507,
              "context": "g pointless searches through other variables. The MRV heuristic usually performs better than a random o"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para100",
          "content": "The MRV heuristic doesn’t help at all in choosing the first region to color in Australia, because initially every region has three legal colors. In this case, the\ndegree heuristic\ncomes in handy. It attempts to reduce the branching factor on future choices by selecting the variable that is involved in the largest number of constraints on other unassigned variables. In\nFigure 5.1\n,\nSA\nis the variable with highest degree, 5; the other variables have degree 2 or 3, except for\nT\n, which has degree 0. If we assign the\nSA\nfirst, we can then go around the five mainland regions in clockwise or counterclockwise order and assign each one a color that is different than\nSA\nand different than the previous region. The minimum-remaining-values heuristic is usually a more powerful guide, but the degree heuristic can be useful as a tie-breaker.",
          "sentence_count": 6,
          "char_count": 708,
          "prev_para_id": "chap5_para99",
          "next_para_id": "chap5_para101",
          "style_metadata": {
            "para_id": "chap5_para100",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.33,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 158,
            "sentence_count": 6
          },
          "terminology": {
            "mrv": 1,
            "heuristic": 4,
            "help": 1,
            "choosing": 1,
            "first": 1,
            "region": 4,
            "color": 3,
            "australia": 1,
            "legal": 1,
            "case": 1,
            "degree": 5,
            "come": 1,
            "handy": 1,
            "attempt": 1,
            "reduce": 1,
            "branching": 1,
            "factor": 1,
            "future": 1,
            "choice": 1,
            "selecting": 1,
            "variable": 4,
            "involved": 1,
            "largest": 1,
            "number": 1,
            "constraint": 1,
            "unassigned": 1,
            "figure": 1,
            "highest": 1,
            "assign": 2,
            "mainland": 1,
            "clockwise": 1,
            "counterclockwise": 1,
            "order": 1,
            "different": 2,
            "previous": 1,
            "minimum-remaining-values": 1,
            "powerful": 1,
            "guide": 1,
            "useful": 1,
            "tie-breaker": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para100",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 4,
              "end_char": 7,
              "context": "The MRV heuristic doesn’t help at all in choosing the fir"
            },
            {
              "para_id": "chap5_para100",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 79,
              "end_char": 88,
              "context": "p at all in choosing the first region to color in Australia, because initially every region has three legal c"
            },
            {
              "para_id": "chap5_para100",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 384,
              "end_char": 386,
              "context": "ts on other unassigned variables. In\nFigure 5.1\n,\nSA\nis the variable with highest degree, 5; the other"
            },
            {
              "para_id": "chap5_para100",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 667,
              "end_char": 669,
              "context": "nd assign each one a color that is different than\nSA\nand different than the previous region. The minim"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para101",
          "content": "Once a variable has been selected, the algorithm must decide on the order in which to examine its values. The\nleast-constraining-value\nheuristic is effective for this. It prefers the value that rules out the fewest choices for the neighboring variables in the constraint\ngraph. For example, suppose that in\nFigure 5.1\nwe have generated the partial assignment with\nWA = red\nand\nNT = green\nand that our next choice is for\nQ\n. Blue would be a bad choice because it eliminates the last legal value left for\nQ\n’s neighbor,\nSA\n. The least-constraining-value heuristic therefore prefers red to blue. In general, the heuristic is trying to leave the maximum flexibility for subsequent variable assignments.",
          "sentence_count": 7,
          "char_count": 597,
          "prev_para_id": "chap5_para100",
          "next_para_id": "chap5_para102",
          "style_metadata": {
            "para_id": "chap5_para101",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 18.14,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 127,
            "sentence_count": 7
          },
          "terminology": {
            "variable": 3,
            "selected": 1,
            "algorithm": 1,
            "decide": 1,
            "order": 1,
            "examine": 1,
            "value": 3,
            "least-constraining-value": 2,
            "heuristic": 3,
            "effective": 1,
            "prefers": 2,
            "rule": 1,
            "fewest": 1,
            "choice": 3,
            "neighboring": 1,
            "constraint": 1,
            "graph": 1,
            "example": 1,
            "suppose": 1,
            "figure": 1,
            "generated": 1,
            "partial": 1,
            "assignment": 2,
            "red": 2,
            "green": 1,
            "next": 1,
            "blue": 2,
            "bad": 1,
            "eliminates": 1,
            "last": 1,
            "legal": 1,
            "left": 1,
            "neighbor": 1,
            "therefore": 1,
            "general": 1,
            "trying": 1,
            "leave": 1,
            "maximum": 1,
            "flexibility": 1,
            "subsequent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para101",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 518,
              "end_char": 520,
              "context": "ates the last legal value left for\nQ\n’s neighbor,\nSA\n. The least-constraining-value heuristic therefor"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para102",
          "content": "Why should variable selection be fail-first, but value selection be fail-last? Every variable has to be assigned eventually, so by choosing the ones that are likely to fail first, we will on average have fewer successful assignments to backtrack over. For value ordering, the trick is that we only need one solution; therefore it makes sense to look for the most likely values first. If we wanted to enumerate all solutions rather than just find one, then value ordering would be irrelevant.",
          "sentence_count": 4,
          "char_count": 410,
          "prev_para_id": "chap5_para101",
          "next_para_id": "chap5_para103",
          "style_metadata": {
            "para_id": "chap5_para102",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 92,
            "sentence_count": 4
          },
          "terminology": {
            "variable": 2,
            "selection": 2,
            "fail-first": 1,
            "value": 4,
            "fail-last": 1,
            "assigned": 1,
            "choosing": 1,
            "one": 1,
            "fail": 1,
            "first": 1,
            "average": 1,
            "fewer": 1,
            "successful": 1,
            "assignment": 1,
            "backtrack": 1,
            "ordering": 2,
            "trick": 1,
            "need": 1,
            "solution": 2,
            "therefore": 1,
            "make": 1,
            "sense": 1,
            "likely": 1,
            "wanted": 1,
            "enumerate": 1,
            "find": 1,
            "irrelevant": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para103",
          "content": "5.3.2\nInterleaving search and inference\nWe saw how AC-3 can reduce the domains of variables\nbefore\nwe begin the search. But inference can be even more powerful\nduring\nthe course of a search: every time we make a choice of a value for a variable, we have a brand-new opportunity to infer new domain reductions on the neighboring variables.",
          "sentence_count": 2,
          "char_count": 286,
          "prev_para_id": "chap5_para102",
          "next_para_id": "chap5_para104",
          "style_metadata": {
            "para_id": "chap5_para103",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 63,
            "sentence_count": 2
          },
          "terminology": {
            "interleaving": 1,
            "search": 3,
            "inference": 2,
            "saw": 1,
            "ac-3": 1,
            "reduce": 1,
            "domain": 2,
            "variable": 3,
            "begin": 1,
            "powerful": 1,
            "course": 1,
            "time": 1,
            "make": 1,
            "choice": 1,
            "value": 1,
            "brand-new": 1,
            "opportunity": 1,
            "infer": 1,
            "new": 1,
            "reduction": 1,
            "neighboring": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para104",
          "content": "One of the simplest forms of inference is called\nforward checking\n. Whenever a variable\nX\nis assigned, the forward-checking process establishes arc consistency for it: for each unassigned variable\nY\nthat is connected to\nX\nby a constraint, delete from\nY\n's domain any value that is inconsistent with the value chosen for\nX\n.",
          "sentence_count": 2,
          "char_count": 280,
          "prev_para_id": "chap5_para103",
          "next_para_id": "chap5_para105",
          "style_metadata": {
            "para_id": "chap5_para104",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 9.0,
            "avg_sentence_length": 29.5,
            "passive_voice_ratio": 0.051,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 2
          },
          "terminology": {
            "simplest": 1,
            "form": 1,
            "inference": 1,
            "called": 1,
            "checking": 1,
            "variable": 2,
            "assigned": 1,
            "forward-checking": 1,
            "process": 1,
            "establishes": 1,
            "arc": 1,
            "consistency": 1,
            "unassigned": 1,
            "connected": 1,
            "constraint": 1,
            "delete": 1,
            "domain": 1,
            "value": 2,
            "inconsistent": 1,
            "chosen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para105",
          "content": "Figure 5.7\nshows the progress of backtracking search on the Australia CSP with forward checking. There are two important points to notice about this example. First, notice that after\nWA = red\nand\nQ = green\nare assigned, the domains of\nNT\nand\nSA\nare reduced to a single value; we have eliminated branching on these variables altogether by propagating information from\nWA\nand\nQ\n. A second point to notice is that after\nV = blue,\nthe domain of\nSA\nis empty. Hence, forward checking has detected that the partial assignment {\nWA = red, Q = green, V = blue\n} is inconsistent with the constraints of the problem, and the algorithm backtracks immediately.",
          "sentence_count": 5,
          "char_count": 551,
          "prev_para_id": "chap5_para104",
          "next_para_id": "chap5_para106",
          "style_metadata": {
            "para_id": "chap5_para105",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 5
          },
          "terminology": {
            "figure": 1,
            "show": 1,
            "progress": 1,
            "backtracking": 1,
            "search": 1,
            "australia": 1,
            "csp": 1,
            "checking": 2,
            "important": 1,
            "point": 2,
            "notice": 2,
            "example": 1,
            "first": 1,
            "red": 2,
            "green": 2,
            "assigned": 1,
            "domain": 2,
            "reduced": 1,
            "single": 1,
            "value": 1,
            "eliminated": 1,
            "branching": 1,
            "variable": 1,
            "propagating": 1,
            "information": 1,
            "second": 1,
            "blue": 2,
            "empty": 1,
            "detected": 1,
            "partial": 1,
            "assignment": 1,
            "inconsistent": 1,
            "constraint": 1,
            "problem": 1,
            "algorithm": 1,
            "backtracks": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para105",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 60,
              "end_char": 69,
              "context": "\nshows the progress of backtracking search on the Australia CSP with forward checking. There are two importan"
            },
            {
              "para_id": "chap5_para105",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 441,
              "end_char": 443,
              "context": "t to notice is that after\nV = blue,\nthe domain of\nSA\nis empty. Hence, forward checking has detected th"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para106",
          "content": "Description\nPart (“a”): Selection. The node at the top is labeled 37 by 100. The three child nodes of the node are labeled 60 by 79, 1 by 10, and 2 by 11. The two child nodes of 60 by 79 are labeled 3 by 26 and 16 by 53. The two child nodes of 1 by 10 are labeled 6 by 6 and 3 by 4. The two child nodes of 16 by 53 are labeled 27 by 35 and 10 by 18. The two child nodes of 6 by 6 are labeled 0 by 3 and 0 by 3. Normal arrows are shown from parent nodes to child nodes. Bold arrows are shown for the following. From 37 by 100 to 60 by 79. From 60 by 79 to 16 by 53. From 16 by 53 to 27 by 35.",
          "sentence_count": 12,
          "char_count": 451,
          "prev_para_id": "chap5_para105",
          "next_para_id": "chap5_para107",
          "style_metadata": {
            "para_id": "chap5_para106",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.75,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 153,
            "sentence_count": 12
          },
          "terminology": {
            "description": 1,
            "part": 1,
            "selection": 1,
            "top": 1,
            "labeled": 6,
            "child": 6,
            "node": 8,
            "normal": 1,
            "arrow": 2,
            "shown": 2,
            "parent": 1,
            "bold": 1,
            "following": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para106",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 106,
              "end_char": 110,
              "context": "s labeled 37 by 100. The three child nodes of the node are labeled 60 by 79, 1 by 10, and 2 by 11. The t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para107",
          "content": "Part (b): Expansion and simulation. The node at the top is labeled 37 by 100. The three child nodes of the node are labeled 60 by 79, 1 by 10, and 2 by 11. The two child nodes of 60 by 79 are labeled 3 by 26 and 16 by 53. The two child nodes of 1 by 10 are labeled 6 by 6 and 3 by 4. The two child nodes of 16 by 53 are labeled 27 by 35 and 10 by 18. The two child nodes of 6 by 6 are labeled 0 by 3 and 0 by 3. The child node of 27 by 35 is labeled 0 by 0. Normal arrows are shown from parent nodes to child nodes. A bold arrow is shown from 27 by 35 to 0 by 0. A curved arrow from 0 by 0 is labeled black wins.",
          "sentence_count": 11,
          "char_count": 465,
          "prev_para_id": "chap5_para106",
          "next_para_id": "chap5_para108",
          "style_metadata": {
            "para_id": "chap5_para107",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.18,
            "passive_voice_ratio": 0.019,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 156,
            "sentence_count": 11
          },
          "terminology": {
            "part": 1,
            "expansion": 1,
            "simulation": 1,
            "top": 1,
            "labeled": 8,
            "child": 7,
            "node": 9,
            "normal": 1,
            "arrow": 3,
            "shown": 2,
            "parent": 1,
            "bold": 1,
            "curved": 1,
            "black": 1,
            "win": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para107",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 107,
              "end_char": 111,
              "context": "s labeled 37 by 100. The three child nodes of the node are labeled 60 by 79, 1 by 10, and 2 by 11. The t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para108",
          "content": "Part (c): Backpropagation. The node at the top is labeled 37 by 101. The three child nodes of the node are labeled 61 by 80, 1 by 10, and 2 by 11. The two child nodes of 61 by 80 are labeled 3 by 26 and 16 by 54. The two child nodes of 1 by 10 are labeled 6 by 6 and 3 by 4. The two child nodes of 16 by 54 are labeled 28 by 36 and 10 by 18. The two child nodes of 6 by 6 are labeled 0 by 3 and 0 by 3. The child node of 28 by 36 is labeled 0 by 1. Normal arrows are shown from parent nodes to child nodes. Bold arrows are shown from child nodes to parent nodes for the following. From 0 by 1 to 28 by 36. From 28 by 36 to 16 by 54. From 16 by 54 to 61 by 80. From 61 by 80 to 37 by 101.",
          "sentence_count": 14,
          "char_count": 521,
          "prev_para_id": "chap5_para107",
          "next_para_id": "chap5_para109",
          "style_metadata": {
            "para_id": "chap5_para108",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.57,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [
              "backpropagation"
            ],
            "formal_keywords": [],
            "word_count": 176,
            "sentence_count": 14
          },
          "terminology": {
            "part": 1,
            "backpropagation": 2,
            "top": 1,
            "labeled": 7,
            "child": 8,
            "node": 11,
            "normal": 1,
            "arrow": 2,
            "shown": 2,
            "parent": 2,
            "bold": 1,
            "following": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para108",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 98,
              "end_char": 102,
              "context": "s labeled 37 by 101. The three child nodes of the node are labeled 61 by 80, 1 by 10, and 2 by 11. The t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para109",
          "content": "×\nFigure 5.7\nThe progress of a map-coloring search with forward checking.",
          "sentence_count": 1,
          "char_count": 64,
          "prev_para_id": "chap5_para108",
          "next_para_id": "chap5_para110",
          "style_metadata": {
            "para_id": "chap5_para109",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "figure": 1,
            "progress": 1,
            "map-coloring": 1,
            "search": 1,
            "forward": 1,
            "checking": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para110",
          "content": "WA = red\nis assigned first; then forward checking deletes\nred\nfrom the domains of the neighboring variables\nNT\nand\nSA\n. After\nQ = green\nis assigned,\ngreen\nis deleted from the domains of\nNT\n,\nSA\n, and\nNSW\n. After\nV = blue\nis assigned,\nblue\nis deleted from the domains of\nNSW\nand\nSA\n, leaving\nSA\nwith no legal values.",
          "sentence_count": 3,
          "char_count": 278,
          "prev_para_id": "chap5_para109",
          "next_para_id": "chap5_para111",
          "style_metadata": {
            "para_id": "chap5_para110",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.072,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 69,
            "sentence_count": 3
          },
          "terminology": {
            "red": 2,
            "assigned": 3,
            "checking": 1,
            "deletes": 1,
            "domain": 3,
            "neighboring": 1,
            "variable": 1,
            "green": 2,
            "deleted": 2,
            "nsw": 1,
            "blue": 1,
            "leaving": 1,
            "legal": 1,
            "value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para110",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 191,
              "end_char": 193,
              "context": "signed,\ngreen\nis deleted from the domains of\nNT\n,\nSA\n, and\nNSW\n. After\nV = blue\nis assigned,\nblue\nis d"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para111",
          "content": "For many problems the search will be more effective if we combine the MRV heuristic with forward checking. Consider\nFigure 5.7\nafter assigning {\nWA = red\n}. Intuitively, it seems that that assignment constrains its neighbors,\nNT\nand\nSA\n, so we should handle those variables next, and then all the other variables will fall into place. That’s exactly what happens with MRV:\nNT\nand\nSA\neach have two values, so one of them is chosen first, then the other, then\nQ\n,\nNSW\n, and\nV\nin order. Finally\nT\nstill has three values, and any one of them works. We can view forward checking as an efficient way to incrementally compute the information that the MRV heuristic needs to do its job.",
          "sentence_count": 6,
          "char_count": 574,
          "prev_para_id": "chap5_para110",
          "next_para_id": "chap5_para112",
          "style_metadata": {
            "para_id": "chap5_para111",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 141,
            "sentence_count": 6
          },
          "terminology": {
            "many": 1,
            "problem": 1,
            "search": 1,
            "effective": 1,
            "combine": 1,
            "mrv": 3,
            "heuristic": 2,
            "forward": 1,
            "checking": 2,
            "consider": 1,
            "figure": 1,
            "assigning": 1,
            "red": 1,
            "seems": 1,
            "assignment": 1,
            "constrains": 1,
            "neighbor": 1,
            "handle": 1,
            "variable": 2,
            "fall": 1,
            "place": 1,
            "happens": 1,
            "value": 2,
            "chosen": 1,
            "nsw": 1,
            "order": 1,
            "work": 1,
            "view": 1,
            "efficient": 1,
            "way": 1,
            "compute": 1,
            "information": 1,
            "need": 1,
            "job": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para111",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 70,
              "end_char": 73,
              "context": "e search will be more effective if we combine the MRV heuristic with forward checking. Consider\nFigure "
            },
            {
              "para_id": "chap5_para111",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 644,
              "end_char": 647,
              "context": "to incrementally compute the information that the MRV heuristic needs to do its job."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para112",
          "content": "Although forward checking detects many inconsistencies, it does not detect all of them. The problem is that it doesn't look ahead far enough. For example, consider the\nQ = green\nrow of\nFigure 5.7\n. We’ve made\nWA\nand\nQ\narc-consistent, but we’ve left both\nNT\nand\nSA\nwith blue as their only possible value, which is an inconsistency, since they are neighbors.",
          "sentence_count": 4,
          "char_count": 306,
          "prev_para_id": "chap5_para111",
          "next_para_id": "chap5_para113",
          "style_metadata": {
            "para_id": "chap5_para112",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 4
          },
          "terminology": {
            "checking": 1,
            "detects": 1,
            "many": 1,
            "inconsistency": 2,
            "detect": 1,
            "problem": 1,
            "look": 1,
            "enough": 1,
            "example": 1,
            "consider": 1,
            "green": 1,
            "row": 1,
            "figure": 1,
            "made": 1,
            "arc-consistent": 1,
            "left": 1,
            "blue": 1,
            "possible": 1,
            "value": 1,
            "neighbor": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para113",
          "content": "The algorithm called MAC (for\nMaintaining Arc Consistency\n) detects inconsistencies like this. After a variable\nX\ni\nis assigned a value, the I\nNFERENCE\nprocedure calls AC-3, but instead of a queue of all arcs in the CSP, we start with only the arcs (\nX\nj\n,\nX\ni\n) for all\nX\nj\nthat are unassigned variables that are neighbors of\nX\ni\n. From there, AC-3 does constraint propagation in the usual way, and if any variable has its domain reduced to the empty set, the call to AC-3\nfails and we know to backtrack immediately. We can see that MAC is strictly more powerful than forward checking because forward checking does the same thing as MAC on the initial arcs in MAC’s queue; but unlike MAC, forward checking does not recursively propagate constraints when changes are made to the domains of variables.",
          "sentence_count": 4,
          "char_count": 674,
          "prev_para_id": "chap5_para112",
          "next_para_id": "chap5_para114",
          "style_metadata": {
            "para_id": "chap5_para113",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 40.25,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 161,
            "sentence_count": 4
          },
          "terminology": {
            "algorithm": 1,
            "called": 1,
            "mac": 3,
            "maintaining": 1,
            "arc": 4,
            "consistency": 1,
            "detects": 1,
            "inconsistency": 1,
            "variable": 4,
            "assigned": 1,
            "value": 1,
            "nference": 1,
            "procedure": 1,
            "call": 2,
            "ac-3": 3,
            "queue": 2,
            "csp": 1,
            "start": 1,
            "unassigned": 1,
            "neighbor": 1,
            "constraint": 2,
            "propagation": 1,
            "usual": 1,
            "way": 1,
            "domain": 2,
            "reduced": 1,
            "empty": 1,
            "set": 1,
            "fails": 1,
            "know": 1,
            "see": 1,
            "powerful": 1,
            "checking": 3,
            "thing": 1,
            "initial": 1,
            "propagate": 1,
            "change": 1,
            "made": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para113",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 21,
              "end_char": 24,
              "context": "The algorithm called MAC (for\nMaintaining Arc Consistency\n) detects incons"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "Maintaining Arc Consistency",
              "entity_type": "WORK_OF_ART",
              "start_char": 30,
              "end_char": 57,
              "context": "The algorithm called MAC (for\nMaintaining Arc Consistency\n) detects inconsistencies like this. After a vari"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "AC-3",
              "entity_type": "GPE",
              "start_char": 168,
              "end_char": 172,
              "context": " assigned a value, the I\nNFERENCE\nprocedure calls AC-3, but instead of a queue of all arcs in the CSP, w"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 216,
              "end_char": 219,
              "context": "s AC-3, but instead of a queue of all arcs in the CSP, we start with only the arcs (\nX\nj\n,\nX\ni\n) for al"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "AC-3",
              "entity_type": "ORG",
              "start_char": 345,
              "end_char": 349,
              "context": "variables that are neighbors of\nX\ni\n. From there, AC-3 does constraint propagation in the usual way, and"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 534,
              "end_char": 537,
              "context": "we know to backtrack immediately. We can see that MAC is strictly more powerful than forward checking b"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 634,
              "end_char": 637,
              "context": "g because forward checking does the same thing as MAC on the initial arcs in MAC’s queue; but unlike MA"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 661,
              "end_char": 664,
              "context": "does the same thing as MAC on the initial arcs in MAC’s queue; but unlike MAC, forward checking does no"
            },
            {
              "para_id": "chap5_para113",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 685,
              "end_char": 688,
              "context": "AC on the initial arcs in MAC’s queue; but unlike MAC, forward checking does not recursively propagate "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para114",
          "content": "5.3.3\nIntelligent backtracking: Looking backward\nThe B\nACKTRACKING\n-S\nEARCH\nalgorithm in\nFigure 5.5\nhas a very simple policy for what to do when a branch of the search fails: back up to the preceding variable and try a different value for it. This is called c\nhronological backtracking\nbecause the\nmost recent\ndecision point is revisited. in this subsection, we consider better possibilities.",
          "sentence_count": 3,
          "char_count": 341,
          "prev_para_id": "chap5_para113",
          "next_para_id": "chap5_para115",
          "style_metadata": {
            "para_id": "chap5_para114",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.33,
            "passive_voice_ratio": 0.029,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 3
          },
          "terminology": {
            "intelligent": 1,
            "backtracking": 2,
            "looking": 1,
            "acktracking": 1,
            "earch": 1,
            "algorithm": 1,
            "figure": 1,
            "simple": 1,
            "policy": 1,
            "branch": 1,
            "search": 1,
            "fails": 1,
            "preceding": 1,
            "variable": 1,
            "try": 1,
            "different": 1,
            "value": 1,
            "called": 1,
            "hronological": 1,
            "recent": 1,
            "decision": 1,
            "point": 1,
            "revisited": 1,
            "subsection": 1,
            "consider": 1,
            "better": 1,
            "possibility": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para115",
          "content": "Consider what happens when we apply simple backtracking in\nFigure 5.1\nwith a fixed variable ordering\nQ\n,\nNSW\n,\nV\n,\nT\n,\nSA\n,\nWA\n,\nNT\n. Suppose we have generated the partial assignment {\nQ = red, NSW = green,V = blue,T = red\n}. When we try the next variable,\nSA\n, we see that every value violates a constraint. We back up to\nT\nand try a new color for Tasmania! Obviously this is silly—recoloring Tasmania cannot possibly help in resolving the problem with South Australia.",
          "sentence_count": 5,
          "char_count": 401,
          "prev_para_id": "chap5_para114",
          "next_para_id": "chap5_para116",
          "style_metadata": {
            "para_id": "chap5_para115",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 103,
            "sentence_count": 5
          },
          "terminology": {
            "consider": 1,
            "happens": 1,
            "simple": 1,
            "backtracking": 1,
            "figure": 1,
            "fixed": 1,
            "variable": 2,
            "ordering": 1,
            "nsw": 2,
            "generated": 1,
            "partial": 1,
            "assignment": 1,
            "red": 2,
            "green": 1,
            "blue": 1,
            "try": 2,
            "next": 1,
            "see": 1,
            "value": 1,
            "violates": 1,
            "constraint": 1,
            "new": 1,
            "color": 1,
            "tasmania": 2,
            "silly—recoloring": 1,
            "help": 1,
            "resolving": 1,
            "problem": 1,
            "south": 1,
            "australia": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para115",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 119,
              "end_char": 121,
              "context": "\nwith a fixed variable ordering\nQ\n,\nNSW\n,\nV\n,\nT\n,\nSA\n,\nWA\n,\nNT\n. Suppose we have generated the partial"
            },
            {
              "para_id": "chap5_para115",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 257,
              "end_char": 259,
              "context": " = blue,T = red\n}. When we try the next variable,\nSA\n, we see that every value violates a constraint. "
            },
            {
              "para_id": "chap5_para115",
              "entity_text": "Tasmania",
              "entity_type": "ORG",
              "start_char": 349,
              "end_char": 357,
              "context": "nstraint. We back up to\nT\nand try a new color for Tasmania! Obviously this is silly—recoloring Tasmania cann"
            },
            {
              "para_id": "chap5_para115",
              "entity_text": "Tasmania",
              "entity_type": "ORG",
              "start_char": 394,
              "end_char": 402,
              "context": " for Tasmania! Obviously this is silly—recoloring Tasmania cannot possibly help in resolving the problem wit"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para116",
          "content": "A more intelligent approach is to backtrack to a variable that might fix the problem—a variable that was responsible for making one of the possible values of\nSA\nimpossible. To do this, we will keep track of a set of assignments that are in conflict with some value for\nSA\n. The set (in this case {\nQ = red, NSW = green, V = blue\n}), is called the\nconflict set\nfor\nSA\n. The\nbackjumping\nmethod backtracks to the\nmost recent\nassignment in the conflict set; in this case, backjumping would jump over Tasmania and try a new value for\nV\n. This method is easily implemented by a modification to B\nACKTRACK\nsuch that it accumulates the conflict set while checking for a legal value to assign. If no legal value is found, the algorithm should return the most recent element of the conflict set along with the failure indicator.",
          "sentence_count": 6,
          "char_count": 684,
          "prev_para_id": "chap5_para115",
          "next_para_id": "chap5_para117",
          "style_metadata": {
            "para_id": "chap5_para116",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.006,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 165,
            "sentence_count": 6
          },
          "terminology": {
            "intelligent": 1,
            "approach": 1,
            "backtrack": 1,
            "variable": 2,
            "fix": 1,
            "problem—a": 1,
            "responsible": 1,
            "making": 1,
            "possible": 1,
            "value": 5,
            "impossible": 1,
            "keep": 1,
            "track": 1,
            "set": 6,
            "assignment": 2,
            "conflict": 5,
            "case": 2,
            "red": 1,
            "nsw": 1,
            "green": 1,
            "blue": 1,
            "called": 1,
            "backjumping": 2,
            "method": 2,
            "backtracks": 1,
            "recent": 2,
            "jump": 1,
            "try": 1,
            "new": 1,
            "implemented": 1,
            "modification": 1,
            "acktrack": 1,
            "accumulates": 1,
            "checking": 1,
            "legal": 2,
            "assign": 1,
            "found": 1,
            "return": 1,
            "element": 1,
            "failure": 1,
            "indicator": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para116",
              "entity_text": "Tasmania",
              "entity_type": "ORG",
              "start_char": 496,
              "end_char": 504,
              "context": "ct set; in this case, backjumping would jump over Tasmania and try a new value for\nV\n. This method is easily"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para117",
          "content": "The sharp-eyed reader may have noticed that forward checking can supply the conflict set with no extra work: whenever forward checking based on an assignment\nX = x\ndeletes a value from\nY\n’s domain, it should add\nX = x\nto\nY\n’s conflict set. If the last value is deleted from\nY\n’s domain, then the assignments in the conflict set of\nY\nare added to the conflict set of\nX\n. That is, we now know that\nX = x\nleads to a contradiction (in\nY\n), and thus a different assignment should be tried for\nX\n.",
          "sentence_count": 3,
          "char_count": 411,
          "prev_para_id": "chap5_para116",
          "next_para_id": "chap5_para118",
          "style_metadata": {
            "para_id": "chap5_para117",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 37.0,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 111,
            "sentence_count": 3
          },
          "terminology": {
            "sharp-eyed": 1,
            "reader": 1,
            "noticed": 1,
            "checking": 2,
            "supply": 1,
            "conflict": 4,
            "set": 4,
            "extra": 1,
            "work": 1,
            "based": 1,
            "assignment": 3,
            "deletes": 1,
            "value": 2,
            "domain": 2,
            "add": 1,
            "last": 1,
            "deleted": 1,
            "added": 1,
            "know": 1,
            "lead": 1,
            "contradiction": 1,
            "different": 1,
            "tried": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para118",
          "content": "The eagle-eyed reader may have noticed something odd: backjumping occurs when every value in a domain is in conflict with the current assignment; but forward checking detects this event and prevents the search from ever reaching such a node! In fact, it can be shown that\nevery\nbranch pruned by backjumping is also pruned by forward checking. Hence, simple backjumping is redundant in a forward-checking search or, indeed, in a search that uses stronger consistency checking, such as MAC—you need only do one or the other.",
          "sentence_count": 3,
          "char_count": 439,
          "prev_para_id": "chap5_para117",
          "next_para_id": "chap5_para119",
          "style_metadata": {
            "para_id": "chap5_para118",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 96,
            "sentence_count": 3
          },
          "terminology": {
            "eagle-eyed": 1,
            "reader": 1,
            "noticed": 1,
            "something": 1,
            "odd": 1,
            "backjumping": 3,
            "occurs": 1,
            "value": 1,
            "domain": 1,
            "conflict": 1,
            "current": 1,
            "assignment": 1,
            "checking": 3,
            "detects": 1,
            "event": 1,
            "prevents": 1,
            "search": 3,
            "reaching": 1,
            "node": 1,
            "fact": 1,
            "shown": 1,
            "branch": 1,
            "pruned": 2,
            "simple": 1,
            "redundant": 1,
            "forward-checking": 1,
            "us": 1,
            "stronger": 1,
            "consistency": 1,
            "mac—you": 1,
            "need": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para118",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 484,
              "end_char": 487,
              "context": " that uses stronger consistency checking, such as MAC—you need only do one or the other."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para119",
          "content": "Despite the observations of the preceding paragraph, the idea behind backjumping remains a good one: to backtrack based on the reasons for failure. Backjumping notices failure when a variable’s domain becomes empty, but in many cases a branch is doomed long before this occurs. Consider again the partial assignment {\nWA = red, NSW = red\n} (which, from our earlier discussion, is inconsistent). Suppose we try\nT = red\nnext and then assign\nNT\n,\nQ\n,\nV\n,\nSA\n. We know that no assignment can work for these last four variables, so eventually we run out of values to try at\nNT\n. Now, the question is, where to backtrack? Backjumping cannot work, because\nNT does\nhave values consistent with the preceding assigned variables—\nNT\ndoesn’t have a complete conflict set of preceding variables that caused it to fail. We know, however, that the four variables\nNT\n,\nQ\n,\nV\n, and\nSA\n,\ntaken together,\nfailed because of a set of preceding variables, which must be those variables that directly conflict with the four.",
          "sentence_count": 8,
          "char_count": 851,
          "prev_para_id": "chap5_para118",
          "next_para_id": "chap5_para120",
          "style_metadata": {
            "para_id": "chap5_para119",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 25.75,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 206,
            "sentence_count": 8
          },
          "terminology": {
            "observation": 1,
            "preceding": 4,
            "paragraph": 1,
            "idea": 1,
            "backjumping": 3,
            "remains": 1,
            "good": 1,
            "backtrack": 2,
            "based": 1,
            "reason": 1,
            "failure": 2,
            "notice": 1,
            "variable": 6,
            "domain": 1,
            "becomes": 1,
            "empty": 1,
            "many": 1,
            "case": 1,
            "branch": 1,
            "doomed": 1,
            "long": 1,
            "occurs": 1,
            "consider": 1,
            "partial": 1,
            "assignment": 2,
            "red": 3,
            "nsw": 1,
            "earlier": 1,
            "discussion": 1,
            "inconsistent": 1,
            "suppose": 1,
            "try": 2,
            "next": 1,
            "assign": 1,
            "know": 2,
            "work": 2,
            "last": 1,
            "run": 1,
            "value": 2,
            "question": 1,
            "consistent": 1,
            "assigned": 1,
            "variables—": 1,
            "complete": 1,
            "conflict": 2,
            "set": 2,
            "caused": 1,
            "fail": 1,
            "taken": 1,
            "failed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para119",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 452,
              "end_char": 454,
              "context": " we try\nT = red\nnext and then assign\nNT\n,\nQ\n,\nV\n,\nSA\n. We know that no assignment can work for these l"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para120",
          "content": "This leads to a different–and deeper–notion of the conflict set for a variable such as\nNT\n: it is that set of preceding variables that caused\nNT\n,\ntogether with any subsequent variables,\nto have no consistent solution. In this case, the set is\nWA\nand\nNSW\n, so the algorithm should backtrack to\nNSW\nand skip over Tasmania. A backjumping algorithm that uses conflict sets defined in this way is called\nconflict-directed backjumping\n.",
          "sentence_count": 3,
          "char_count": 371,
          "prev_para_id": "chap5_para119",
          "next_para_id": "chap5_para121",
          "style_metadata": {
            "para_id": "chap5_para120",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.33,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 79,
            "sentence_count": 3
          },
          "terminology": {
            "lead": 1,
            "different–and": 1,
            "deeper–notion": 1,
            "conflict": 2,
            "set": 4,
            "variable": 3,
            "preceding": 1,
            "caused": 1,
            "subsequent": 1,
            "consistent": 1,
            "solution": 1,
            "case": 1,
            "algorithm": 2,
            "backtrack": 1,
            "nsw": 1,
            "skip": 1,
            "tasmania": 1,
            "backjumping": 2,
            "us": 1,
            "defined": 1,
            "way": 1,
            "called": 1,
            "conflict-directed": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para120",
              "entity_text": "Tasmania",
              "entity_type": "GPE",
              "start_char": 312,
              "end_char": 320,
              "context": "e algorithm should backtrack to\nNSW\nand skip over Tasmania. A backjumping algorithm that uses conflict sets "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para121",
          "content": "We must now explain how these new conflict sets are computed. The method is in fact quite simple. The “terminal” failure of a branch of the search always occurs because a variable’s domain becomes empty; that variable has a standard conflict set. In our example,\nSA\nfails, and its conflict set is (say) {\nWA, NT, Q\n}. We backjump to\nQ\n, and\nQ absorbs\nthe conflict set from\nSA\n(minus\nQ\nitself, of course) into its own direct conflict set, which is {\nNT, NSW\n}; the new conflict set is {\nWA, NT, NSW\n}. That is, there is no solution from\nQ\nonward, given the preceding assignment to {\nWA, NT, NSW\n}. Therefore, we backtrack to\nNT\n, the most recent of these.",
          "sentence_count": 7,
          "char_count": 549,
          "prev_para_id": "chap5_para120",
          "next_para_id": "chap5_para122",
          "style_metadata": {
            "para_id": "chap5_para121",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 22.71,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 159,
            "sentence_count": 7
          },
          "terminology": {
            "explain": 1,
            "new": 2,
            "conflict": 6,
            "set": 6,
            "computed": 1,
            "method": 1,
            "fact": 1,
            "simple": 1,
            "terminal": 1,
            "failure": 1,
            "branch": 1,
            "search": 1,
            "occurs": 1,
            "variable": 2,
            "domain": 1,
            "becomes": 1,
            "empty": 1,
            "standard": 1,
            "example": 1,
            "fails": 1,
            "say": 1,
            "backjump": 1,
            "absorbs": 1,
            "course": 1,
            "direct": 1,
            "nsw": 3,
            "solution": 1,
            "given": 1,
            "preceding": 1,
            "assignment": 1,
            "backtrack": 1,
            "recent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para121",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 373,
              "end_char": 375,
              "context": "ckjump to\nQ\n, and\nQ absorbs\nthe conflict set from\nSA\n(minus\nQ\nitself, of course) into its own direct c"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para122",
          "content": "NT\nabsorbs {\nWA, NT, NSW\n} – {\nNT\n} into its own direct conflict set {\nWA\n}, giving {\nWA, NSW\n} (as stated in the previous paragraph). Now the algorithm backjumps to\nNSW\n, as we would hope. To summarize: let\nX\nj\nbe the current variable, and let\nconf\n(\nX\nj\n) be its conflict set. If every possible value for\nX\nj\nfails, backjump to the most recent variable\nX\ni\nin\nconf\n(\nX\nj\n) and recompute the conflict set for\nX\ni\nas follows:\nc\no\nn\nf\n(\nX\ni\n)\n←\nc\no\nn\nf\n(\nX\ni\n)\n∪\nc\no\nn\nf\n(\nX\nj\n)\n−\n{\nX\ni\n}\n.",
          "sentence_count": 4,
          "char_count": 429,
          "prev_para_id": "chap5_para121",
          "next_para_id": "chap5_para123",
          "style_metadata": {
            "para_id": "chap5_para122",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 34.75,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 139,
            "sentence_count": 4
          },
          "terminology": {
            "absorbs": 1,
            "nsw": 2,
            "direct": 1,
            "conflict": 3,
            "set": 3,
            "giving": 1,
            "stated": 1,
            "previous": 1,
            "paragraph": 1,
            "algorithm": 1,
            "backjumps": 1,
            "hope": 1,
            "summarize": 1,
            "let": 2,
            "current": 1,
            "variable": 2,
            "conf": 2,
            "possible": 1,
            "value": 1,
            "fails": 1,
            "backjump": 1,
            "recent": 1,
            "recompute": 1,
            "follows": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para122",
              "entity_text": "←",
              "entity_type": "PERSON",
              "start_char": 442,
              "end_char": 443,
              "context": " conflict set for\nX\ni\nas follows:\nc\no\nn\nf\n(\nX\ni\n)\n←\nc\no\nn\nf\n(\nX\ni\n)\n∪\nc\no\nn\nf\n(\nX\nj\n)\n−\n{\nX\ni\n}\n."
            },
            {
              "para_id": "chap5_para122",
              "entity_text": "−",
              "entity_type": "GPE",
              "start_char": 478,
              "end_char": 479,
              "context": "o\nn\nf\n(\nX\ni\n)\n←\nc\no\nn\nf\n(\nX\ni\n)\n∪\nc\no\nn\nf\n(\nX\nj\n)\n−\n{\nX\ni\n}\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para123",
          "content": "5.3.4\nConstraint learning\nWhen we reach a contradiction, backjumping can tell us how far to back up, so we don’t waste time changing variables that won’t fix the problem. But we would also like to avoid running into the same problem again. When the search arrives at a contradiction, we know that some subset of the conflict set is responsible for the problem.",
          "sentence_count": 3,
          "char_count": 300,
          "prev_para_id": "chap5_para122",
          "next_para_id": "chap5_para124",
          "style_metadata": {
            "para_id": "chap5_para123",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 24.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 3
          },
          "terminology": {
            "constraint": 1,
            "learning": 1,
            "reach": 1,
            "contradiction": 2,
            "backjumping": 1,
            "tell": 1,
            "waste": 1,
            "time": 1,
            "changing": 1,
            "variable": 1,
            "fix": 1,
            "problem": 3,
            "like": 1,
            "running": 1,
            "search": 1,
            "arrives": 1,
            "subset": 1,
            "conflict": 1,
            "set": 1,
            "responsible": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para124",
          "content": "Constraint learning\nis the idea of finding a minimum set of variables from the conflict set that causes the problem. This set of variables, along with their corresponding values, is called a\nno-good\n. We then record the no-good, either by adding a new constraint to the CSP to forbid this combination of assignments or by keeping a separate cache of no-goods.",
          "sentence_count": 3,
          "char_count": 301,
          "prev_para_id": "chap5_para123",
          "next_para_id": "chap5_para125",
          "style_metadata": {
            "para_id": "chap5_para124",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.33,
            "passive_voice_ratio": 0.015,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 67,
            "sentence_count": 3
          },
          "terminology": {
            "constraint": 2,
            "learning": 1,
            "idea": 1,
            "finding": 1,
            "minimum": 1,
            "set": 3,
            "variable": 2,
            "conflict": 1,
            "cause": 1,
            "problem": 1,
            "corresponding": 1,
            "value": 1,
            "called": 1,
            "no-good": 2,
            "record": 1,
            "adding": 1,
            "new": 1,
            "csp": 1,
            "forbid": 1,
            "combination": 1,
            "assignment": 1,
            "keeping": 1,
            "separate": 1,
            "cache": 1,
            "no-goods": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para124",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 270,
              "end_char": 273,
              "context": "no-good, either by adding a new constraint to the CSP to forbid this combination of assignments or by k"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para125",
          "content": "For example, consider the state {\nWA = red, NT = green, Q = blue\n} in the bottom row of\nFigure 5.6\n. Forward checking can tell us this state is a no-good because there is no valid assignment to\nSA\n. In this particular case, recording the no-good would not help, because once we prune this branch from the search tree, we will never encounter this combination again. But suppose that the search tree in\nFigure 5.6\nwere actually part of a larger search tree that started by first assigning values for\nV\nand\nT\n. Then it would be worthwhile to record {\nWA = red, NT = green, Q = blue\n} as a no-good because we are going to run into the same problem again for each possible set of assignments to\nV\nand\nT\n.",
          "sentence_count": 5,
          "char_count": 578,
          "prev_para_id": "chap5_para124",
          "next_para_id": "chap5_para126",
          "style_metadata": {
            "para_id": "chap5_para125",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 30.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 150,
            "sentence_count": 5
          },
          "terminology": {
            "example": 1,
            "consider": 1,
            "state": 2,
            "red": 2,
            "green": 2,
            "blue": 2,
            "bottom": 1,
            "row": 1,
            "figure": 2,
            "forward": 1,
            "checking": 1,
            "tell": 1,
            "no-good": 3,
            "valid": 1,
            "assignment": 2,
            "particular": 1,
            "case": 1,
            "recording": 1,
            "help": 1,
            "prune": 1,
            "branch": 1,
            "search": 3,
            "tree": 3,
            "encounter": 1,
            "combination": 1,
            "suppose": 1,
            "part": 1,
            "larger": 1,
            "started": 1,
            "assigning": 1,
            "value": 1,
            "worthwhile": 1,
            "record": 1,
            "going": 1,
            "run": 1,
            "problem": 1,
            "possible": 1,
            "set": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para125",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 194,
              "end_char": 196,
              "context": "a no-good because there is no valid assignment to\nSA\n. In this particular case, recording the no-good "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para126",
          "content": "No-goods can be effectively used by forward checking or by backjumping. Constraint learning is one of the most important techniques used by modern CSP solvers to achieve efficiency on complex problems.",
          "sentence_count": 2,
          "char_count": 171,
          "prev_para_id": "chap5_para125",
          "next_para_id": "chap5_para127",
          "style_metadata": {
            "para_id": "chap5_para126",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "no-goods": 1,
            "used": 2,
            "checking": 1,
            "backjumping": 1,
            "constraint": 1,
            "learning": 1,
            "important": 1,
            "technique": 1,
            "modern": 1,
            "csp": 1,
            "solver": 1,
            "achieve": 1,
            "efficiency": 1,
            "complex": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para126",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 147,
              "end_char": 150,
              "context": "e of the most important techniques used by modern CSP solvers to achieve efficiency on complex problems"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para127",
          "content": "5.4Local Search for CSPs\n5.4\nLocal Search for CSPs\nLocal search algorithms (see\nSection 4.1\n) turn out to be very effective in solving many CSPs. They use a complete-state formulation (as introduced in\nSection 4.1.1\n) where each state assigns a value to every variable, and the search changes the value of one variable at a time. As an example, we’ll use the 8-queens problem, as defined as a CSP on\npage 167\n. In\nFigure 5.8\nwe start on the left with a complete assignment to the 8 variables; typically this will violate several constraints. We then randomly choose a conflicted variable, which turns out to be\nQ\n8\n, the rightmost column. We’d like to change the value to something that brings us closer to a solution; the most obvious approach is to select the value that results in the minimum number of conflicts with other variables—the\nmin-conflicts\nheuristic.",
          "sentence_count": 6,
          "char_count": 730,
          "prev_para_id": "chap5_para126",
          "next_para_id": "chap5_para128",
          "style_metadata": {
            "para_id": "chap5_para127",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 169,
            "sentence_count": 6
          },
          "terminology": {
            "5.4local": 1,
            "search": 4,
            "csps": 3,
            "local": 2,
            "algorithm": 1,
            "see": 1,
            "section": 2,
            "turn": 2,
            "effective": 1,
            "solving": 1,
            "many": 1,
            "use": 2,
            "complete-state": 1,
            "formulation": 1,
            "introduced": 1,
            "state": 1,
            "assigns": 1,
            "value": 4,
            "variable": 4,
            "change": 2,
            "time": 1,
            "example": 1,
            "8-queens": 1,
            "problem": 1,
            "defined": 1,
            "csp": 1,
            "page": 1,
            "figure": 1,
            "start": 1,
            "left": 1,
            "complete": 1,
            "assignment": 1,
            "violate": 1,
            "several": 1,
            "constraint": 1,
            "choose": 1,
            "conflicted": 1,
            "rightmost": 1,
            "column": 1,
            "something": 1,
            "brings": 1,
            "closer": 1,
            "solution": 1,
            "obvious": 1,
            "approach": 1,
            "select": 1,
            "result": 1,
            "minimum": 1,
            "number": 1,
            "conflict": 1,
            "variables—the": 1,
            "min-conflicts": 1,
            "heuristic": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para127",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 393,
              "end_char": 396,
              "context": ", we’ll use the 8-queens problem, as defined as a CSP on\npage 167\n. In\nFigure 5.8\nwe start on the left "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para128",
          "content": "Description\nTwo dice show the numbers 6 and 5. The columns in the top row are numbered from 1 to 12 from the left to right. The columns in the bottom row are numbered from 13 to 24 from the right to left. Top row: Column 1, two whites. Column 2, empty. Column 3, three blacks. Column 4, two whites. Column 5, two blacks. Column 6, three blacks. Column 7, three whites. Column 8, two whites. Column 9, two whites. Column 10, one white. Columns 11 and 12, empty. Bottom row: Column 13 to 18, empty. Column 19, two blacks. Column 20, empty. Column 21, two blacks. Column 22, two blacks. Column 23, three blacks. Column 24, one black.",
          "sentence_count": 21,
          "char_count": 513,
          "prev_para_id": "chap5_para127",
          "next_para_id": "chap5_para129",
          "style_metadata": {
            "para_id": "chap5_para128",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.57,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 159,
            "sentence_count": 21
          },
          "terminology": {
            "description": 1,
            "dice": 1,
            "show": 1,
            "number": 1,
            "column": 20,
            "top": 2,
            "row": 4,
            "numbered": 2,
            "left": 2,
            "right": 2,
            "bottom": 2,
            "white": 6,
            "empty": 4,
            "black": 8,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para129",
          "content": "×\nFigure 5.8\nA two-step solution using min-conflicts for an 8-queens problem. At each stage, a queen is chosen for reassignment in its column. The number of conflicts (in this case, the number of attacking queens) is shown in each square. The algorithm moves the queen to the min-conflicts square, breaking ties randomly.",
          "sentence_count": 4,
          "char_count": 271,
          "prev_para_id": "chap5_para128",
          "next_para_id": "chap5_para130",
          "style_metadata": {
            "para_id": "chap5_para129",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 1,
            "two-step": 1,
            "solution": 1,
            "using": 1,
            "min-conflicts": 2,
            "8-queens": 1,
            "problem": 1,
            "stage": 1,
            "queen": 3,
            "chosen": 1,
            "reassignment": 1,
            "column": 1,
            "number": 2,
            "conflict": 1,
            "case": 1,
            "attacking": 1,
            "shown": 1,
            "square": 2,
            "algorithm": 1,
            "move": 1,
            "breaking": 1,
            "tie": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para130",
          "content": "In the figure we see there are two rows that only violate one constraint; we pick\nQ\n8\n= 3 (that is, we move the queen to the 8th column, 3rd row). On the next iteration, in the middle board of the figure, we select\nQ\n6\nas the variable to change, and note that moving the queen to the 8th row results in no conflicts. At this point there are no more conflicted variables, so we have a solution. The algorithm is shown in\nFigure 5.9\n.",
          "sentence_count": 4,
          "char_count": 353,
          "prev_para_id": "chap5_para129",
          "next_para_id": "chap5_para131",
          "style_metadata": {
            "para_id": "chap5_para130",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 100,
            "sentence_count": 4
          },
          "terminology": {
            "figure": 3,
            "see": 1,
            "row": 3,
            "violate": 1,
            "constraint": 1,
            "pick": 1,
            "move": 1,
            "column": 1,
            "next": 1,
            "iteration": 1,
            "middle": 1,
            "board": 1,
            "select": 1,
            "variable": 2,
            "change": 1,
            "note": 1,
            "moving": 1,
            "queen": 1,
            "result": 1,
            "conflict": 1,
            "point": 1,
            "conflicted": 1,
            "solution": 1,
            "shown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para131",
          "content": "2\nDescription\nUp and down triangles represent MAX and MIN nodes and circles represent CHANCE nodes. The first level of the game tree is labeled MAX and the root node is a MAX node. The second level is labeled CHANCE and contains many circles. Paths from the node in the MAX level connect to each circle. The third level is labeled MIN and the nodes are MIN nodes. Four nodes are shown with labels 1 by 36, 1 to 1; 1 by 18, 1 to 2; 1 by 18, 6 to 5; and 1 by 36, 6 to 6. Paths from the third circle in the CHANCE level connect to each of the nodes in the MIN level. The fourth level is labeled CHANCE and contains many circles. The first circle is labeled C. Paths from the MIN node labeled 1 by 18, 6 to 5 in the MIN level connect to each of the circles in the second CHANCE level. The fifth level is labeled MAX and the nodes are MAX nodes. Four nodes are shown with labels 1 by 36, 1 to 1; 1 by 18, 1 to 2; 1 by 18, 6 to 5; and 1 by 36, 6 to 6. Paths from circle C in the second CHANCE level connect to each node in the second MAX level. The final level is labeled TERMINAL. Paths from the MAX node labeled 1 by 18, 6 to 5 in the second MAX level connect to the nodes in the terminal level. The nodes are labeled 2, negative 1, 1, negative 1, and 1.",
          "sentence_count": 15,
          "char_count": 988,
          "prev_para_id": "chap5_para130",
          "next_para_id": "chap5_para132",
          "style_metadata": {
            "para_id": "chap5_para131",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.87,
            "passive_voice_ratio": 0.023,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 298,
            "sentence_count": 15
          },
          "terminology": {
            "description": 1,
            "triangle": 1,
            "represent": 2,
            "max": 9,
            "min": 5,
            "node": 12,
            "circle": 8,
            "chance": 6,
            "level": 15,
            "game": 1,
            "tree": 1,
            "labeled": 10,
            "root": 1,
            "second": 5,
            "contains": 2,
            "many": 2,
            "path": 5,
            "connect": 5,
            "third": 2,
            "shown": 2,
            "label": 2,
            "fourth": 1,
            "fifth": 1,
            "final": 1,
            "terminal": 2,
            "negative": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 46,
              "end_char": 49,
              "context": "2\nDescription\nUp and down triangles represent MAX and MIN nodes and circles represent CHANCE nodes."
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 54,
              "end_char": 57,
              "context": "scription\nUp and down triangles represent MAX and MIN nodes and circles represent CHANCE nodes. The fir"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "CHANCE",
              "entity_type": "PERSON",
              "start_char": 86,
              "end_char": 92,
              "context": "represent MAX and MIN nodes and circles represent CHANCE nodes. The first level of the game tree is labele"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 144,
              "end_char": 147,
              "context": "odes. The first level of the game tree is labeled MAX and the root node is a MAX node. The second level"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 171,
              "end_char": 174,
              "context": "e game tree is labeled MAX and the root node is a MAX node. The second level is labeled CHANCE and cont"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 209,
              "end_char": 215,
              "context": "t node is a MAX node. The second level is labeled CHANCE and contains many circles. Paths from the node in"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 270,
              "end_char": 273,
              "context": "contains many circles. Paths from the node in the MAX level connect to each circle. The third level is "
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 331,
              "end_char": 334,
              "context": "onnect to each circle. The third level is labeled MIN and the nodes are MIN nodes. Four nodes are shown"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 353,
              "end_char": 356,
              "context": " The third level is labeled MIN and the nodes are MIN nodes. Four nodes are shown with labels 1 by 36, "
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 504,
              "end_char": 510,
              "context": "by 36, 6 to 6. Paths from the third circle in the CHANCE level connect to each of the nodes in the MIN lev"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 553,
              "end_char": 556,
              "context": " CHANCE level connect to each of the nodes in the MIN level. The fourth level is labeled CHANCE and con"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 592,
              "end_char": 598,
              "context": "des in the MIN level. The fourth level is labeled CHANCE and contains many circles. The first circle is la"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "C. Paths",
              "entity_type": "ORG",
              "start_char": 654,
              "end_char": 662,
              "context": "ontains many circles. The first circle is labeled C. Paths from the MIN node labeled 1 by 18, 6 to 5 in the "
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 672,
              "end_char": 675,
              "context": "es. The first circle is labeled C. Paths from the MIN node labeled 1 by 18, 6 to 5 in the MIN level con"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 712,
              "end_char": 715,
              "context": " from the MIN node labeled 1 by 18, 6 to 5 in the MIN level connect to each of the circles in the secon"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 808,
              "end_char": 811,
              "context": "e second CHANCE level. The fifth level is labeled MAX and the nodes are MAX nodes. Four nodes are shown"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 830,
              "end_char": 833,
              "context": " The fifth level is labeled MAX and the nodes are MAX nodes. Four nodes are shown with labels 1 by 36, "
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 980,
              "end_char": 986,
              "context": " by 36, 6 to 6. Paths from circle C in the second CHANCE level connect to each node in the second MAX leve"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 1028,
              "end_char": 1031,
              "context": "d CHANCE level connect to each node in the second MAX level. The final level is labeled TERMINAL. Paths"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "TERMINAL",
              "entity_type": "ORG",
              "start_char": 1066,
              "end_char": 1074,
              "context": " the second MAX level. The final level is labeled TERMINAL. Paths from the MAX node labeled 1 by 18, 6 to 5 "
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 1091,
              "end_char": 1094,
              "context": "e final level is labeled TERMINAL. Paths from the MAX node labeled 1 by 18, 6 to 5 in the second MAX le"
            },
            {
              "para_id": "chap5_para131",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 1138,
              "end_char": 1141,
              "context": "he MAX node labeled 1 by 18, 6 to 5 in the second MAX level connect to the nodes in the terminal level."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para132",
          "content": "×\nFigure 5.9\nThe M\nIN\n-C\nONFLICTS\nlocal search algorithm for CSPs. The initial state may be chosen randomly or by a greedy assignment process that chooses a minimal-conflict value for each variable in turn. The C\nONFLICTS\nfunction counts the number of constraints violated by a particular value, given the rest of the current assignment.",
          "sentence_count": 3,
          "char_count": 289,
          "prev_para_id": "chap5_para131",
          "next_para_id": "chap5_para133",
          "style_metadata": {
            "para_id": "chap5_para132",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "onflicts": 2,
            "local": 1,
            "search": 1,
            "algorithm": 1,
            "csps": 1,
            "initial": 1,
            "state": 1,
            "chosen": 1,
            "randomly": 1,
            "greedy": 1,
            "assignment": 2,
            "process": 1,
            "chooses": 1,
            "minimal-conflict": 1,
            "value": 2,
            "variable": 1,
            "turn": 1,
            "function": 1,
            "count": 1,
            "number": 1,
            "constraint": 1,
            "violated": 1,
            "particular": 1,
            "given": 1,
            "rest": 1,
            "current": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para132",
              "entity_text": "The M\nIN",
              "entity_type": "WORK_OF_ART",
              "start_char": 13,
              "end_char": 21,
              "context": "×\nFigure 5.9\nThe M\nIN\n-C\nONFLICTS\nlocal search algorithm for CSPs. The "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para133",
          "content": "Min-conflicts is surprisingly effective for many CSPs. Amazingly, on the\nn\n-queens problem, if you don’t count the initial placement of queens, the run time of min-conflicts is roughly\nindependent of problem size\n. It solves even the\nmillion\n-queens problem in an average of 50 steps (after the initial assignment). This remarkable observation was the stimulus leading to a great deal of research in the 1990s on local search and the distinction between easy and hard problems, which we take up in\nSection 7.6.3\n. Roughly speaking,\nn\n-queens is easy for local search because solutions are densely distributed throughout the state space. Min-conflicts also works well for hard problems. For example, it has been used to schedule observations for the Hubble Space Telescope, reducing the time taken to schedule a week of observations from three weeks (!) to around 10 minutes.",
          "sentence_count": 8,
          "char_count": 742,
          "prev_para_id": "chap5_para132",
          "next_para_id": "chap5_para134",
          "style_metadata": {
            "para_id": "chap5_para133",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.12,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 161,
            "sentence_count": 8
          },
          "terminology": {
            "min-conflicts": 3,
            "effective": 1,
            "many": 1,
            "csps": 1,
            "-queens": 3,
            "problem": 5,
            "count": 1,
            "initial": 2,
            "placement": 1,
            "queen": 1,
            "run": 1,
            "time": 2,
            "independent": 1,
            "size": 1,
            "solves": 1,
            "average": 1,
            "step": 1,
            "assignment": 1,
            "remarkable": 1,
            "observation": 3,
            "stimulus": 1,
            "leading": 1,
            "great": 1,
            "deal": 1,
            "research": 1,
            "local": 2,
            "search": 2,
            "distinction": 1,
            "easy": 2,
            "hard": 2,
            "take": 1,
            "section": 1,
            "speaking": 1,
            "solution": 1,
            "distributed": 1,
            "state": 1,
            "space": 2,
            "work": 1,
            "example": 1,
            "used": 1,
            "schedule": 2,
            "hubble": 1,
            "telescope": 1,
            "reducing": 1,
            "taken": 1,
            "week": 2,
            "minute": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para134",
          "content": "All the local search techniques from\nSection 4.1\nare candidates for application to CSPs, and some of those have proved especially effective. The landscape of a CSP under the min- conflicts heuristic usually has a series of plateaus. There may be millions of variable assignments that are only one conflict away from a solution. Plateau search—allowing sideways moves to another state with the same score—can help local search find its way off this\nplateau. This wandering on the plateau can be directed with a technique called\ntabu search\n: keeping a small list of recently visited states and forbidding the algorithm to return to those states. Simulated annealing can also be used to escape from plateaus.",
          "sentence_count": 6,
          "char_count": 596,
          "prev_para_id": "chap5_para133",
          "next_para_id": "chap5_para135",
          "style_metadata": {
            "para_id": "chap5_para134",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 123,
            "sentence_count": 6
          },
          "terminology": {
            "local": 2,
            "search": 3,
            "technique": 2,
            "section": 1,
            "candidate": 1,
            "application": 1,
            "csps": 1,
            "proved": 1,
            "effective": 1,
            "landscape": 1,
            "csp": 1,
            "min-": 1,
            "conflict": 2,
            "heuristic": 1,
            "series": 1,
            "plateau": 4,
            "million": 1,
            "variable": 1,
            "assignment": 1,
            "solution": 1,
            "search—allowing": 1,
            "sideways": 1,
            "move": 1,
            "state": 3,
            "score—can": 1,
            "help": 1,
            "find": 1,
            "way": 1,
            "wandering": 1,
            "directed": 1,
            "called": 1,
            "tabu": 1,
            "keeping": 1,
            "small": 1,
            "list": 1,
            "visited": 1,
            "forbidding": 1,
            "algorithm": 1,
            "return": 1,
            "simulated": 1,
            "annealing": 1,
            "used": 1,
            "escape": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para134",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 160,
              "end_char": 163,
              "context": "e proved especially effective. The landscape of a CSP under the min- conflicts heuristic usually has a "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para135",
          "content": "Another technique called\nconstraint weighting\naims to concentrate the search on the important constraints. Each constraint is given a numeric weight, initially all 1. At each step of the search, the algorithm chooses a variable/value pair to change that will result in the lowest total weight of all violated constraints. The weights are then adjusted by incrementing the weight of each constraint that is violated by the current assignment. This has two benefits: it adds topography to plateaus, making sure that it is possible to improve from the current state, and it also adds learning: over time the difficult constraints are assigned higher weights.",
          "sentence_count": 5,
          "char_count": 554,
          "prev_para_id": "chap5_para134",
          "next_para_id": "chap5_para136",
          "style_metadata": {
            "para_id": "chap5_para135",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.8,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 114,
            "sentence_count": 5
          },
          "terminology": {
            "technique": 1,
            "called": 1,
            "constraint": 6,
            "weighting": 1,
            "aim": 1,
            "concentrate": 1,
            "search": 2,
            "important": 1,
            "given": 1,
            "numeric": 1,
            "weight": 5,
            "step": 1,
            "algorithm": 1,
            "chooses": 1,
            "variable/value": 1,
            "pair": 1,
            "change": 1,
            "result": 1,
            "lowest": 1,
            "total": 1,
            "violated": 2,
            "adjusted": 1,
            "incrementing": 1,
            "current": 2,
            "assignment": 1,
            "benefit": 1,
            "add": 2,
            "topography": 1,
            "plateau": 1,
            "making": 1,
            "sure": 1,
            "possible": 1,
            "improve": 1,
            "state": 1,
            "learning": 1,
            "time": 1,
            "difficult": 1,
            "assigned": 1,
            "higher": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para136",
          "content": "Another advantage of local search is that it can be used in an online setting (see\nsection 4.5\n) when the problem changes. Consider a scheduling problem for an airline’s weekly flights. The schedule may involve thousands of flights and tens of thousands of personnel\nassignments, but bad weather at one airport can render the schedule infeasible. We would like to repair the schedule with a minimum number of changes. This can be easily done with a local search algorithm starting from the current schedule. A backtracking search with the new set of constraints usually requires much more time and might find a solution with many changes from the current schedule.",
          "sentence_count": 6,
          "char_count": 557,
          "prev_para_id": "chap5_para135",
          "next_para_id": "chap5_para137",
          "style_metadata": {
            "para_id": "chap5_para136",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 121,
            "sentence_count": 6
          },
          "terminology": {
            "advantage": 1,
            "local": 2,
            "search": 3,
            "used": 1,
            "online": 1,
            "setting": 1,
            "see": 1,
            "section": 1,
            "problem": 2,
            "change": 3,
            "consider": 1,
            "scheduling": 1,
            "airline": 1,
            "weekly": 1,
            "flight": 2,
            "schedule": 5,
            "involve": 1,
            "thousand": 2,
            "ten": 1,
            "personnel": 1,
            "assignment": 1,
            "bad": 1,
            "weather": 1,
            "airport": 1,
            "render": 1,
            "infeasible": 1,
            "like": 1,
            "repair": 1,
            "minimum": 1,
            "number": 1,
            "done": 1,
            "starting": 1,
            "current": 2,
            "backtracking": 1,
            "new": 1,
            "set": 1,
            "constraint": 1,
            "requires": 1,
            "much": 1,
            "time": 1,
            "find": 1,
            "solution": 1,
            "many": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para137",
          "content": "5.5The Structure of Problems\n5.5\nThe Structure of Problems\nIn this section, we examine ways in which the\nstructure\nof the problem, as represented by the constraint graph, can be used to find solutions quickly. Most of the approaches here also apply to other problems besides CSPs, such as probabilistic reasoning.",
          "sentence_count": 2,
          "char_count": 268,
          "prev_para_id": "chap5_para136",
          "next_para_id": "chap5_para138",
          "style_metadata": {
            "para_id": "chap5_para137",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 57,
            "sentence_count": 2
          },
          "terminology": {
            "structure": 3,
            "problem": 4,
            "section": 1,
            "examine": 1,
            "way": 1,
            "represented": 1,
            "constraint": 1,
            "graph": 1,
            "used": 1,
            "find": 1,
            "solution": 1,
            "approach": 1,
            "apply": 1,
            "csps": 1,
            "probabilistic": 1,
            "reasoning": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para137",
              "entity_text": "The Structure of Problems",
              "entity_type": "WORK_OF_ART",
              "start_char": 33,
              "end_char": 58,
              "context": "5.5The Structure of Problems\n5.5\nThe Structure of Problems\nIn this section, we examine ways in which the\nstr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para138",
          "content": "The only way we can possibly hope to deal with the vast real world is to decompose it into subproblems. Looking again at the constraint graph for Australia (\nFigure 5.1(b)\n, repeated as\nFigure 5.12(a)\n), one fact stands out: Tasmania is not connected to the mainland.",
          "sentence_count": 2,
          "char_count": 224,
          "prev_para_id": "chap5_para137",
          "next_para_id": "chap5_para139",
          "style_metadata": {
            "para_id": "chap5_para138",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "way": 1,
            "hope": 1,
            "deal": 1,
            "vast": 1,
            "real": 1,
            "world": 1,
            "decompose": 1,
            "subproblems": 1,
            "looking": 1,
            "constraint": 1,
            "graph": 1,
            "australia": 1,
            "figure": 2,
            "repeated": 1,
            "fact": 1,
            "stand": 1,
            "connected": 1,
            "mainland": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para138",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 146,
              "end_char": 155,
              "context": "oblems. Looking again at the constraint graph for Australia (\nFigure 5.1(b)\n, repeated as\nFigure 5.12(a)\n), o"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para139",
          "content": "3\nIntuitively, it is obvious that coloring Tasmania and coloring the mainland are\nindependent subproblems\n—any solution for the mainland combined with any solution for Tasmania yields a solution for the whole map.",
          "sentence_count": 1,
          "char_count": 184,
          "prev_para_id": "chap5_para138",
          "next_para_id": "chap5_para140",
          "style_metadata": {
            "para_id": "chap5_para139",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 35.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 35,
            "sentence_count": 1
          },
          "terminology": {
            "obvious": 1,
            "coloring": 2,
            "tasmania": 2,
            "mainland": 2,
            "independent": 1,
            "subproblems": 1,
            "—any": 1,
            "solution": 3,
            "combined": 1,
            "yield": 1,
            "whole": 1,
            "map": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para139",
              "entity_text": "Tasmania",
              "entity_type": "ORG",
              "start_char": 43,
              "end_char": 51,
              "context": "3\nIntuitively, it is obvious that coloring Tasmania and coloring the mainland are\nindependent subprob"
            },
            {
              "para_id": "chap5_para139",
              "entity_text": "Tasmania",
              "entity_type": "ORG",
              "start_char": 168,
              "end_char": 176,
              "context": "n for the mainland combined with any solution for Tasmania yields a solution for the whole map."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para140",
          "content": "Independence can be ascertained simply by finding\nconnected components\nof the constraint graph. Each component corresponds to a subproblem\nCSP\ni\n. If assignment\nS\ni\nis a solution of\nCSP\ni\n, then ⋃\ni\nS\ni\nis a solution of ⋃\ni\nCSP\ni\n. Why is this important? Suppose each\nCSP\ni\nhas\nc\nvariables from the total of\nn\nvariables, where\nc\nis a constant. Then there are\nn/c\nsubproblems, each of which takes at most\nd\nc\nwork to solve, where\nd\nis the size of the domain. Hence, the total work is\nO\n(\nd\nc\nn/c\n), which is\nlinear\nin\nn\n; without the decomposition, the total work is\nO\n(\nd\nn\n), which is exponential in\nn\n. Let’s make this more concrete: dividing a Boolean CSP with 100 variables into four subproblems reduces the worst-case solution time from the lifetime of the universe down to less than a second.",
          "sentence_count": 8,
          "char_count": 691,
          "prev_para_id": "chap5_para139",
          "next_para_id": "chap5_para141",
          "style_metadata": {
            "para_id": "chap5_para140",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 21.88,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 175,
            "sentence_count": 8
          },
          "terminology": {
            "independence": 1,
            "ascertained": 1,
            "finding": 1,
            "connected": 1,
            "component": 2,
            "constraint": 1,
            "graph": 1,
            "corresponds": 1,
            "subproblem": 1,
            "csp": 5,
            "assignment": 1,
            "solution": 3,
            "important": 1,
            "suppose": 1,
            "variable": 3,
            "total": 3,
            "constant": 1,
            "n/c": 1,
            "subproblems": 2,
            "take": 1,
            "work": 3,
            "size": 1,
            "domain": 1,
            "hence": 1,
            "linear": 1,
            "decomposition": 1,
            "exponential": 1,
            "let": 1,
            "make": 1,
            "concrete": 1,
            "dividing": 1,
            "boolean": 1,
            "reduces": 1,
            "worst-case": 1,
            "time": 1,
            "lifetime": 1,
            "universe": 1,
            "less": 1,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para140",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 139,
              "end_char": 142,
              "context": "graph. Each component corresponds to a subproblem\nCSP\ni\n. If assignment\nS\ni\nis a solution of\nCSP\ni\n, th"
            },
            {
              "para_id": "chap5_para140",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 182,
              "end_char": 185,
              "context": "roblem\nCSP\ni\n. If assignment\nS\ni\nis a solution of\nCSP\ni\n, then ⋃\ni\nS\ni\nis a solution of ⋃\ni\nCSP\ni\n. Why"
            },
            {
              "para_id": "chap5_para140",
              "entity_text": "⋃",
              "entity_type": "PRODUCT",
              "start_char": 195,
              "end_char": 196,
              "context": ". If assignment\nS\ni\nis a solution of\nCSP\ni\n, then ⋃\ni\nS\ni\nis a solution of ⋃\ni\nCSP\ni\n. Why is this im"
            },
            {
              "para_id": "chap5_para140",
              "entity_text": "⋃",
              "entity_type": "PRODUCT",
              "start_char": 220,
              "end_char": 221,
              "context": "solution of\nCSP\ni\n, then ⋃\ni\nS\ni\nis a solution of ⋃\ni\nCSP\ni\n. Why is this important? Suppose each\nCSP"
            },
            {
              "para_id": "chap5_para140",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 224,
              "end_char": 227,
              "context": "tion of\nCSP\ni\n, then ⋃\ni\nS\ni\nis a solution of ⋃\ni\nCSP\ni\n. Why is this important? Suppose each\nCSP\ni\nhas"
            },
            {
              "para_id": "chap5_para140",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 268,
              "end_char": 271,
              "context": "f ⋃\ni\nCSP\ni\n. Why is this important? Suppose each\nCSP\ni\nhas\nc\nvariables from the total of\nn\nvariables, "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para141",
          "content": "Completely independent subproblems are delicious, then, but rare. Fortunately, some other graph structures are also easy to solve. For example, a constraint graph is a\ntree\nwhen any two variables are connected by only one path. We will show that\nany tree-structured CSP can be solved in time linear in the number of variables.",
          "sentence_count": 4,
          "char_count": 276,
          "prev_para_id": "chap5_para140",
          "next_para_id": "chap5_para142",
          "style_metadata": {
            "para_id": "chap5_para141",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 62,
            "sentence_count": 4
          },
          "terminology": {
            "independent": 1,
            "subproblems": 1,
            "delicious": 1,
            "rare": 1,
            "graph": 2,
            "structure": 1,
            "easy": 1,
            "solve": 1,
            "example": 1,
            "constraint": 1,
            "variable": 2,
            "connected": 1,
            "path": 1,
            "show": 1,
            "tree-structured": 1,
            "csp": 1,
            "solved": 1,
            "time": 1,
            "linear": 1,
            "number": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para141",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 266,
              "end_char": 269,
              "context": "y one path. We will show that\nany tree-structured CSP can be solved in time linear in the number of var"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para142",
          "content": "4\nThe key is a new notion of consistency, called\ndirectional arc consistency\nor DAC. A CSP is defined to be directional arc-consistent under an ordering of variables\nX\n1\n,\nX\n2\n,...,\nX\nn\nif and only if every\nX\ni\nis arc-consistent with each\nX\nj\nfor\nj\n>\ni\n.",
          "sentence_count": 2,
          "char_count": 223,
          "prev_para_id": "chap5_para141",
          "next_para_id": "chap5_para143",
          "style_metadata": {
            "para_id": "chap5_para142",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.017,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "key": 1,
            "new": 1,
            "notion": 1,
            "consistency": 2,
            "called": 1,
            "directional": 2,
            "arc": 1,
            "dac": 1,
            "csp": 1,
            "defined": 1,
            "arc-consistent": 2,
            "ordering": 1,
            "variable": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para142",
              "entity_text": "DAC",
              "entity_type": "ORG",
              "start_char": 80,
              "end_char": 83,
              "context": "onsistency, called\ndirectional arc consistency\nor DAC. A CSP is defined to be directional arc-consisten"
            },
            {
              "para_id": "chap5_para142",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 87,
              "end_char": 90,
              "context": "ncy, called\ndirectional arc consistency\nor DAC. A CSP is defined to be directional arc-consistent under"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para143",
          "content": "To solve a tree-structured CSP, first pick any variable to be the root of the tree, and choose an ordering of the variables such that each variable appears after its parent in the tree. Such an ordering is called a\ntopological sort\n.",
          "sentence_count": 2,
          "char_count": 193,
          "prev_para_id": "chap5_para142",
          "next_para_id": "chap5_para144",
          "style_metadata": {
            "para_id": "chap5_para143",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.022,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 46,
            "sentence_count": 2
          },
          "terminology": {
            "solve": 1,
            "tree-structured": 1,
            "csp": 1,
            "pick": 1,
            "variable": 3,
            "root": 1,
            "tree": 2,
            "choose": 1,
            "ordering": 2,
            "appears": 1,
            "parent": 1,
            "called": 1,
            "topological": 1,
            "sort": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para143",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 27,
              "end_char": 30,
              "context": "To solve a tree-structured CSP, first pick any variable to be the root of the tr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para144",
          "content": "Figure 5.10(a)\nshows a sample tree and\n(b)\nshows one possible ordering. Any tree with\nn\nnodes has\nn –\n1 edges, so we can make this graph directed arc-consistent in\nO\n(\nn\n) steps, each of which must compare up to\nd\npossible domain values for two variables, for a total time of\nO\n(\nnd\n2\n). Once we have a directed arc-consistent graph, we can just march down the list of variables and choose any remaining value. Since each edge from a parent to its child is arc-consistent, we know that for any value we choose for the parent, there will be a valid value left to choose for the child. That means we won’t\nhave to backtrack; we can move linearly through the variables. The complete algorithm is shown in\nFigure 5.11\n.",
          "sentence_count": 6,
          "char_count": 599,
          "prev_para_id": "chap5_para143",
          "next_para_id": "chap5_para145",
          "style_metadata": {
            "para_id": "chap5_para144",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 157,
            "sentence_count": 6
          },
          "terminology": {
            "figure": 2,
            "show": 2,
            "sample": 1,
            "tree": 2,
            "possible": 2,
            "ordering": 1,
            "node": 1,
            "edge": 2,
            "make": 1,
            "graph": 2,
            "directed": 2,
            "arc-consistent": 3,
            "step": 1,
            "compare": 1,
            "domain": 1,
            "value": 4,
            "variable": 3,
            "total": 1,
            "time": 1,
            "march": 1,
            "list": 1,
            "choose": 3,
            "remaining": 1,
            "parent": 2,
            "child": 2,
            "know": 1,
            "valid": 1,
            "left": 1,
            "mean": 1,
            "backtrack": 1,
            "move": 1,
            "complete": 1,
            "shown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para145",
          "content": "Description\nTwo three-level binary trees are shown. Up and down triangles represent MAX and MIN nodes, respectively, and circles represent CHANCE nodes.",
          "sentence_count": 2,
          "char_count": 132,
          "prev_para_id": "chap5_para144",
          "next_para_id": "chap5_para146",
          "style_metadata": {
            "para_id": "chap5_para145",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 26,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "three-level": 1,
            "binary": 1,
            "tree": 1,
            "shown": 1,
            "triangle": 1,
            "represent": 2,
            "max": 1,
            "min": 1,
            "node": 2,
            "circle": 1,
            "chance": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para145",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 84,
              "end_char": 87,
              "context": " trees are shown. Up and down triangles represent MAX and MIN nodes, respectively, and circles represen"
            },
            {
              "para_id": "chap5_para145",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 92,
              "end_char": 95,
              "context": "re shown. Up and down triangles represent MAX and MIN nodes, respectively, and circles represent CHANCE"
            },
            {
              "para_id": "chap5_para145",
              "entity_text": "CHANCE",
              "entity_type": "PERSON",
              "start_char": 139,
              "end_char": 145,
              "context": "nd MIN nodes, respectively, and circles represent CHANCE nodes."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para146",
          "content": "Binary tree 1: The first level of the game tree is labeled MAX and a MAX node is present. The node connects to two nodes in the second level. The second level is labeled CHANCE and the two nodes are CHANCE nodes labeled 2.1 and 1.3. An arrow labeled “a” subscript 1 from the MAX node connects to node 2.1. A path labeled “a” subscript 2 from the MAX node connects to node 1.3. The two nodes in the CHANCE level each have two child nodes in the third level. The third level is labeled MIN and has four MIN nodes. The two child nodes of 2.1 are labeled 2 and 3. Paths labeled 0.9 and 0.1 from node 2.1 connect to nodes 2 and 3, respectively. The two child nodes of 1.3 are labeled 1 and 4. Paths labeled 0.9 and 0.1 from node 1.3 connect to nodes 1 and 4, respectively. The two child nodes of 1 are labeled 1 and 1. The two child nodes of 2 are labeled 2 and 2. The two child nodes of 3 are labeled 3 and 3. The two child nodes of 4 are labeled 4 and 4.",
          "sentence_count": 15,
          "char_count": 755,
          "prev_para_id": "chap5_para145",
          "next_para_id": "chap5_para147",
          "style_metadata": {
            "para_id": "chap5_para146",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.07,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 211,
            "sentence_count": 15
          },
          "terminology": {
            "binary": 1,
            "tree": 2,
            "level": 6,
            "game": 1,
            "labeled": 14,
            "max": 4,
            "node": 19,
            "present": 1,
            "connects": 3,
            "second": 2,
            "chance": 3,
            "arrow": 1,
            "subscript": 2,
            "path": 3,
            "child": 7,
            "third": 2,
            "min": 1,
            "connect": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para146",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 59,
              "end_char": 62,
              "context": "ee 1: The first level of the game tree is labeled MAX and a MAX node is present. The node connects to t"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 69,
              "end_char": 72,
              "context": "first level of the game tree is labeled MAX and a MAX node is present. The node connects to two nodes i"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 170,
              "end_char": 176,
              "context": " in the second level. The second level is labeled CHANCE and the two nodes are CHANCE nodes labeled 2.1 an"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 199,
              "end_char": 205,
              "context": "ond level is labeled CHANCE and the two nodes are CHANCE nodes labeled 2.1 and 1.3. An arrow labeled “a” s"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 275,
              "end_char": 278,
              "context": "nd 1.3. An arrow labeled “a” subscript 1 from the MAX node connects to node 2.1. A path labeled “a” sub"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 346,
              "end_char": 349,
              "context": "node 2.1. A path labeled “a” subscript 2 from the MAX node connects to node 1.3. The two nodes in the C"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 398,
              "end_char": 404,
              "context": "X node connects to node 1.3. The two nodes in the CHANCE level each have two child nodes in the third leve"
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 484,
              "end_char": 487,
              "context": "es in the third level. The third level is labeled MIN and has four MIN nodes. The two child nodes of 2."
            },
            {
              "para_id": "chap5_para146",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 501,
              "end_char": 504,
              "context": "evel. The third level is labeled MIN and has four MIN nodes. The two child nodes of 2.1 are labeled 2 a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para147",
          "content": "Binary tree 2: The first level of the game tree is labeled MAX and a MAX node is present. The node connects to two nodes in the second level. The second level is labeled CHANCE and the two nodes are CHANCE nodes labeled 21 and 40.9. An arrow labeled “a” subscript 2 from the MAX node connects to node 40.9. A path labeled “a” subscript 1 from the MAX node connects to node 21. The two nodes in the CHANCE level each have two child nodes in the third level. The third level is labeled MIN and has four MIN nodes. The two child nodes of 21 are labeled 20 and 30. Paths labeled 0.9 and 0.1 from node 21 connect to nodes 20 and 30, respectively. The two child nodes of 40.9 are labeled 1 and 400. Paths labeled 0.9 and 0.1 from node 40.9 connect to nodes 1 and 400, respectively. The two child nodes of 1 are labeled 1 and 1. The two child nodes of 20 are labeled 20 and 20. The two child nodes of 30 are labeled 30 and 30. The two child nodes of 400 are labeled 400 and 400.",
          "sentence_count": 15,
          "char_count": 775,
          "prev_para_id": "chap5_para146",
          "next_para_id": "chap5_para148",
          "style_metadata": {
            "para_id": "chap5_para147",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.07,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 211,
            "sentence_count": 15
          },
          "terminology": {
            "binary": 1,
            "tree": 2,
            "level": 6,
            "game": 1,
            "labeled": 14,
            "max": 4,
            "node": 19,
            "present": 1,
            "connects": 3,
            "second": 2,
            "chance": 3,
            "arrow": 1,
            "subscript": 2,
            "path": 3,
            "child": 7,
            "third": 2,
            "min": 1,
            "connect": 2,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para147",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 59,
              "end_char": 62,
              "context": "ee 2: The first level of the game tree is labeled MAX and a MAX node is present. The node connects to t"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 69,
              "end_char": 72,
              "context": "first level of the game tree is labeled MAX and a MAX node is present. The node connects to two nodes i"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 170,
              "end_char": 176,
              "context": " in the second level. The second level is labeled CHANCE and the two nodes are CHANCE nodes labeled 21 and"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 199,
              "end_char": 205,
              "context": "ond level is labeled CHANCE and the two nodes are CHANCE nodes labeled 21 and 40.9. An arrow labeled “a” s"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 275,
              "end_char": 278,
              "context": "d 40.9. An arrow labeled “a” subscript 2 from the MAX node connects to node 40.9. A path labeled “a” su"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 347,
              "end_char": 350,
              "context": "ode 40.9. A path labeled “a” subscript 1 from the MAX node connects to node 21. The two nodes in the CH"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "CHANCE",
              "entity_type": "ORG",
              "start_char": 398,
              "end_char": 404,
              "context": "AX node connects to node 21. The two nodes in the CHANCE level each have two child nodes in the third leve"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 484,
              "end_char": 487,
              "context": "es in the third level. The third level is labeled MIN and has four MIN nodes. The two child nodes of 21"
            },
            {
              "para_id": "chap5_para147",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 501,
              "end_char": 504,
              "context": "evel. The third level is labeled MIN and has four MIN nodes. The two child nodes of 21 are labeled 20 a"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para148",
          "content": "×\nFigure 5.10\n(a) The constraint graph of a tree-structured CSP. (b) A linear ordering of the variables consistent with the tree with\nA\nas the root. This is known as a\ntopological sort\nof the variables.",
          "sentence_count": 3,
          "char_count": 172,
          "prev_para_id": "chap5_para147",
          "next_para_id": "chap5_para149",
          "style_metadata": {
            "para_id": "chap5_para148",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 3
          },
          "terminology": {
            "figure": 1,
            "constraint": 1,
            "graph": 1,
            "tree-structured": 1,
            "csp": 1,
            "ordering": 1,
            "variable": 2,
            "consistent": 1,
            "tree": 1,
            "root": 1,
            "known": 1,
            "topological": 1,
            "sort": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para148",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 60,
              "end_char": 63,
              "context": ".10\n(a) The constraint graph of a tree-structured CSP. (b) A linear ordering of the variables consisten"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para149",
          "content": "Description\nFive reduced chess boards are shown. The chess boards are reduced to 4 by 4, with row labels “a” to d from left to right and column labels 1 to 4 from bottom to top.",
          "sentence_count": 2,
          "char_count": 143,
          "prev_para_id": "chap5_para148",
          "next_para_id": "chap5_para150",
          "style_metadata": {
            "para_id": "chap5_para149",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "description": 1,
            "reduced": 2,
            "chess": 2,
            "board": 2,
            "shown": 1,
            "row": 1,
            "label": 2,
            "left": 1,
            "right": 1,
            "column": 1,
            "bottom": 1,
            "top": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para150",
          "content": "Board 1: The blacks are in the following positions. Kings, “a” 4, b 4, and c 4. The whites are in the following positions. King, d 2. Rook d 3. A line labeled K c 3 question mark from Board 1 connects to a circular node. An arrow labeled Illegal from the node points to board 2.",
          "sentence_count": 7,
          "char_count": 222,
          "prev_para_id": "chap5_para149",
          "next_para_id": "chap5_para151",
          "style_metadata": {
            "para_id": "chap5_para150",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.71,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 68,
            "sentence_count": 7
          },
          "terminology": {
            "board": 3,
            "black": 1,
            "following": 2,
            "position": 2,
            "king": 2,
            "white": 1,
            "rook": 1,
            "line": 1,
            "labeled": 2,
            "question": 1,
            "mark": 1,
            "connects": 1,
            "circular": 1,
            "node": 2,
            "arrow": 1,
            "illegal": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para150",
              "entity_text": "K c",
              "entity_type": "ORG",
              "start_char": 159,
              "end_char": 162,
              "context": "ng positions. King, d 2. Rook d 3. A line labeled K c 3 question mark from Board 1 connects to a circul"
            },
            {
              "para_id": "chap5_para150",
              "entity_text": "Board 1",
              "entity_type": "ORG",
              "start_char": 184,
              "end_char": 191,
              "context": "Rook d 3. A line labeled K c 3 question mark from Board 1 connects to a circular node. An arrow labeled Ill"
            },
            {
              "para_id": "chap5_para150",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 255,
              "end_char": 259,
              "context": " circular node. An arrow labeled Illegal from the node points to board 2."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para151",
          "content": "Board 2: The blacks are in the following positions. Kings, b 4 and c 4. The whites are in the following positions. King, d 2. Rook d 3. A line labeled R c 3 connects Board 2 to a second circular node. An arrow labeled OK from the second node points to board 3.",
          "sentence_count": 7,
          "char_count": 207,
          "prev_para_id": "chap5_para150",
          "next_para_id": "chap5_para152",
          "style_metadata": {
            "para_id": "chap5_para151",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 8.71,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 61,
            "sentence_count": 7
          },
          "terminology": {
            "board": 3,
            "black": 1,
            "following": 2,
            "position": 2,
            "king": 2,
            "white": 1,
            "rook": 1,
            "line": 1,
            "labeled": 2,
            "connects": 1,
            "second": 2,
            "circular": 1,
            "node": 2,
            "arrow": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para152",
          "content": "Board 3: A black is in the following position. King, b 4. The whites are in the following positions. King, d 2. Rook c 3. Another arrow labeled Check from the second node points to board 4.",
          "sentence_count": 6,
          "char_count": 153,
          "prev_para_id": "chap5_para151",
          "next_para_id": "chap5_para153",
          "style_metadata": {
            "para_id": "chap5_para152",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.17,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 43,
            "sentence_count": 6
          },
          "terminology": {
            "board": 2,
            "black": 1,
            "following": 2,
            "position": 2,
            "king": 2,
            "white": 1,
            "rook": 1,
            "arrow": 1,
            "labeled": 1,
            "check": 1,
            "second": 1,
            "node": 1,
            "point": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para152",
              "entity_text": "Check",
              "entity_type": "PERSON",
              "start_char": 144,
              "end_char": 149,
              "context": "tions. King, d 2. Rook c 3. Another arrow labeled Check from the second node points to board 4."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para153",
          "content": "Board 4: A black is in the following position. King, b 4. The whites are in the following positions. King, d 2. Rook c 3.",
          "sentence_count": 5,
          "char_count": 97,
          "prev_para_id": "chap5_para152",
          "next_para_id": "chap5_para154",
          "style_metadata": {
            "para_id": "chap5_para153",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 5
          },
          "terminology": {
            "board": 1,
            "black": 1,
            "following": 2,
            "position": 2,
            "king": 2,
            "white": 1,
            "rook": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para154",
          "content": "An arrow labeled OK from the first node points to board 5.",
          "sentence_count": 1,
          "char_count": 47,
          "prev_para_id": "chap5_para153",
          "next_para_id": "chap5_para155",
          "style_metadata": {
            "para_id": "chap5_para154",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 13,
            "sentence_count": 1
          },
          "terminology": {
            "arrow": 1,
            "labeled": 1,
            "node": 1,
            "point": 1,
            "board": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para155",
          "content": "Board 5: A black is in the following position. King, \"a\" 4. The whites are in the following positions. King, c 3. Rook d 3.",
          "sentence_count": 5,
          "char_count": 99,
          "prev_para_id": "chap5_para154",
          "next_para_id": "chap5_para156",
          "style_metadata": {
            "para_id": "chap5_para155",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 6.6,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 5
          },
          "terminology": {
            "board": 1,
            "black": 1,
            "following": 2,
            "position": 2,
            "king": 2,
            "white": 1,
            "rook": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para156",
          "content": "×\nFigure 5.11\nThe T\nREE\n-CSP-S\nOLVER\nalgorithm for solving tree-structured CSPs. If the CSP has a solution, we will find it in linear time; if not, we will detect a contradiction.",
          "sentence_count": 2,
          "char_count": 153,
          "prev_para_id": "chap5_para155",
          "next_para_id": "chap5_para157",
          "style_metadata": {
            "para_id": "chap5_para156",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 1,
            "ree": 1,
            "-csp-s": 1,
            "algorithm": 1,
            "solving": 1,
            "tree-structured": 1,
            "csps": 1,
            "csp": 1,
            "solution": 1,
            "linear": 1,
            "time": 1,
            "detect": 1,
            "contradiction": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para156",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 88,
              "end_char": 91,
              "context": "lgorithm for solving tree-structured CSPs. If the CSP has a solution, we will find it in linear time; i"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para157",
          "content": "Now that we have an efficient algorithm for trees, we can consider whether more general constraint graphs can be\nreduced\nto trees somehow. There are two ways to do this: by removing nodes (\nSection 5.5.1\n) or by collapsing nodes together (\nSection 5.5.2\n).",
          "sentence_count": 2,
          "char_count": 217,
          "prev_para_id": "chap5_para156",
          "next_para_id": "chap5_para158",
          "style_metadata": {
            "para_id": "chap5_para157",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 2
          },
          "terminology": {
            "efficient": 1,
            "algorithm": 1,
            "tree": 2,
            "consider": 1,
            "general": 1,
            "constraint": 1,
            "graph": 1,
            "reduced": 1,
            "way": 1,
            "removing": 1,
            "node": 2,
            "section": 2,
            "collapsing": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para158",
          "content": "5.5.1\nCutset conditioning\nThe first way to reduce a constraint graph to a tree involves assigning values to some variables so that the remaining variables form a tree. Consider the constraint graph for Australia, shown again in\nFigure 5.12(a)\n. Without South Australia, the graph would become a tree, as in\n(b)\n. Fortunately, we can delete South Australia (in the graph, not the country) by fixing a value for\nSA\nand deleting from the domains of the other variables any values that are inconsistent with the value chosen for\nSA\n.",
          "sentence_count": 4,
          "char_count": 448,
          "prev_para_id": "chap5_para157",
          "next_para_id": "chap5_para159",
          "style_metadata": {
            "para_id": "chap5_para158",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 105,
            "sentence_count": 4
          },
          "terminology": {
            "cutset": 1,
            "conditioning": 1,
            "first": 1,
            "way": 1,
            "reduce": 1,
            "constraint": 2,
            "graph": 4,
            "tree": 3,
            "involves": 1,
            "assigning": 1,
            "value": 4,
            "variable": 3,
            "remaining": 1,
            "consider": 1,
            "australia": 3,
            "shown": 1,
            "figure": 1,
            "south": 1,
            "become": 1,
            "delete": 1,
            "country": 1,
            "fixing": 1,
            "deleting": 1,
            "domain": 1,
            "inconsistent": 1,
            "chosen": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para158",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 202,
              "end_char": 211,
              "context": "es form a tree. Consider the constraint graph for Australia, shown again in\nFigure 5.12(a)\n. Without South Au"
            },
            {
              "para_id": "chap5_para158",
              "entity_text": "South Australia",
              "entity_type": "GPE",
              "start_char": 253,
              "end_char": 268,
              "context": "ustralia, shown again in\nFigure 5.12(a)\n. Without South Australia, the graph would become a tree, as in\n(b)\n. Fortu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para159",
          "content": "Description\nThe first level of game tree is labeled MAX and the node is labeled \"A\". Node \"A\" has two child nodes. Node \"A\" is represented by an up triangle. The second level is labeled MIN and the two nodes are labeled 99 and 100. The two nodes are represented by down triangles and each has four child nodes. The four child nodes of B are labeled 99, 1000, 1000, and 1000 and represented by up triangles. The four child nodes of 100 are labeled 100, 101, 102, and 103 and represented by up triangles.",
          "sentence_count": 7,
          "char_count": 409,
          "prev_para_id": "chap5_para158",
          "next_para_id": "chap5_para160",
          "style_metadata": {
            "para_id": "chap5_para159",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.14,
            "passive_voice_ratio": 0.035,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 113,
            "sentence_count": 7
          },
          "terminology": {
            "description": 1,
            "level": 2,
            "game": 1,
            "tree": 1,
            "labeled": 6,
            "max": 1,
            "node": 7,
            "child": 4,
            "represented": 4,
            "triangle": 4,
            "second": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para159",
              "entity_text": "MAX",
              "entity_type": "ORG",
              "start_char": 52,
              "end_char": 55,
              "context": "scription\nThe first level of game tree is labeled MAX and the node is labeled \"A\". Node \"A\" has two chi"
            },
            {
              "para_id": "chap5_para159",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 85,
              "end_char": 89,
              "context": " tree is labeled MAX and the node is labeled \"A\". Node \"A\" has two child nodes. Node \"A\" is represented "
            },
            {
              "para_id": "chap5_para159",
              "entity_text": "Node",
              "entity_type": "PERSON",
              "start_char": 115,
              "end_char": 119,
              "context": "ode is labeled \"A\". Node \"A\" has two child nodes. Node \"A\" is represented by an up triangle. The second "
            },
            {
              "para_id": "chap5_para159",
              "entity_text": "MIN",
              "entity_type": "ORG",
              "start_char": 186,
              "end_char": 189,
              "context": "ed by an up triangle. The second level is labeled MIN and the two nodes are labeled 99 and 100. The two"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para160",
          "content": "×\nFigure 5.12\n(a) The original constraint graph from\nFigure 5.1\n. (b) After the removal of\nSA\n, the constraint graph becomes a forest of two trees.",
          "sentence_count": 2,
          "char_count": 126,
          "prev_para_id": "chap5_para159",
          "next_para_id": "chap5_para161",
          "style_metadata": {
            "para_id": "chap5_para160",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "figure": 2,
            "original": 1,
            "constraint": 2,
            "graph": 2,
            "removal": 1,
            "becomes": 1,
            "forest": 1,
            "tree": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para160",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 91,
              "end_char": 93,
              "context": " graph from\nFigure 5.1\n. (b) After the removal of\nSA\n, the constraint graph becomes a forest of two tr"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para161",
          "content": "Now, any solution for the CSP after\nSA\nand its constraints are removed will be consistent with the value chosen for\nSA\n. (This works for binary CSPs; the situation is more complicated with higher-order constraints.) Therefore, we can solve the remaining tree with the algorithm\ngiven above and thus solve the whole problem. Of course, in the general case (as opposed to map coloring), the value chosen for\nSA\ncould be the wrong one, so we would need to try each possible value. The general algorithm is as follows:\n1.",
          "sentence_count": 5,
          "char_count": 435,
          "prev_para_id": "chap5_para160",
          "next_para_id": "chap5_para162",
          "style_metadata": {
            "para_id": "chap5_para161",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.5,
            "avg_sentence_length": 21.2,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 106,
            "sentence_count": 5
          },
          "terminology": {
            "solution": 1,
            "csp": 1,
            "constraint": 2,
            "removed": 1,
            "consistent": 1,
            "value": 3,
            "chosen": 2,
            "work": 1,
            "binary": 1,
            "csps": 1,
            "situation": 1,
            "complicated": 1,
            "higher-order": 1,
            "solve": 2,
            "remaining": 1,
            "tree": 1,
            "algorithm": 2,
            "given": 1,
            "whole": 1,
            "problem": 1,
            "course": 1,
            "general": 2,
            "case": 1,
            "opposed": 1,
            "map": 1,
            "coloring": 1,
            "wrong": 1,
            "need": 1,
            "try": 1,
            "possible": 1,
            "follows": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para161",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 26,
              "end_char": 29,
              "context": "Now, any solution for the CSP after\nSA\nand its constraints are removed will be "
            },
            {
              "para_id": "chap5_para161",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 36,
              "end_char": 38,
              "context": "Now, any solution for the CSP after\nSA\nand its constraints are removed will be consisten"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para162",
          "content": "Choose a subset\nS\nof the CSP’s variables such that the constraint graph becomes a tree after removal of\nS. S\nis called a\ncycle cutset\n.",
          "sentence_count": 1,
          "char_count": 115,
          "prev_para_id": "chap5_para161",
          "next_para_id": "chap5_para163",
          "style_metadata": {
            "para_id": "chap5_para162",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.034,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "choose": 1,
            "subset": 1,
            "csp": 1,
            "variable": 1,
            "constraint": 1,
            "graph": 1,
            "becomes": 1,
            "tree": 1,
            "removal": 1,
            "called": 1,
            "cycle": 1,
            "cutset": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para162",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 25,
              "end_char": 28,
              "context": "Choose a subset\nS\nof the CSP’s variables such that the constraint graph become"
            },
            {
              "para_id": "chap5_para162",
              "entity_text": "S. S",
              "entity_type": "ORG",
              "start_char": 104,
              "end_char": 108,
              "context": " constraint graph becomes a tree after removal of\nS. S\nis called a\ncycle cutset\n."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para163",
          "content": "2.",
          "sentence_count": 1,
          "char_count": 2,
          "prev_para_id": "chap5_para162",
          "next_para_id": "chap5_para164",
          "style_metadata": {
            "para_id": "chap5_para163",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 2.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 2,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para164",
          "content": "For each possible assignment to the variables in\nS\nthat satisfies all constraints on\nS\n,\n(a)\nremove from the domains of the remaining variables any values that are inconsistent with the assignment for\nS\n, and\n(b)\nif the remaining CSP has a solution, return it together with the assignment for\nS\n.",
          "sentence_count": 1,
          "char_count": 255,
          "prev_para_id": "chap5_para163",
          "next_para_id": "chap5_para165",
          "style_metadata": {
            "para_id": "chap5_para164",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 59.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 59,
            "sentence_count": 1
          },
          "terminology": {
            "possible": 1,
            "assignment": 3,
            "variable": 2,
            "satisfies": 1,
            "constraint": 1,
            "remove": 1,
            "domain": 1,
            "remaining": 2,
            "value": 1,
            "inconsistent": 1,
            "csp": 1,
            "solution": 1,
            "return": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para164",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 230,
              "end_char": 233,
              "context": "h the assignment for\nS\n, and\n(b)\nif the remaining CSP has a solution, return it together with the assig"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para165",
          "content": "If the cycle cutset has size\nc\n, then the total run time is\nO\n(\nd\nc\n·\n(n – c)d\n2\n): we have to try each of the\nd\nc\ncombinations of values for the variables in\nS\n, and for each combination we must solve a tree problem of size\nn – c\n. If the graph is “nearly a tree,” then\nc\nwill be small and the savings over straight backtracking will be huge—for our 100-Boolean-variable example, if we could find a cutset of size\nc\n= 20, this would get us down from the lifetime of the Universe to a few minutes. In the worst case, however,\nc\ncan be as large as (\nn\n– 2). Finding the\nsmallest\ncycle cutset is NP-hard, but several efficient approximation algorithms are known. The overall algorithmic approach is called\ncutset conditioning\n; it comes up again in\nChapter 13\n, where it is used for reasoning about probabilities.",
          "sentence_count": 5,
          "char_count": 681,
          "prev_para_id": "chap5_para164",
          "next_para_id": "chap5_para166",
          "style_metadata": {
            "para_id": "chap5_para165",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 35.8,
            "passive_voice_ratio": 0.011,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 179,
            "sentence_count": 5
          },
          "terminology": {
            "cycle": 2,
            "cutset": 4,
            "size": 3,
            "total": 1,
            "run": 1,
            "time": 1,
            "try": 1,
            "combination": 2,
            "value": 1,
            "variable": 1,
            "solve": 1,
            "tree": 2,
            "problem": 1,
            "graph": 1,
            "small": 1,
            "saving": 1,
            "straight": 1,
            "backtracking": 1,
            "huge—for": 1,
            "100-boolean-variable": 1,
            "example": 1,
            "find": 1,
            "get": 1,
            "lifetime": 1,
            "universe": 1,
            "minute": 1,
            "worst": 1,
            "case": 1,
            "large": 1,
            "finding": 1,
            "smallest": 1,
            "np-hard": 1,
            "several": 1,
            "efficient": 1,
            "approximation": 1,
            "algorithm": 1,
            "known": 1,
            "overall": 1,
            "algorithmic": 1,
            "approach": 1,
            "called": 1,
            "conditioning": 1,
            "come": 1,
            "chapter": 1,
            "used": 1,
            "reasoning": 1,
            "probability": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para165",
              "entity_text": "Universe",
              "entity_type": "ORG",
              "start_char": 471,
              "end_char": 479,
              "context": ", this would get us down from the lifetime of the Universe to a few minutes. In the worst case, however,\nc\nc"
            },
            {
              "para_id": "chap5_para165",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 594,
              "end_char": 596,
              "context": "as (\nn\n– 2). Finding the\nsmallest\ncycle cutset is NP-hard, but several efficient approximation algorit"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para166",
          "content": "5.5.2\nTree decomposition\nThe second way to reduce a constraint graph to a tree is based on constructing a\ntree decomposition\nof the constraint graph: a transformation of the original graph into a tree where each node in the tree consists of a set of variables, as in\nFigure 5.13\n. A tree decomposition must satisfy these three requirements:\n×\nFigure 5.13\nA tree decomposition of the constraint graph in\nFigure 5.12(a)\n.",
          "sentence_count": 2,
          "char_count": 358,
          "prev_para_id": "chap5_para165",
          "next_para_id": "chap5_para167",
          "style_metadata": {
            "para_id": "chap5_para166",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.5,
            "passive_voice_ratio": 0.013,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 79,
            "sentence_count": 2
          },
          "terminology": {
            "tree": 7,
            "decomposition": 4,
            "second": 1,
            "way": 1,
            "reduce": 1,
            "constraint": 3,
            "graph": 4,
            "based": 1,
            "constructing": 1,
            "transformation": 1,
            "original": 1,
            "node": 1,
            "consists": 1,
            "set": 1,
            "variable": 1,
            "figure": 3,
            "satisfy": 1,
            "requirement": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para167",
          "content": "•\nEvery variable in the original problem appears in at least one of the tree nodes.",
          "sentence_count": 1,
          "char_count": 69,
          "prev_para_id": "chap5_para166",
          "next_para_id": "chap5_para168",
          "style_metadata": {
            "para_id": "chap5_para167",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 17,
            "sentence_count": 1
          },
          "terminology": {
            "variable": 1,
            "original": 1,
            "problem": 1,
            "appears": 1,
            "least": 1,
            "tree": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para168",
          "content": "•\nIf two variables are connected by a constraint in the original problem, they must appear together (along with the constraint) in at least one of the tree nodes.",
          "sentence_count": 1,
          "char_count": 135,
          "prev_para_id": "chap5_para167",
          "next_para_id": "chap5_para169",
          "style_metadata": {
            "para_id": "chap5_para168",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 1
          },
          "terminology": {
            "variable": 1,
            "connected": 1,
            "constraint": 2,
            "original": 1,
            "problem": 1,
            "appear": 1,
            "least": 1,
            "tree": 1,
            "node": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para169",
          "content": "•\nIf a variable appears in two nodes in the tree, it must appear in every node along the path connecting those nodes.",
          "sentence_count": 1,
          "char_count": 96,
          "prev_para_id": "chap5_para168",
          "next_para_id": "chap5_para170",
          "style_metadata": {
            "para_id": "chap5_para169",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 25,
            "sentence_count": 1
          },
          "terminology": {
            "variable": 1,
            "appears": 1,
            "node": 3,
            "tree": 1,
            "appear": 1,
            "path": 1,
            "connecting": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para170",
          "content": "The first two conditions ensure that all the variables and constraints are represented in the tree decomposition. The third condition seems rather technical, but allows us to say that any variable from the original problem must have the same value wherever it appears: the constraints in the tree say that a variable in one node of the tree must have the same value as the corresponding variable in the adjacent node in the tree. For example,\nSA\nappears in all four of the connected nodes in\nFigure 5.13\n, so each edge in the tree decomposition therefore includes the constraint that the value of\nSA\nin one node must be the same as the value of\nSA\nin the next. You can verify from\nFigure 5.12\nthat this decomposition makes sense.",
          "sentence_count": 4,
          "char_count": 609,
          "prev_para_id": "chap5_para169",
          "next_para_id": "chap5_para171",
          "style_metadata": {
            "para_id": "chap5_para170",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 34.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "therefore"
            ],
            "word_count": 138,
            "sentence_count": 4
          },
          "terminology": {
            "condition": 2,
            "ensure": 1,
            "variable": 4,
            "constraint": 3,
            "represented": 1,
            "tree": 5,
            "decomposition": 3,
            "third": 1,
            "seems": 1,
            "technical": 1,
            "allows": 1,
            "say": 2,
            "original": 1,
            "problem": 1,
            "value": 4,
            "appears": 2,
            "node": 4,
            "corresponding": 1,
            "adjacent": 1,
            "example": 1,
            "connected": 1,
            "figure": 2,
            "edge": 1,
            "includes": 1,
            "next": 1,
            "verify": 1,
            "make": 1,
            "sense": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para170",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 443,
              "end_char": 445,
              "context": "le in the adjacent node in the tree. For example,\nSA\nappears in all four of the connected nodes in\nFig"
            },
            {
              "para_id": "chap5_para170",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 597,
              "end_char": 599,
              "context": "erefore includes the constraint that the value of\nSA\nin one node must be the same as the value of\nSA\ni"
            },
            {
              "para_id": "chap5_para170",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 645,
              "end_char": 647,
              "context": "f\nSA\nin one node must be the same as the value of\nSA\nin the next. You can verify from\nFigure 5.12\nthat"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para171",
          "content": "Once we have a tree-structured graph, we can apply T\nREE\n-CSP-S\nOLVER\nto get a solution in\nO\n(\nnd\n2\n) time, where\nn\nis the number of tree nodes and\nd\nis the size of the largest domain. But note that in the tree, a domain is a set of\ntuples\nof values, not just individual values.",
          "sentence_count": 2,
          "char_count": 234,
          "prev_para_id": "chap5_para170",
          "next_para_id": "chap5_para172",
          "style_metadata": {
            "para_id": "chap5_para171",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 66,
            "sentence_count": 2
          },
          "terminology": {
            "tree-structured": 1,
            "graph": 1,
            "apply": 1,
            "ree": 1,
            "-csp-s": 1,
            "olver": 1,
            "get": 1,
            "solution": 1,
            "time": 1,
            "number": 1,
            "tree": 2,
            "node": 1,
            "size": 1,
            "largest": 1,
            "domain": 2,
            "note": 1,
            "set": 1,
            "tuples": 1,
            "value": 2,
            "individual": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para172",
          "content": "For example, the top left node in\nFigure 5.13\nrepresents, at the level of the original problem, a subproblem with variables {\nWA, NT, SA\n}, domain {\nred, green, blue\n}, and constraints\nWA ≠ NT, SA ≠ NT, WA ≠ SA\n. At the level of the tree, the node represents a single variable, which we can call\nSANTWA\n, whose value must be a three-tuple of colors, such as (\nred, green, blue\n), but not (\nred, red, blue\n), because that would violate the constraint\nSA ≠ NT\nfrom the original problem. We can then move from that node to the adjacent one, with the variable we can call\nSANTQ\n, and find that there is only one tuple, (\nred, green, blue\n), that is consistent with the choice for\nSANTWA\n. The exact same process is repeated for the next two nodes, and independently we can make any choice for\nT\n.",
          "sentence_count": 4,
          "char_count": 658,
          "prev_para_id": "chap5_para171",
          "next_para_id": "chap5_para173",
          "style_metadata": {
            "para_id": "chap5_para172",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 46.5,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 186,
            "sentence_count": 4
          },
          "terminology": {
            "example": 1,
            "top": 1,
            "left": 1,
            "node": 3,
            "figure": 1,
            "represents": 2,
            "level": 2,
            "original": 2,
            "problem": 2,
            "subproblem": 1,
            "variable": 3,
            "domain": 1,
            "red": 5,
            "green": 3,
            "blue": 4,
            "constraint": 2,
            "tree": 1,
            "single": 1,
            "call": 2,
            "santwa": 2,
            "value": 1,
            "three-tuple": 1,
            "color": 1,
            "violate": 1,
            "move": 1,
            "adjacent": 1,
            "santq": 1,
            "find": 1,
            "tuple": 1,
            "consistent": 1,
            "choice": 2,
            "exact": 1,
            "process": 1,
            "repeated": 1,
            "next": 1,
            "make": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para172",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 26,
              "end_char": 30,
              "context": "For example, the top left node in\nFigure 5.13\nrepresents, at the level of the or"
            },
            {
              "para_id": "chap5_para172",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 134,
              "end_char": 136,
              "context": "al problem, a subproblem with variables {\nWA, NT, SA\n}, domain {\nred, green, blue\n}, and constraints\nW"
            },
            {
              "para_id": "chap5_para172",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 243,
              "end_char": 247,
              "context": " SA ≠ NT, WA ≠ SA\n. At the level of the tree, the node represents a single variable, which we can call\nS"
            },
            {
              "para_id": "chap5_para172",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 450,
              "end_char": 452,
              "context": "blue\n), because that would violate the constraint\nSA ≠ NT\nfrom the original problem. We can then move "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para173",
          "content": "We can solve any tree decomposition problem in\nO\n(\nnd\n2\n) time with T\nREE\n-CSP-S\nOLVER\n, which will be efficient as long as\nd\nremains small. Going back to our example with 100 Boolean variables, if each node has 10 variables, then\nd =\n2\n10\nand we should be able to solve the problem in seconds. But if there is a node with 30 variables, it would take centuries.",
          "sentence_count": 3,
          "char_count": 303,
          "prev_para_id": "chap5_para172",
          "next_para_id": "chap5_para174",
          "style_metadata": {
            "para_id": "chap5_para173",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 80,
            "sentence_count": 3
          },
          "terminology": {
            "solve": 2,
            "tree": 1,
            "decomposition": 1,
            "problem": 2,
            "time": 1,
            "ree": 1,
            "-csp-s": 1,
            "efficient": 1,
            "long": 1,
            "remains": 1,
            "small": 1,
            "going": 1,
            "example": 1,
            "boolean": 1,
            "variable": 3,
            "node": 2,
            "able": 1,
            "second": 1,
            "take": 1,
            "century": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para173",
              "entity_text": "node",
              "entity_type": "GPE",
              "start_char": 203,
              "end_char": 207,
              "context": "o our example with 100 Boolean variables, if each node has 10 variables, then\nd =\n2\n10\nand we should be "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para174",
          "content": "A given graph admits many tree decompositions; in choosing a decomposition, the aim is to make the subproblems as small as possible. (Putting all the variables into one node is technically a tree, but is not helpful.) The\ntree width\nof a tree decomposition of a graph is\none less than the size of the largest node; the tree width of the graph itself is defined to be the minimum width among all its tree decompositions. If a graph has tree width\nw\nthen the problem can be solved in\nO\n(\nnd\nw\n+1\n) time given the corresponding tree decomposition. Hence,\nCSPs with constraint graphs of bounded tree width are solvable in polynomial time.",
          "sentence_count": 5,
          "char_count": 531,
          "prev_para_id": "chap5_para173",
          "next_para_id": "chap5_para175",
          "style_metadata": {
            "para_id": "chap5_para174",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.6,
            "passive_voice_ratio": 0.008,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 128,
            "sentence_count": 5
          },
          "terminology": {
            "given": 2,
            "graph": 5,
            "admits": 1,
            "many": 1,
            "tree": 9,
            "decomposition": 5,
            "choosing": 1,
            "aim": 1,
            "make": 1,
            "subproblems": 1,
            "small": 1,
            "possible": 1,
            "putting": 1,
            "variable": 1,
            "node": 2,
            "helpful": 1,
            "width": 5,
            "less": 1,
            "size": 1,
            "largest": 1,
            "defined": 1,
            "minimum": 1,
            "problem": 1,
            "solved": 1,
            "time": 2,
            "corresponding": 1,
            "hence": 1,
            "csps": 1,
            "constraint": 1,
            "bounded": 1,
            "solvable": 1,
            "polynomial": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para175",
          "content": "Unfortunately, finding the decomposition with minimal tree width is NP-hard, but there are heuristic methods that work well in practice. Which is better: the cutset decomposition with time\nO\n(\nd\nc\n· (\nn —\nc\n)\nd\n2\n), or the tree decomposition with time\nO\n(\nnd\nw\n+1\n)? Whenever you have a cycle-cutset of size\nc\n, there is also a tree width of size\nw < c\n+ 1, and it may be far smaller in some cases. So time consideration favors tree decomposition, but the advantage of the cycle-cutset approach is that it can be executed in linear memory, while tree decomposition requires memory exponential in\nw\n.",
          "sentence_count": 4,
          "char_count": 508,
          "prev_para_id": "chap5_para174",
          "next_para_id": "chap5_para176",
          "style_metadata": {
            "para_id": "chap5_para175",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.25,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 125,
            "sentence_count": 4
          },
          "terminology": {
            "finding": 1,
            "decomposition": 5,
            "minimal": 1,
            "tree": 5,
            "np-hard": 1,
            "heuristic": 1,
            "method": 1,
            "work": 1,
            "practice": 1,
            "cutset": 1,
            "time": 3,
            "cycle-cutset": 2,
            "size": 2,
            "width": 1,
            "smaller": 1,
            "case": 1,
            "consideration": 1,
            "favor": 1,
            "advantage": 1,
            "approach": 1,
            "executed": 1,
            "linear": 1,
            "memory": 2,
            "requires": 1,
            "exponential": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para175",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 68,
              "end_char": 70,
              "context": "ding the decomposition with minimal tree width is NP-hard, but there are heuristic methods that work w"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para176",
          "content": "5.5.3\nValue symmetry\nSo far, we have looked at the structure of the constraint graph. There can also be important structure in the\nvalues\nof variables, or in the structure of the constraint relations themselves. Consider the map-coloring problem with\nd\ncolors. For every consistent solution, there is actually a set of\nd\n! solutions formed by permuting the color names. For example, on the Australia map we know that\nWA\n,\nNT,\nand\nSA\nmust all have different colors, but there are 3! = 6 ways to assign three colors to three regions. This is called\nvalue symmetry\n. We would like to reduce the search space by a factor of\nd\n! by breaking the symmetry in assignments. We do this by introducing a\nsymmetry-breaking constraint\n. For our example, we might impose an arbitrary ordering constraint,\nNT < SA < WA,\nthat requires the three values to be in alphabetical order. This constraint ensures that only one of the\nd\n! solutions is possible: {\nNT = blue, SA = green, WA = red\n}.",
          "sentence_count": 14,
          "char_count": 822,
          "prev_para_id": "chap5_para175",
          "next_para_id": "chap5_para177",
          "style_metadata": {
            "para_id": "chap5_para176",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.21,
            "passive_voice_ratio": 0.005,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 199,
            "sentence_count": 14
          },
          "terminology": {
            "value": 4,
            "symmetry": 3,
            "looked": 1,
            "structure": 3,
            "constraint": 5,
            "graph": 1,
            "important": 1,
            "variable": 1,
            "relation": 1,
            "consider": 1,
            "map-coloring": 1,
            "problem": 1,
            "color": 4,
            "consistent": 1,
            "solution": 3,
            "set": 1,
            "formed": 1,
            "permuting": 1,
            "name": 1,
            "example": 2,
            "australia": 1,
            "map": 1,
            "know": 1,
            "different": 1,
            "way": 1,
            "assign": 1,
            "region": 1,
            "called": 1,
            "like": 1,
            "reduce": 1,
            "search": 1,
            "space": 1,
            "factor": 1,
            "breaking": 1,
            "assignment": 1,
            "introducing": 1,
            "symmetry-breaking": 1,
            "impose": 1,
            "arbitrary": 1,
            "ordering": 1,
            "requires": 1,
            "alphabetical": 1,
            "order": 1,
            "ensures": 1,
            "possible": 1,
            "blue": 1,
            "green": 1,
            "red": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para176",
              "entity_text": "Australia",
              "entity_type": "GPE",
              "start_char": 390,
              "end_char": 399,
              "context": "by permuting the color names. For example, on the Australia map we know that\nWA\n,\nNT,\nand\nSA\nmust all have di"
            },
            {
              "para_id": "chap5_para176",
              "entity_text": "SA",
              "entity_type": "ORG",
              "start_char": 950,
              "end_char": 952,
              "context": "ne of the\nd\n! solutions is possible: {\nNT = blue, SA = green, WA = red\n}."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para177",
          "content": "For map coloring, it was easy to find a constraint that eliminates the symmetry. In general it is NP-hard to eliminate all symmetry, but breaking value symmetry has proved to be important and effective on a wide range of problems.",
          "sentence_count": 2,
          "char_count": 191,
          "prev_para_id": "chap5_para176",
          "next_para_id": "chap5_para178",
          "style_metadata": {
            "para_id": "chap5_para177",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "map": 1,
            "coloring": 1,
            "easy": 1,
            "find": 1,
            "constraint": 1,
            "eliminates": 1,
            "symmetry": 3,
            "general": 1,
            "np-hard": 1,
            "eliminate": 1,
            "breaking": 1,
            "value": 1,
            "proved": 1,
            "important": 1,
            "effective": 1,
            "wide": 1,
            "range": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para177",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 98,
              "end_char": 100,
              "context": "nt that eliminates the symmetry. In general it is NP-hard to eliminate all symmetry, but breaking valu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para178",
          "content": "Summary\nSummary\n•\nConstraint satisfaction problems\n(CSPs) represent a state with a set of variable/value pairs and represent the conditions for a solution by a set of constraints on the variables. Many important real-world problems can be described as CSPs.",
          "sentence_count": 2,
          "char_count": 222,
          "prev_para_id": "chap5_para177",
          "next_para_id": "chap5_para179",
          "style_metadata": {
            "para_id": "chap5_para178",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 22.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 44,
            "sentence_count": 2
          },
          "terminology": {
            "summary": 2,
            "constraint": 2,
            "satisfaction": 1,
            "problem": 2,
            "csps": 2,
            "represent": 2,
            "state": 1,
            "set": 2,
            "variable/value": 1,
            "pair": 1,
            "condition": 1,
            "solution": 1,
            "variable": 1,
            "many": 1,
            "important": 1,
            "real-world": 1,
            "described": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para179",
          "content": "•\nA number of\ninference\ntechniques use the constraints to rule out certain variable assignments. These include node, arc, path, and\nk\n-consistency.",
          "sentence_count": 2,
          "char_count": 130,
          "prev_para_id": "chap5_para178",
          "next_para_id": "chap5_para180",
          "style_metadata": {
            "para_id": "chap5_para179",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 14.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 28,
            "sentence_count": 2
          },
          "terminology": {
            "number": 1,
            "inference": 1,
            "technique": 1,
            "use": 1,
            "constraint": 1,
            "rule": 1,
            "certain": 1,
            "variable": 1,
            "assignment": 1,
            "include": 1,
            "node": 1,
            "arc": 1,
            "path": 1,
            "-consistency": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para179",
              "entity_text": "node",
              "entity_type": "ORG",
              "start_char": 111,
              "end_char": 115,
              "context": "e out certain variable assignments. These include node, arc, path, and\nk\n-consistency."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para180",
          "content": "•\nBacktracking search\n, a form of depth-first search, is commonly used for solving CSPs. Inference can be interwoven with search.",
          "sentence_count": 2,
          "char_count": 111,
          "prev_para_id": "chap5_para179",
          "next_para_id": "chap5_para181",
          "style_metadata": {
            "para_id": "chap5_para180",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 12.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 24,
            "sentence_count": 2
          },
          "terminology": {
            "backtracking": 1,
            "search": 3,
            "form": 1,
            "depth-first": 1,
            "used": 1,
            "solving": 1,
            "csps": 1,
            "inference": 1,
            "interwoven": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para181",
          "content": "•\nThe\nminimum-remaining-values\nand\ndegree\nheuristics are domain-independent methods for deciding which variable to choose next in a backtracking search. The\nleast-constraining-value\nheuristic helps in deciding which value to try first for a given variable. Backtracking occurs when no legal assignment can be found for a variable.",
          "sentence_count": 3,
          "char_count": 291,
          "prev_para_id": "chap5_para180",
          "next_para_id": "chap5_para182",
          "style_metadata": {
            "para_id": "chap5_para181",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 50,
            "sentence_count": 3
          },
          "terminology": {
            "minimum-remaining-values": 1,
            "degree": 1,
            "heuristic": 2,
            "domain-independent": 1,
            "method": 1,
            "deciding": 2,
            "variable": 3,
            "choose": 1,
            "next": 1,
            "backtracking": 2,
            "search": 1,
            "least-constraining-value": 1,
            "help": 1,
            "value": 1,
            "try": 1,
            "given": 1,
            "occurs": 1,
            "legal": 1,
            "assignment": 1,
            "found": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para182",
          "content": "Conflict-directed backjumping\nbacktracks directly to the source of the problem.",
          "sentence_count": 1,
          "char_count": 71,
          "prev_para_id": "chap5_para181",
          "next_para_id": "chap5_para183",
          "style_metadata": {
            "para_id": "chap5_para182",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 11,
            "sentence_count": 1
          },
          "terminology": {
            "conflict-directed": 1,
            "backjumping": 1,
            "backtracks": 1,
            "source": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para183",
          "content": "Constraint learning\nrecords the conflicts as they are encountered during search in order to avoid the same conflict later in the search.",
          "sentence_count": 1,
          "char_count": 116,
          "prev_para_id": "chap5_para182",
          "next_para_id": "chap5_para184",
          "style_metadata": {
            "para_id": "chap5_para183",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 23,
            "sentence_count": 1
          },
          "terminology": {
            "constraint": 1,
            "learning": 1,
            "record": 1,
            "conflict": 2,
            "encountered": 1,
            "search": 2,
            "order": 1,
            "avoid": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para184",
          "content": "•\nLocal search using the\nmin-conflicts\nheuristic has also been applied to constraint satisfaction problems with great success.",
          "sentence_count": 1,
          "char_count": 112,
          "prev_para_id": "chap5_para183",
          "next_para_id": "chap5_para185",
          "style_metadata": {
            "para_id": "chap5_para184",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 1
          },
          "terminology": {
            "local": 1,
            "search": 1,
            "using": 1,
            "min-conflicts": 1,
            "heuristic": 1,
            "applied": 1,
            "constraint": 1,
            "satisfaction": 1,
            "problem": 1,
            "great": 1,
            "success": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para185",
          "content": "•\nThe complexity of solving a CSP is strongly related to the structure of its constraint graph. Tree-structured problems can be solved in linear time.",
          "sentence_count": 2,
          "char_count": 127,
          "prev_para_id": "chap5_para184",
          "next_para_id": "chap5_para186",
          "style_metadata": {
            "para_id": "chap5_para185",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 2
          },
          "terminology": {
            "complexity": 1,
            "solving": 1,
            "csp": 1,
            "related": 1,
            "structure": 1,
            "constraint": 1,
            "graph": 1,
            "tree-structured": 1,
            "problem": 1,
            "solved": 1,
            "linear": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para185",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 30,
              "end_char": 33,
              "context": "•\nThe complexity of solving a CSP is strongly related to the structure of its const"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para186",
          "content": "Cutset conditioning\ncan reduce a general CSP to a tree-structured one and is quite efficient (requiring only linear memory) if a small cutset can be found.",
          "sentence_count": 1,
          "char_count": 131,
          "prev_para_id": "chap5_para185",
          "next_para_id": "chap5_para187",
          "style_metadata": {
            "para_id": "chap5_para186",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 29,
            "sentence_count": 1
          },
          "terminology": {
            "cutset": 2,
            "conditioning": 1,
            "reduce": 1,
            "general": 1,
            "csp": 1,
            "tree-structured": 1,
            "quite": 1,
            "efficient": 1,
            "requiring": 1,
            "linear": 1,
            "memory": 1,
            "small": 1,
            "found": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para186",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 41,
              "end_char": 44,
              "context": "Cutset conditioning\ncan reduce a general CSP to a tree-structured one and is quite efficient ("
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para187",
          "content": "Tree decomposition\ntechniques transform the CSP into a tree of subproblems and are efficient if the\ntree width\nof the constraint graph is small; however they need memory exponential in the tree width of the constraint graph. Combining cutset conditioning with tree decomposition can allow a better tradeoff of memory versus time.",
          "sentence_count": 2,
          "char_count": 281,
          "prev_para_id": "chap5_para186",
          "next_para_id": "chap5_para188",
          "style_metadata": {
            "para_id": "chap5_para187",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.5,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [
              "however"
            ],
            "word_count": 55,
            "sentence_count": 2
          },
          "terminology": {
            "tree": 5,
            "decomposition": 2,
            "technique": 1,
            "transform": 1,
            "csp": 1,
            "subproblems": 1,
            "efficient": 1,
            "width": 2,
            "constraint": 2,
            "graph": 2,
            "small": 1,
            "need": 1,
            "memory": 2,
            "exponential": 1,
            "combining": 1,
            "cutset": 1,
            "conditioning": 1,
            "better": 1,
            "tradeoff": 1,
            "versus": 1,
            "time": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para187",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 44,
              "end_char": 47,
              "context": "Tree decomposition\ntechniques transform the CSP into a tree of subproblems and are efficient if t"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para188",
          "content": "Bibliographical and Historical Notes\nBibliographical and Historical Notes\nThe Greek mathematician Diophantus (c. 200–284) presented and solved problems involving algebraic constraints on equations, although he didn’t develop a generalized methodology. We now call equations over integer domains\nDiophantine equations\n. The Indian mathematician Brahmagupta (c. 650) was the first to show a general solution over the domain of integers for the equation\nax + by = c.",
          "sentence_count": 3,
          "char_count": 402,
          "prev_para_id": "chap5_para187",
          "next_para_id": "chap5_para189",
          "style_metadata": {
            "para_id": "chap5_para188",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 76,
            "sentence_count": 3
          },
          "terminology": {
            "bibliographical": 2,
            "historical": 2,
            "note": 2,
            "greek": 1,
            "mathematician": 2,
            "diophantus": 1,
            "presented": 1,
            "solved": 1,
            "problem": 1,
            "involving": 1,
            "algebraic": 1,
            "constraint": 1,
            "equation": 4,
            "develop": 1,
            "generalized": 1,
            "methodology": 1,
            "call": 1,
            "integer": 2,
            "domain": 2,
            "diophantine": 1,
            "indian": 1,
            "brahmagupta": 1,
            "show": 1,
            "general": 1,
            "solution": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para188",
              "entity_text": "Diophantus",
              "entity_type": "ORG",
              "start_char": 98,
              "end_char": 108,
              "context": "ical and Historical Notes\nThe Greek mathematician Diophantus (c. 200–284) presented and solved problems involv"
            },
            {
              "para_id": "chap5_para188",
              "entity_text": "= c.",
              "entity_type": "PERSON",
              "start_char": 459,
              "end_char": 463,
              "context": "r the domain of integers for the equation\nax + by = c."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para189",
          "content": "Systematic methods for solving linear equations by variable elimination were studied by Gauss (1829); the solution of linear inequality constraints goes back to Fourier (1827).",
          "sentence_count": 1,
          "char_count": 152,
          "prev_para_id": "chap5_para188",
          "next_para_id": "chap5_para190",
          "style_metadata": {
            "para_id": "chap5_para189",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 31.0,
            "passive_voice_ratio": 0.032,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 31,
            "sentence_count": 1
          },
          "terminology": {
            "systematic": 1,
            "method": 1,
            "solving": 1,
            "linear": 2,
            "equation": 1,
            "variable": 1,
            "elimination": 1,
            "studied": 1,
            "gauss": 1,
            "solution": 1,
            "inequality": 1,
            "constraint": 1,
            "go": 1,
            "fourier": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para189",
              "entity_text": "linear",
              "entity_type": "ORG",
              "start_char": 31,
              "end_char": 37,
              "context": "Systematic methods for solving linear equations by variable elimination were studied by"
            },
            {
              "para_id": "chap5_para189",
              "entity_text": "Gauss",
              "entity_type": "ORG",
              "start_char": 88,
              "end_char": 93,
              "context": "equations by variable elimination were studied by Gauss (1829); the solution of linear inequality constra"
            },
            {
              "para_id": "chap5_para189",
              "entity_text": "Fourier",
              "entity_type": "PERSON",
              "start_char": 161,
              "end_char": 168,
              "context": "ion of linear inequality constraints goes back to Fourier (1827)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para190",
          "content": "Finite-domain constraint satisfaction problems also have a long history. For example,\ngraph coloring\n(of which map coloring is a special case) is an old problem in mathematics. The four-color conjecture (that every planar graph can be colored with four or fewer colors) was first made by Francis Guthrie, a student of De Morgan, in 1852. It resisted solution—despite several published claims to the contrary—until a proof was devised by Appel and Haken (1977) (see the book\nFour Colors Suffice\n(Wilson, 2004)). Purists were disappointed that part of the proof relied on a computer, so Georges Gonthier (2008), using the C\nOQ\ntheorem prover, derived a formal proof that Appel and Haken’s proof program was correct.",
          "sentence_count": 5,
          "char_count": 605,
          "prev_para_id": "chap5_para189",
          "next_para_id": "chap5_para191",
          "style_metadata": {
            "para_id": "chap5_para190",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 28.0,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 140,
            "sentence_count": 5
          },
          "terminology": {
            "finite-domain": 1,
            "constraint": 1,
            "satisfaction": 1,
            "problem": 2,
            "history": 1,
            "example": 1,
            "graph": 2,
            "coloring": 2,
            "map": 1,
            "special": 1,
            "case": 1,
            "old": 1,
            "mathematics": 1,
            "four-color": 1,
            "conjecture": 1,
            "planar": 1,
            "colored": 1,
            "fewer": 1,
            "color": 2,
            "made": 1,
            "francis": 1,
            "guthrie": 1,
            "student": 1,
            "morgan": 1,
            "resisted": 1,
            "solution—despite": 1,
            "several": 1,
            "published": 1,
            "claim": 1,
            "contrary—until": 1,
            "proof": 4,
            "devised": 1,
            "haken": 2,
            "see": 1,
            "book": 1,
            "suffice": 1,
            "wilson": 1,
            "purist": 1,
            "disappointed": 1,
            "part": 1,
            "relied": 1,
            "computer": 1,
            "george": 1,
            "gonthier": 1,
            "using": 1,
            "theorem": 1,
            "prover": 1,
            "derived": 1,
            "formal": 1,
            "appel": 1,
            "program": 1,
            "correct": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para190",
              "entity_text": "Francis Guthrie",
              "entity_type": "PERSON",
              "start_char": 288,
              "end_char": 303,
              "context": "ored with four or fewer colors) was first made by Francis Guthrie, a student of De Morgan, in 1852. It resisted sol"
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "De Morgan",
              "entity_type": "PERSON",
              "start_char": 318,
              "end_char": 327,
              "context": ") was first made by Francis Guthrie, a student of De Morgan, in 1852. It resisted solution—despite several pu"
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "Appel and",
              "entity_type": "ORG",
              "start_char": 437,
              "end_char": 446,
              "context": "aims to the contrary—until a proof was devised by Appel and Haken (1977) (see the book\nFour Colors Suffice\n(W"
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "Haken",
              "entity_type": "PERSON",
              "start_char": 447,
              "end_char": 452,
              "context": "e contrary—until a proof was devised by Appel and Haken (1977) (see the book\nFour Colors Suffice\n(Wilson,"
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "Wilson",
              "entity_type": "ORG",
              "start_char": 495,
              "end_char": 501,
              "context": "d Haken (1977) (see the book\nFour Colors Suffice\n(Wilson, 2004)). Purists were disappointed that part of t"
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "Georges Gonthier",
              "entity_type": "PERSON",
              "start_char": 585,
              "end_char": 601,
              "context": "d that part of the proof relied on a computer, so Georges Gonthier (2008), using the C\nOQ\ntheorem prover, derived a "
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "Appel",
              "entity_type": "PERSON",
              "start_char": 669,
              "end_char": 674,
              "context": " C\nOQ\ntheorem prover, derived a formal proof that Appel and Haken’s proof program was correct."
            },
            {
              "para_id": "chap5_para190",
              "entity_text": "Haken",
              "entity_type": "ORG",
              "start_char": 679,
              "end_char": 684,
              "context": "rem prover, derived a formal proof that Appel and Haken’s proof program was correct."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para191",
          "content": "Specific classes of constraint satisfaction problems occur throughout the history of computer science. One of the most influential early examples was S\nKETCHPAD\n(Sutherland, 1963), which solved geometric constraints in diagrams and was the forerunner of modern drawing programs and CAD tools. The identification of CSPs as a\ngeneral\nclass is due to Ugo Montanari (1974). The reduction of higher-order CSPs to purely binary CSPs with auxiliary variables (see Exercise\n5.",
          "sentence_count": 4,
          "char_count": 404,
          "prev_para_id": "chap5_para190",
          "next_para_id": "chap5_para192",
          "style_metadata": {
            "para_id": "chap5_para191",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 82,
            "sentence_count": 4
          },
          "terminology": {
            "specific": 1,
            "class": 2,
            "constraint": 2,
            "satisfaction": 1,
            "problem": 1,
            "occur": 1,
            "history": 1,
            "computer": 1,
            "science": 1,
            "influential": 1,
            "early": 1,
            "example": 1,
            "sutherland": 1,
            "solved": 1,
            "geometric": 1,
            "diagram": 1,
            "forerunner": 1,
            "modern": 1,
            "drawing": 1,
            "program": 1,
            "cad": 1,
            "tool": 1,
            "identification": 1,
            "csps": 3,
            "general": 1,
            "due": 1,
            "ugo": 1,
            "montanari": 1,
            "reduction": 1,
            "higher-order": 1,
            "binary": 1,
            "auxiliary": 1,
            "variable": 1,
            "see": 1,
            "exercise": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para191",
              "entity_text": "Sutherland",
              "entity_type": "GPE",
              "start_char": 162,
              "end_char": 172,
              "context": "e most influential early examples was S\nKETCHPAD\n(Sutherland, 1963), which solved geometric constraints in dia"
            },
            {
              "para_id": "chap5_para191",
              "entity_text": "CAD",
              "entity_type": "ORG",
              "start_char": 282,
              "end_char": 285,
              "context": "was the forerunner of modern drawing programs and CAD tools. The identification of CSPs as a\ngeneral\ncl"
            },
            {
              "para_id": "chap5_para191",
              "entity_text": "Ugo Montanari",
              "entity_type": "PERSON",
              "start_char": 349,
              "end_char": 362,
              "context": "entification of CSPs as a\ngeneral\nclass is due to Ugo Montanari (1974). The reduction of higher-order CSPs to pur"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para192",
          "content": "NARY\n) is due originally to the 19th-century logician Charles Sanders Peirce. It was introduced into the CSP literature by Dechter (1990b) and was elaborated by Bacchus and van Beek (1998). CSPs with preferences among solutions are studied widely in the optimization literature; see Bistarelli\net al.",
          "sentence_count": 3,
          "char_count": 256,
          "prev_para_id": "chap5_para191",
          "next_para_id": "chap5_para193",
          "style_metadata": {
            "para_id": "chap5_para192",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.33,
            "passive_voice_ratio": 0.036,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 3
          },
          "terminology": {
            "nary": 1,
            "due": 1,
            "19th-century": 1,
            "logician": 1,
            "charles": 1,
            "sander": 1,
            "peirce": 1,
            "introduced": 1,
            "csp": 1,
            "literature": 2,
            "dechter": 1,
            "elaborated": 1,
            "van": 1,
            "beek": 1,
            "csps": 1,
            "preference": 1,
            "solution": 1,
            "studied": 1,
            "optimization": 1,
            "see": 1,
            "bistarelli": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para192",
              "entity_text": "NARY",
              "entity_type": "GPE",
              "start_char": 0,
              "end_char": 4,
              "context": "NARY\n) is due originally to the 19th-century logician "
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "Charles Sanders Peirce",
              "entity_type": "PERSON",
              "start_char": 54,
              "end_char": 76,
              "context": "\n) is due originally to the 19th-century logician Charles Sanders Peirce. It was introduced into the CSP literature by Dec"
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 105,
              "end_char": 108,
              "context": "harles Sanders Peirce. It was introduced into the CSP literature by Dechter (1990b) and was elaborated "
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 123,
              "end_char": 130,
              "context": "rce. It was introduced into the CSP literature by Dechter (1990b) and was elaborated by Bacchus and van Bee"
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "Bacchus",
              "entity_type": "ORG",
              "start_char": 161,
              "end_char": 168,
              "context": "terature by Dechter (1990b) and was elaborated by Bacchus and van Beek (1998). CSPs with preferences among "
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "van Beek",
              "entity_type": "PERSON",
              "start_char": 173,
              "end_char": 181,
              "context": "Dechter (1990b) and was elaborated by Bacchus and van Beek (1998). CSPs with preferences among solutions are"
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "Bistarelli",
              "entity_type": "PERSON",
              "start_char": 283,
              "end_char": 293,
              "context": "tudied widely in the optimization literature; see Bistarelli\net al."
            },
            {
              "para_id": "chap5_para192",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 297,
              "end_char": 299,
              "context": "in the optimization literature; see Bistarelli\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para193",
          "content": "(1997) for a generalization of the CSP framework to allow for preferences.",
          "sentence_count": 1,
          "char_count": 63,
          "prev_para_id": "chap5_para192",
          "next_para_id": "chap5_para194",
          "style_metadata": {
            "para_id": "chap5_para193",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "generalization": 1,
            "csp": 1,
            "framework": 1,
            "allow": 1,
            "preference": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para193",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 35,
              "end_char": 38,
              "context": "(1997) for a generalization of the CSP framework to allow for preferences."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para194",
          "content": "Constraint propagation methods were popularized by Waltz’s (1975) success on polyhedral line-labeling problems for computer vision. Waltz showed that in many problems, propagation completely eliminates the need for backtracking. Montanari (1974) introduced the notion of constraint graphs and propagation by path consistency. Alan Mackworth (1977) proposed the AC-3 algorithm for enforcing arc consistency as well as the general idea of combining backtracking with some degree of consistency enforcement. AC-4, a more efficient\narc-consistency algorithm developed by Mohr and Henderson (1986), runs in\nO\n(\ncd\n2\n) worst-case time but can be slower than AC-3 on average cases. The PC-2 algorithm (Mackworth, 1977) achieves path consistency in much the same way that AC-3 achieves arc consistency.",
          "sentence_count": 6,
          "char_count": 685,
          "prev_para_id": "chap5_para193",
          "next_para_id": "chap5_para195",
          "style_metadata": {
            "para_id": "chap5_para194",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.0,
            "passive_voice_ratio": 0.007,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 138,
            "sentence_count": 6
          },
          "terminology": {
            "constraint": 2,
            "propagation": 3,
            "method": 1,
            "popularized": 1,
            "waltz": 2,
            "success": 1,
            "polyhedral": 1,
            "line-labeling": 1,
            "problem": 2,
            "computer": 1,
            "vision": 1,
            "showed": 1,
            "many": 1,
            "eliminates": 1,
            "need": 1,
            "backtracking": 2,
            "montanari": 1,
            "introduced": 1,
            "notion": 1,
            "graph": 1,
            "path": 2,
            "consistency": 5,
            "alan": 1,
            "mackworth": 2,
            "proposed": 1,
            "ac-3": 3,
            "algorithm": 3,
            "enforcing": 1,
            "arc": 2,
            "general": 1,
            "idea": 1,
            "combining": 1,
            "degree": 1,
            "enforcement": 1,
            "ac-4": 1,
            "efficient": 1,
            "arc-consistency": 1,
            "developed": 1,
            "mohr": 1,
            "henderson": 1,
            "run": 1,
            "worst-case": 1,
            "time": 1,
            "slower": 1,
            "average": 1,
            "case": 1,
            "pc-2": 1,
            "achieves": 2,
            "much": 1,
            "way": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para194",
              "entity_text": "Waltz’s",
              "entity_type": "ORG",
              "start_char": 51,
              "end_char": 58,
              "context": "onstraint propagation methods were popularized by Waltz’s (1975) success on polyhedral line-labeling proble"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "Waltz",
              "entity_type": "PERSON",
              "start_char": 132,
              "end_char": 137,
              "context": "edral line-labeling problems for computer vision. Waltz showed that in many problems, propagation complet"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "Montanari",
              "entity_type": "PERSON",
              "start_char": 229,
              "end_char": 238,
              "context": " completely eliminates the need for backtracking. Montanari (1974) introduced the notion of constraint graphs"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "Alan Mackworth",
              "entity_type": "PERSON",
              "start_char": 326,
              "end_char": 340,
              "context": "raint graphs and propagation by path consistency. Alan Mackworth (1977) proposed the AC-3 algorithm for enforcing "
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "AC-3",
              "entity_type": "PRODUCT",
              "start_char": 361,
              "end_char": 365,
              "context": "h consistency. Alan Mackworth (1977) proposed the AC-3 algorithm for enforcing arc consistency as well a"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "Mohr",
              "entity_type": "ORG",
              "start_char": 567,
              "end_char": 571,
              "context": " efficient\narc-consistency algorithm developed by Mohr and Henderson (1986), runs in\nO\n(\ncd\n2\n) worst-ca"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "Henderson",
              "entity_type": "GPE",
              "start_char": 576,
              "end_char": 585,
              "context": "t\narc-consistency algorithm developed by Mohr and Henderson (1986), runs in\nO\n(\ncd\n2\n) worst-case time but ca"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "PC-2",
              "entity_type": "ORG",
              "start_char": 679,
              "end_char": 683,
              "context": "but can be slower than AC-3 on average cases. The PC-2 algorithm (Mackworth, 1977) achieves path consist"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "Mackworth",
              "entity_type": "ORG",
              "start_char": 695,
              "end_char": 704,
              "context": "r than AC-3 on average cases. The PC-2 algorithm (Mackworth, 1977) achieves path consistency in much the same"
            },
            {
              "para_id": "chap5_para194",
              "entity_text": "AC-3",
              "entity_type": "ORG",
              "start_char": 764,
              "end_char": 768,
              "context": "hieves path consistency in much the same way that AC-3 achieves arc consistency."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para195",
          "content": "Soon after Mackworth’s paper appeared, researchers began experimenting with the tradeoff between the cost of consistency enforcement and the benefits in terms of search reduction. Haralick and Elliott (1980) favored the minimal forward-checking algorithm described by McGregor (1979), whereas Gaschnig (1979) suggested full arc-consistency checking after each variable assignment—an algorithm later called MAC by Sabin and Freuder (1994). The latter paper provides somewhat convincing evidence that on harder CSPs, full arc-consistency checking pays off. Freuder (1978, 1982) investigated the notion of\nk\n-consistency and its relationship to the complexity of solving CSPs. Dechter and Dechter (1987) introduced directional arc consistency. Apt (1999) describes a generic algorithmic framework within which consistency propagation algorithms can be analyzed, and surveys are given by Bessière (2006) and Barták\net al.",
          "sentence_count": 6,
          "char_count": 795,
          "prev_para_id": "chap5_para194",
          "next_para_id": "chap5_para196",
          "style_metadata": {
            "para_id": "chap5_para195",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.83,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 155,
            "sentence_count": 6
          },
          "terminology": {
            "mackworth": 1,
            "paper": 2,
            "appeared": 1,
            "researcher": 1,
            "began": 1,
            "experimenting": 1,
            "tradeoff": 1,
            "cost": 1,
            "consistency": 3,
            "enforcement": 1,
            "benefit": 1,
            "term": 1,
            "search": 1,
            "reduction": 1,
            "haralick": 1,
            "elliott": 1,
            "favored": 1,
            "minimal": 1,
            "forward-checking": 1,
            "algorithm": 2,
            "described": 1,
            "mcgregor": 1,
            "whereas": 1,
            "gaschnig": 1,
            "suggested": 1,
            "full": 2,
            "arc-consistency": 2,
            "checking": 2,
            "variable": 1,
            "assignment—an": 1,
            "called": 1,
            "mac": 1,
            "sabin": 1,
            "freuder": 2,
            "latter": 1,
            "provides": 1,
            "convincing": 1,
            "evidence": 1,
            "harder": 1,
            "csps": 2,
            "pay": 1,
            "investigated": 1,
            "notion": 1,
            "-consistency": 1,
            "relationship": 1,
            "complexity": 1,
            "solving": 1,
            "dechter": 2,
            "introduced": 1,
            "directional": 1,
            "arc": 1,
            "apt": 1,
            "describes": 1,
            "generic": 1,
            "algorithmic": 1,
            "framework": 1,
            "propagation": 1,
            "analyzed": 1,
            "survey": 1,
            "given": 1,
            "bessière": 1,
            "barták": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para195",
              "entity_text": "Mackworth",
              "entity_type": "PERSON",
              "start_char": 11,
              "end_char": 20,
              "context": "Soon after Mackworth’s paper appeared, researchers began experimenting"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Haralick",
              "entity_type": "PERSON",
              "start_char": 180,
              "end_char": 188,
              "context": "nt and the benefits in terms of search reduction. Haralick and Elliott (1980) favored the minimal forward-ch"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Elliott",
              "entity_type": "PERSON",
              "start_char": 193,
              "end_char": 200,
              "context": "nefits in terms of search reduction. Haralick and Elliott (1980) favored the minimal forward-checking algor"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "McGregor",
              "entity_type": "PERSON",
              "start_char": 268,
              "end_char": 276,
              "context": "e minimal forward-checking algorithm described by McGregor (1979), whereas Gaschnig (1979) suggested full ar"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Gaschnig",
              "entity_type": "PERSON",
              "start_char": 293,
              "end_char": 301,
              "context": "g algorithm described by McGregor (1979), whereas Gaschnig (1979) suggested full arc-consistency checking af"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "MAC",
              "entity_type": "ORG",
              "start_char": 406,
              "end_char": 409,
              "context": "ach variable assignment—an algorithm later called MAC by Sabin and Freuder (1994). The latter paper pro"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Sabin",
              "entity_type": "PERSON",
              "start_char": 413,
              "end_char": 418,
              "context": "iable assignment—an algorithm later called MAC by Sabin and Freuder (1994). The latter paper provides som"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Freuder",
              "entity_type": "PERSON",
              "start_char": 423,
              "end_char": 430,
              "context": "gnment—an algorithm later called MAC by Sabin and Freuder (1994). The latter paper provides somewhat convin"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Freuder",
              "entity_type": "PERSON",
              "start_char": 555,
              "end_char": 562,
              "context": "der CSPs, full arc-consistency checking pays off. Freuder (1978, 1982) investigated the notion of\nk\n-consis"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 686,
              "end_char": 693,
              "context": "ip to the complexity of solving CSPs. Dechter and Dechter (1987) introduced directional arc consistency. Ap"
            },
            {
              "para_id": "chap5_para195",
              "entity_text": "Bessière",
              "entity_type": "ORG",
              "start_char": 884,
              "end_char": 892,
              "context": "orithms can be analyzed, and surveys are given by Bessière (2006) and Barták\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para196",
          "content": "(2010).",
          "sentence_count": 1,
          "char_count": 7,
          "prev_para_id": "chap5_para195",
          "next_para_id": "chap5_para197",
          "style_metadata": {
            "para_id": "chap5_para196",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 4.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 4,
            "sentence_count": 1
          },
          "terminology": {
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para197",
          "content": "Special methods for handling higher-order or global constraints were developed first within the context of\nconstraint logic programming\n. Marriott and Stuckey (1998) provide excellent coverage of research in this area. The\nAlldiff\nconstraint was studied by Regin (1994), Stergiou and Walsh (1999), and van Hoeve (2001). There are more complex inference algorithms for\nAlldiff\n(see van Hoeve and Katriel, 2006) that propagate more constraints but are more computationally expensive to run. Bounds constraints were incorporated into constraint logic programming by Van Hentenryck\net al.",
          "sentence_count": 5,
          "char_count": 507,
          "prev_para_id": "chap5_para196",
          "next_para_id": "chap5_para198",
          "style_metadata": {
            "para_id": "chap5_para197",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.4,
            "passive_voice_ratio": 0.029,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 102,
            "sentence_count": 5
          },
          "terminology": {
            "special": 1,
            "method": 1,
            "handling": 1,
            "higher-order": 1,
            "global": 1,
            "constraint": 6,
            "developed": 1,
            "context": 1,
            "logic": 2,
            "programming": 2,
            "marriott": 1,
            "stuckey": 1,
            "provide": 1,
            "excellent": 1,
            "coverage": 1,
            "research": 1,
            "area": 1,
            "alldiff": 2,
            "studied": 1,
            "regin": 1,
            "stergiou": 1,
            "walsh": 1,
            "van": 3,
            "hoeve": 2,
            "complex": 1,
            "inference": 1,
            "algorithm": 1,
            "see": 1,
            "katriel": 1,
            "propagate": 1,
            "expensive": 1,
            "run": 1,
            "bound": 1,
            "incorporated": 1,
            "hentenryck": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para197",
              "entity_text": "Marriott",
              "entity_type": "GPE",
              "start_char": 138,
              "end_char": 146,
              "context": "hin the context of\nconstraint logic programming\n. Marriott and Stuckey (1998) provide excellent coverage of "
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "Stuckey",
              "entity_type": "GPE",
              "start_char": 151,
              "end_char": 158,
              "context": "xt of\nconstraint logic programming\n. Marriott and Stuckey (1998) provide excellent coverage of research in "
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "Regin",
              "entity_type": "PERSON",
              "start_char": 257,
              "end_char": 262,
              "context": " this area. The\nAlldiff\nconstraint was studied by Regin (1994), Stergiou and Walsh (1999), and van Hoeve "
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "Stergiou",
              "entity_type": "PERSON",
              "start_char": 271,
              "end_char": 279,
              "context": "e\nAlldiff\nconstraint was studied by Regin (1994), Stergiou and Walsh (1999), and van Hoeve (2001). There are"
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "Walsh",
              "entity_type": "PERSON",
              "start_char": 284,
              "end_char": 289,
              "context": "straint was studied by Regin (1994), Stergiou and Walsh (1999), and van Hoeve (2001). There are more comp"
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "van Hoeve",
              "entity_type": "PERSON",
              "start_char": 302,
              "end_char": 311,
              "context": "d by Regin (1994), Stergiou and Walsh (1999), and van Hoeve (2001). There are more complex inference algorith"
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "van Hoeve",
              "entity_type": "PERSON",
              "start_char": 381,
              "end_char": 390,
              "context": "ore complex inference algorithms for\nAlldiff\n(see van Hoeve and Katriel, 2006) that propagate more constraint"
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "Katriel",
              "entity_type": "GPE",
              "start_char": 395,
              "end_char": 402,
              "context": "ference algorithms for\nAlldiff\n(see van Hoeve and Katriel, 2006) that propagate more constraints but are mo"
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "Van Hentenryck",
              "entity_type": "PERSON",
              "start_char": 563,
              "end_char": 577,
              "context": "incorporated into constraint logic programming by Van Hentenryck\net al."
            },
            {
              "para_id": "chap5_para197",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 581,
              "end_char": 583,
              "context": "constraint logic programming by Van Hentenryck\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para198",
          "content": "(1998). A survey of global constraints is provided by van Hoeve and Katriel (2006).",
          "sentence_count": 2,
          "char_count": 70,
          "prev_para_id": "chap5_para197",
          "next_para_id": "chap5_para199",
          "style_metadata": {
            "para_id": "chap5_para198",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 10.0,
            "passive_voice_ratio": 0.05,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 20,
            "sentence_count": 2
          },
          "terminology": {
            "survey": 1,
            "global": 1,
            "constraint": 1,
            "provided": 1,
            "van": 1,
            "hoeve": 1,
            "katriel": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para198",
              "entity_text": "van Hoeve",
              "entity_type": "PERSON",
              "start_char": 54,
              "end_char": 63,
              "context": "8). A survey of global constraints is provided by van Hoeve and Katriel (2006)."
            },
            {
              "para_id": "chap5_para198",
              "entity_text": "Katriel",
              "entity_type": "PERSON",
              "start_char": 68,
              "end_char": 75,
              "context": "f global constraints is provided by van Hoeve and Katriel (2006)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para199",
          "content": "Sudoku has become the most widely known CSP and was described as such by Simonis (2005). Agerbeck and Hansen (2008) describe some of the strategies and show that Sudoku on an\nn\n2\n×\nn\n2\nboard is in the class of\nNP\n-hard problems.",
          "sentence_count": 2,
          "char_count": 192,
          "prev_para_id": "chap5_para198",
          "next_para_id": "chap5_para200",
          "style_metadata": {
            "para_id": "chap5_para199",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 25.5,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 51,
            "sentence_count": 2
          },
          "terminology": {
            "sudoku": 2,
            "become": 1,
            "known": 1,
            "csp": 1,
            "described": 1,
            "simonis": 1,
            "agerbeck": 1,
            "hansen": 1,
            "describe": 1,
            "strategy": 1,
            "show": 1,
            "board": 1,
            "class": 1,
            "-hard": 1,
            "problem": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para199",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 40,
              "end_char": 43,
              "context": "Sudoku has become the most widely known CSP and was described as such by Simonis (2005). Ager"
            },
            {
              "para_id": "chap5_para199",
              "entity_text": "Simonis",
              "entity_type": "PERSON",
              "start_char": 73,
              "end_char": 80,
              "context": "ost widely known CSP and was described as such by Simonis (2005). Agerbeck and Hansen (2008) describe some "
            },
            {
              "para_id": "chap5_para199",
              "entity_text": "Agerbeck",
              "entity_type": "PERSON",
              "start_char": 89,
              "end_char": 97,
              "context": " CSP and was described as such by Simonis (2005). Agerbeck and Hansen (2008) describe some of the strategies"
            },
            {
              "para_id": "chap5_para199",
              "entity_text": "Hansen",
              "entity_type": "PERSON",
              "start_char": 102,
              "end_char": 108,
              "context": "described as such by Simonis (2005). Agerbeck and Hansen (2008) describe some of the strategies and show t"
            },
            {
              "para_id": "chap5_para199",
              "entity_text": "Sudoku",
              "entity_type": "PERSON",
              "start_char": 162,
              "end_char": 168,
              "context": "08) describe some of the strategies and show that Sudoku on an\nn\n2\n×\nn\n2\nboard is in the class of\nNP\n-hard"
            },
            {
              "para_id": "chap5_para199",
              "entity_text": "NP",
              "entity_type": "ORG",
              "start_char": 210,
              "end_char": 212,
              "context": "t Sudoku on an\nn\n2\n×\nn\n2\nboard is in the class of\nNP\n-hard problems."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para200",
          "content": "In 1850, C. F. Gauss described a recursive backtracking algorithm for solving the 8- queens problem, which had been published in the German chess magazine\nSchachzeitung\nin 1848. Gauss called his method\nTatonniren,\nderived from the French word\ntâtonner\n—to grope around, as if in the dark.",
          "sentence_count": 2,
          "char_count": 248,
          "prev_para_id": "chap5_para199",
          "next_para_id": "chap5_para201",
          "style_metadata": {
            "para_id": "chap5_para200",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 26.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 52,
            "sentence_count": 2
          },
          "terminology": {
            "gauss": 2,
            "described": 1,
            "recursive": 1,
            "backtracking": 1,
            "algorithm": 1,
            "solving": 1,
            "queen": 1,
            "problem": 1,
            "published": 1,
            "german": 1,
            "chess": 1,
            "magazine": 1,
            "schachzeitung": 1,
            "called": 1,
            "method": 1,
            "tatonniren": 1,
            "derived": 1,
            "french": 1,
            "word": 1,
            "tâtonner": 1,
            "—to": 1,
            "grope": 1,
            "dark": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para200",
              "entity_text": "C. F. Gauss",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 20,
              "context": "In 1850, C. F. Gauss described a recursive backtracking algorithm for "
            },
            {
              "para_id": "chap5_para200",
              "entity_text": "Schachzeitung",
              "entity_type": "PERSON",
              "start_char": 155,
              "end_char": 168,
              "context": "h had been published in the German chess magazine\nSchachzeitung\nin 1848. Gauss called his method\nTatonniren,\nderi"
            },
            {
              "para_id": "chap5_para200",
              "entity_text": "Tatonniren",
              "entity_type": "PERSON",
              "start_char": 202,
              "end_char": 212,
              "context": "ne\nSchachzeitung\nin 1848. Gauss called his method\nTatonniren,\nderived from the French word\ntâtonner\n—to grope "
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para201",
          "content": "According to Donald Knuth (personal communication), R. J. Walker introduced the term\nbacktrack\nin the 1950s. Walker (1960) described the basic backtracking algorithm and used it to find all solutions to the 13-queens problem. Golomb and Baumert (1965) formulated, with examples, the general class of combinatorial problems to which backtracking can be applied, and introduced what we call the MRV heuristic. Bitner and Reingold (1975) provided an influential survey of backtracking techniques. Brelaz (1979) used the degree heuristic as a tiebreaker after applying the MRV heuristic. The resulting algorithm, despite its simplicity, is still the best method for\nk\n-coloring arbitrary graphs. Haralick and Elliott (1980) proposed the least-constraining-value heuristic.",
          "sentence_count": 7,
          "char_count": 663,
          "prev_para_id": "chap5_para200",
          "next_para_id": "chap5_para202",
          "style_metadata": {
            "para_id": "chap5_para201",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.29,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 135,
            "sentence_count": 7
          },
          "terminology": {
            "according": 1,
            "donald": 1,
            "knuth": 1,
            "personal": 1,
            "communication": 1,
            "walker": 2,
            "introduced": 2,
            "term": 1,
            "backtrack": 1,
            "described": 1,
            "basic": 1,
            "backtracking": 3,
            "algorithm": 2,
            "used": 2,
            "find": 1,
            "solution": 1,
            "13-queens": 1,
            "problem": 2,
            "golomb": 1,
            "baumert": 1,
            "formulated": 1,
            "example": 1,
            "general": 1,
            "class": 1,
            "combinatorial": 1,
            "applied": 1,
            "call": 1,
            "mrv": 2,
            "heuristic": 4,
            "bitner": 1,
            "reingold": 1,
            "provided": 1,
            "influential": 1,
            "survey": 1,
            "technique": 1,
            "brelaz": 1,
            "degree": 1,
            "tiebreaker": 1,
            "applying": 1,
            "resulting": 1,
            "simplicity": 1,
            "best": 1,
            "method": 1,
            "-coloring": 1,
            "arbitrary": 1,
            "graph": 1,
            "haralick": 1,
            "elliott": 1,
            "proposed": 1,
            "least-constraining-value": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para201",
              "entity_text": "Donald Knuth",
              "entity_type": "PERSON",
              "start_char": 13,
              "end_char": 25,
              "context": "According to Donald Knuth (personal communication), R. J. Walker introduced"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "R. J. Walker",
              "entity_type": "PERSON",
              "start_char": 52,
              "end_char": 64,
              "context": "cording to Donald Knuth (personal communication), R. J. Walker introduced the term\nbacktrack\nin the 1950s. Walke"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "Golomb and Baumert",
              "entity_type": "PERSON",
              "start_char": 226,
              "end_char": 244,
              "context": "t to find all solutions to the 13-queens problem. Golomb and Baumert (1965) formulated, with examples, the general cla"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 393,
              "end_char": 396,
              "context": "g can be applied, and introduced what we call the MRV heuristic. Bitner and Reingold (1975) provided an"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "Reingold",
              "entity_type": "PERSON",
              "start_char": 419,
              "end_char": 427,
              "context": "oduced what we call the MRV heuristic. Bitner and Reingold (1975) provided an influential survey of backtrac"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "Brelaz",
              "entity_type": "ORG",
              "start_char": 494,
              "end_char": 500,
              "context": "an influential survey of backtracking techniques. Brelaz (1979) used the degree heuristic as a tiebreaker "
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "MRV",
              "entity_type": "ORG",
              "start_char": 569,
              "end_char": 572,
              "context": "gree heuristic as a tiebreaker after applying the MRV heuristic. The resulting algorithm, despite its s"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "Haralick",
              "entity_type": "PERSON",
              "start_char": 692,
              "end_char": 700,
              "context": "the best method for\nk\n-coloring arbitrary graphs. Haralick and Elliott (1980) proposed the least-constrainin"
            },
            {
              "para_id": "chap5_para201",
              "entity_text": "Elliott",
              "entity_type": "PERSON",
              "start_char": 705,
              "end_char": 712,
              "context": "od for\nk\n-coloring arbitrary graphs. Haralick and Elliott (1980) proposed the least-constraining-value heur"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para202",
          "content": "The basic backjumping method is due to John Gaschnig (1977, 1979). Kondrak and van Beek (1997) showed that this algorithm is essentially subsumed by forward checking. Conflict-directed backjumping was devised by Prosser (1993). Dechter (1990a) introduced graph-based backjumping, which bounds the complexity of backjumping-based algorithms as a function of the constraint graph (Dechter and Frost, 2002).",
          "sentence_count": 4,
          "char_count": 349,
          "prev_para_id": "chap5_para201",
          "next_para_id": "chap5_para203",
          "style_metadata": {
            "para_id": "chap5_para202",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.25,
            "passive_voice_ratio": 0.014,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 73,
            "sentence_count": 4
          },
          "terminology": {
            "basic": 1,
            "backjumping": 3,
            "method": 1,
            "due": 1,
            "john": 1,
            "gaschnig": 1,
            "kondrak": 1,
            "van": 1,
            "beek": 1,
            "showed": 1,
            "algorithm": 2,
            "subsumed": 1,
            "checking": 1,
            "conflict-directed": 1,
            "devised": 1,
            "dechter": 2,
            "introduced": 1,
            "graph-based": 1,
            "bound": 1,
            "complexity": 1,
            "backjumping-based": 1,
            "function": 1,
            "constraint": 1,
            "graph": 1,
            "frost": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para202",
              "entity_text": "John Gaschnig",
              "entity_type": "PERSON",
              "start_char": 39,
              "end_char": 52,
              "context": "The basic backjumping method is due to John Gaschnig (1977, 1979). Kondrak and van Beek (1997) showed "
            },
            {
              "para_id": "chap5_para202",
              "entity_text": "Kondrak",
              "entity_type": "PERSON",
              "start_char": 67,
              "end_char": 74,
              "context": "ping method is due to John Gaschnig (1977, 1979). Kondrak and van Beek (1997) showed that this algorithm is"
            },
            {
              "para_id": "chap5_para202",
              "entity_text": "van Beek",
              "entity_type": "PERSON",
              "start_char": 79,
              "end_char": 87,
              "context": "is due to John Gaschnig (1977, 1979). Kondrak and van Beek (1997) showed that this algorithm is essentially "
            },
            {
              "para_id": "chap5_para202",
              "entity_text": "Prosser",
              "entity_type": "PRODUCT",
              "start_char": 212,
              "end_char": 219,
              "context": "ing. Conflict-directed backjumping was devised by Prosser (1993). Dechter (1990a) introduced graph-based ba"
            },
            {
              "para_id": "chap5_para202",
              "entity_text": "Frost",
              "entity_type": "PERSON",
              "start_char": 391,
              "end_char": 396,
              "context": "s a function of the constraint graph (Dechter and Frost, 2002)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para203",
          "content": "A very general form of intelligent backtracking was developed early on by Stallman and Sussman (1977). Their technique of\ndependency-directed backtracking\ncombines\nback-jumping with no-good learning (McAllester, 1990) and led to the development of\ntruth maintenance systems\n(Doyle, 1979), which we discuss in\nSection 10.6.2\n. The connection between the two areas is analyzed by de Kleer (1989).",
          "sentence_count": 3,
          "char_count": 344,
          "prev_para_id": "chap5_para202",
          "next_para_id": "chap5_para204",
          "style_metadata": {
            "para_id": "chap5_para203",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.67,
            "passive_voice_ratio": 0.028,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 71,
            "sentence_count": 3
          },
          "terminology": {
            "general": 1,
            "form": 1,
            "intelligent": 1,
            "backtracking": 2,
            "developed": 1,
            "early": 1,
            "stallman": 1,
            "sussman": 1,
            "technique": 1,
            "dependency-directed": 1,
            "combine": 1,
            "back-jumping": 1,
            "no-good": 1,
            "learning": 1,
            "mcallester": 1,
            "led": 1,
            "development": 1,
            "truth": 1,
            "maintenance": 1,
            "system": 1,
            "doyle": 1,
            "discus": 1,
            "section": 1,
            "connection": 1,
            "area": 1,
            "analyzed": 1,
            "kleer": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para203",
              "entity_text": "Stallman and Sussman",
              "entity_type": "ORG",
              "start_char": 74,
              "end_char": 94,
              "context": "ntelligent backtracking was developed early on by Stallman and Sussman (1977). Their technique of\ndependency-directed ba"
            },
            {
              "para_id": "chap5_para203",
              "entity_text": "McAllester",
              "entity_type": "PERSON",
              "start_char": 200,
              "end_char": 210,
              "context": "king\ncombines\nback-jumping with no-good learning (McAllester, 1990) and led to the development of\ntruth mainte"
            },
            {
              "para_id": "chap5_para203",
              "entity_text": "de Kleer",
              "entity_type": "PERSON",
              "start_char": 378,
              "end_char": 386,
              "context": "e connection between the two areas is analyzed by de Kleer (1989)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para204",
          "content": "The work of Stallman and Sussman also introduced the idea of\nconstraint learning\n, in which partial results obtained by search can be saved and reused later in the search. The idea was formalized by Dechter (1990a).",
          "sentence_count": 2,
          "char_count": 181,
          "prev_para_id": "chap5_para203",
          "next_para_id": "chap5_para205",
          "style_metadata": {
            "para_id": "chap5_para204",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 20.5,
            "passive_voice_ratio": 0.024,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 41,
            "sentence_count": 2
          },
          "terminology": {
            "work": 1,
            "stallman": 1,
            "sussman": 1,
            "introduced": 1,
            "idea": 2,
            "constraint": 1,
            "learning": 1,
            "partial": 1,
            "result": 1,
            "obtained": 1,
            "search": 2,
            "saved": 1,
            "reused": 1,
            "formalized": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para204",
              "entity_text": "Stallman and Sussman",
              "entity_type": "ORG",
              "start_char": 12,
              "end_char": 32,
              "context": "The work of Stallman and Sussman also introduced the idea of\nconstraint learning\n,"
            },
            {
              "para_id": "chap5_para204",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 199,
              "end_char": 206,
              "context": "d later in the search. The idea was formalized by Dechter (1990a)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para205",
          "content": "Backmarking\n(Gaschnig, 1979) is a particularly simple method in which consistent and inconsistent pairwise assignments are saved and used to avoid rechecking constraints. Backmarking can be combined with conflict-directed back-jumping; Kondrak and van Beek (1997) present a hybrid algorithm that provably subsumes either method taken separately.",
          "sentence_count": 2,
          "char_count": 301,
          "prev_para_id": "chap5_para204",
          "next_para_id": "chap5_para206",
          "style_metadata": {
            "para_id": "chap5_para205",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 54,
            "sentence_count": 2
          },
          "terminology": {
            "backmarking": 2,
            "gaschnig": 1,
            "simple": 1,
            "method": 2,
            "consistent": 1,
            "inconsistent": 1,
            "pairwise": 1,
            "assignment": 1,
            "saved": 1,
            "used": 1,
            "avoid": 1,
            "rechecking": 1,
            "constraint": 1,
            "combined": 1,
            "conflict-directed": 1,
            "back-jumping": 1,
            "kondrak": 1,
            "van": 1,
            "beek": 1,
            "present": 1,
            "hybrid": 1,
            "algorithm": 1,
            "subsumes": 1,
            "taken": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para205",
              "entity_text": "Kondrak",
              "entity_type": "GPE",
              "start_char": 236,
              "end_char": 243,
              "context": " be combined with conflict-directed back-jumping; Kondrak and van Beek (1997) present a hybrid algorithm th"
            },
            {
              "para_id": "chap5_para205",
              "entity_text": "van Beek",
              "entity_type": "PERSON",
              "start_char": 248,
              "end_char": 256,
              "context": " with conflict-directed back-jumping; Kondrak and van Beek (1997) present a hybrid algorithm that provably s"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para206",
          "content": "The method of\ndynamic backtracking\n(Ginsberg, 1993) retains successful partial assignments from later subsets of variables when backtracking over an earlier choice that does not invalidate the later success. Moskewicz\net al.",
          "sentence_count": 2,
          "char_count": 196,
          "prev_para_id": "chap5_para205",
          "next_para_id": "chap5_para207",
          "style_metadata": {
            "para_id": "chap5_para206",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "method": 1,
            "dynamic": 1,
            "backtracking": 2,
            "ginsberg": 1,
            "retains": 1,
            "successful": 1,
            "partial": 1,
            "assignment": 1,
            "subset": 1,
            "variable": 1,
            "earlier": 1,
            "choice": 1,
            "invalidate": 1,
            "success": 1,
            "moskewicz": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para206",
              "entity_text": "Ginsberg",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 44,
              "context": "The method of\ndynamic backtracking\n(Ginsberg, 1993) retains successful partial assignments fro"
            },
            {
              "para_id": "chap5_para206",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 221,
              "end_char": 223,
              "context": "es not invalidate the later success. Moskewicz\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para207",
          "content": "(2001) show how these techniques and others are used to create an efficient SAT solver. Empirical studies of several randomized backtracking methods were done by Gomes\net al.",
          "sentence_count": 2,
          "char_count": 148,
          "prev_para_id": "chap5_para206",
          "next_para_id": "chap5_para208",
          "style_metadata": {
            "para_id": "chap5_para207",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 2
          },
          "terminology": {
            "show": 1,
            "technique": 1,
            "others": 1,
            "used": 1,
            "create": 1,
            "efficient": 1,
            "sat": 1,
            "solver": 1,
            "empirical": 1,
            "study": 1,
            "several": 1,
            "randomized": 1,
            "backtracking": 1,
            "method": 1,
            "done": 1,
            "gomes": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para207",
              "entity_text": "SAT",
              "entity_type": "ORG",
              "start_char": 76,
              "end_char": 79,
              "context": "niques and others are used to create an efficient SAT solver. Empirical studies of several randomized b"
            },
            {
              "para_id": "chap5_para207",
              "entity_text": "Gomes",
              "entity_type": "PERSON",
              "start_char": 162,
              "end_char": 167,
              "context": "eral randomized backtracking methods were done by Gomes\net al."
            },
            {
              "para_id": "chap5_para207",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 171,
              "end_char": 173,
              "context": "omized backtracking methods were done by Gomes\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para208",
          "content": "(2000) and Gomes and Selman (2001). Van Beek (2006) surveys backtracking.",
          "sentence_count": 2,
          "char_count": 63,
          "prev_para_id": "chap5_para207",
          "next_para_id": "chap5_para209",
          "style_metadata": {
            "para_id": "chap5_para208",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 9.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 19,
            "sentence_count": 2
          },
          "terminology": {
            "gomes": 1,
            "selman": 1,
            "van": 1,
            "beek": 1,
            "survey": 1,
            "backtracking": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para208",
              "entity_text": "Gomes",
              "entity_type": "PERSON",
              "start_char": 11,
              "end_char": 16,
              "context": "(2000) and Gomes and Selman (2001). Van Beek (2006) surveys backtr"
            },
            {
              "para_id": "chap5_para208",
              "entity_text": "Selman",
              "entity_type": "PERSON",
              "start_char": 21,
              "end_char": 27,
              "context": "(2000) and Gomes and Selman (2001). Van Beek (2006) surveys backtracking."
            },
            {
              "para_id": "chap5_para208",
              "entity_text": "Van Beek",
              "entity_type": "PERSON",
              "start_char": 36,
              "end_char": 44,
              "context": "(2000) and Gomes and Selman (2001). Van Beek (2006) surveys backtracking."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para209",
          "content": "Local search in constraint satisfaction problems was popularized by the work of Kirkpatrick\net al.",
          "sentence_count": 1,
          "char_count": 85,
          "prev_para_id": "chap5_para208",
          "next_para_id": "chap5_para210",
          "style_metadata": {
            "para_id": "chap5_para209",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.062,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 16,
            "sentence_count": 1
          },
          "terminology": {
            "local": 1,
            "search": 1,
            "constraint": 1,
            "satisfaction": 1,
            "problem": 1,
            "popularized": 1,
            "work": 1,
            "kirkpatrick": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para209",
              "entity_text": "Kirkpatrick",
              "entity_type": "GPE",
              "start_char": 80,
              "end_char": 91,
              "context": "isfaction problems was popularized by the work of Kirkpatrick\net al."
            },
            {
              "para_id": "chap5_para209",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 95,
              "end_char": 97,
              "context": "ems was popularized by the work of Kirkpatrick\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para210",
          "content": "(1983) on simulated annealing (see\nChapter 4\n), which is widely used for VLSI layout and scheduling problems. Beck\net al.",
          "sentence_count": 2,
          "char_count": 104,
          "prev_para_id": "chap5_para209",
          "next_para_id": "chap5_para211",
          "style_metadata": {
            "para_id": "chap5_para210",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 13.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 27,
            "sentence_count": 2
          },
          "terminology": {
            "simulated": 1,
            "annealing": 1,
            "see": 1,
            "chapter": 1,
            "used": 1,
            "vlsi": 1,
            "scheduling": 1,
            "problem": 1,
            "beck": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para210",
              "entity_text": "VLSI",
              "entity_type": "ORG",
              "start_char": 73,
              "end_char": 77,
              "context": "ealing (see\nChapter 4\n), which is widely used for VLSI layout and scheduling problems. Beck\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para211",
          "content": "(2011) give an overview of recent work on jobshop scheduling. The min-conflicts heuristic was first proposed by Gu (1989) and was developed independently by Minton\net al.",
          "sentence_count": 2,
          "char_count": 145,
          "prev_para_id": "chap5_para210",
          "next_para_id": "chap5_para212",
          "style_metadata": {
            "para_id": "chap5_para211",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.03,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "give": 1,
            "overview": 1,
            "recent": 1,
            "work": 1,
            "jobshop": 1,
            "scheduling": 1,
            "min-conflicts": 1,
            "heuristic": 1,
            "proposed": 1,
            "developed": 1,
            "minton": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para211",
              "entity_text": "Gu",
              "entity_type": "PERSON",
              "start_char": 112,
              "end_char": 114,
              "context": "The min-conflicts heuristic was first proposed by Gu (1989) and was developed independently by Minton\n"
            },
            {
              "para_id": "chap5_para211",
              "entity_text": "Minton",
              "entity_type": "PERSON",
              "start_char": 157,
              "end_char": 163,
              "context": "d by Gu (1989) and was developed independently by Minton\net al."
            },
            {
              "para_id": "chap5_para211",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 167,
              "end_char": 169,
              "context": "989) and was developed independently by Minton\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para212",
          "content": "(1992). Sosic and Gu (1994) showed how it could be applied to solve the 3,000,000 queens problem in less than a minute. The astounding success of local search using min-conflicts on the n-queens problem led to a reappraisal of the nature and prevalence of “easy” and “hard” problems. Peter Cheeseman\net al.",
          "sentence_count": 4,
          "char_count": 256,
          "prev_para_id": "chap5_para211",
          "next_para_id": "chap5_para213",
          "style_metadata": {
            "para_id": "chap5_para212",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 64,
            "sentence_count": 4
          },
          "terminology": {
            "sosic": 1,
            "showed": 1,
            "applied": 1,
            "solve": 1,
            "queen": 1,
            "problem": 3,
            "less": 1,
            "minute": 1,
            "astounding": 1,
            "success": 1,
            "local": 1,
            "search": 1,
            "using": 1,
            "min-conflicts": 1,
            "n-queens": 1,
            "led": 1,
            "reappraisal": 1,
            "nature": 1,
            "prevalence": 1,
            "easy": 1,
            "hard": 1,
            "peter": 1,
            "cheeseman": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para212",
              "entity_text": "Gu",
              "entity_type": "PERSON",
              "start_char": 18,
              "end_char": 20,
              "context": "(1992). Sosic and Gu (1994) showed how it could be applied to solve th"
            },
            {
              "para_id": "chap5_para212",
              "entity_text": "Peter Cheeseman",
              "entity_type": "PERSON",
              "start_char": 284,
              "end_char": 299,
              "context": "ure and prevalence of “easy” and “hard” problems. Peter Cheeseman\net al."
            },
            {
              "para_id": "chap5_para212",
              "entity_text": "al",
              "entity_type": "ORG",
              "start_char": 303,
              "end_char": 305,
              "context": "of “easy” and “hard” problems. Peter Cheeseman\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para213",
          "content": "(1991) explored the difficulty of randomly generated CSPs and discovered that almost all such problems either are trivially easy or have no solutions. Only if the parameters of the problem generator are set in a certain narrow range, within which roughly half of the problems are solvable, do we find “hard” problem instances. We discuss this phenomenon further in\nChapter 7\n.",
          "sentence_count": 3,
          "char_count": 317,
          "prev_para_id": "chap5_para212",
          "next_para_id": "chap5_para214",
          "style_metadata": {
            "para_id": "chap5_para213",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 23.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 70,
            "sentence_count": 3
          },
          "terminology": {
            "explored": 1,
            "difficulty": 1,
            "generated": 1,
            "csps": 1,
            "discovered": 1,
            "problem": 4,
            "easy": 1,
            "solution": 1,
            "parameter": 1,
            "generator": 1,
            "set": 1,
            "certain": 1,
            "narrow": 1,
            "range": 1,
            "half": 1,
            "solvable": 1,
            "find": 1,
            "hard": 1,
            "instance": 1,
            "discus": 1,
            "phenomenon": 1,
            "chapter": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para214",
          "content": "Konolige (1994) showed that local search is inferior to backtracking search on problems with a certain degree of local structure; this led to work that combined local search and inference, such as that by Pinkas and Dechter (1995). Hoos and Tsang (2006) provide a survey of local search techniques, and textbooks are offered by Hoos and Stützle (2004) and Aarts and Lenstra (2003).",
          "sentence_count": 2,
          "char_count": 319,
          "prev_para_id": "chap5_para213",
          "next_para_id": "chap5_para215",
          "style_metadata": {
            "para_id": "chap5_para214",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 39.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 78,
            "sentence_count": 2
          },
          "terminology": {
            "konolige": 1,
            "showed": 1,
            "local": 4,
            "search": 4,
            "inferior": 1,
            "backtracking": 1,
            "problem": 1,
            "certain": 1,
            "degree": 1,
            "structure": 1,
            "led": 1,
            "work": 1,
            "combined": 1,
            "inference": 1,
            "pinkas": 1,
            "dechter": 1,
            "hoos": 2,
            "tsang": 1,
            "provide": 1,
            "survey": 1,
            "technique": 1,
            "textbook": 1,
            "offered": 1,
            "stützle": 1,
            "aarts": 1,
            "lenstra": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para214",
              "entity_text": "Konolige",
              "entity_type": "PERSON",
              "start_char": 0,
              "end_char": 8,
              "context": "Konolige (1994) showed that local search is inferior to ba"
            },
            {
              "para_id": "chap5_para214",
              "entity_text": "Pinkas",
              "entity_type": "ORG",
              "start_char": 205,
              "end_char": 211,
              "context": "bined local search and inference, such as that by Pinkas and Dechter (1995). Hoos and Tsang (2006) provide"
            },
            {
              "para_id": "chap5_para214",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 216,
              "end_char": 223,
              "context": " search and inference, such as that by Pinkas and Dechter (1995). Hoos and Tsang (2006) provide a survey of"
            },
            {
              "para_id": "chap5_para214",
              "entity_text": "Hoos",
              "entity_type": "PERSON",
              "start_char": 232,
              "end_char": 236,
              "context": "rence, such as that by Pinkas and Dechter (1995). Hoos and Tsang (2006) provide a survey of local search"
            },
            {
              "para_id": "chap5_para214",
              "entity_text": "Tsang",
              "entity_type": "PERSON",
              "start_char": 241,
              "end_char": 246,
              "context": "ch as that by Pinkas and Dechter (1995). Hoos and Tsang (2006) provide a survey of local search technique"
            },
            {
              "para_id": "chap5_para214",
              "entity_text": "Hoos",
              "entity_type": "PERSON",
              "start_char": 328,
              "end_char": 332,
              "context": "l search techniques, and textbooks are offered by Hoos and Stützle (2004) and Aarts and Lenstra (2003)."
            },
            {
              "para_id": "chap5_para214",
              "entity_text": "Stützle",
              "entity_type": "PERSON",
              "start_char": 337,
              "end_char": 344,
              "context": "techniques, and textbooks are offered by Hoos and Stützle (2004) and Aarts and Lenstra (2003)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para215",
          "content": "Work relating the structure and complexity of CSPs originates with Freuder (1985) and Mackworth and Freuder (1985), who showed that search on arc-consistent trees works without any backtracking. A similar result, with extensions to acyclic hypergraphs, was developed in the database community (Beeri\net al.",
          "sentence_count": 2,
          "char_count": 263,
          "prev_para_id": "chap5_para214",
          "next_para_id": "chap5_para216",
          "style_metadata": {
            "para_id": "chap5_para215",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 27.5,
            "passive_voice_ratio": 0.018,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 55,
            "sentence_count": 2
          },
          "terminology": {
            "work": 2,
            "relating": 1,
            "structure": 1,
            "complexity": 1,
            "csps": 1,
            "originates": 1,
            "freuder": 2,
            "mackworth": 1,
            "showed": 1,
            "search": 1,
            "arc-consistent": 1,
            "tree": 1,
            "backtracking": 1,
            "similar": 1,
            "result": 1,
            "extension": 1,
            "acyclic": 1,
            "hypergraphs": 1,
            "developed": 1,
            "database": 1,
            "community": 1,
            "beeri": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para215",
              "entity_text": "Freuder",
              "entity_type": "PERSON",
              "start_char": 67,
              "end_char": 74,
              "context": " structure and complexity of CSPs originates with Freuder (1985) and Mackworth and Freuder (1985), who show"
            },
            {
              "para_id": "chap5_para215",
              "entity_text": "Mackworth",
              "entity_type": "PERSON",
              "start_char": 86,
              "end_char": 95,
              "context": "lexity of CSPs originates with Freuder (1985) and Mackworth and Freuder (1985), who showed that search on arc"
            },
            {
              "para_id": "chap5_para215",
              "entity_text": "Freuder",
              "entity_type": "PERSON",
              "start_char": 100,
              "end_char": 107,
              "context": " originates with Freuder (1985) and Mackworth and Freuder (1985), who showed that search on arc-consistent "
            },
            {
              "para_id": "chap5_para215",
              "entity_text": "acyclic hypergraphs",
              "entity_type": "PERSON",
              "start_char": 232,
              "end_char": 251,
              "context": "acktracking. A similar result, with extensions to acyclic hypergraphs, was developed in the database community (Beeri\ne"
            },
            {
              "para_id": "chap5_para215",
              "entity_text": "Beeri",
              "entity_type": "PERSON",
              "start_char": 294,
              "end_char": 299,
              "context": "rgraphs, was developed in the database community (Beeri\net al."
            },
            {
              "para_id": "chap5_para215",
              "entity_text": "al",
              "entity_type": "ORG",
              "start_char": 303,
              "end_char": 305,
              "context": "was developed in the database community (Beeri\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para216",
          "content": ", 1983). Bayardo and Miranker (1994) present an algorithm for tree-structured CSPs that runs in linear time without any preprocessing. Dechter (1990a) describes the cycle-cutset approach.",
          "sentence_count": 3,
          "char_count": 162,
          "prev_para_id": "chap5_para215",
          "next_para_id": "chap5_para217",
          "style_metadata": {
            "para_id": "chap5_para216",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 11.33,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 34,
            "sentence_count": 3
          },
          "terminology": {
            "bayardo": 1,
            "miranker": 1,
            "present": 1,
            "algorithm": 1,
            "tree-structured": 1,
            "csps": 1,
            "run": 1,
            "linear": 1,
            "time": 1,
            "preprocessing": 1,
            "dechter": 1,
            "describes": 1,
            "cycle-cutset": 1,
            "approach": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para216",
              "entity_text": "Bayardo",
              "entity_type": "PERSON",
              "start_char": 9,
              "end_char": 16,
              "context": ", 1983). Bayardo and Miranker (1994) present an algorithm for tree"
            },
            {
              "para_id": "chap5_para216",
              "entity_text": "Miranker",
              "entity_type": "ORG",
              "start_char": 21,
              "end_char": 29,
              "context": ", 1983). Bayardo and Miranker (1994) present an algorithm for tree-structured C"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para217",
          "content": "Since those papers were published, there has been a great deal of progress in developing more general results relating the complexity of solving a CSP to the structure of its constraint graph. The notion of tree width was introduced by the graph theorists Robertson and Seymour (1986). Dechter and Pearl (1987, 1989), building on the work of Freuder, applied a related notion (which they called\ninduced width\nbut is identical to tree width) to constraint satisfaction problems and developed the tree decomposition approach sketched in\nSection 5.5\n.",
          "sentence_count": 3,
          "char_count": 465,
          "prev_para_id": "chap5_para216",
          "next_para_id": "chap5_para218",
          "style_metadata": {
            "para_id": "chap5_para217",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 33.33,
            "passive_voice_ratio": 0.02,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 100,
            "sentence_count": 3
          },
          "terminology": {
            "paper": 1,
            "published": 1,
            "great": 1,
            "deal": 1,
            "progress": 1,
            "developing": 1,
            "general": 1,
            "result": 1,
            "relating": 1,
            "complexity": 1,
            "solving": 1,
            "csp": 1,
            "structure": 1,
            "constraint": 2,
            "graph": 2,
            "notion": 2,
            "tree": 3,
            "width": 3,
            "introduced": 1,
            "theorist": 1,
            "robertson": 1,
            "seymour": 1,
            "dechter": 1,
            "pearl": 1,
            "building": 1,
            "work": 1,
            "freuder": 1,
            "applied": 1,
            "related": 1,
            "called": 1,
            "induced": 1,
            "identical": 1,
            "satisfaction": 1,
            "problem": 1,
            "developed": 1,
            "decomposition": 1,
            "approach": 1,
            "sketched": 1,
            "section": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para217",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 147,
              "end_char": 150,
              "context": "eral results relating the complexity of solving a CSP to the structure of its constraint graph. The not"
            },
            {
              "para_id": "chap5_para217",
              "entity_text": "Robertson",
              "entity_type": "PERSON",
              "start_char": 256,
              "end_char": 265,
              "context": " tree width was introduced by the graph theorists Robertson and Seymour (1986). Dechter and Pearl (1987, 1989"
            },
            {
              "para_id": "chap5_para217",
              "entity_text": "Seymour",
              "entity_type": "PERSON",
              "start_char": 270,
              "end_char": 277,
              "context": "s introduced by the graph theorists Robertson and Seymour (1986). Dechter and Pearl (1987, 1989), building "
            },
            {
              "para_id": "chap5_para217",
              "entity_text": "Pearl",
              "entity_type": "PERSON",
              "start_char": 298,
              "end_char": 303,
              "context": "eorists Robertson and Seymour (1986). Dechter and Pearl (1987, 1989), building on the work of Freuder, ap"
            },
            {
              "para_id": "chap5_para217",
              "entity_text": "Freuder",
              "entity_type": "PERSON",
              "start_char": 342,
              "end_char": 349,
              "context": "r and Pearl (1987, 1989), building on the work of Freuder, applied a related notion (which they called\nindu"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para218",
          "content": "Drawing on this work and on results from database theory, Gottlob\net al.",
          "sentence_count": 1,
          "char_count": 61,
          "prev_para_id": "chap5_para217",
          "next_para_id": "chap5_para219",
          "style_metadata": {
            "para_id": "chap5_para218",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 15.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 15,
            "sentence_count": 1
          },
          "terminology": {
            "drawing": 1,
            "work": 1,
            "result": 1,
            "database": 1,
            "theory": 1,
            "gottlob": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para219",
          "content": "(1999a, 1999b) developed a notion,\nhypertree width\n, that is based on the characterization of the CSP as a hypergraph. In addition to showing that any CSP with hypertree width\nw\ncan be solved in time\nO\n(\nn\nw\n+1\nlog\nn\n), they also showed that hypertree width subsumes all previously defined measures of “width” in the sense that there are cases where the hypertree width is bounded and the other measures are unbounded.",
          "sentence_count": 2,
          "char_count": 355,
          "prev_para_id": "chap5_para218",
          "next_para_id": "chap5_para220",
          "style_metadata": {
            "para_id": "chap5_para219",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 42.5,
            "passive_voice_ratio": 0.024,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 85,
            "sentence_count": 2
          },
          "terminology": {
            "developed": 1,
            "notion": 1,
            "hypertree": 4,
            "width": 5,
            "based": 1,
            "characterization": 1,
            "csp": 2,
            "hypergraph": 1,
            "addition": 1,
            "showing": 1,
            "solved": 1,
            "time": 1,
            "log": 1,
            "showed": 1,
            "subsumes": 1,
            "defined": 1,
            "measure": 2,
            "sense": 1,
            "case": 1,
            "bounded": 1,
            "unbounded": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para219",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 98,
              "end_char": 101,
              "context": "th\n, that is based on the characterization of the CSP as a hypergraph. In addition to showing that any "
            },
            {
              "para_id": "chap5_para219",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 151,
              "end_char": 154,
              "context": " as a hypergraph. In addition to showing that any CSP with hypertree width\nw\ncan be solved in time\nO\n(\n"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para220",
          "content": "The R\nELSAT\nalgorithm of Bayardo and Schrag (1997) combined constraint learning and backjumping and was shown to outperform many other algorithms of the time. This led to AND-OR search algorithms applicable to both CSPs and probabilistic reasoning (Dechter and Mateescu, 2007). Brown\net al.",
          "sentence_count": 3,
          "char_count": 249,
          "prev_para_id": "chap5_para219",
          "next_para_id": "chap5_para221",
          "style_metadata": {
            "para_id": "chap5_para220",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.67,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 53,
            "sentence_count": 3
          },
          "terminology": {
            "elsat": 1,
            "algorithm": 3,
            "bayardo": 1,
            "schrag": 1,
            "combined": 1,
            "constraint": 1,
            "learning": 1,
            "backjumping": 1,
            "shown": 1,
            "outperform": 1,
            "many": 1,
            "time": 1,
            "led": 1,
            "and-or": 1,
            "search": 1,
            "applicable": 1,
            "csps": 1,
            "probabilistic": 1,
            "reasoning": 1,
            "dechter": 1,
            "mateescu": 1,
            "brown": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para220",
              "entity_text": "Bayardo",
              "entity_type": "ORG",
              "start_char": 25,
              "end_char": 32,
              "context": "The R\nELSAT\nalgorithm of Bayardo and Schrag (1997) combined constraint learning an"
            },
            {
              "para_id": "chap5_para220",
              "entity_text": "Schrag",
              "entity_type": "GPE",
              "start_char": 37,
              "end_char": 43,
              "context": "The R\nELSAT\nalgorithm of Bayardo and Schrag (1997) combined constraint learning and backjumpi"
            },
            {
              "para_id": "chap5_para220",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 249,
              "end_char": 256,
              "context": "licable to both CSPs and probabilistic reasoning (Dechter and Mateescu, 2007). Brown\net al."
            },
            {
              "para_id": "chap5_para220",
              "entity_text": "Mateescu",
              "entity_type": "PERSON",
              "start_char": 261,
              "end_char": 269,
              "context": "oth CSPs and probabilistic reasoning (Dechter and Mateescu, 2007). Brown\net al."
            },
            {
              "para_id": "chap5_para220",
              "entity_text": "Brown",
              "entity_type": "PERSON",
              "start_char": 278,
              "end_char": 283,
              "context": "abilistic reasoning (Dechter and Mateescu, 2007). Brown\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para221",
          "content": "(1988) introduce the idea of symmetry breaking in CSPs, and Gent\net al.",
          "sentence_count": 1,
          "char_count": 60,
          "prev_para_id": "chap5_para220",
          "next_para_id": "chap5_para222",
          "style_metadata": {
            "para_id": "chap5_para221",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 17.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 17,
            "sentence_count": 1
          },
          "terminology": {
            "introduce": 1,
            "idea": 1,
            "symmetry": 1,
            "breaking": 1,
            "csps": 1,
            "gent": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para222",
          "content": "(2006) give a survey.",
          "sentence_count": 1,
          "char_count": 18,
          "prev_para_id": "chap5_para221",
          "next_para_id": "chap5_para223",
          "style_metadata": {
            "para_id": "chap5_para222",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 7.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 7,
            "sentence_count": 1
          },
          "terminology": {
            "give": 1,
            "survey": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para223",
          "content": "The field of\ndistributed constraint satisfaction\nlooks at solving CSPs when there is a collection of agents, each of which controls a subset of the constraint variables. There have been annual workshops on this problem since 2000, and good coverage elsewhere (Collin\net al.,\n1999; Pearce\net al.,\n2008).",
          "sentence_count": 2,
          "char_count": 260,
          "prev_para_id": "chap5_para222",
          "next_para_id": "chap5_para224",
          "style_metadata": {
            "para_id": "chap5_para223",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 29.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 58,
            "sentence_count": 2
          },
          "terminology": {
            "field": 1,
            "distributed": 1,
            "constraint": 2,
            "satisfaction": 1,
            "look": 1,
            "solving": 1,
            "csps": 1,
            "collection": 1,
            "agent": 1,
            "control": 1,
            "subset": 1,
            "variable": 1,
            "annual": 1,
            "workshop": 1,
            "problem": 1,
            "good": 1,
            "coverage": 1,
            "collin": 1,
            "al.": 2,
            "pearce": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para223",
              "entity_text": "Collin",
              "entity_type": "GPE",
              "start_char": 260,
              "end_char": 266,
              "context": " problem since 2000, and good coverage elsewhere (Collin\net al.,\n1999; Pearce\net al.,\n2008)."
            },
            {
              "para_id": "chap5_para223",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 270,
              "end_char": 273,
              "context": "ince 2000, and good coverage elsewhere (Collin\net al.,\n1999; Pearce\net al.,\n2008)."
            },
            {
              "para_id": "chap5_para223",
              "entity_text": "al.",
              "entity_type": "PERSON",
              "start_char": 291,
              "end_char": 294,
              "context": "overage elsewhere (Collin\net al.,\n1999; Pearce\net al.,\n2008)."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para224",
          "content": "Comparing CSP algorithms is mostly an empirical science: few theoretical results show that one algorithm dominates another on all problems; instead, we need to run experiments to see which algorithms perform better on typical instances of problems. As Hooker (1995) points out, we need to be careful to distinguish between competitive testing—as occurs in competitions among algorithms based on run time—and scientific testing, whose goal is to identify the properties of an algorithm that determine its efficacy on a class of problems.",
          "sentence_count": 2,
          "char_count": 455,
          "prev_para_id": "chap5_para223",
          "next_para_id": "chap5_para225",
          "style_metadata": {
            "para_id": "chap5_para224",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 45.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 91,
            "sentence_count": 2
          },
          "terminology": {
            "comparing": 1,
            "csp": 1,
            "empirical": 1,
            "science": 1,
            "theoretical": 1,
            "result": 1,
            "show": 1,
            "algorithm": 4,
            "dominates": 1,
            "problem": 3,
            "need": 2,
            "run": 2,
            "experiment": 1,
            "see": 1,
            "perform": 1,
            "better": 1,
            "typical": 1,
            "instance": 1,
            "hooker": 1,
            "point": 1,
            "careful": 1,
            "distinguish": 1,
            "competitive": 1,
            "testing—as": 1,
            "occurs": 1,
            "competition": 1,
            "based": 1,
            "time—and": 1,
            "scientific": 1,
            "testing": 1,
            "goal": 1,
            "identify": 1,
            "property": 1,
            "determine": 1,
            "efficacy": 1,
            "class": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para224",
              "entity_text": "CSP",
              "entity_type": "ORG",
              "start_char": 10,
              "end_char": 13,
              "context": "Comparing CSP algorithms is mostly an empirical science: few th"
            },
            {
              "para_id": "chap5_para224",
              "entity_text": "Hooker",
              "entity_type": "ORG",
              "start_char": 252,
              "end_char": 258,
              "context": "rform better on typical instances of problems. As Hooker (1995) points out, we need to be careful to disti"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para225",
          "content": "The textbooks by Apt (2003), Dechter (2003), Tsang (1993), and Lecoutre (2009), and the collection by Rossi\net al.",
          "sentence_count": 1,
          "char_count": 97,
          "prev_para_id": "chap5_para224",
          "next_para_id": "chap5_para226",
          "style_metadata": {
            "para_id": "chap5_para225",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 32.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 32,
            "sentence_count": 1
          },
          "terminology": {
            "textbook": 1,
            "apt": 1,
            "dechter": 1,
            "tsang": 1,
            "lecoutre": 1,
            "collection": 1,
            "rossi": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para225",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 29,
              "end_char": 36,
              "context": "The textbooks by Apt (2003), Dechter (2003), Tsang (1993), and Lecoutre (2009), and th"
            },
            {
              "para_id": "chap5_para225",
              "entity_text": "Tsang",
              "entity_type": "PERSON",
              "start_char": 45,
              "end_char": 50,
              "context": "The textbooks by Apt (2003), Dechter (2003), Tsang (1993), and Lecoutre (2009), and the collection b"
            },
            {
              "para_id": "chap5_para225",
              "entity_text": "Lecoutre",
              "entity_type": "ORG",
              "start_char": 63,
              "end_char": 71,
              "context": " by Apt (2003), Dechter (2003), Tsang (1993), and Lecoutre (2009), and the collection by Rossi\net al."
            },
            {
              "para_id": "chap5_para225",
              "entity_text": "Rossi",
              "entity_type": "GPE",
              "start_char": 102,
              "end_char": 107,
              "context": "1993), and Lecoutre (2009), and the collection by Rossi\net al."
            },
            {
              "para_id": "chap5_para225",
              "entity_text": "al",
              "entity_type": "PERSON",
              "start_char": 111,
              "end_char": 113,
              "context": "d Lecoutre (2009), and the collection by Rossi\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para226",
          "content": "(2006), are excellent resources on constraint processing. There are several good survey articles, including those by Dechter and Frost (2002), and Barták\net al.",
          "sentence_count": 2,
          "char_count": 138,
          "prev_para_id": "chap5_para225",
          "next_para_id": "chap5_para227",
          "style_metadata": {
            "para_id": "chap5_para226",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 16.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 33,
            "sentence_count": 2
          },
          "terminology": {
            "excellent": 1,
            "resource": 1,
            "constraint": 1,
            "processing": 1,
            "several": 1,
            "good": 1,
            "survey": 1,
            "article": 1,
            "including": 1,
            "dechter": 1,
            "frost": 1,
            "barták": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para226",
              "entity_text": "Dechter",
              "entity_type": "ORG",
              "start_char": 117,
              "end_char": 124,
              "context": " several good survey articles, including those by Dechter and Frost (2002), and Barták\net al."
            },
            {
              "para_id": "chap5_para226",
              "entity_text": "Frost",
              "entity_type": "PERSON",
              "start_char": 129,
              "end_char": 134,
              "context": "d survey articles, including those by Dechter and Frost (2002), and Barták\net al."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para227",
          "content": "(2010). Carbonnel and Cooper (2016) survey tractable classes of CSPs. Kondrak and van Beek (1997) give an analytical survey of backtracking search algorithms, and Bacchus and van Run (1995) give a more empirical survey. Constraint programming is covered in the books by Apt (2003) and Fruhwirth and Abdennadher (2003). Papers on constraint satisfaction appear regularly in\nArtificial Intelligence\nand in the specialist journal\nConstraints;\nthe latest SAT solvers are described in the annual International SAT Competition. The primary conference venue is the International Conference on Principles and Practice of Constraint Programming, often called\nCP.",
          "sentence_count": 6,
          "char_count": 565,
          "prev_para_id": "chap5_para226",
          "next_para_id": "chap5_para228",
          "style_metadata": {
            "para_id": "chap5_para227",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 19.17,
            "passive_voice_ratio": 0.009,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 115,
            "sentence_count": 6
          },
          "terminology": {
            "carbonnel": 1,
            "cooper": 1,
            "survey": 3,
            "tractable": 1,
            "class": 1,
            "csps": 1,
            "kondrak": 1,
            "van": 2,
            "beek": 1,
            "give": 2,
            "analytical": 1,
            "backtracking": 1,
            "search": 1,
            "algorithm": 1,
            "run": 1,
            "empirical": 1,
            "constraint": 4,
            "programming": 2,
            "covered": 1,
            "book": 1,
            "apt": 1,
            "fruhwirth": 1,
            "abdennadher": 1,
            "paper": 1,
            "satisfaction": 1,
            "appear": 1,
            "artificial": 1,
            "intelligence": 1,
            "specialist": 1,
            "journal": 1,
            "latest": 1,
            "sat": 2,
            "solver": 1,
            "described": 1,
            "annual": 1,
            "international": 2,
            "competition": 1,
            "primary": 1,
            "conference": 2,
            "venue": 1,
            "principle": 1,
            "practice": 1,
            "called": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para227",
              "entity_text": "Cooper",
              "entity_type": "PERSON",
              "start_char": 22,
              "end_char": 28,
              "context": "(2010). Carbonnel and Cooper (2016) survey tractable classes of CSPs. Kondrak "
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "Kondrak",
              "entity_type": "PERSON",
              "start_char": 70,
              "end_char": 77,
              "context": "d Cooper (2016) survey tractable classes of CSPs. Kondrak and van Beek (1997) give an analytical survey of "
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "van Beek",
              "entity_type": "PERSON",
              "start_char": 82,
              "end_char": 90,
              "context": "16) survey tractable classes of CSPs. Kondrak and van Beek (1997) give an analytical survey of backtracking "
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "Bacchus",
              "entity_type": "ORG",
              "start_char": 163,
              "end_char": 170,
              "context": "cal survey of backtracking search algorithms, and Bacchus and van Run (1995) give a more empirical survey. "
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "van Run",
              "entity_type": "PERSON",
              "start_char": 175,
              "end_char": 182,
              "context": "f backtracking search algorithms, and Bacchus and van Run (1995) give a more empirical survey. Constraint p"
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "Fruhwirth",
              "entity_type": "PERSON",
              "start_char": 285,
              "end_char": 294,
              "context": "ramming is covered in the books by Apt (2003) and Fruhwirth and Abdennadher (2003). Papers on constraint sati"
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "Artificial Intelligence",
              "entity_type": "PERSON",
              "start_char": 373,
              "end_char": 396,
              "context": "rs on constraint satisfaction appear regularly in\nArtificial Intelligence\nand in the specialist journal\nConstraints;\nthe la"
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "SAT",
              "entity_type": "ORG",
              "start_char": 451,
              "end_char": 454,
              "context": "in the specialist journal\nConstraints;\nthe latest SAT solvers are described in the annual International"
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "International SAT Competition",
              "entity_type": "EVENT",
              "start_char": 491,
              "end_char": 520,
              "context": "he latest SAT solvers are described in the annual International SAT Competition. The primary conference venue is the Internationa"
            },
            {
              "para_id": "chap5_para227",
              "entity_text": "the International Conference on Principles and Practice of Constraint Programming",
              "entity_type": "ORG",
              "start_char": 554,
              "end_char": 635,
              "context": " SAT Competition. The primary conference venue is the International Conference on Principles and Practice of Constraint Programming, often called\nCP."
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para228",
          "content": "1\nWe have been using the term “edge” rather than “arc,” so it would make more sense to call this “edge-consistent,” but the name “arc-consistent” is historical.",
          "sentence_count": 1,
          "char_count": 135,
          "prev_para_id": "chap5_para227",
          "next_para_id": "chap5_para229",
          "style_metadata": {
            "para_id": "chap5_para228",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 38.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 38,
            "sentence_count": 1
          },
          "terminology": {
            "using": 1,
            "term": 1,
            "edge": 1,
            "make": 1,
            "sense": 1,
            "call": 1,
            "edge-consistent": 1,
            "name": 1,
            "arc-consistent": 1,
            "historical": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para229",
          "content": "2\nLocal search can easily be extended to constrained optimization problems (COPs). In that case, all the techniques for hill climbing and simulated annealing can be applied to optimize the objective function.",
          "sentence_count": 2,
          "char_count": 178,
          "prev_para_id": "chap5_para228",
          "next_para_id": "chap5_para230",
          "style_metadata": {
            "para_id": "chap5_para229",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.5,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 37,
            "sentence_count": 2
          },
          "terminology": {
            "local": 1,
            "search": 1,
            "extended": 1,
            "constrained": 1,
            "optimization": 1,
            "problem": 1,
            "cop": 1,
            "case": 1,
            "technique": 1,
            "hill": 1,
            "climbing": 1,
            "simulated": 1,
            "annealing": 1,
            "applied": 1,
            "optimize": 1,
            "objective": 1,
            "function": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para230",
          "content": "3\nA careful cartographer or patriotic Tasmanian might object that Tasmania should not be colored the same as its nearest mainland neighbor, to avoid the impression that it\nmight\nbe part of that state.",
          "sentence_count": 1,
          "char_count": 170,
          "prev_para_id": "chap5_para229",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap5_para230",
            "domain": "AI_Popular",
            "style": "Formal_Academic",
            "formality_score": 8.0,
            "avg_sentence_length": 36.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 36,
            "sentence_count": 1
          },
          "terminology": {
            "careful": 1,
            "patriotic": 1,
            "tasmanian": 1,
            "object": 1,
            "tasmania": 1,
            "colored": 1,
            "nearest": 1,
            "mainland": 1,
            "neighbor": 1,
            "avoid": 1,
            "impression": 1,
            "part": 1,
            "state": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para230",
              "entity_text": "Tasmania",
              "entity_type": "ORG",
              "start_char": 66,
              "end_char": 74,
              "context": "ographer or patriotic Tasmanian might object that Tasmania should not be colored the same as its nearest mai"
            }
          ],
          "cultural_words": []
        },
        {
          "para_id": "chap5_para231",
          "content": "4\nSadly, very few regions of the world have tree-structured maps, although Sulawesi comes close.",
          "sentence_count": 1,
          "char_count": 83,
          "prev_para_id": "chap5_para230",
          "next_para_id": "None",
          "style_metadata": {
            "para_id": "chap5_para231",
            "domain": "AI_Popular",
            "style": "Semi_Formal_Academic",
            "formality_score": 7.0,
            "avg_sentence_length": 18.0,
            "passive_voice_ratio": 0.0,
            "domain_keywords": [],
            "formal_keywords": [],
            "word_count": 18,
            "sentence_count": 1
          },
          "terminology": {
            "region": 1,
            "world": 1,
            "tree-structured": 1,
            "map": 1,
            "sulawesi": 1,
            "come": 1,
            "reinforcement learning": 1,
            "attention mechanism": 1,
            "backpropagation": 1,
            "rational agent": 1,
            "convolutional neural network": 1,
            "neural network": 1,
            "markov decision process": 1,
            "perceptron": 1,
            "machine learning": 1,
            "bayesian network": 1
          },
          "named_entities": [
            {
              "para_id": "chap5_para231",
              "entity_text": "Sulawesi",
              "entity_type": "PERSON",
              "start_char": 75,
              "end_char": 83,
              "context": " of the world have tree-structured maps, although Sulawesi comes close."
            }
          ],
          "cultural_words": []
        }
      ],
      "para_count": 231,
      "char_count": 81672
    }
  ],
  "global_terminology": {
    "introduction": 6,
    "try": 36,
    "explain": 8,
    "consider": 81,
    "artificial": 31,
    "intelligence": 48,
    "subject": 12,
    "worthy": 2,
    "study": 25,
    "good": 58,
    "thing": 27,
    "decide": 7,
    "embarking": 1,
    "reinforcement learning": 1394,
    "attention mechanism": 1394,
    "backpropagation": 1395,
    "rational agent": 1394,
    "convolutional neural network": 1394,
    "neural network": 1394,
    "markov decision process": 1394,
    "perceptron": 1397,
    "machine learning": 1394,
    "bayesian network": 1394,
    "call": 43,
    "homo": 1,
    "sapiens": 1,
    "—man": 1,
    "wise—because": 1,
    "important": 43,
    "thousand": 19,
    "year": 31,
    "tried": 9,
    "understand": 11,
    "think": 30,
    "act": 21,
    "brain": 36,
    "handful": 1,
    "matter": 10,
    "perceive": 5,
    "predict": 11,
    "manipulate": 5,
    "world": 204,
    "larger": 14,
    "complicated": 6,
    "field": 49,
    "concerned": 8,
    "understanding": 26,
    "building": 10,
    "intelligent": 38,
    "entities—machines": 1,
    "compute": 16,
    "wide": 15,
    "variety": 22,
    "novel": 1,
    "situation": 16,
    "survey": 12,
    "rank": 1,
    "interesting": 10,
    "fastest-growing": 1,
    "generating": 9,
    "dollar": 3,
    "revenue": 1,
    "expert": 22,
    "kai-fu": 2,
    "lee": 2,
    "predicts": 2,
    "impact": 9,
    "anything": 8,
    "history": 28,
    "mankind.": 1,
    "intellectual": 4,
    "frontier": 53,
    "open": 16,
    "whereas": 11,
    "student": 15,
    "older": 2,
    "science": 31,
    "physic": 7,
    "feel": 1,
    "best": 55,
    "idea": 73,
    "discovered": 6,
    "galileo": 2,
    "newton": 5,
    "curie": 1,
    "einstein": 1,
    "rest": 19,
    "many": 113,
    "opening": 2,
    "full-time": 1,
    "mastermind": 1,
    "encompasses": 1,
    "huge": 3,
    "subfields": 5,
    "ranging": 2,
    "general": 84,
    "learning": 141,
    "reasoning": 45,
    "perception": 6,
    "specific": 22,
    "playing": 6,
    "chess": 25,
    "proving": 3,
    "mathematical": 25,
    "theorem": 15,
    "writing": 5,
    "poetry": 1,
    "driving": 30,
    "car": 30,
    "diagnosing": 5,
    "disease": 7,
    "relevant": 8,
    "task": 83,
    "universal": 5,
    "claimed": 3,
    "said": 10,
    "researcher": 21,
    "pursued": 3,
    "several": 40,
    "different": 88,
    "version": 30,
    "defined": 30,
    "term": 42,
    "fidelity": 1,
    "human": 116,
    "performance": 98,
    "others": 30,
    "prefer": 3,
    "abstract": 10,
    "formal": 20,
    "definition": 22,
    "called": 98,
    "rationality": 21,
    "speaking": 9,
    "right": 85,
    "thing.": 1,
    "varies": 1,
    "property": 30,
    "internal": 26,
    "thought": 29,
    "process": 49,
    "focus": 8,
    "behavior": 46,
    "external": 11,
    "characterization": 4,
    "dimensions—human": 1,
    "rational": 56,
    "possible": 116,
    "combination": 16,
    "adherent": 1,
    "research": 41,
    "program": 127,
    "method": 91,
    "used": 80,
    "pursuit": 1,
    "human-like": 2,
    "part": 118,
    "empirical": 9,
    "related": 11,
    "psychology": 13,
    "involving": 14,
    "observation": 22,
    "hypothesis": 2,
    "actual": 20,
    "rationalist": 1,
    "approach": 65,
    "hand": 28,
    "involves": 13,
    "mathematics": 11,
    "engineering": 10,
    "connects": 10,
    "statistic": 6,
    "control": 49,
    "theory": 81,
    "economics": 10,
    "various": 22,
    "group": 13,
    "disparaged": 1,
    "helped": 4,
    "let": 19,
    "look": 19,
    "detail": 13,
    "acting": 7,
    "turing": 28,
    "test": 28,
    "proposed": 16,
    "alan": 6,
    "designed": 13,
    "experiment": 16,
    "sidestep": 1,
    "philosophical": 5,
    "vagueness": 1,
    "question": 30,
    "machine": 119,
    "computer": 86,
    "pass": 5,
    "interrogator": 1,
    "posing": 1,
    "written": 13,
    "tell": 11,
    "response": 12,
    "come": 36,
    "person": 6,
    "chapter": 135,
    "discusses": 2,
    "passed": 4,
    "note": 34,
    "programming": 39,
    "pas": 5,
    "applied": 31,
    "provides": 21,
    "plenty": 3,
    "work": 127,
    "need": 95,
    "following": 46,
    "capability": 10,
    "natural": 19,
    "language": 52,
    "processing": 15,
    "communicate": 3,
    "knowledge": 59,
    "representation": 56,
    "store": 8,
    "know": 69,
    "hears": 1,
    "automated": 16,
    "answer": 17,
    "draw": 6,
    "new": 103,
    "conclusion": 8,
    "adapt": 2,
    "circumstance": 4,
    "detect": 11,
    "extrapolate": 1,
    "pattern": 22,
    "viewed": 8,
    "physical": 38,
    "simulation": 7,
    "unnecessary": 1,
    "demonstrate": 4,
    "total": 25,
    "requires": 19,
    "interaction": 5,
    "object": 30,
    "people": 14,
    "real": 35,
    "robot": 49,
    "vision": 21,
    "speech": 21,
    "recognition": 23,
    "robotics": 8,
    "move": 86,
    "discipline": 8,
    "devoted": 5,
    "little": 13,
    "effort": 11,
    "passing": 2,
    "believing": 1,
    "underlying": 8,
    "principle": 20,
    "quest": 2,
    "flight": 15,
    "succeeded": 1,
    "engineer": 6,
    "inventor": 2,
    "stopped": 2,
    "imitating": 1,
    "bird": 2,
    "started": 5,
    "using": 69,
    "wind": 1,
    "tunnel": 1,
    "aerodynamics": 1,
    "aeronautical": 1,
    "text": 10,
    "define": 7,
    "goal": 220,
    "making": 31,
    "pigeon": 2,
    "fool": 1,
    "pigeons.": 1,
    "thinking": 18,
    "cognitive": 17,
    "modeling": 6,
    "say": 58,
    "learn": 39,
    "way": 111,
    "introspection": 3,
    "—trying": 1,
    "catch": 3,
    "psychological": 3,
    "—observing": 2,
    "action": 377,
    "imaging": 2,
    "precise": 9,
    "mind": 28,
    "becomes": 14,
    "express": 3,
    "input–output": 1,
    "match": 9,
    "corresponding": 23,
    "evidence": 9,
    "mechanism": 15,
    "operating": 6,
    "example": 225,
    "allen": 4,
    "herbert": 8,
    "simon": 23,
    "developed": 49,
    "gps": 8,
    "problem": 498,
    "solver": 12,
    "content": 6,
    "solve": 47,
    "comparing": 5,
    "sequence": 80,
    "timing": 2,
    "step": 67,
    "solving": 40,
    "interdisciplinary": 1,
    "brings": 3,
    "model": 81,
    "experimental": 8,
    "technique": 54,
    "construct": 12,
    "testable": 1,
    "fascinating": 1,
    "textbook": 4,
    "least": 30,
    "encyclopedia": 1,
    "wilson": 2,
    "keil": 1,
    "comment": 2,
    "similarity": 1,
    "difference": 13,
    "cognition": 6,
    "based": 37,
    "investigation": 3,
    "animal": 14,
    "leave": 5,
    "book": 33,
    "assume": 16,
    "reader": 11,
    "experimentation": 1,
    "early": 33,
    "day": 10,
    "confusion": 2,
    "author": 10,
    "argue": 2,
    "algorithm": 312,
    "performs": 5,
    "vice": 3,
    "versa": 3,
    "modern": 15,
    "separate": 9,
    "kind": 33,
    "claim": 5,
    "distinction": 16,
    "allowed": 11,
    "develop": 6,
    "incorporates": 1,
    "neurophysiological": 1,
    "computational": 20,
    "neuroimaging": 1,
    "combined": 11,
    "analyzing": 4,
    "data": 51,
    "led": 22,
    "beginning": 8,
    "read": 10,
    "ascertain": 1,
    "semantic": 2,
    "inner": 1,
    "turn": 36,
    "shed": 2,
    "light": 15,
    "law": 17,
    "greek": 3,
    "first": 124,
    "attempt": 14,
    "codify": 1,
    "irrefutable": 1,
    "syllogism": 2,
    "provided": 18,
    "argument": 3,
    "structure": 48,
    "yielded": 3,
    "correct": 24,
    "given": 84,
    "premise": 3,
    "canonical": 3,
    "start": 59,
    "socrates": 2,
    "man": 3,
    "men": 1,
    "mortal": 3,
    "concludes": 3,
    "due": 15,
    "sextus": 1,
    "empiricus": 1,
    "aristotle": 7,
    "supposed": 1,
    "govern": 2,
    "operation": 33,
    "initiated": 3,
    "logic": 33,
    "logician": 2,
    "19th": 2,
    "century": 10,
    "notation": 8,
    "statement": 10,
    "relation": 7,
    "contrast": 7,
    "ordinary": 8,
    "arithmetic": 6,
    "number": 135,
    "solvable": 7,
    "described": 39,
    "logical": 25,
    "so-called": 2,
    "logicist": 2,
    "tradition": 3,
    "hope": 7,
    "build": 21,
    "create": 10,
    "system": 116,
    "understood": 4,
    "certain": 18,
    "condition": 26,
    "reality": 5,
    "achieved": 12,
    "rule": 54,
    "politics": 1,
    "warfare": 1,
    "probability": 37,
    "fill": 21,
    "gap": 3,
    "allowing": 9,
    "rigorous": 5,
    "uncertain": 13,
    "information": 54,
    "allows": 11,
    "construction": 5,
    "comprehensive": 4,
    "leading": 14,
    "raw": 3,
    "perceptual": 3,
    "prediction": 12,
    "future": 23,
    "generate": 21,
    "agent": 609,
    "something": 11,
    "agere": 1,
    "course": 25,
    "expected": 25,
    "environment": 247,
    "persist": 1,
    "prolonged": 1,
    "time": 176,
    "period": 9,
    "change": 39,
    "pursue": 2,
    "achieve": 28,
    "outcome": 27,
    "uncertainty": 19,
    "emphasis": 4,
    "inference": 22,
    "deduce": 1,
    "involve": 6,
    "recoiling": 1,
    "hot": 1,
    "stove": 2,
    "reflex": 32,
    "successful": 10,
    "slower": 5,
    "taken": 13,
    "careful": 10,
    "deliberation": 1,
    "skill": 2,
    "needed": 15,
    "allow": 22,
    "enable": 8,
    "reach": 53,
    "decision": 60,
    "able": 26,
    "comprehensible": 1,
    "sentence": 6,
    "get": 54,
    "complex": 31,
    "society": 6,
    "erudition": 1,
    "improves": 2,
    "ability": 8,
    "effective": 25,
    "rational-agent": 3,
    "advantage": 17,
    "achieving": 5,
    "second": 123,
    "amenable": 1,
    "scientific": 13,
    "development": 19,
    "standard": 35,
    "specification": 5,
    "derive": 10,
    "design": 53,
    "it—something": 1,
    "impossible": 9,
    "imitate": 2,
    "reason": 19,
    "prevailed": 1,
    "decade": 6,
    "built": 11,
    "foundation": 7,
    "formed": 7,
    "definite": 4,
    "plan": 46,
    "creation": 5,
    "make": 83,
    "attain": 1,
    "nutshell": 1,
    "focused": 6,
    "count": 12,
    "objective": 48,
    "provide": 24,
    "paradigm": 1,
    "pervasive": 2,
    "prevails": 1,
    "controller": 3,
    "minimizes": 4,
    "cost": 211,
    "function": 147,
    "policy": 6,
    "maximizes": 7,
    "sum": 12,
    "reward": 5,
    "loss": 3,
    "maker": 4,
    "utility": 43,
    "measure": 47,
    "social": 7,
    "welfare": 1,
    "refinement": 4,
    "account": 6,
    "fact": 25,
    "perfect": 9,
    "rationality—always": 1,
    "taking": 14,
    "optimal": 93,
    "action—is": 1,
    "feasible": 6,
    "demand": 1,
    "high": 10,
    "deal": 29,
    "issue": 13,
    "limited": 10,
    "—acting": 1,
    "enough": 6,
    "computation": 26,
    "like": 8,
    "remains": 8,
    "starting": 9,
    "point": 269,
    "theoretical": 12,
    "analysis": 17,
    "beneficial": 3,
    "useful": 29,
    "guide": 5,
    "inception": 2,
    "long": 29,
    "run": 36,
    "assumes": 3,
    "specified": 8,
    "shortest-path": 1,
    "in—so": 1,
    "applicable": 8,
    "difficult": 13,
    "specify": 11,
    "designing": 10,
    "self-driving": 5,
    "destination": 17,
    "road": 34,
    "incurs": 2,
    "risk": 15,
    "injury": 2,
    "errant": 1,
    "driver": 16,
    "equipment": 2,
    "failure": 28,
    "strict": 2,
    "safety": 4,
    "staying": 2,
    "garage": 1,
    "tradeoff": 8,
    "progress": 38,
    "towards": 11,
    "incurring": 1,
    "made": 27,
    "extent": 7,
    "take": 69,
    "annoy": 1,
    "much": 42,
    "moderate": 2,
    "acceleration": 3,
    "steering": 5,
    "braking": 8,
    "avoid": 14,
    "shaking": 4,
    "passenger": 9,
    "problematic": 1,
    "area": 31,
    "human–robot": 1,
    "agreement": 3,
    "true": 20,
    "preference": 23,
    "put": 17,
    "value": 206,
    "alignment": 1,
    "aligned": 2,
    "developing": 6,
    "lab": 3,
    "simulator—as": 1,
    "case": 83,
    "easy": 24,
    "fix": 4,
    "reset": 1,
    "capable": 8,
    "deployed": 4,
    "viable": 2,
    "incorrect": 5,
    "negative": 12,
    "consequence": 10,
    "returning": 1,
    "unproblematic": 1,
    "happens": 13,
    "confines": 1,
    "chessboard": 3,
    "increase": 15,
    "chance": 18,
    "winning": 2,
    "rus": 1,
    "hypnotizing": 1,
    "blackmailing": 1,
    "opponent": 10,
    "bribing": 1,
    "audience": 2,
    "rustling": 1,
    "noise": 3,
    "hijack": 1,
    "additional": 14,
    "computing": 17,
    "power": 13,
    "unintelligent": 1,
    "insane": 1,
    "defining": 9,
    "sole": 1,
    "anticipate": 3,
    "pursuing": 4,
    "fixed": 14,
    "misbehave": 1,
    "inadequate": 2,
    "want": 16,
    "sense": 20,
    "transfer": 2,
    "complete": 55,
    "incentive": 2,
    "ask": 7,
    "permission": 1,
    "defer": 1,
    "return": 40,
    "topic": 14,
    "section": 70,
    "brief": 2,
    "contributed": 4,
    "viewpoint": 4,
    "concentrate": 3,
    "small": 47,
    "event": 8,
    "ignores": 1,
    "organize": 2,
    "series": 10,
    "wish": 3,
    "give": 38,
    "impression": 3,
    "one": 12,
    "working": 9,
    "ultimate": 3,
    "fruition": 1,
    "philosophy": 3,
    "valid": 10,
    "arise": 10,
    "lead": 32,
    "bce": 5,
    "formulate": 7,
    "set": 148,
    "governing": 2,
    "informal": 3,
    "proper": 5,
    "initial": 78,
    "ramon": 2,
    "llull": 2,
    "devised": 6,
    "published": 8,
    "ar": 1,
    "great": 17,
    "art": 6,
    "implement": 12,
    "mechanical": 11,
    "device": 12,
    "paper": 26,
    "wheel": 12,
    "rotated": 1,
    "permutation": 1,
    "leonardo": 1,
    "vinci": 1,
    "calculator": 8,
    "recent": 12,
    "reconstruction": 1,
    "shown": 97,
    "functional": 4,
    "known": 38,
    "calculating": 3,
    "constructed": 5,
    "german": 4,
    "scientist": 9,
    "wilhelm": 3,
    "schickard": 1,
    "blaise": 2,
    "pascal": 2,
    "pascaline": 1,
    "wrote": 5,
    "produce": 13,
    "effect": 19,
    "appear": 20,
    "nearer": 1,
    "animals.": 1,
    "gottfried": 1,
    "leibniz": 2,
    "intended": 5,
    "carry": 10,
    "concept": 31,
    "scope": 4,
    "leviathan": 1,
    "thomas": 2,
    "hobbes": 1,
    "suggested": 8,
    "word": 22,
    "arguing": 2,
    "heart": 2,
    "spring": 1,
    "nerve": 2,
    "string": 16,
    "joint": 4,
    "wheels.": 1,
    "numerical": 2,
    "nothing": 16,
    "reckoning": 1,
    "adding": 12,
    "subtracting.": 1,
    "operates": 4,
    "according": 20,
    "emulate": 1,
    "rené": 1,
    "descartes": 2,
    "gave": 5,
    "clear": 5,
    "discussion": 7,
    "noted": 9,
    "conception": 2,
    "seems": 20,
    "room": 2,
    "free": 6,
    "governed": 1,
    "rock": 3,
    "deciding": 5,
    "fall": 4,
    "proponent": 1,
    "dualism": 2,
    "held": 4,
    "soul": 1,
    "spirit": 1,
    "nature": 16,
    "exempt": 1,
    "possess": 1,
    "dual": 5,
    "quality": 11,
    "treated": 4,
    "alternative": 15,
    "materialism": 1,
    "hold": 5,
    "constitutes": 2,
    "available": 26,
    "choice": 39,
    "appears": 20,
    "choosing": 11,
    "entity": 4,
    "physicalism": 1,
    "naturalism": 1,
    "describe": 18,
    "view": 18,
    "stand": 3,
    "supernatural": 1,
    "manipulates": 1,
    "next": 56,
    "establish": 2,
    "source": 6,
    "empiricism": 2,
    "movement": 11,
    "francis": 3,
    "bacon": 2,
    "novum": 2,
    "organum": 2,
    "characterized": 7,
    "dictum": 1,
    "john": 17,
    "locke": 1,
    "senses.": 1,
    "david": 4,
    "hume": 2,
    "treatise": 2,
    "induction": 2,
    "acquired": 4,
    "exposure": 1,
    "repeated": 9,
    "association": 3,
    "element": 37,
    "ludwig": 1,
    "wittgenstein": 1,
    "bertrand": 2,
    "russell": 11,
    "famous": 6,
    "vienna": 2,
    "circle": 32,
    "sigmund": 1,
    "philosopher": 6,
    "mathematician": 8,
    "meeting": 2,
    "doctrine": 2,
    "positivism": 2,
    "connected": 44,
    "correspond": 6,
    "sensory": 4,
    "input": 22,
    "combine": 10,
    "rationalism": 1,
    "confirmation": 1,
    "rudolf": 1,
    "carnap": 2,
    "carl": 2,
    "hempel": 1,
    "attempted": 1,
    "analyze": 4,
    "acquisition": 1,
    "experience": 18,
    "quantifying": 1,
    "degree": 12,
    "belief": 153,
    "assigned": 18,
    "connection": 19,
    "confirm": 2,
    "disconfirm": 2,
    "final": 9,
    "picture": 4,
    "vital": 1,
    "justified": 2,
    "justifiable": 1,
    "argued": 2,
    "motu": 1,
    "animalium": 1,
    "happen": 9,
    "accompanied": 3,
    "motion": 2,
    "unchanging": 1,
    "end": 36,
    "speculative": 1,
    "proposition": 2,
    "result": 73,
    "covering": 4,
    "cloak": 5,
    "nicomachean": 2,
    "ethic": 4,
    "iii": 3,
    "elaborates": 1,
    "suggesting": 5,
    "deliberate": 3,
    "mean": 44,
    "doctor": 5,
    "heal": 1,
    "orator": 1,
    "persuade": 1,
    "attained": 1,
    "produced": 4,
    "cause": 14,
    "last": 18,
    "order": 32,
    "becoming": 3,
    "impossibility": 1,
    "search": 596,
    "e.g.": 11,
    "money": 9,
    "got": 1,
    "implemented": 12,
    "greedy": 19,
    "regression": 1,
    "planning": 29,
    "see": 102,
    "dominated": 1,
    "inapplicable": 1,
    "choose": 33,
    "certainty": 5,
    "antoine": 1,
    "notion": 26,
    "gambling": 3,
    "quantitative": 2,
    "formula": 10,
    "maximizing": 6,
    "monetary": 4,
    "daniel": 4,
    "bernoulli": 3,
    "introduced": 31,
    "capture": 7,
    "subjective": 2,
    "explained": 12,
    "public": 10,
    "interest": 16,
    "multiple": 26,
    "individual": 36,
    "jeremy": 1,
    "bentham": 1,
    "stuart": 1,
    "mill": 2,
    "promoted": 2,
    "utilitarianism": 2,
    "apply": 9,
    "sphere": 2,
    "activity": 11,
    "including": 26,
    "behalf": 2,
    "consequentialism": 2,
    "wrong": 10,
    "determined": 4,
    "immanuel": 1,
    "kant": 1,
    "rule-based": 1,
    "deontological": 1,
    "allowable": 4,
    "lie": 4,
    "kill.": 1,
    "utilitarian": 1,
    "white": 33,
    "outweighs": 2,
    "bad": 12,
    "kantian": 1,
    "bound": 17,
    "lying": 1,
    "acknowledged": 1,
    "efficient": 48,
    "procedure": 9,
    "compiled": 1,
    "first-principles": 1,
    "adopt": 2,
    "computed": 11,
    "staked": 1,
    "fundamental": 4,
    "leap": 1,
    "required": 10,
    "mathematization": 1,
    "branch": 15,
    "traced": 5,
    "ancient": 2,
    "greece": 1,
    "india": 2,
    "china": 2,
    "began": 10,
    "george": 3,
    "boole": 4,
    "worked": 9,
    "propositional": 6,
    "boolean": 14,
    "gottlob": 2,
    "frege": 3,
    "extended": 6,
    "include": 17,
    "creating": 10,
    "first-order": 9,
    "today": 8,
    "addition": 15,
    "central": 11,
    "role": 7,
    "motivated": 4,
    "gödel": 1,
    "underpinned": 1,
    "seen": 22,
    "generalizing": 1,
    "information—a": 1,
    "consideration": 5,
    "importance": 5,
    "gerolamo": 1,
    "cardano": 1,
    "framed": 1,
    "describing": 5,
    "letter": 8,
    "pierre": 2,
    "fermat": 1,
    "showed": 26,
    "unfinished": 1,
    "game": 32,
    "assign": 9,
    "average": 20,
    "payoff": 3,
    "gambler": 1,
    "became": 13,
    "invaluable": 1,
    "helping": 1,
    "measurement": 5,
    "incomplete": 6,
    "jacob": 1,
    "uncle": 1,
    "laplace": 1,
    "advanced": 5,
    "statistical": 3,
    "updating": 9,
    "bayes": 1,
    "crucial": 5,
    "tool": 16,
    "formalization": 2,
    "availability": 4,
    "emergence": 1,
    "us": 25,
    "graunt": 1,
    "london": 2,
    "census": 1,
    "ronald": 1,
    "fisher": 2,
    "considered": 20,
    "statistician": 2,
    "brought": 3,
    "computing—in": 1,
    "insisted": 4,
    "illionaire": 1,
    "multiplication": 1,
    "annual": 6,
    "salary": 1,
    "ross": 2,
    "old": 7,
    "nontrivial": 3,
    "euclid": 1,
    "greatest": 1,
    "common": 22,
    "divisor": 1,
    "muhammad": 1,
    "ibn": 1,
    "musa": 1,
    "al-khwarizmi": 1,
    "arabic": 1,
    "numeral": 1,
    "europe": 3,
    "discussed": 12,
    "deduction": 3,
    "formalize": 1,
    "kurt": 1,
    "gӧdel": 2,
    "exists": 8,
    "prove": 6,
    "characterize": 7,
    "limit": 27,
    "exist": 5,
    "incompleteness": 1,
    "strong": 6,
    "peano": 1,
    "elementary": 3,
    "proof": 9,
    "interpreted": 1,
    "showing": 10,
    "integer": 15,
    "represented": 28,
    "computable": 2,
    "—capable": 1,
    "church–turing": 1,
    "thesis": 1,
    "proposes": 2,
    "identify": 5,
    "computability": 2,
    "tractability": 2,
    "greater": 11,
    "intractable": 7,
    "instance": 27,
    "grows": 2,
    "size": 35,
    "polynomial": 6,
    "exponential": 14,
    "growth": 4,
    "complexity": 44,
    "emphasized": 3,
    "mid-1960s": 1,
    "cobham": 1,
    "edmonds": 2,
    "large": 43,
    "solved": 32,
    "reasonable": 6,
    "np-completeness": 1,
    "pioneered": 4,
    "cook": 1,
    "karp": 3,
    "basis": 9,
    "class": 19,
    "np-complete": 5,
    "reduced": 14,
    "proved": 11,
    "theoretician": 1,
    "believe": 4,
    "optimism": 5,
    "popular": 11,
    "press": 2,
    "greeted": 1,
    "computers—": 1,
    "electronic": 6,
    "super-brains": 1,
    "increasing": 14,
    "speed": 8,
    "use": 88,
    "resource": 6,
    "necessary": 8,
    "imperfection": 1,
    "accordance": 2,
    "along": 2,
    "originated": 5,
    "smith": 5,
    "inquiry": 1,
    "wealth": 3,
    "nation": 2,
    "economy": 4,
    "consisting": 7,
    "attending": 1,
    "advocating": 1,
    "financial": 2,
    "greed": 2,
    "moral": 3,
    "position": 35,
    "sentiment": 2,
    "begin": 10,
    "pointing": 3,
    "concern": 10,
    "well-being": 1,
    "essential": 1,
    "component": 34,
    "maximum-expected-value": 1,
    "arnauld": 1,
    "dealt": 2,
    "bet": 1,
    "noticed": 5,
    "seem": 12,
    "amount": 18,
    "investment": 3,
    "trading": 2,
    "expedition": 1,
    "maximization": 2,
    "proposing": 2,
    "marginal": 1,
    "quantity": 1,
    "diminished": 1,
    "léon": 1,
    "walras": 1,
    "pronounced": 2,
    "valrasse": 1,
    "gamble": 1,
    "improved": 9,
    "ramsey": 1,
    "von": 5,
    "oskar": 1,
    "morgenstern": 2,
    "economic": 5,
    "desire": 6,
    "framework": 9,
    "uncertainty—that": 1,
    "probabilistic": 17,
    "description": 94,
    "suitable": 7,
    "pay": 4,
    "attention": 8,
    "player": 11,
    "affect": 7,
    "neumann": 1,
    "luce": 1,
    "raiffa": 1,
    "included": 8,
    "surprising": 1,
    "randomized": 5,
    "offer": 2,
    "unambiguous": 1,
    "prescription": 1,
    "selecting": 11,
    "studied": 13,
    "heading": 4,
    "multiagent": 17,
    "economist": 4,
    "exception": 4,
    "address": 4,
    "third": 67,
    "listed": 4,
    "immediate": 2,
    "emerged": 2,
    "war": 2,
    "britain": 4,
    "optimize": 3,
    "radar": 1,
    "installation": 1,
    "found": 33,
    "innumerable": 1,
    "civilian": 1,
    "application": 28,
    "bellman": 5,
    "formalized": 3,
    "sequential": 9,
    "markov": 5,
    "reinforcement": 12,
    "path": 356,
    "apparent": 5,
    "pioneering": 2,
    "nobel": 3,
    "prize": 3,
    "satisficing": 4,
    "—making": 1,
    "decision—gave": 1,
    "better": 25,
    "resurgence": 6,
    "decision-theoretic": 2,
    "neuroscience": 3,
    "nervous": 2,
    "exact": 20,
    "enables": 1,
    "mystery": 1,
    "appreciated": 2,
    "blow": 2,
    "head": 4,
    "mental": 4,
    "incapacitation": 1,
    "somehow": 2,
    "largest": 6,
    "proportion": 2,
    "size.": 1,
    "middle": 19,
    "18th": 1,
    "recognized": 4,
    "seat": 3,
    "consciousness": 2,
    "candidate": 6,
    "location": 52,
    "spleen": 1,
    "paul": 1,
    "broca": 2,
    "aphasia": 1,
    "deficit": 1,
    "brain-damaged": 1,
    "patient": 4,
    "organization": 4,
    "identifying": 5,
    "localized": 1,
    "left": 85,
    "hemisphere—now": 1,
    "responsible": 7,
    "production": 3,
    "consisted": 1,
    "cell": 98,
    "neuron": 21,
    "camillo": 1,
    "golgi": 2,
    "staining": 1,
    "figure": 270,
    "cajal": 2,
    "neuronal": 2,
    "accepted": 3,
    "electrochemical": 2,
    "collection": 8,
    "simple": 64,
    "pithy": 1,
    "searle": 1,
    "consists": 19,
    "body": 8,
    "labeled": 333,
    "soma": 2,
    "nucleus": 1,
    "present": 13,
    "center": 4,
    "finger-like": 1,
    "fiber": 4,
    "dendrite": 4,
    "extend": 7,
    "single": 46,
    "extends": 3,
    "tubular": 1,
    "axon": 4,
    "tree-like": 15,
    "projection": 3,
    "axonal": 1,
    "arborization": 1,
    "contact": 2,
    "region": 22,
    "junction": 4,
    "synapse": 1,
    "synapsis": 2,
    "contains": 23,
    "branching": 21,
    "stretch": 3,
    "scale": 3,
    "diagram": 10,
    "indicates": 2,
    "meter": 1,
    "signal": 3,
    "propagated": 2,
    "reaction": 2,
    "short": 4,
    "long-term": 3,
    "connectivity": 1,
    "form": 55,
    "go": 19,
    "cerebral": 1,
    "cortex": 2,
    "outer": 3,
    "layer": 2,
    "basic": 20,
    "organizational": 1,
    "unit": 13,
    "column": 186,
    "tissue": 1,
    "diameter": 2,
    "containing": 4,
    "extending": 3,
    "full": 8,
    "depth": 48,
    "mapping": 9,
    "receive": 4,
    "week": 5,
    "map": 47,
    "damaged": 1,
    "memory": 73,
    "stored": 5,
    "higher-level": 1,
    "operate": 8,
    "intact": 1,
    "invention": 4,
    "han": 2,
    "berger": 1,
    "electroencephalograph": 1,
    "eeg": 1,
    "magnetic": 1,
    "resonance": 1,
    "fmri": 1,
    "ogawa": 1,
    "al.": 55,
    "cabeza": 1,
    "giving": 7,
    "neuroscientist": 2,
    "detailed": 10,
    "image": 16,
    "enabling": 1,
    "ongoing": 1,
    "augmented": 2,
    "advance": 7,
    "single-cell": 1,
    "electrical": 2,
    "recording": 6,
    "optogenetics": 1,
    "crick": 2,
    "zemelman": 1,
    "boyden": 1,
    "modified": 7,
    "light-sensitive": 1,
    "brain-machine": 1,
    "interface": 2,
    "lebedev": 1,
    "nicolelis": 1,
    "sensing": 9,
    "motor": 4,
    "promise": 3,
    "restore": 1,
    "disabled": 1,
    "aspect": 13,
    "neural": 16,
    "remarkable": 6,
    "finding": 27,
    "adjust": 2,
    "treating": 2,
    "organ": 2,
    "limb": 1,
    "digital": 5,
    "show": 78,
    "cycle": 31,
    "storage": 3,
    "interconnection": 1,
    "high-end": 1,
    "personal": 7,
    "supercomputer": 4,
    "metric": 1,
    "futurist": 1,
    "approaching": 4,
    "singularity": 1,
    "superhuman": 3,
    "level": 93,
    "vinge": 1,
    "kurzweil": 1,
    "doctorow": 1,
    "stross": 1,
    "improve": 14,
    "comparison": 8,
    "informative": 2,
    "unlimited": 3,
    "capacity": 6,
    "require": 13,
    "conceptual": 4,
    "breakthrough": 3,
    "block": 221,
    "rectangular": 9,
    "pyramidal": 4,
    "square": 143,
    "shape": 6,
    "thin-walled": 1,
    "transparent": 3,
    "box": 70,
    "top": 46,
    "kept": 6,
    "similar": 22,
    "outside": 3,
    "similar-sized": 1,
    "crude": 3,
    "summit": 1,
    "feldman": 2,
    "typical": 12,
    "changed": 6,
    "megaflop": 1,
    "gigaflops": 1,
    "teraflop": 1,
    "petaflops": 1,
    "exaflop": 1,
    "floating": 1,
    "origin": 4,
    "physicist": 2,
    "hermann": 1,
    "helmholtz": 3,
    "wundt": 3,
    "handbook": 2,
    "physiological": 1,
    "optic": 1,
    "physiology": 2,
    "nalwa": 1,
    "p.15": 1,
    "opened": 1,
    "laboratory": 1,
    "university": 9,
    "leipzig": 1,
    "controlled": 3,
    "worker": 3,
    "perform": 12,
    "associative": 1,
    "introspecting": 1,
    "went": 2,
    "unlikely": 7,
    "experimenter": 1,
    "biologist": 1,
    "studying": 3,
    "lacked": 1,
    "introspective": 1,
    "methodology": 5,
    "jennings": 1,
    "influential": 17,
    "organism": 8,
    "applying": 11,
    "behaviorism": 4,
    "watson": 3,
    "rejected": 2,
    "ground": 3,
    "reliable": 2,
    "behaviorist": 5,
    "percept": 89,
    "stimulus": 3,
    "resulting": 17,
    "lot": 11,
    "rat": 1,
    "less": 17,
    "success": 23,
    "information-processing": 2,
    "william": 1,
    "james": 6,
    "involved": 9,
    "unconscious": 1,
    "eclipsed": 1,
    "united": 6,
    "state": 934,
    "cambridge": 1,
    "directed": 6,
    "frederic": 1,
    "bartlett": 2,
    "flourish": 1,
    "explanation": 1,
    "successor": 46,
    "kenneth": 1,
    "craik": 5,
    "reestablished": 1,
    "legitimacy": 1,
    "pressure": 2,
    "temperature": 6,
    "talk": 3,
    "gas": 7,
    "molecule": 8,
    "key": 11,
    "knowledge-based": 1,
    "translated": 3,
    "manipulated": 3,
    "retranslated": 1,
    "small-scale": 1,
    "conclude": 2,
    "react": 2,
    "utilize": 1,
    "dealing": 2,
    "fuller": 1,
    "safer": 4,
    "competent": 2,
    "manner": 2,
    "emergency": 1,
    "face": 5,
    "death": 1,
    "bicycle": 1,
    "accident": 6,
    "continued": 1,
    "donald": 4,
    "broadbent": 1,
    "communication": 3,
    "phenomenon": 4,
    "workshop": 8,
    "september": 1,
    "mit—just": 1,
    "month": 4,
    "conference": 22,
    "born.": 1,
    "miller": 1,
    "presented": 8,
    "magic": 2,
    "noam": 1,
    "chomsky": 4,
    "psychologist": 2,
    "anderson": 2,
    "purpose": 14,
    "review": 5,
    "human–computer": 1,
    "hci": 2,
    "doug": 1,
    "pioneer": 2,
    "championed": 2,
    "augmentation": 2,
    "—ia": 1,
    "believed": 2,
    "augment": 2,
    "automate": 1,
    "engelbart": 1,
    "mother": 1,
    "demo": 1,
    "mouse": 2,
    "windowing": 1,
    "hypertext": 1,
    "video": 9,
    "conferencing—all": 1,
    "accomplish": 1,
    "likely": 9,
    "side": 8,
    "coin": 2,
    "former": 2,
    "emphasizing": 2,
    "invented": 12,
    "country": 5,
    "embattled": 1,
    "operational": 2,
    "electromechanical": 1,
    "heath": 1,
    "robinson": 3,
    "team": 4,
    "deciphering": 1,
    "message": 1,
    "colossus": 1,
    "powerful": 8,
    "general-purpose": 7,
    "vacuum": 119,
    "tube": 2,
    "programmable": 2,
    "z-3": 1,
    "konrad": 1,
    "zuse": 2,
    "germany": 1,
    "floating-point": 1,
    "high-level": 4,
    "plankalkül": 1,
    "abc": 1,
    "assembled": 1,
    "clifford": 1,
    "berry": 1,
    "iowa": 1,
    "atanasoff": 1,
    "received": 5,
    "support": 4,
    "eniac": 1,
    "secret": 1,
    "military": 3,
    "project": 11,
    "pennsylvania": 1,
    "eckert": 1,
    "forerunner": 2,
    "generation": 11,
    "hardware": 8,
    "decrease": 10,
    "price—a": 1,
    "trend": 2,
    "captured": 2,
    "doubled": 2,
    "dissipation": 1,
    "manufacturer": 1,
    "multiplying": 1,
    "cpu": 4,
    "core": 5,
    "clock": 5,
    "current": 99,
    "expectation": 3,
    "functionality": 1,
    "massive": 1,
    "parallelism—a": 1,
    "curious": 1,
    "convergence": 2,
    "bit": 20,
    "precision": 1,
    "bfloat16": 1,
    "tuned": 1,
    "graphic": 1,
    "gpu": 3,
    "tensor": 1,
    "tpu": 2,
    "wafer": 1,
    "engine": 7,
    "wse": 1,
    "train": 2,
    "followed": 7,
    "300,000-fold": 1,
    "doubling": 3,
    "amodei": 1,
    "hernandez": 1,
    "took": 3,
    "minute": 16,
    "ying": 1,
    "practical": 14,
    "quantum": 1,
    "subclass": 2,
    "earliest": 2,
    "dating": 1,
    "17th": 2,
    "page": 17,
    "loom": 1,
    "joseph": 1,
    "marie": 1,
    "jacquard": 1,
    "punched": 2,
    "card": 4,
    "instruction": 2,
    "mid-19th": 1,
    "charles": 3,
    "babbage": 4,
    "completed": 2,
    "table": 35,
    "swade": 1,
    "analytical": 4,
    "ambitious": 2,
    "addressable": 1,
    "conditional": 14,
    "jump": 4,
    "colleague": 3,
    "ada": 1,
    "lovelace": 3,
    "daughter": 1,
    "poet": 1,
    "lord": 1,
    "byron": 1,
    "potential": 10,
    "universe": 7,
    "anticipated": 1,
    "hype": 1,
    "desirable": 5,
    "guard": 1,
    "possibility": 15,
    "exaggerated": 1,
    "engine.": 1,
    "unfortunately": 3,
    "forgotten": 9,
    "owes": 1,
    "debt": 2,
    "software": 10,
    "supplied": 3,
    "write": 7,
    "repaid": 1,
    "mainstream": 1,
    "sharing": 1,
    "interactive": 1,
    "interpreter": 2,
    "window": 4,
    "rapid": 3,
    "linked-list": 1,
    "type": 19,
    "automatic": 7,
    "management": 2,
    "symbolic": 9,
    "declarative": 1,
    "object-oriented": 1,
    "cybernetics": 2,
    "artifact": 4,
    "ktesibios": 1,
    "alexandria": 1,
    "self-controlling": 1,
    "water": 2,
    "regulator": 1,
    "maintained": 3,
    "constant": 13,
    "flow": 3,
    "rate": 7,
    "living": 2,
    "modify": 7,
    "self-regulating": 1,
    "feedback": 6,
    "steam": 1,
    "governor": 1,
    "created": 5,
    "watt": 1,
    "thermostat": 1,
    "cornelis": 1,
    "drebbel": 1,
    "submarine": 1,
    "clerk": 1,
    "post-war": 1,
    "norbert": 4,
    "wiener": 10,
    "brilliant": 1,
    "biological": 2,
    "arturo": 1,
    "rosenblueth": 2,
    "julian": 1,
    "bigelow": 1,
    "challenged": 2,
    "orthodoxy": 1,
    "purposive": 1,
    "arising": 2,
    "regulatory": 1,
    "trying": 20,
    "minimize": 6,
    "error": 7,
    "—the": 4,
    "late": 3,
    "warren": 2,
    "mcculloch": 4,
    "walter": 3,
    "pitt": 5,
    "organized": 3,
    "explored": 5,
    "bestseller": 1,
    "awoke": 1,
    "ashby": 4,
    "grey": 2,
    "ratio": 11,
    "club": 1,
    "appeared.": 1,
    "elaborated": 2,
    "homeostatic": 1,
    "appropriate": 20,
    "loop": 20,
    "stable": 1,
    "adaptive": 3,
    "stochastic": 23,
    "behave": 6,
    "close": 13,
    "founder": 2,
    "coupling": 2,
    "familiar": 3,
    "participant": 1,
    "encompassed": 1,
    "calculus": 7,
    "matrix": 4,
    "algebra": 2,
    "lend": 1,
    "describable": 1,
    "continuous": 26,
    "variable": 228,
    "founded": 3,
    "escape": 7,
    "perceived": 3,
    "limitation": 6,
    "fell": 2,
    "theorist": 6,
    "purview": 1,
    "linguistics": 4,
    "relate": 1,
    "skinner": 1,
    "verbal": 1,
    "foremost": 1,
    "served": 1,
    "kill": 1,
    "linguist": 4,
    "syntactic": 2,
    "pointed": 2,
    "creativity": 1,
    "language—it": 1,
    "child": 101,
    "heard": 1,
    "theory—based": 1,
    "going": 18,
    "indian": 2,
    "panini": 1,
    "previous": 26,
    "programmed": 2,
    "born": 1,
    "grew": 1,
    "intersecting": 2,
    "hybrid": 4,
    "turned": 6,
    "seemed": 4,
    "context": 4,
    "obvious": 11,
    "tied": 3,
    "informed": 9,
    "quick": 1,
    "summarize": 4,
    "milestone": 1,
    "list": 18,
    "award": 2,
    "winner": 1,
    "marvin": 4,
    "minsky": 11,
    "mccarthy": 13,
    "feigenbaum": 5,
    "raj": 1,
    "reddy": 3,
    "encode": 2,
    "real-world": 13,
    "judea": 2,
    "principled": 1,
    "yoshua": 1,
    "bengio": 1,
    "geoffrey": 2,
    "hinton": 5,
    "yann": 1,
    "lecun": 2,
    "deep": 22,
    "multilayer": 2,
    "network": 31,
    "critical": 2,
    "phase": 2,
    "done": 22,
    "inspired": 2,
    "advisor": 1,
    "nicolas": 1,
    "rashevsky": 1,
    "drew": 1,
    "whitehead": 2,
    "switch": 5,
    "occurring": 3,
    "stimulation": 1,
    "sufficient": 5,
    "neighboring": 13,
    "conceived": 2,
    "equivalent": 6,
    "adequate": 2,
    "stimulus.": 1,
    "connective": 1,
    "hebb": 2,
    "demonstrated": 6,
    "modifying": 2,
    "strength": 2,
    "hebbian": 1,
    "undergraduate": 1,
    "harvard": 1,
    "dean": 1,
    "narc": 1,
    "pilot": 1,
    "b-24": 1,
    "bomber": 1,
    "simulate": 5,
    "princeton": 2,
    "ph.d.": 2,
    "committee": 1,
    "skeptical": 2,
    "someday.": 1,
    "checkers-playing": 1,
    "christopher": 1,
    "strachey": 1,
    "manchester": 1,
    "arthur": 4,
    "samuel": 11,
    "ibm": 5,
    "lecture": 3,
    "articulated": 1,
    "persuasive": 1,
    "agenda": 1,
    "article": 8,
    "machinery": 1,
    "intelligence.": 1,
    "therein": 1,
    "genetic": 29,
    "objection": 1,
    "raised": 3,
    "easier": 8,
    "human-level": 5,
    "teaching": 4,
    "subsequent": 6,
    "warned": 2,
    "race": 4,
    "dartmouth": 5,
    "college": 3,
    "convinced": 1,
    "claude": 1,
    "shannon": 1,
    "nathaniel": 2,
    "rochester": 2,
    "help": 18,
    "bring": 4,
    "u.s.": 7,
    "interested": 3,
    "net": 2,
    "two-month": 1,
    "summer": 3,
    "attendee": 2,
    "carnegie": 2,
    "tech": 1,
    "ray": 1,
    "solomonoff": 1,
    "selfridge": 1,
    "mit": 5,
    "proposal": 2,
    "propose": 4,
    "carried": 8,
    "hanover": 1,
    "hampshire": 1,
    "proceed": 1,
    "conjecture": 2,
    "feature": 8,
    "find": 103,
    "abstraction": 10,
    "reserved": 1,
    "significant": 10,
    "selected": 11,
    "optimistic": 6,
    "mature": 1,
    "theorem-proving": 2,
    "venerable": 2,
    "mind–body": 1,
    "problem.": 1,
    "principia": 2,
    "mathematica": 1,
    "delighted": 1,
    "told": 2,
    "shorter": 1,
    "editor": 3,
    "journal": 12,
    "impressed": 1,
    "coauthored": 1,
    "enthusiasm": 2,
    "establishment": 3,
    "preferred": 6,
    "gathered": 1,
    "responded": 1,
    "demonstrating": 2,
    "particular": 23,
    "indicative": 1,
    "puzzle": 34,
    "referred": 1,
    "era": 2,
    "problem-solving": 13,
    "protocol": 1,
    "handle": 14,
    "subgoals": 2,
    "approached": 1,
    "embody": 3,
    "symbol": 5,
    "action.": 1,
    "meant": 2,
    "exhibiting": 1,
    "manipulating": 1,
    "composed": 2,
    "direction": 29,
    "geometry": 1,
    "prover": 2,
    "quite": 2,
    "tricky": 4,
    "precursor": 3,
    "provers": 1,
    "exploratory": 2,
    "checker": 2,
    "draught": 1,
    "learned": 5,
    "play": 5,
    "amateur": 2,
    "disproved": 1,
    "creator": 2,
    "television": 1,
    "trouble": 2,
    "night": 1,
    "testing": 2,
    "floor": 9,
    "manufacturing": 3,
    "plant": 2,
    "td-g": 1,
    "ammon": 1,
    "tesauro": 1,
    "backgammon": 1,
    "lpha": 5,
    "shocked": 1,
    "defeating": 1,
    "champion": 6,
    "contribution": 3,
    "memo": 1,
    "lisp": 1,
    "become": 21,
    "dominant": 1,
    "entitled": 1,
    "describes": 15,
    "advice": 4,
    "taker": 3,
    "hypothetical": 1,
    "illustrated": 7,
    "axiom": 2,
    "suffice": 3,
    "drive": 9,
    "airport": 17,
    "normal": 5,
    "competence": 2,
    "reprogrammed": 1,
    "embodied": 3,
    "explicit": 10,
    "deductive": 1,
    "influenced": 1,
    "marked": 17,
    "moved": 5,
    "collaboration": 1,
    "stressed": 1,
    "getting": 12,
    "anti-logic": 1,
    "outlook": 1,
    "stanford": 7,
    "discovery": 1,
    "resolution": 4,
    "cordell": 1,
    "green": 62,
    "question-answering": 1,
    "shakey": 4,
    "institute": 1,
    "sri": 2,
    "latter": 4,
    "integration": 4,
    "supervised": 1,
    "chose": 1,
    "appeared": 6,
    "domain": 97,
    "microworlds": 2,
    "slagle": 2,
    "aint": 2,
    "closed-form": 1,
    "first-year": 1,
    "tom": 3,
    "evans": 1,
    "nalogy": 1,
    "geometric": 4,
    "analogy": 2,
    "bobrow": 1,
    "tudent": 1,
    "story": 5,
    "customer": 2,
    "percent": 13,
    "advertisement": 2,
    "microworld": 1,
    "solid": 63,
    "placed": 12,
    "tabletop": 1,
    "rearrange": 1,
    "pick": 11,
    "home": 2,
    "huffman": 1,
    "constraint-propagation": 1,
    "patrick": 3,
    "winston": 3,
    "natural-language-understanding": 1,
    "terry": 1,
    "winograd": 3,
    "planner": 1,
    "scott": 1,
    "fahlman": 1,
    "scene": 1,
    "hrdlu": 2,
    "command": 1,
    "taller": 1,
    "holding": 1,
    "flourished": 1,
    "shmuel": 1,
    "jack": 1,
    "cowan": 1,
    "represent": 26,
    "robustness": 1,
    "parallelism": 1,
    "enhanced": 1,
    "bernie": 1,
    "widrow": 3,
    "hoff": 1,
    "adalines": 1,
    "frank": 1,
    "rosenblatt": 1,
    "perceptrons": 3,
    "dose": 1,
    "shy": 1,
    "coming": 4,
    "quoted": 1,
    "aim": 13,
    "surprise": 1,
    "shock": 1,
    "you—but": 1,
    "simplest": 10,
    "until—in": 1,
    "visible": 3,
    "future—the": 1,
    "range": 13,
    "coextensive": 1,
    "vague": 1,
    "concrete": 4,
    "came": 6,
    "overconfidence": 1,
    "promising": 2,
    "failed": 4,
    "main": 14,
    "solution": 265,
    "lack": 4,
    "appreciation": 2,
    "intractability": 2,
    "attempting": 1,
    "strategy": 22,
    "contained": 5,
    "scaling": 1,
    "faster": 3,
    "dampened": 1,
    "dozen": 4,
    "practice": 18,
    "illusion": 1,
    "confined": 1,
    "evolution": 14,
    "friedberg": 3,
    "mutation": 17,
    "machine-code": 1,
    "random": 32,
    "selection": 20,
    "preserve": 1,
    "hour": 10,
    "grip": 1,
    "combinatorial": 4,
    "explosion": 1,
    "criticism": 1,
    "lighthill": 3,
    "report": 7,
    "british": 3,
    "government": 6,
    "oral": 1,
    "paint": 1,
    "colorful": 2,
    "political": 2,
    "ambition": 2,
    "animosity": 1,
    "difficulty": 11,
    "arose": 1,
    "papert": 1,
    "representing": 9,
    "two-input": 1,
    "trained": 1,
    "recognize": 3,
    "funding": 3,
    "neural-net": 2,
    "dwindled": 1,
    "back-propagation": 2,
    "enormous": 2,
    "kelley": 1,
    "bryson": 1,
    "arisen": 1,
    "weak": 2,
    "domain-specific": 6,
    "narrow": 3,
    "expertise": 2,
    "hard": 14,
    "endral": 6,
    "buchanan": 3,
    "bruce": 1,
    "joshua": 1,
    "lederberg": 1,
    "laureate": 1,
    "geneticist": 1,
    "teamed": 1,
    "inferring": 1,
    "molecular": 1,
    "mass": 9,
    "spectrometer": 1,
    "spectrum": 5,
    "fragment": 3,
    "generated": 48,
    "bombarded": 1,
    "electron": 1,
    "beam": 16,
    "contain": 8,
    "peak": 13,
    "methyl": 1,
    "naive": 1,
    "consistent": 41,
    "predicted": 10,
    "observed": 3,
    "expect": 5,
    "moderate-sized": 1,
    "consulted": 1,
    "chemist": 1,
    "looking": 12,
    "well-known": 2,
    "substructure": 2,
    "ketone": 2,
    "c=o": 1,
    "subgroup": 2,
    "weighs": 1,
    "whole": 11,
    "recognizing": 2,
    "reduces": 6,
    "spectroscopy": 1,
    "cookbook": 1,
    "recipe": 1,
    "significance": 1,
    "knowledge-intensive": 1,
    "derived": 8,
    "special-purpose": 3,
    "heuristic": 177,
    "hpp": 1,
    "investigate": 1,
    "major": 12,
    "ycin": 4,
    "blood": 3,
    "infection": 2,
    "junior": 1,
    "existed": 1,
    "deduced": 2,
    "extensive": 2,
    "interviewing": 1,
    "reflect": 5,
    "associated": 2,
    "medical": 6,
    "incorporated": 2,
    "factor": 27,
    "fit": 10,
    "well": 1,
    "assessed": 1,
    "diagnosis": 6,
    "commercial": 5,
    "corporation": 4,
    "mcdermott": 2,
    "configure": 1,
    "saving": 6,
    "company": 9,
    "estimated": 14,
    "dec": 1,
    "dupont": 1,
    "investigating": 1,
    "ambiguity": 1,
    "relied": 2,
    "tiny": 3,
    "eugene": 1,
    "charniak": 1,
    "roger": 1,
    "schank": 5,
    "yale": 1,
    "robust": 5,
    "claiming": 1,
    "syntax": 2,
    "upset": 2,
    "serve": 2,
    "abelson": 1,
    "wilensky": 1,
    "riesbeck": 1,
    "widespread": 5,
    "logic—for": 1,
    "prolog": 3,
    "japan": 2,
    "lanner": 1,
    "family": 7,
    "adopted": 4,
    "structured": 10,
    "assembling": 1,
    "arranging": 1,
    "taxonomic": 1,
    "hierarchy": 1,
    "analogous": 4,
    "taxonomy": 1,
    "japanese": 1,
    "announced": 1,
    "fifth": 19,
    "10-year": 1,
    "parallel": 4,
    "running": 8,
    "budget": 1,
    "exceed": 5,
    "microelectronics": 1,
    "technology": 5,
    "consortium": 1,
    "assure": 1,
    "national": 1,
    "competitiveness": 1,
    "broad": 5,
    "chip": 3,
    "human-interface": 1,
    "alvey": 1,
    "reinstated": 1,
    "removed": 6,
    "none": 6,
    "met": 3,
    "overall": 11,
    "industry": 4,
    "boomed": 1,
    "billion": 6,
    "hundred": 10,
    "specialized": 4,
    "deliver": 1,
    "extravagant": 1,
    "maintain": 5,
    "broke": 1,
    "mid-1980s": 2,
    "reinvented": 2,
    "dissemination": 1,
    "distributed": 8,
    "rumelhart": 1,
    "mcclelland": 1,
    "caused": 4,
    "excitement": 1,
    "connectionist": 2,
    "direct": 4,
    "competitor": 1,
    "symbols—in": 1,
    "anthropologist": 1,
    "terrence": 1,
    "deacon": 1,
    "specie": 3,
    "suggests": 5,
    "characteristic": 2,
    "geoff": 1,
    "luminiferous": 1,
    "reference": 5,
    "non-existent": 1,
    "medium": 5,
    "19th-century": 2,
    "electromagnetic": 1,
    "wave": 4,
    "name": 13,
    "fail": 6,
    "closer": 6,
    "inspection": 2,
    "hoped": 1,
    "axiomatic": 1,
    "fluid": 1,
    "imprecise": 1,
    "suited": 1,
    "messiness": 1,
    "examples—they": 1,
    "compare": 6,
    "output": 4,
    "parameter": 3,
    "brittleness": 1,
    "incorporating": 2,
    "hand-coding": 1,
    "existing": 3,
    "brand-new": 3,
    "base": 3,
    "cohen": 1,
    "intuition": 1,
    "relevance": 2,
    "toy": 1,
    "shared": 2,
    "benchmark": 3,
    "norm": 1,
    "irvine": 1,
    "repository": 4,
    "international": 15,
    "competition": 6,
    "librispeech": 1,
    "corpus": 2,
    "mnist": 1,
    "handwritten": 2,
    "digit": 20,
    "imagenet": 5,
    "coco": 1,
    "answering": 4,
    "wmt": 1,
    "translation": 7,
    "sat": 4,
    "satisfiability": 3,
    "rebellion": 1,
    "embraced": 1,
    "positive": 11,
    "mcallester": 3,
    "plausible": 1,
    "frame": 4,
    "classical": 3,
    "obsolete": 1,
    "isolationism": 2,
    "separated": 1,
    "abandoned": 2,
    "isolated": 5,
    "optimization": 34,
    "static": 11,
    "illustrates": 3,
    "architecture": 10,
    "hoc": 1,
    "fragile": 2,
    "hidden": 3,
    "hmms": 5,
    "dominate": 1,
    "training": 4,
    "ensures": 2,
    "blind": 1,
    "score": 9,
    "character": 2,
    "transition": 23,
    "industrial": 1,
    "consumer": 1,
    "comfortable": 1,
    "narrative": 1,
    "acceptance": 3,
    "pearl": 10,
    "bayesian": 4,
    "formalism": 4,
    "cover": 12,
    "increased": 12,
    "expressive": 7,
    "rich": 1,
    "sutton": 2,
    "connecting": 4,
    "learning—which": 1,
    "checker-playing": 2,
    "flood": 1,
    "mdps": 1,
    "acquiring": 1,
    "newfound": 1,
    "gradual": 1,
    "reunification": 1,
    "reintegration": 1,
    "benefit": 12,
    "applications—for": 2,
    "deployment": 1,
    "expanded": 54,
    "period—and": 1,
    "big": 6,
    "web": 6,
    "facilitated": 1,
    "sets—a": 1,
    "trillion": 1,
    "vast": 9,
    "genomic": 1,
    "vehicle": 12,
    "tracking": 1,
    "clickstream": 1,
    "majority": 3,
    "unlabeled": 10,
    "yarowsky": 1,
    "word-sense": 1,
    "disambiguation": 1,
    "occurrence": 1,
    "indicate": 3,
    "refer": 3,
    "flora": 1,
    "factory": 4,
    "accuracy": 9,
    "moreover": 1,
    "banko": 1,
    "brill": 1,
    "improvement": 10,
    "obtained": 8,
    "magnitude": 3,
    "tweaking": 1,
    "occur": 11,
    "filling": 2,
    "hole": 1,
    "photographs—holes": 1,
    "damage": 1,
    "removal": 4,
    "ex-friends": 1,
    "hay": 1,
    "efros": 1,
    "clever": 2,
    "blending": 1,
    "pixel": 2,
    "poorly": 1,
    "database": 23,
    "crossed": 1,
    "threshold": 1,
    "million": 10,
    "ten": 7,
    "deng": 2,
    "sparked": 2,
    "revolution": 1,
    "shift": 5,
    "recover": 4,
    "attractiveness": 1,
    "havenstein": 1,
    "halevy": 1,
    "victory": 3,
    "jeopardy": 3,
    "quiz": 1,
    "2011–present": 1,
    "refers": 6,
    "adjustable": 1,
    "convolutional": 1,
    "hand-written": 1,
    "occurred": 4,
    "visual": 5,
    "classifying": 1,
    "category": 5,
    "armadillo": 1,
    "corkscrew": 1,
    "krizhevsky": 1,
    "dramatic": 1,
    "handcrafted": 1,
    "exceeded": 3,
    "lag": 2,
    "gain": 5,
    "reported": 1,
    "evaluation": 26,
    "silver": 3,
    "investor": 1,
    "news": 4,
    "exceeding": 3,
    "speculation": 1,
    "accelerated": 1,
    "winter": 1,
    "relies": 2,
    "fpga": 1,
    "consume": 1,
    "parallelized": 1,
    "vector": 7,
    "depends": 17,
    "algorithmic": 5,
    "trick": 9,
    "ai100": 2,
    "convenes": 1,
    "panel": 1,
    "stone": 2,
    "grosz": 1,
    "substantial": 2,
    "healthcare": 2,
    "diagnostics": 1,
    "targeted": 1,
    "treatment": 2,
    "assistance": 3,
    "elder": 1,
    "care": 9,
    "juncture": 1,
    "determining": 2,
    "deploy": 2,
    "ai-based": 1,
    "promote": 1,
    "democratic": 1,
    "freedom": 1,
    "equality": 2,
    "transparency.": 1,
    "index": 5,
    "aiindex.org": 1,
    "track": 24,
    "highlight": 2,
    "baseline": 5,
    "stated": 5,
    "publication": 3,
    "20-fold": 2,
    "neutral": 1,
    "tone": 1,
    "ethical": 4,
    "privacy": 2,
    "bias": 3,
    "enrollment": 1,
    "5-fold": 1,
    "16-fold": 1,
    "specialization": 1,
    "diversity": 4,
    "professor": 2,
    "worldwide": 1,
    "male": 1,
    "female": 2,
    "hire": 2,
    "neurips": 1,
    "seeing": 2,
    "startup": 1,
    "internationalization": 1,
    "publishes": 1,
    "citation-weighted": 1,
    "chinese": 1,
    "singapore": 1,
    "brazil": 1,
    "canada": 1,
    "fastest": 2,
    "growing": 2,
    "detection": 5,
    "lsvrc": 1,
    "large-scale": 2,
    "challenge": 4,
    "open-ended": 1,
    "vqa": 1,
    "dropped": 2,
    "measured": 3,
    "dataset": 1,
    "variant": 14,
    "poker": 3,
    "pac-man": 1,
    "chinese-to-english": 1,
    "restricted": 2,
    "quake": 2,
    "dota": 2,
    "starcraft": 2,
    "atari": 1,
    "skin": 2,
    "cancer": 3,
    "prostate": 1,
    "folding": 1,
    "diabetic": 1,
    "retinopathy": 1,
    "ford": 3,
    "interview": 2,
    "target": 3,
    "grace": 1,
    "respondent": 1,
    "never.": 1,
    "split": 5,
    "philip": 1,
    "tetlock": 1,
    "demonstrates": 1,
    "predicting": 4,
    "itself—first": 1,
    "bold": 25,
    "encoding": 1,
    "induce": 1,
    "well-understood": 1,
    "reveal": 1,
    "robotic": 11,
    "radio-controlled": 1,
    "demonstration": 2,
    "autonomous": 13,
    "special": 8,
    "kanade": 1,
    "dickmanns": 1,
    "zapp": 1,
    "dirt": 43,
    "132-mile": 1,
    "darpa": 2,
    "grand": 2,
    "thrun": 1,
    "street": 8,
    "traffic": 14,
    "urban": 2,
    "earnest": 1,
    "waymo": 1,
    "landmark": 29,
    "mile": 11,
    "serious": 3,
    "stepping": 2,
    "offering": 1,
    "taxi": 30,
    "service": 8,
    "air": 3,
    "fixed-wing": 1,
    "drone": 1,
    "providing": 2,
    "cross-country": 2,
    "delivery": 1,
    "rwanda": 1,
    "quadcopters": 1,
    "aerobatic": 1,
    "maneuver": 2,
    "explore": 9,
    "constructing": 4,
    "3-d": 1,
    "self-assemble": 1,
    "formation": 1,
    "legged": 1,
    "locomotion": 1,
    "bigdog": 1,
    "quadruped": 1,
    "raibert": 1,
    "upended": 1,
    "slow": 2,
    "stiff-legged": 1,
    "side-to-side": 1,
    "gait": 1,
    "hollywood": 1,
    "movie": 1,
    "resembling": 1,
    "shoved": 1,
    "slipping": 1,
    "icy": 1,
    "puddle": 2,
    "atlas": 1,
    "humanoid": 1,
    "walk": 12,
    "terrain": 2,
    "backflips": 1,
    "ackerman": 1,
    "guizzo": 1,
    "scheduling": 17,
    "nasa": 2,
    "remote": 2,
    "spacecraft": 1,
    "jonsson": 1,
    "monitored": 1,
    "execution": 4,
    "plans—detecting": 1,
    "recovering": 1,
    "toolkit": 1,
    "barreiro": 1,
    "daily": 2,
    "mar": 1,
    "rover": 1,
    "extant": 1,
    "winternitz": 1,
    "navigation": 5,
    "space": 168,
    "global": 25,
    "persian": 1,
    "gulf": 1,
    "crisis": 1,
    "force": 1,
    "dynamic": 17,
    "replanning": 1,
    "cross": 15,
    "walker": 3,
    "logistics": 1,
    "transportation": 1,
    "cargo": 2,
    "route": 23,
    "transport": 1,
    "port": 3,
    "airfield": 1,
    "conflict": 35,
    "defense": 1,
    "agency": 2,
    "paid": 1,
    "30-year": 1,
    "ride": 1,
    "hailing": 1,
    "uber": 1,
    "google": 4,
    "user": 12,
    "plotting": 1,
    "online": 40,
    "reading": 2,
    "document": 1,
    "native": 1,
    "render": 3,
    "french": 3,
    "english": 3,
    "microsoft": 2,
    "conversational": 1,
    "reached": 54,
    "matching": 2,
    "switchboard": 1,
    "transcribing": 1,
    "telephone": 1,
    "conversation": 2,
    "xiong": 1,
    "voice": 3,
    "keyboard": 1,
    "skype": 1,
    "real-time": 2,
    "speech-to-speech": 1,
    "siri": 1,
    "cortana": 1,
    "assistant": 2,
    "duplex": 1,
    "synthesis": 1,
    "restaurant": 1,
    "reservation": 1,
    "carrying": 2,
    "fluent": 1,
    "recommendation": 2,
    "amazon": 1,
    "facebook": 1,
    "netflix": 1,
    "spotify": 1,
    "youtube": 2,
    "walmart": 1,
    "recommend": 4,
    "past": 5,
    "recommender": 1,
    "resnick": 1,
    "varian": 1,
    "changing": 3,
    "music": 1,
    "metadata": 1,
    "van": 11,
    "den": 1,
    "oord": 1,
    "zhang": 2,
    "spam": 2,
    "filtering": 2,
    "dis-recommendation": 1,
    "filter": 1,
    "email": 2,
    "recipient": 1,
    "blue": 46,
    "defeated": 1,
    "garry": 1,
    "kasparov": 1,
    "defender": 1,
    "supremacy": 1,
    "piet": 1,
    "hut": 1,
    "astrophysicist": 1,
    "enthusiast": 1,
    "beat": 2,
    "surpassed": 1,
    "jie": 1,
    "played": 3,
    "god": 2,
    "go.": 1,
    "benefited": 1,
    "distilled": 1,
    "followup": 1,
    "ero": 1,
    "self-play": 1,
    "defeat": 1,
    "shogi": 1,
    "beaten": 1,
    "diverse": 4,
    "ferrucci": 1,
    "bowling": 1,
    "moravčík": 1,
    "brown": 3,
    "sandholm": 1,
    "fernandez": 1,
    "mahlmann": 1,
    "vinyals": 2,
    "jaderberg": 1,
    "challenging": 1,
    "captioning": 1,
    "impressive": 2,
    "riding": 1,
    "motorcycle": 1,
    "pizza": 1,
    "sitting": 3,
    "oven": 1,
    "young": 1,
    "frisbee": 1,
    "refrigerator": 1,
    "filled": 6,
    "food": 3,
    "drink": 2,
    "no-parking": 1,
    "sign": 5,
    "obscured": 1,
    "sticker": 1,
    "medicine": 2,
    "equal": 45,
    "alzheimer": 1,
    "ding": 1,
    "metastatic": 2,
    "liu": 4,
    "esteva": 1,
    "ophthalmic": 1,
    "gulshan": 1,
    "systematic": 8,
    "meta-analysis": 1,
    "health": 1,
    "professional": 2,
    "facilitating": 1,
    "human–machine": 1,
    "partnership": 2,
    "yna": 1,
    "achieves": 5,
    "breast": 1,
    "cancer—better": 1,
    "unaided": 1,
    "expert—but": 1,
    "steiner": 1,
    "adoption": 1,
    "diagnostic": 1,
    "clinical": 1,
    "ensure": 6,
    "transparency": 1,
    "topol": 1,
    "approved": 1,
    "fda": 1,
    "continues": 6,
    "rise": 6,
    "climate": 5,
    "gordon": 1,
    "discovers": 1,
    "extreme": 3,
    "weather": 4,
    "buried": 1,
    "exaop": 1,
    "kurth": 1,
    "rolnick": 1,
    "60-page": 1,
    "catalog": 1,
    "tackle": 1,
    "fiction—but": 1,
    "credited": 1,
    "wisdom": 1,
    "ambiguous": 1,
    "serving": 1,
    "hurt": 2,
    "remedy.": 1,
    "remedies—in": 1,
    "parlance": 1,
    "summarized": 2,
    "covered": 8,
    "entire": 16,
    "civilization": 1,
    "product": 2,
    "access": 8,
    "ceiling": 1,
    "humanity": 1,
    "menial": 1,
    "repetitive": 1,
    "presage": 1,
    "peace": 1,
    "accelerate": 1,
    "cure": 2,
    "shortage": 1,
    "demis": 1,
    "hassabis": 1,
    "ceo": 1,
    "deepmind": 1,
    "everything": 6,
    "else.": 1,
    "opportunity": 4,
    "incur": 2,
    "misuse": 3,
    "inadvertent": 1,
    "lethal": 2,
    "weapon": 6,
    "locate": 1,
    "select": 13,
    "eliminate": 13,
    "intervention": 2,
    "primary": 3,
    "scalability": 1,
    "absence": 1,
    "requirement": 10,
    "supervision": 1,
    "criterion": 6,
    "moving": 24,
    "pre-treaty": 1,
    "stage": 16,
    "governmental": 1,
    "surveillance": 2,
    "persuasion": 1,
    "expensive": 6,
    "tedious": 1,
    "questionable": 1,
    "security": 1,
    "personnel": 4,
    "monitor": 3,
    "phone": 1,
    "line": 130,
    "camera": 11,
    "feed": 2,
    "messaging": 1,
    "channel": 3,
    "scalable": 1,
    "fashion": 1,
    "tailoring": 1,
    "extent—a": 1,
    "election": 1,
    "biased": 2,
    "careless": 1,
    "evaluating": 3,
    "parole": 1,
    "loan": 1,
    "gender": 1,
    "protected": 1,
    "employment": 2,
    "eliminating": 3,
    "job": 8,
    "productive": 1,
    "employable": 1,
    "profitable": 1,
    "higher": 8,
    "wage": 1,
    "impractical": 1,
    "tends": 3,
    "shifting": 1,
    "labor": 2,
    "capital": 1,
    "exacerbating": 1,
    "inequality": 8,
    "technology—such": 1,
    "looms—have": 1,
    "resulted": 1,
    "disruption": 1,
    "safety-critical": 2,
    "high-stakes": 1,
    "managing": 1,
    "supply": 4,
    "city": 30,
    "fatal": 1,
    "verification": 1,
    "technical": 4,
    "comparable": 3,
    "prevalent": 1,
    "life": 6,
    "stake": 1,
    "cybersecurity": 1,
    "defending": 1,
    "cyberattack": 1,
    "detecting": 1,
    "unusual": 1,
    "contribute": 4,
    "potency": 1,
    "survivability": 1,
    "proliferation": 1,
    "malware": 1,
    "personalized": 1,
    "blackmail": 1,
    "phishing": 1,
    "attack": 6,
    "revisit": 1,
    "societal": 2,
    "perpetrate": 2,
    "mischief": 2,
    "governance": 1,
    "regulation": 2,
    "community": 8,
    "voluntary": 1,
    "self-governance": 1,
    "ai-related": 1,
    "setting": 3,
    "advisory": 1,
    "devise": 3,
    "prepare": 1,
    "longer": 5,
    "long-standing": 1,
    "overshadowed": 1,
    "grind": 2,
    "subfield": 3,
    "game-playing": 3,
    "understanding—often": 1,
    "assumption": 7,
    "broader": 2,
    "nil": 3,
    "nilsson": 11,
    "original": 20,
    "leader": 1,
    "reminded": 1,
    "beal": 1,
    "concurred": 1,
    "warning": 5,
    "focusing": 2,
    "measurable": 1,
    "root": 38,
    "striving": 2,
    "herb": 1,
    "create.": 1,
    "hlai—a": 1,
    "symposium": 2,
    "agi": 1,
    "goertzel": 1,
    "superintelligence": 2,
    "asi": 1,
    "—intelligence": 1,
    "surpasses": 1,
    "ability—might": 1,
    "yudkowsky": 1,
    "drawing": 3,
    "butler": 2,
    "probable": 1,
    "outstrip": 1,
    "feeble": 1,
    "mentioned": 6,
    "erewhon": 1,
    "pronouncement": 1,
    "stephen": 1,
    "hawking": 1,
    "bill": 1,
    "gate": 3,
    "martin": 2,
    "rees": 1,
    "elon": 1,
    "musk": 1,
    "experiencing": 1,
    "unease": 1,
    "superintelligent": 2,
    "gorilla": 3,
    "now-extinct": 1,
    "primate": 1,
    "evolved": 1,
    "happy": 6,
    "cede": 1,
    "future—then": 1,
    "stop": 3,
    "corollary": 1,
    "essence": 2,
    "black": 39,
    "arrived": 1,
    "wise": 1,
    "exercise": 11,
    "caution": 1,
    "sure": 8,
    "culture": 1,
    "myth": 1,
    "genie": 1,
    "magician": 1,
    "devil": 1,
    "regret": 1,
    "undo": 3,
    "king": 17,
    "midas": 4,
    "legendary": 1,
    "mythology": 1,
    "asked": 2,
    "touched": 2,
    "gold": 1,
    "regretted": 1,
    "touching": 2,
    "member": 4,
    "modification": 4,
    "putting": 7,
    "predicament": 1,
    "strive": 1,
    "unfortunate": 2,
    "date": 4,
    "material": 2,
    "edition": 1,
    "reflects": 3,
    "switched": 3,
    "inverse": 2,
    "principal": 4,
    "depend": 8,
    "invert": 1,
    "group—so": 1,
    "summary": 11,
    "defines": 5,
    "establishes": 2,
    "cultural": 1,
    "background": 4,
    "follows": 28,
    "ideal": 1,
    "pursues": 1,
    "replaced": 5,
    "conceivable": 1,
    "encoded": 3,
    "groundwork": 1,
    "maximize": 11,
    "ever-more-powerful": 1,
    "usable": 1,
    "misplaced": 7,
    "cutback": 1,
    "introducing": 2,
    "creative": 1,
    "refining": 1,
    "matured": 1,
    "compared": 6,
    "hand-crafted": 1,
    "controlling": 1,
    "evolve": 1,
    "unpredictable": 1,
    "necessitate": 1,
    "bibliographical": 11,
    "historical": 12,
    "pedro": 1,
    "domingo": 1,
    "overview": 3,
    "leadership": 1,
    "advancement": 1,
    "aaai": 4,
    "acm": 2,
    "sigai": 1,
    "sigart": 1,
    "european": 2,
    "behaviour": 1,
    "aisb": 1,
    "nonprofit": 1,
    "magazine": 2,
    "topical": 1,
    "tutorial": 2,
    "site": 5,
    "aaai.org": 1,
    "proceeding": 1,
    "ijcai": 2,
    "ecai": 1,
    "ieee": 3,
    "transaction": 2,
    "eye": 6,
    "learning.": 1,
    "irrational": 3,
    "dictionary": 1,
    "deprived": 2,
    "clarity.": 1,
    "conceding": 1,
    "ruy": 1,
    "lopez": 1,
    "place": 22,
    "board": 23,
    "sun": 1,
    "eyes.": 1,
    "update": 17,
    "organon": 1,
    "instrument": 1,
    "logic—an": 1,
    "arcane": 1,
    "textual": 1,
    "features—never": 1,
    "tree": 192,
    "shrew": 1,
    "brain/body": 1,
    "cite": 1,
    "alexander": 1,
    "hood": 1,
    "prior": 3,
    "persisted": 1,
    "embedded": 1,
    "propounded": 1,
    "doctrine.": 1,
    "antagonistic": 1,
    "named": 4,
    "cartoonist": 1,
    "depicted": 12,
    "whimsical": 1,
    "contraption": 1,
    "everyday": 1,
    "buttering": 1,
    "toast": 1,
    "postwar": 1,
    "wanted": 3,
    "research—for": 1,
    "outline": 2,
    "—but": 1,
    "blocked": 1,
    "mellon": 1,
    "cmu": 1,
    "official": 1,
    "usage": 3,
    "threatening": 1,
    "stuck": 11,
    "50th": 1,
    "anniversary": 1,
    "resisted": 2,
    "deference": 1,
    "promoting": 1,
    "analog": 1,
    "cybernetic": 1,
    "list-processing": 1,
    "ipl": 1,
    "lt.": 1,
    "compiler": 1,
    "code": 8,
    "calling": 1,
    "binary": 84,
    "agreed": 1,
    "neats": 1,
    "—those": 2,
    "grounded": 1,
    "rigor—over": 1,
    "scruffies": 2,
    "neatness": 1,
    "implies": 1,
    "stability": 1,
    "maturity": 1,
    "richard": 2,
    "thornton": 1,
    "primitive": 3,
    "expounder": 1,
    "railed": 1,
    "outruns": 1,
    "necessity": 1,
    "existence": 2,
    "inventing": 1,
    "perfection": 4,
    "remedy": 1,
    "defect": 1,
    "ken": 1,
    "button": 3,
    "discus": 10,
    "menagerie": 1,
    "identified": 3,
    "imaginable": 1,
    "agents—systems": 1,
    "examining": 3,
    "agent—one": 1,
    "behaves": 1,
    "categorization": 1,
    "influence": 1,
    "skeleton": 3,
    "flesh": 1,
    "perceiving": 4,
    "sensor": 52,
    "actuator": 23,
    "ear": 2,
    "leg": 3,
    "vocal": 1,
    "tract": 1,
    "infrared": 1,
    "finder": 1,
    "receives": 8,
    "file": 2,
    "packet": 2,
    "keyboard/mouse/touchscreen/voice": 1,
    "sending": 1,
    "displaying": 2,
    "sound": 3,
    "everything—the": 1,
    "agent—the": 1,
    "perceives": 6,
    "affected": 1,
    "unknown": 25,
    "mark": 4,
    "inside": 3,
    "arrow": 194,
    "interact": 3,
    "instant": 1,
    "built-in": 4,
    "specifying": 5,
    "imagine": 8,
    "tabulating": 1,
    "table—infinite": 1,
    "length": 16,
    "keep": 50,
    "distinct": 8,
    "implementation": 18,
    "illustrate": 6,
    "vacuum-cleaner": 7,
    "vacuum-cleaning": 4,
    "dirty": 25,
    "clean": 39,
    "configuration": 11,
    "suck": 28,
    "partial": 28,
    "tabulation": 2,
    "occupies": 2,
    "succeed": 4,
    "vacuum-world": 1,
    "right-hand": 1,
    "stupid": 1,
    "otherwise": 1,
    "unbounded": 4,
    "restriction": 7,
    "closing": 1,
    "emphasize": 3,
    "absolute": 4,
    "divide": 1,
    "non-agents": 1,
    "hand-held": 1,
    "chooses": 15,
    "aid": 1,
    "evaluate": 4,
    "plunked": 1,
    "generates": 8,
    "performed": 3,
    "desirability": 1,
    "evaluates": 2,
    "designer": 11,
    "implicit—the": 1,
    "recalling": 1,
    "preceding": 11,
    "cleaned": 4,
    "eight-hour": 1,
    "cleaning": 7,
    "dumping": 1,
    "awarded": 1,
    "penalty": 4,
    "electricity": 1,
    "consumed": 3,
    "pitfall": 3,
    "avoided": 2,
    "knotty": 1,
    "remain": 5,
    "paragraph": 4,
    "cleanliness": 2,
    "mediocre": 1,
    "break": 4,
    "preferable": 1,
    "fine": 2,
    "janitorial": 1,
    "far-reaching": 1,
    "implication": 3,
    "better—a": 1,
    "reckless": 1,
    "low": 4,
    "safe": 3,
    "humdrum": 1,
    "better—an": 1,
    "everyone": 1,
    "poverty": 1,
    "live": 1,
    "poor": 3,
    "diligent": 1,
    "accept": 2,
    "piece": 7,
    "copy": 2,
    "belong": 1,
    "tabulated": 3,
    "lifetime": 5,
    "geography": 7,
    "priori": 2,
    "distribution": 5,
    "stay": 2,
    "sucking": 1,
    "oscillate": 1,
    "forth": 4,
    "includes": 11,
    "fare": 4,
    "check": 21,
    "re-clean": 1,
    "vacr": 1,
    "asks": 2,
    "omniscience": 3,
    "autonomy": 3,
    "distinguish": 4,
    "omniscient": 1,
    "walking": 2,
    "champ": 1,
    "elysées": 1,
    "friend": 1,
    "nearby": 3,
    "engaged": 2,
    "foot": 2,
    "door": 2,
    "airliner": 1,
    "flattened": 1,
    "obituary": 1,
    "idiot": 1,
    "street.": 1,
    "retreating": 1,
    "fair": 1,
    "fulfill": 1,
    "specification—unless": 1,
    "crystal": 1,
    "ball": 8,
    "engage": 1,
    "underintelligent": 1,
    "crossing": 2,
    "busy": 1,
    "truck": 7,
    "uninformative": 1,
    "gathering": 2,
    "—is": 1,
    "exploration": 13,
    "undertaken": 1,
    "gather": 2,
    "predictable": 1,
    "dung": 6,
    "beetle": 5,
    "digging": 1,
    "nest": 2,
    "laying": 1,
    "egg": 3,
    "fetch": 1,
    "heap": 1,
    "plug": 1,
    "entrance": 1,
    "grasp": 1,
    "pantomime": 1,
    "plugging": 1,
    "nonexistent": 1,
    "noticing": 1,
    "missing": 3,
    "violated": 5,
    "unsuccessful": 1,
    "sphex": 4,
    "dig": 1,
    "burrow": 4,
    "sting": 1,
    "caterpillar": 5,
    "drag": 2,
    "enter": 2,
    "lay": 1,
    "serf": 1,
    "hatch": 1,
    "entomologist": 1,
    "inch": 1,
    "revert": 1,
    "continue": 5,
    "re-checking": 1,
    "caterpillar-moving": 1,
    "unable": 3,
    "innate": 2,
    "failing": 1,
    "autonomous—it": 1,
    "compensate": 1,
    "learns": 2,
    "seldom": 4,
    "survive": 1,
    "independent": 6,
    "hence": 8,
    "incorporation": 2,
    "ready": 1,
    "solutions.": 1,
    "illustrating": 1,
    "flavor": 1,
    "minded": 1,
    "pea": 6,
    "erformance": 1,
    "nvironment": 1,
    "ctuators": 1,
    "ensors": 1,
    "summarizes": 1,
    "fourth": 36,
    "evolves": 7,
    "dashed": 53,
    "sixth": 13,
    "aspire": 1,
    "minimizing": 7,
    "fuel": 2,
    "consumption": 1,
    "tear": 1,
    "trip": 5,
    "violation": 2,
    "disturbance": 1,
    "comfort": 1,
    "profit": 1,
    "rural": 1,
    "lane": 2,
    "alley": 1,
    "12-lane": 1,
    "freeway": 1,
    "pedestrian": 3,
    "stray": 4,
    "police": 1,
    "pothole": 1,
    "optional": 1,
    "southern": 1,
    "california": 2,
    "snow": 1,
    "alaska": 1,
    "flexible": 3,
    "accelerator": 1,
    "display": 1,
    "screen": 2,
    "synthesizer": 1,
    "ultrasound": 1,
    "distance": 40,
    "obstacle": 11,
    "speeding": 1,
    "ticket": 3,
    "speedometer": 1,
    "curve": 7,
    "accelerometer": 1,
    "determine": 7,
    "usual": 3,
    "array": 3,
    "lost": 6,
    "touchscreen": 1,
    "request": 3,
    "sketched": 2,
    "virtual": 3,
    "softbot": 1,
    "trade": 1,
    "auction": 1,
    "reselling": 1,
    "arow": 2,
    "seventh": 8,
    "dimension": 7,
    "categorized": 1,
    "applicability": 1,
    "observable": 54,
    "convenient": 1,
    "noisy": 1,
    "inaccurate": 2,
    "data—for": 1,
    "local": 85,
    "unobservable": 1,
    "plight": 1,
    "hopeless": 1,
    "achievable": 2,
    "single-agent": 8,
    "crossword": 2,
    "two-agent": 1,
    "subtle": 1,
    "treat": 8,
    "behaving": 1,
    "beach": 1,
    "leaf": 27,
    "blowing": 2,
    "competitive": 11,
    "taxi-driving": 3,
    "avoiding": 3,
    "collision": 2,
    "cooperative": 1,
    "occupy": 1,
    "parking": 2,
    "agent-design": 1,
    "emerges": 2,
    "avoids": 2,
    "predictability": 1,
    "deterministic": 29,
    "nondeterministic": 38,
    "executed": 3,
    "worry": 4,
    "unobserved": 4,
    "tire": 1,
    "seize": 1,
    "variation": 7,
    "appearing": 1,
    "unreliable": 1,
    "suction": 1,
    "vfin": 1,
    "synonym": 4,
    "rain": 2,
    "tomorrow": 2,
    "quantified": 1,
    "episodic": 8,
    "divided": 6,
    "atomic": 18,
    "episode": 4,
    "classification": 1,
    "spot": 1,
    "defective": 2,
    "short-term": 1,
    "simpler": 4,
    "deliberating": 1,
    "passage": 2,
    "asking": 3,
    "decided": 1,
    "semidynamic": 2,
    "dither": 1,
    "discrete": 13,
    "discrete/continuous": 1,
    "applies": 4,
    "handled": 6,
    "finite": 20,
    "excluding": 1,
    "continuous-state": 2,
    "continuous-time": 1,
    "sweep": 1,
    "smoothly": 1,
    "angle": 2,
    "varying": 5,
    "intensity": 2,
    "observable—for": 1,
    "solitaire": 1,
    "observable—in": 1,
    "user—whose": 1,
    "matter—is": 1,
    "prefers": 4,
    "speedy": 3,
    "journey": 1,
    "cautious": 1,
    "aggressive": 1,
    "style": 1,
    "knowing": 2,
    "owner": 2,
    "hardest": 3,
    "sens": 1,
    "rented": 1,
    "unfamiliar": 3,
    "exciting": 1,
    "cut": 4,
    "dried": 1,
    "medical-diagnosis": 2,
    "modeled": 2,
    "recalcitrant": 1,
    "staff": 1,
    "conceives": 1,
    "symptom": 1,
    "handling": 2,
    "eighth": 7,
    "known/unknown": 1,
    "aima.cs.berkeley.edu": 1,
    "simulator": 1,
    "drawn": 2,
    "simulated": 17,
    "lighting": 1,
    "talked": 1,
    "bite": 1,
    "bullet": 1,
    "function—the": 1,
    "actuators—we": 1,
    "notice": 15,
    "remember": 4,
    "pseudocode": 1,
    "appendix": 5,
    "trivial": 5,
    "table—an": 1,
    "—represents": 1,
    "embodies": 1,
    "critic": 7,
    "generator": 6,
    "riven": 2,
    "gent": 8,
    "invoked": 1,
    "retains": 4,
    "instructive": 1,
    "table-driven": 1,
    "doomed": 3,
    "lookup": 2,
    "entry": 7,
    "megabyte": 1,
    "color": 23,
    "chess—a": 1,
    "well-behaved": 1,
    "world—has": 1,
    "atom": 2,
    "daunting": 1,
    "assuming": 8,
    "desired": 4,
    "smallish": 1,
    "schoolchildren": 1,
    "five-line": 1,
    "yes": 1,
    "remainder": 1,
    "model-based": 13,
    "goal-based": 16,
    "utility-based": 13,
    "explains": 4,
    "convert": 2,
    "organizing": 1,
    "ignoring": 4,
    "factored": 12,
    "bar": 25,
    "bottom": 22,
    "alternating": 2,
    "shade": 18,
    "shaded": 17,
    "red": 81,
    "arranged": 9,
    "row": 151,
    "two-location": 1,
    "reduction": 8,
    "if-then-else": 1,
    "circuit": 10,
    "front": 7,
    "brake": 11,
    "initiate": 3,
    "braking.": 2,
    "trigger": 1,
    "established": 2,
    "condition–action": 4,
    "car-in-front-is-braking": 2,
    "initiate-braking": 1,
    "blinking": 1,
    "schematic": 3,
    "rectangle": 1,
    "denote": 3,
    "oval": 1,
    "nterpret": 1,
    "nput": 1,
    "abstracted": 3,
    "ule": 1,
    "atch": 1,
    "implementing": 2,
    "nonlinear": 2,
    "admirable": 1,
    "unobservability": 1,
    "percept—a": 1,
    "mounted": 1,
    "identifiable": 1,
    "taillight": 2,
    "turn-signal": 1,
    "unnecessarily": 1,
    "worse": 7,
    "suppose": 21,
    "fails": 7,
    "infinite": 35,
    "unavoidable": 2,
    "randomize": 1,
    "flip": 1,
    "outperform": 2,
    "randomization": 2,
    "sophisticated": 1,
    "observability": 9,
    "sort": 4,
    "thereby": 2,
    "extensive—just": 1,
    "edge": 20,
    "clockwise": 3,
    "raining": 1,
    "wet": 3,
    "theories—is": 1,
    "reflected": 1,
    "illuminated": 1,
    "forward-facing": 1,
    "droplet-shaped": 1,
    "obscuring": 1,
    "world—to": 1,
    "updated": 9,
    "pdate": 4,
    "tate": 2,
    "vary": 6,
    "depending": 6,
    "represents": 9,
    "guess": 3,
    "entertains": 1,
    "causing": 1,
    "hold-up": 1,
    "straight": 4,
    "desirable—for": 1,
    "achievement": 1,
    "straightforward—for": 1,
    "satisfaction": 21,
    "tricky—for": 1,
    "twist": 2,
    "such-and-such": 1,
    "hitting": 1,
    "high-quality": 1,
    "quicker": 1,
    "cheaper": 1,
    "unhappy": 1,
    "assigns": 2,
    "internalization": 1,
    "rational—we": 1,
    "is—but": 1,
    "flexibility": 3,
    "conflicting": 1,
    "specifies": 6,
    "likelihood": 1,
    "weighed": 1,
    "nondeterminism": 7,
    "ubiquitous": 1,
    "therefore": 5,
    "expects": 2,
    "possesses": 2,
    "maximized": 1,
    "rationality—designating": 1,
    "highest": 6,
    "performance—is": 1,
    "constraint": 240,
    "expressed": 4,
    "decision-making": 1,
    "inherent": 1,
    "averaging": 1,
    "weighted": 16,
    "wondering": 1,
    "utility-maximizing": 1,
    "requiring": 2,
    "ingenious": 2,
    "unachievable": 1,
    "model-free": 1,
    "considers": 5,
    "estimate": 30,
    "expeditious": 1,
    "desirable.": 1,
    "state-of-the-art": 1,
    "etc": 1,
    "briefly": 1,
    "introduce": 6,
    "decides": 1,
    "determines": 4,
    "respect": 8,
    "indication": 3,
    "indicating": 3,
    "checkmated": 1,
    "willing": 2,
    "suboptimal": 7,
    "suggest": 4,
    "dropping": 2,
    "tower": 1,
    "pisa": 1,
    "valuable": 1,
    "pair": 29,
    "successive": 2,
    "exerts": 1,
    "deceleration": 1,
    "skid": 1,
    "surface": 8,
    "improving": 4,
    "conform": 1,
    "tip": 3,
    "shaken": 1,
    "inform": 1,
    "violent": 1,
    "distinguishes": 1,
    "incoming": 2,
    "hard-wired": 1,
    "pain": 1,
    "hunger": 1,
    "loud": 1,
    "settle": 2,
    "horn": 1,
    "ensuring": 2,
    "consequent": 1,
    "behavior—covering": 1,
    "cutting": 1,
    "wire": 3,
    "horn—would": 1,
    "unifying": 1,
    "theme": 3,
    "earth": 1,
    "inhabits": 1,
    "axis": 3,
    "power—atomic": 1,
    "do.": 1,
    "depiction": 1,
    "attribute": 5,
    "real-valued": 2,
    "relationship": 5,
    "indivisible—it": 1,
    "reduce": 14,
    "in—a": 1,
    "discernible": 1,
    "identical": 8,
    "higher-fidelity": 1,
    "tank": 1,
    "coordinate": 3,
    "oil": 1,
    "toll": 1,
    "station": 1,
    "radio": 3,
    "common—they": 1,
    "boxes—two": 1,
    "share": 5,
    "reversing": 1,
    "dairy": 1,
    "farm": 1,
    "loose": 1,
    "cow": 2,
    "blocking": 1,
    "pre-equipped": 1,
    "truckaheadbackinglntodairyfarmdrivewayblockedbyloosecow": 1,
    "false": 2,
    "underlie": 1,
    "relational": 1,
    "expressiveness": 1,
    "concise": 3,
    "structured-representation": 1,
    "factored-representation": 1,
    "finite-state": 2,
    "automaton": 2,
    "drawback": 2,
    "one-to-one": 1,
    "localist": 2,
    "spread": 6,
    "employed": 1,
    "arbitrary": 10,
    "transmission": 2,
    "garbles": 1,
    "confuse": 1,
    "unrelated": 4,
    "truce": 1,
    "multidimensional": 1,
    "garble": 1,
    "meaning": 3,
    "tour": 3,
    "recall": 2,
    "optimizing": 1,
    "reflecting": 1,
    "efficiency": 14,
    "compactness": 1,
    "respond": 1,
    "evident": 1,
    "happiness.": 1,
    "intelligence—the": 1,
    "reasoning—goes": 1,
    "concentrated": 3,
    "agents—question-answering": 1,
    "theorem-provers": 1,
    "genesereth": 3,
    "whole-agent": 1,
    "padgham": 1,
    "winikoff": 1,
    "jones": 1,
    "poole": 1,
    "mackworth": 6,
    "peripheral": 1,
    "jon": 1,
    "doyle": 2,
    "mission": 1,
    "spin": 4,
    "tradition—for": 1,
    "dorf": 1,
    "bishop": 4,
    "kirk": 1,
    "kumar": 2,
    "varaiya": 1,
    "bertsekas": 1,
    "shreve": 1,
    "henzinger": 1,
    "sastry": 1,
    "cassandra": 1,
    "lygeros": 1,
    "literature": 7,
    "puterman": 1,
    "leverage": 1,
    "rosenschein": 1,
    "brook": 1,
    "questioned": 1,
    "gone": 2,
    "keeping": 8,
    "bar-shalom": 1,
    "choset": 1,
    "presupposed": 1,
    "fikes": 2,
    "embodiment": 1,
    "agent-oriented": 2,
    "shoham": 1,
    "agent-based": 2,
    "ciancarini": 1,
    "wooldridge": 3,
    "infiltrated": 1,
    "autonomic": 1,
    "perceive–act": 1,
    "kephart": 1,
    "noting": 1,
    "exhibit": 1,
    "modularity—the": 1,
    "environment—it": 1,
    "sub-agents": 1,
    "monolithic": 1,
    "dominates": 4,
    "newell": 1,
    "analyzed": 6,
    "intention": 1,
    "michael": 1,
    "bratman": 1,
    "eschewed": 1,
    "favor": 3,
    "sproull": 1,
    "horvitz": 1,
    "exposition": 1,
    "biggest": 2,
    "remarkably": 1,
    "assumed": 3,
    "hadfield-menell": 1,
    "portrayed": 1,
    "classic": 2,
    "mitchell": 3,
    "collected": 1,
    "huhns": 1,
    "singh": 1,
    "rao": 1,
    "weiss": 1,
    "atal": 1,
    "multi-agent": 3,
    "icmas": 1,
    "merged": 1,
    "aamas": 1,
    "aose": 1,
    "ecology": 1,
    "hanski": 1,
    "cambefort": 1,
    "inspiring": 1,
    "left.": 1,
    "backward.": 1,
    "chosen": 16,
    "follow": 9,
    "ease": 1,
    "henderson": 2,
    "latch": 1,
    "urged": 1,
    "boeing": 1,
    "jumbo": 1,
    "jet": 1,
    "washington": 1,
    "post": 1,
    "august": 1,
    "antonym": 1,
    "parallel.": 1,
    "coroutines": 1,
    "coroutine": 1,
    "writes": 1,
    "situation–action": 1,
    "if–then": 1,
    "electric": 2,
    "waterworks": 1,
    "searching": 19,
    "undertakes": 1,
    "uninformed": 15,
    "relaxes": 2,
    "asymptotic": 3,
    "consult": 1,
    "3.1problem-solving": 1,
    "enjoying": 1,
    "touring": 3,
    "vacation": 1,
    "romania": 18,
    "sight": 2,
    "romanian": 3,
    "enjoy": 1,
    "nightlife": 1,
    "hangover": 1,
    "arad": 54,
    "nonrefundable": 1,
    "fly": 1,
    "bucharest": 52,
    "observes": 2,
    "sibiu": 62,
    "timisoara": 23,
    "zerind": 19,
    "information—that": 1,
    "—then": 1,
    "execute": 6,
    "sad": 1,
    "four-phase": 1,
    "neamt": 2,
    "iasi": 3,
    "valsui": 1,
    "vaslui": 2,
    "urziceni": 4,
    "hirsova": 3,
    "eforie": 2,
    "giurgiu": 2,
    "pitesti": 29,
    "fagaras": 37,
    "craiova": 9,
    "rimnicu": 40,
    "vilcea": 38,
    "oradea": 16,
    "lugoj": 10,
    "mehadia": 4,
    "drobeta": 5,
    "simplified": 6,
    "formulation": 18,
    "adopts": 2,
    "reaching": 9,
    "limiting": 2,
    "goal—an": 1,
    "traveling": 5,
    "adjacent": 18,
    "simulates": 1,
    "ignore": 1,
    "executing": 3,
    "actions—closing": 1,
    "speak—because": 1,
    "guaranteed": 16,
    "open-loop": 1,
    "closed-loop": 1,
    "recommends": 1,
    "arrive": 3,
    "contingency": 6,
    "arrives": 3,
    "saying": 7,
    "drum": 1,
    "închis": 1,
    "closed": 5,
    "oal": 4,
    "simplicity": 2,
    "states.": 1,
    "ctions": 6,
    "esult": 9,
    "denoted": 2,
    "ction": 2,
    "ost": 4,
    "math": 1,
    "numeric": 2,
    "route-finding": 8,
    "additive": 2,
    "lowest": 10,
    "complication": 5,
    "graph": 110,
    "vertex": 9,
    "formulating": 1,
    "—an": 1,
    "description—and": 1,
    "companion": 1,
    "scenery": 1,
    "proximity": 1,
    "enforcement": 3,
    "officer": 1,
    "irrelevant": 3,
    "removing": 4,
    "centimeter": 1,
    "corresponds": 13,
    "elaborate": 1,
    "retaining": 1,
    "validity": 1,
    "swamped": 1,
    "distinguishing": 1,
    "standardized": 5,
    "idiosyncratic": 1,
    "grid": 30,
    "two-dimensional": 7,
    "obstacle-free": 1,
    "push": 3,
    "wall": 6,
    "impassible": 1,
    "prevents": 2,
    "formulated": 6,
    "two-cell": 3,
    "designated": 3,
    "multi-cell": 1,
    "add": 13,
    "downward": 1,
    "egocentric": 1,
    "relative": 1,
    "agent—for": 1,
    "turnright": 2,
    "turnleft": 2,
    "remove": 12,
    "facing": 2,
    "hit": 1,
    "backward": 8,
    "opposite": 1,
    "blank": 24,
    "state-space": 19,
    "sokoban": 1,
    "scattered": 3,
    "empty": 20,
    "non-obstacle": 1,
    "sliding-tile": 2,
    "tile": 38,
    "rush": 2,
    "slide": 3,
    "jam": 1,
    "best-known": 3,
    "8-puzzle": 20,
    "numbered": 3,
    "15-puzzle": 6,
    "vertical": 3,
    "cleaner": 17,
    "parity": 1,
    "partition": 2,
    "space—any": 1,
    "corner": 2,
    "intermediate": 1,
    "sliding": 2,
    "ruled": 1,
    "extracting": 1,
    "knife": 1,
    "manipulation": 2,
    "knuth": 4,
    "conjectured": 1,
    "factorial": 5,
    "operator": 2,
    "explores": 5,
    "shortest": 7,
    "expression": 6,
    "in-car": 1,
    "straightforward": 2,
    "extension": 2,
    "traffic-dependent": 1,
    "delay": 2,
    "rerouting": 1,
    "closure": 1,
    "routing": 4,
    "stream": 1,
    "airline": 6,
    "travel-planning": 2,
    "travel": 5,
    "furthermore": 3,
    "segment": 2,
    "status": 1,
    "domestic": 1,
    "record": 8,
    "extra": 4,
    "leaving": 5,
    "within-airport": 1,
    "arrival": 1,
    "nonstop": 1,
    "flight.": 1,
    "waiting": 4,
    "custom": 1,
    "immigration": 1,
    "airplane": 1,
    "frequent-flyer": 1,
    "byzantine": 1,
    "seasoned": 1,
    "traveler": 1,
    "delayed": 1,
    "missed": 1,
    "visited": 8,
    "salesperson": 2,
    "tsp": 5,
    "expended": 1,
    "fleet": 1,
    "school": 2,
    "bus": 1,
    "boston": 1,
    "saved": 4,
    "pollution": 1,
    "bertsimas": 1,
    "circuit-board": 1,
    "drill": 1,
    "stocking": 1,
    "shop": 2,
    "vlsi": 5,
    "layout": 4,
    "positioning": 1,
    "capacitance": 1,
    "yield": 9,
    "grouped": 1,
    "footprint": 1,
    "overlap": 2,
    "generalization": 4,
    "roam": 1,
    "circular": 13,
    "flat": 9,
    "arm": 1,
    "many-dimensional—one": 1,
    "alter": 1,
    "assembly": 10,
    "sequencing": 3,
    "manual": 1,
    "assemble": 1,
    "undoing": 1,
    "checking": 30,
    "feasibility": 1,
    "geometrical": 1,
    "legal": 16,
    "exploring": 9,
    "fraction": 1,
    "protein": 2,
    "amino": 1,
    "acid": 1,
    "fold": 1,
    "three-dimensional": 2,
    "superimpose": 1,
    "forming": 3,
    "node": 656,
    "unique": 1,
    "expand": 22,
    "considering": 1,
    "parent": 32,
    "lavender-colored": 55,
    "faint": 16,
    "lavender": 22,
    "colored": 7,
    "green-colored": 65,
    "search—following": 1,
    "option": 2,
    "unexpanded": 4,
    "outlined": 1,
    "superimposed": 2,
    "highlighted": 11,
    "topmost": 1,
    "interior": 4,
    "exterior": 3,
    "horizontal": 2,
    "separation": 2,
    "rectangular-grid": 1,
    "remaining": 13,
    "best-first": 37,
    "minimum": 29,
    "iteration": 25,
    "xpand": 1,
    "added": 10,
    "re-added": 1,
    "employing": 1,
    "arrowhead": 47,
    "expanding": 18,
    "arent": 2,
    "ath": 3,
    "pointer": 4,
    "queue": 25,
    "mpty": 1,
    "insert": 2,
    "priority": 4,
    "pop": 4,
    "fifo": 1,
    "first-in-first-out": 2,
    "breadth-first": 30,
    "lifo": 1,
    "last-in-first-out": 1,
    "stack": 1,
    "depth-first": 37,
    "e.g": 2,
    "hash": 1,
    "redundant": 13,
    "loopy": 1,
    "traverse": 1,
    "arad–sibiu": 1,
    "arad–zerind–oradea–sibiu": 1,
    "redundant—it": 1,
    "state—and": 1,
    "fewer": 11,
    "repeat": 3,
    "repeating": 3,
    "rare": 2,
    "evolving": 2,
    "assemblage": 1,
    "ordering": 13,
    "save": 6,
    "est": 5,
    "irst": 5,
    "earch": 10,
    "treelike": 1,
    "examine": 6,
    "compromise": 1,
    "chain": 4,
    "earlier": 5,
    "link": 4,
    "grandparent": 1,
    "great-grandparent": 1,
    "relying": 1,
    "measuring": 1,
    "optimality": 6,
    "completeness": 3,
    "anywhere": 1,
    "reachable": 15,
    "expanse": 1,
    "spiral": 1,
    "state/action": 1,
    "implicit": 3,
    "maximum": 40,
    "clue": 2,
    "couple": 1,
    "deeper": 3,
    "shallower": 1,
    "popped": 1,
    "early-goal": 1,
    "enhancement": 1,
    "indicated": 2,
    "triangular": 1,
    "marker": 1,
    "faded": 17,
    "uniform-cost": 18,
    "minimal": 5,
    "cost-optimal": 15,
    "uniform": 7,
    "yielding": 3,
    "scary": 1,
    "nodes/second": 1,
    "kbyte/node": 1,
    "terabyte": 1,
    "bigger": 1,
    "exponential-complexity": 1,
    "smallest": 4,
    "dijkstra": 5,
    "depth—first": 1,
    "on—uniform-cost": 1,
    "path-cost": 1,
    "least-cost": 2,
    "expands": 19,
    "detected": 6,
    "expansion": 10,
    "lower": 12,
    "replaces": 2,
    "returned": 5,
    "checked": 1,
    "lowest-cost": 5,
    "higher-cost": 1,
    "worst-case": 6,
    "high-cost": 1,
    "caught": 2,
    "deepest": 5,
    "proceeds": 2,
    "back": 2,
    "cheapest": 2,
    "triangle": 14,
    "marking": 2,
    "descendant": 2,
    "discarded": 4,
    "acyclic": 4,
    "cyclic": 7,
    "anyone": 1,
    "smaller": 8,
    "ever-expanding": 1,
    "radius": 1,
    "tree-shaped": 1,
    "proportional": 4,
    "exabyte": 1,
    "kilobyte": 1,
    "parsimonious": 1,
    "workhorse": 1,
    "backtracking": 38,
    "remembers": 2,
    "allocating": 1,
    "maintaining": 3,
    "backtrack": 12,
    "depth-limited": 8,
    "iterative": 22,
    "deepening": 21,
    "wandering": 3,
    "wasting": 1,
    "discover": 3,
    "solves": 5,
    "picking": 2,
    "on—until": 1,
    "cutoff": 5,
    "modest": 1,
    "exhausted": 1,
    "visiting": 2,
    "ycle": 1,
    "storing": 3,
    "iterative-deepening": 4,
    "dark": 7,
    "wasteful": 1,
    "re-generated": 1,
    "next-to-bottom": 1,
    "worst": 9,
    "id": 2,
    "bfs": 1,
    "repetition": 2,
    "bidirectional": 29,
    "backwards": 4,
    "hoping": 1,
    "meet": 5,
    "motivation": 1,
    "forward": 8,
    "collide": 1,
    "unidirectional": 3,
    "considerable": 1,
    "speedup": 7,
    "subscript": 30,
    "erminated": 2,
    "prof": 2,
    "half": 5,
    "joined": 1,
    "oin": 1,
    "ode": 1,
    "bounded": 9,
    "shallowest": 4,
    "superscript": 1,
    "caveat": 1,
    "strategy—one": 1,
    "hint": 2,
    "goals—can": 1,
    "straight-line": 9,
    "value—the": 1,
    "closest": 8,
    "goal—on": 1,
    "sld": 9,
    "correlated": 1,
    "twelve": 1,
    "—straight-line": 1,
    "—on": 1,
    "greediness": 1,
    "-values": 1,
    "a-star": 1,
    "admissibility": 4,
    "admissible": 30,
    "overestimate": 4,
    "contradiction": 6,
    "nearest": 4,
    "supposition": 1,
    "wrong—it": 1,
    "stronger": 4,
    "consistency": 45,
    "stipulates": 1,
    "re-add": 1,
    "inconsistent": 11,
    "costing": 1,
    "implementers": 1,
    "felner": 4,
    "argues": 1,
    "afraid": 1,
    "inadmissible": 5,
    "second-best": 2,
    "contour": 25,
    "topographic": 1,
    "-cost": 8,
    "fan": 1,
    "concentric": 4,
    "band": 2,
    "prime": 8,
    "spreading": 2,
    "monotonic": 4,
    "canceling": 1,
    "decreased": 1,
    "lucky": 1,
    "unlucky": 1,
    "prune": 4,
    "pruning—eliminating": 1,
    "them—is": 1,
    "satisfying": 1,
    "super-powerful": 1,
    "visit": 2,
    "scenario": 1,
    "subset": 12,
    "satisfy": 6,
    "—one": 1,
    "overestimate—then": 1,
    "accurate": 9,
    "reducing": 7,
    "detour": 3,
    "curvature": 1,
    "locality": 2,
    "weight": 9,
    "portion": 8,
    "costlier": 1,
    "respective": 1,
    "encloses": 3,
    "gray": 7,
    "purple": 7,
    "dot": 5,
    "costly": 1,
    "combining": 5,
    "somewhat-greedy": 1,
    "suspend": 1,
    "enough.": 1,
    "guarantee": 4,
    "bounded-cost": 1,
    "unbounded-cost": 2,
    "memory-bounded": 6,
    "duplication": 2,
    "duplicating": 1,
    "complicating": 1,
    "slowing": 1,
    "prohibition": 1,
    "u-turn": 1,
    "outwards": 1,
    "neighbor": 13,
    "conserve": 1,
    "easiest": 2,
    "-scores": 1,
    "discarding": 1,
    "executes": 5,
    "fast": 1,
    "near-optimal": 1,
    "-score": 2,
    "strong-scoring": 1,
    "ida": 11,
    "-contour": 1,
    "steady": 1,
    "recursive": 10,
    "rbfs": 17,
    "mimic": 2,
    "linear": 27,
    "resembles": 5,
    "continuing": 2,
    "f-limit": 2,
    "-value": 7,
    "ancestor": 2,
    "exceeds": 1,
    "recursion": 4,
    "unwinds": 4,
    "backed-up": 1,
    "subtree": 8,
    "worth": 2,
    "reexpanding": 1,
    "later": 1,
    "equidistant": 1,
    "maze": 11,
    "upward": 1,
    "bulk": 2,
    "navigating": 1,
    "irregular": 1,
    "navigates": 1,
    "suffers": 1,
    "excessive": 1,
    "regeneration": 2,
    "increase—": 1,
    "reexpansions": 1,
    "recreate": 1,
    "infinity": 1,
    "unwinding": 1,
    "label": 8,
    "struck": 2,
    "switching": 2,
    "backed": 2,
    "revealing": 1,
    "nonmonotonic": 1,
    "suffer": 3,
    "forget": 1,
    "reexploring": 1,
    "sensible": 1,
    "sma": 14,
    "is—well—simpler": 1,
    "drop": 5,
    "regenerates": 1,
    "worthwhile": 2,
    "accompanying": 1,
    "subtlety": 1,
    "mentioning": 1,
    "deletes": 4,
    "deletion": 1,
    "newest": 1,
    "oldest": 1,
    "coincide": 1,
    "overhead": 1,
    "forced": 2,
    "thrashing": 1,
    "disk": 1,
    "paging": 1,
    "inescapable": 1,
    "saw": 4,
    "optimal-cost": 4,
    "eckerle": 2,
    "max": 33,
    "nonnegative": 1,
    "efficient—any": 1,
    "manage": 1,
    "stick": 1,
    "touch": 2,
    "double-headed": 6,
    "maintains": 3,
    "start-a-f-goal": 1,
    "meet-in-the-middle": 1,
    "front-to-end": 1,
    "front-to-front": 1,
    "inefficient": 4,
    "sample": 2,
    "frontier—for": 1,
    "bounding": 2,
    "3.6heuristic": 1,
    "states—over": 1,
    "trillion—so": 1,
    "diagonal": 6,
    "distances—sometimes": 1,
    "city-block": 1,
    "manhattan": 7,
    "8-puzzles": 3,
    "usefulness": 1,
    "well-designed": 2,
    "korf": 12,
    "reid": 2,
    "pruning": 3,
    "d–k": 1,
    "rubik": 5,
    "cube": 4,
    "sampled": 1,
    "lengths—at": 1,
    "reporting": 1,
    "asterisk": 8,
    "averaged": 1,
    "yes.": 1,
    "domination": 1,
    "translates": 1,
    "breaking": 5,
    "tie": 2,
    "relaxed": 16,
    "invent": 2,
    "occupied": 1,
    "supergraph": 1,
    "creates": 1,
    "shortcut": 5,
    "obey": 3,
    "gasc": 1,
    "decomposed": 1,
    "subproblems": 12,
    "obtain": 2,
    "prieditis": 2,
    "preexisting": 1,
    "composite": 2,
    "subproblem": 14,
    "highway": 2,
    "displayed": 4,
    "kilometer": 2,
    "pane": 2,
    "worrying": 3,
    "instance—in": 1,
    "identity": 1,
    "encountered": 4,
    "expense": 2,
    "amortized": 2,
    "1-2-3-4": 5,
    "5-6-7-8": 4,
    "2-4-6-8": 1,
    "15-puzzles": 2,
    "diminishing": 1,
    "wonder": 1,
    "star": 2,
    "disappear": 1,
    "1-2-3-4.": 1,
    "disjoint": 4,
    "milliseconds—the": 1,
    "subproblem—because": 1,
    "host": 1,
    "millisecond": 1,
    "precomputation": 2,
    "time-consuming": 1,
    "precomputing": 1,
    "time—practical": 1,
    "undirected": 1,
    "graph—e.g.": 1,
    "one-way": 2,
    "streets—we": 1,
    "min": 18,
    "inadmissible—it": 1,
    "trace": 3,
    "—artificial": 1,
    "multi-action": 1,
    "predefined": 1,
    "navigate": 2,
    "berkeley": 1,
    "campus": 1,
    "nyu": 1,
    "york": 2,
    "sacramento": 1,
    "differential": 2,
    "subtraction": 1,
    "subtract": 1,
    "inexact": 1,
    "helpful": 7,
    "furthest": 1,
    "log": 2,
    "requested": 1,
    "perimeter": 1,
    "centroid": 3,
    "arrange": 1,
    "pie-shaped": 1,
    "wedge": 2,
    "farthest": 1,
    "laid": 2,
    "civil": 1,
    "widest": 1,
    "strategies—breadth-first": 1,
    "metalevel": 7,
    "object-level": 2,
    "alters": 2,
    "depicting": 2,
    "harder": 4,
    "misstep": 1,
    "unpromising": 1,
    "subtrees": 2,
    "luck": 1,
    "approximate": 4,
    "imperfect": 1,
    "approximation": 5,
    "inadmissibility": 1,
    "inevitable": 1,
    "state.": 1,
    "adjusted": 2,
    "satisfies": 9,
    "environments—as": 1,
    "domain-dependent": 1,
    "precompute": 1,
    "well-defined": 1,
    "judged": 1,
    "differ": 1,
    "selects": 4,
    "stopping": 3,
    "adresses": 1,
    "sacrificing": 1,
    "relaxing": 1,
    "precomputed": 1,
    "simplifying": 2,
    "footing": 1,
    "cousin": 1,
    "recounted": 1,
    "slocum": 1,
    "sonneveld": 1,
    "attracted": 1,
    "johnson": 1,
    "tait": 1,
    "american": 3,
    "sex": 1,
    "age": 2,
    "news-democrat": 1,
    "emporium": 1,
    "kansa": 1,
    "march": 2,
    "epidemic": 1,
    "country.": 1,
    "sam": 1,
    "noyes": 1,
    "chapman": 1,
    "postmaster": 1,
    "canastota": 1,
    "mid-1870s": 1,
    "generic": 2,
    "patent": 1,
    "granted": 1,
    "ernest": 1,
    "kinsey": 1,
    "ratner": 1,
    "warmuth": 1,
    "belongs": 1,
    "ernő": 1,
    "rokicki": 1,
    "agostinelli": 1,
    "monte": 1,
    "carlo": 1,
    "proprietary": 1,
    "marcken": 1,
    "diophantine": 2,
    "pricing": 1,
    "convoluted": 1,
    "undecidable": 2,
    "lawler": 2,
    "lin": 2,
    "kernighan": 1,
    "arora": 2,
    "scheme": 3,
    "euclidean": 1,
    "tsps": 1,
    "surveyed": 1,
    "bahubalendruni": 1,
    "biswal": 1,
    "cormen": 1,
    "dreyfus": 2,
    "search.": 1,
    "barr": 1,
    "floyd–warshall": 2,
    "floyd": 1,
    "bellman-ford": 1,
    "slate": 1,
    "atkin": 1,
    "hess": 1,
    "martelli": 2,
    "raphael": 2,
    "phrase": 1,
    "ernst": 1,
    "doran": 2,
    "michie": 3,
    "conducted": 1,
    "penetrance": 1,
    "examined": 4,
    "ignored": 1,
    "hart": 2,
    "dechter": 12,
    "monotone": 1,
    "pohl": 5,
    "replacement": 1,
    "gaschnig": 4,
    "huyn": 1,
    "dinh": 1,
    "helmert": 1,
    "röger": 1,
    "implying": 1,
    "ebendt": 1,
    "drechsler": 1,
    "synthesize": 1,
    "hatem": 1,
    "ruml": 3,
    "wilt": 2,
    "burn": 1,
    "holte": 1,
    "nb": 1,
    "chen": 1,
    "goldberg": 1,
    "caching": 1,
    "24-million-point": 1,
    "macro-operators": 1,
    "delling": 1,
    "hierarchical": 3,
    "coarse-to-fine": 2,
    "knoblock": 1,
    "quantify": 1,
    "branch-and-bound": 2,
    "wood": 1,
    "rayward-smith": 1,
    "kanal": 1,
    "unification": 1,
    "cdp—the": 1,
    "process.": 1,
    "traverser": 1,
    "commits": 1,
    "length-": 1,
    "upper": 5,
    "bratko": 1,
    "elegant": 1,
    "dta": 1,
    "wefald": 1,
    "chakrabarti": 1,
    "khorsand": 1,
    "divide-and-conquer": 1,
    "zhou": 2,
    "hansen": 4,
    "memory-efficiency": 1,
    "relaxation": 2,
    "seminal": 1,
    "minimum-spanning-tree": 1,
    "mstr": 1,
    "automation": 1,
    "samadi": 1,
    "arfaee": 1,
    "thayer": 1,
    "lelis": 1,
    "culberson": 1,
    "schaeffer": 1,
    "compress": 1,
    "interpretation": 1,
    "investigated": 2,
    "hansson": 1,
    "mayer": 1,
    "edelkamp": 1,
    "schrödl": 1,
    "socs": 1,
    "icaps": 1,
    "clueless": 1,
    "apologize": 2,
    "pedagogical": 2,
    "bellman–ford": 1,
    "negative-cost": 1,
    "accommodate": 1,
    "zero-cost": 2,
    "consecutive": 4,
    "rotate": 1,
    "zeno": 1,
    "paradox": 1,
    "prevent": 1,
    "evocative": 1,
    "terminology": 1,
    "confused": 3,
    "loading": 1,
    "odd": 2,
    "traditional": 2,
    "heuristic.": 1,
    "pivot": 1,
    "anchor": 1,
    "relax": 4,
    "addressed": 1,
    "determinism": 1,
    "observes—for": 1,
    "4.1local": 1,
    "8-queens": 16,
    "queen": 41,
    "reconstruct": 1,
    "integrated-circuit": 1,
    "telecommunication": 1,
    "crop": 1,
    "portfolio": 1,
    "systematic—they": 1,
    "resides": 1,
    "unsuitable": 1,
    "landscape": 13,
    "elevation": 4,
    "peak—a": 1,
    "—and": 3,
    "hill": 34,
    "climbing": 35,
    "valley—a": 1,
    "gradient": 14,
    "descent": 2,
    "mid-left": 1,
    "shoulder": 3,
    "rising": 2,
    "trough": 1,
    "height": 1,
    "one-dimensional": 4,
    "hill-climbing": 13,
    "steepest": 3,
    "ascent": 2,
    "terminates": 2,
    "mount": 1,
    "everest": 1,
    "thick": 1,
    "fog": 1,
    "suffering": 1,
    "amnesia": 1,
    "climb": 1,
    "complete-state": 2,
    "attacking": 2,
    "intervening": 1,
    "grab": 1,
    "deadly": 1,
    "sin": 1,
    "vicinity": 1,
    "i.e.": 6,
    "ridge": 7,
    "plateau": 13,
    "uphill": 3,
    "exit": 1,
    "illustration": 1,
    "downhill": 3,
    "topology": 2,
    "low-dimensional": 1,
    "plane": 2,
    "intuitive": 2,
    "steepest-ascent": 3,
    "succeeds": 2,
    "stuck—not": 1,
    "plateau—to": 1,
    "sideways": 6,
    "wander": 1,
    "raise": 1,
    "percentage": 2,
    "steepness": 1,
    "converges": 2,
    "first-choice": 2,
    "random-restart": 4,
    "adage": 1,
    "again.": 1,
    "conduct": 1,
    "restarts": 7,
    "balding": 1,
    "porcupine": 3,
    "miniature": 1,
    "needle": 1,
    "np-hard": 4,
    "annealing": 16,
    "vulnerable": 2,
    "stumble": 1,
    "metallurgy": 1,
    "harden": 1,
    "metal": 1,
    "glass": 2,
    "heating": 1,
    "cooling": 2,
    "low-energy": 1,
    "crystalline": 1,
    "ping-pong": 1,
    "crevice": 1,
    "bumpy": 1,
    "roll": 1,
    "shake": 2,
    "bounce": 2,
    "minimum—perhaps": 1,
    "spend": 1,
    "dislodge": 1,
    "simulated-annealing": 2,
    "accepts": 1,
    "badness": 1,
    "move—the": 1,
    "worsened": 1,
    "schedule": 11,
    "boltzmann": 1,
    "population": 14,
    "fitness": 17,
    "8-digit": 2,
    "depict": 3,
    "ranking": 1,
    "crossover": 18,
    "halt": 1,
    "thread": 1,
    "grass": 1,
    "greener": 1,
    "abandon": 1,
    "unfruitful": 1,
    "states—they": 1,
    "clustered": 1,
    "-times-slower": 1,
    "alleviate": 1,
    "evolutionary": 9,
    "metaphor": 2,
    "biology": 2,
    "fittest": 1,
    "offspring": 13,
    "populate": 1,
    "recombination": 4,
    "endless": 1,
    "alphabet": 3,
    "dna": 6,
    "acgt": 1,
    "mixing": 1,
    "gene": 5,
    "asexual": 1,
    "reproduction": 3,
    "occurs": 8,
    "recombine": 1,
    "composition": 1,
    "flipped": 1,
    "makeup": 1,
    "top-scoring": 1,
    "elitism": 1,
    "culling": 1,
    "baum": 1,
    "-th": 1,
    "rated": 1,
    "nonattacking": 1,
    "normalized": 1,
    "arrangement": 1,
    "depicts": 2,
    "positioned": 4,
    "retained": 4,
    "ranked": 1,
    "mating": 1,
    "dotted": 1,
    "interpret": 1,
    "mutated": 1,
    "arc": 38,
    "ordered": 1,
    "advantageous": 1,
    "purpose—for": 1,
    "randomly": 2,
    "permuted—then": 1,
    "conveys": 1,
    "schema": 8,
    "substring": 1,
    "unspecified": 1,
    "grow": 1,
    "darwin": 2,
    "alfred": 1,
    "russel": 1,
    "wallace": 1,
    "preserved": 1,
    "reproductive": 1,
    "trait": 4,
    "inherited": 1,
    "gregor": 1,
    "mendel": 1,
    "monk": 1,
    "experimented": 1,
    "sweet": 1,
    "agtc": 1,
    "adenine": 1,
    "guanine": 1,
    "thymine": 1,
    "cytosine": 1,
    "sexual": 1,
    "wherein": 2,
    "richer": 1,
    "reversal": 1,
    "chunk": 1,
    "virus": 1,
    "borrow": 1,
    "transposable": 1,
    "genome": 3,
    "poison": 1,
    "mate": 1,
    "replication": 1,
    "reproduced": 1,
    "darwinian": 1,
    "iota": 1,
    "naturalist": 1,
    "jean": 1,
    "lamarck": 1,
    "adaptation": 2,
    "baldwin": 4,
    "plasticity": 1,
    "nowlan": 2,
    "reside": 1,
    "morgan": 4,
    "griffith": 2,
    "contiguous": 1,
    "meaningful": 1,
    "antenna": 2,
    "reflector": 1,
    "deflector": 1,
    "marler": 1,
    "job-shop": 2,
    "miikkulainen": 2,
    "appeal": 3,
    "arises": 1,
    "superiority": 1,
    "appealing": 1,
    "4.2local": 1,
    "squared": 1,
    "minimized": 1,
    "six-dimensional": 1,
    "-dimensional": 1,
    "equation": 16,
    "neighborhood": 1,
    "altering": 1,
    "recompute": 2,
    "discretize": 1,
    "spacing": 1,
    "delta": 1,
    "incrementing": 2,
    "sampling": 1,
    "discretized": 1,
    "converge": 3,
    "optimum": 1,
    "slope": 1,
    "placing": 5,
    "alpha": 1,
    "adjusting": 1,
    "overshoot": 1,
    "overcome": 1,
    "dilemma": 1,
    "α—until": 1,
    "newton–raphson": 4,
    "matrix–vector": 1,
    "hessian": 2,
    "derivative": 2,
    "off-diagonal": 1,
    "moment": 2,
    "calculation": 1,
    "high-dimensional": 2,
    "inverting": 1,
    "constrained": 6,
    "airport-siting": 1,
    "constrain": 1,
    "dry": 1,
    "land": 1,
    "lake": 1,
    "convex": 13,
    "observe": 2,
    "calculate": 1,
    "erratic": 5,
    "actions—": 1,
    "deposit": 1,
    "carpet": 1,
    "generalize": 1,
    "esults": 2,
    "if–then–else": 2,
    "runtime": 1,
    "and–or": 7,
    "contingent": 3,
    "alternate": 2,
    "enclosing": 2,
    "enclosed": 4,
    "linking": 1,
    "outgoing": 2,
    "unintended": 1,
    "corrected": 1,
    "noncyclic": 1,
    "incarnation": 2,
    "dead": 6,
    "inscribed": 1,
    "ninth": 3,
    "tenth": 3,
    "eleventh": 3,
    "twelfth": 4,
    "slippery": 5,
    "non-erratic": 1,
    "bracket": 16,
    "referring": 1,
    "slip": 1,
    "occasion": 1,
    "confident": 1,
    "environment—perhaps": 1,
    "belt": 3,
    "snapped": 1,
    "move—then": 1,
    "attributed": 1,
    "pin": 1,
    "aimed": 1,
    "sensorless": 25,
    "conformant": 1,
    "rely": 1,
    "orienting": 1,
    "prescribe": 1,
    "broad-spectrum": 1,
    "antibiotic": 2,
    "prescribing": 1,
    "worsening": 1,
    "gained": 3,
    "coerce": 1,
    "belief-state": 22,
    "predictable—they": 1,
    "transform": 4,
    "etc.": 1,
    "unreachable": 1,
    "unsure": 1,
    "illegal": 3,
    "union": 1,
    "catastrophe": 1,
    "intersection": 1,
    "singleton": 6,
    "mval": 1,
    "transferred": 1,
    "ignorance": 3,
    "tested": 1,
    "superset": 2,
    "discard": 2,
    "space—we": 1,
    "compact": 1,
    "incremental": 9,
    "quickly—when": 1,
    "unsolvable": 2,
    "upper-left": 1,
    "ercepts": 1,
    "ercept": 3,
    "local-sensing": 4,
    "maze-like": 2,
    "north": 1,
    "east": 3,
    "west": 3,
    "south": 8,
    "computes": 5,
    "redlct": 1,
    "possible-percepts": 2,
    "enlarge": 1,
    "border": 2,
    "supersets": 1,
    "black-box": 1,
    "formulates": 1,
    "prediction–observation–update": 1,
    "calculated": 1,
    "kindergarten": 2,
    "self-loop": 2,
    "prediction–update": 1,
    "maintenance": 2,
    "environments—which": 1,
    "environments—maintaining": 1,
    "monitoring": 1,
    "estimation": 2,
    "estimator": 1,
    "localization": 3,
    "equipped": 1,
    "sonar": 1,
    "obstacle—the": 1,
    "figure—in": 1,
    "compass": 1,
    "thin": 2,
    "noiseless": 1,
    "navigational": 1,
    "broken": 1,
    "is—its": 1,
    "inspect": 4,
    "redict": 2,
    "collapsed": 1,
    "shrink": 1,
    "down—as": 1,
    "east-west": 1,
    "corridor": 2,
    "faulty": 2,
    "extract": 1,
    "offline": 4,
    "interleaf": 1,
    "semi-dynamic": 1,
    "creek": 1,
    "paddle": 1,
    "escaping": 1,
    "labyrinths—required": 1,
    "aspiring": 1,
    "hero": 1,
    "antiquity—are": 1,
    "spatial": 1,
    "newborn": 1,
    "baby": 1,
    "experienced": 1,
    "interleaving": 3,
    "stipulate": 1,
    "explorer": 2,
    "ignorant": 1,
    "connect": 14,
    "manhattan-distance": 1,
    "knew": 1,
    "bottomless": 1,
    "pit": 1,
    "dead-end": 1,
    "adversary": 3,
    "—we": 1,
    "wherever": 1,
    "encircled": 4,
    "exploration—staircases": 1,
    "ramp": 1,
    "cliff": 1,
    "irreversible": 2,
    "—there": 1,
    "explorable": 6,
    "reversible": 5,
    "telling": 1,
    "distant": 2,
    "unexplored": 1,
    "entered": 1,
    "predecessor": 1,
    "backtracked": 1,
    "nline": 4,
    "-dfs-a": 4,
    "traversing": 1,
    "excursion": 1,
    "contrived": 1,
    "trap": 1,
    "augmenting": 1,
    "randomness": 2,
    "double": 1,
    "flattening": 1,
    "lrta": 8,
    "encourages": 1,
    "spaces—there": 1,
    "astray": 1,
    "state—simply": 1,
    "acquire": 1,
    "successor—that": 1,
    "pure": 1,
    "suggestion": 1,
    "bright": 1,
    "-coordinate": 1,
    "manipulable": 1,
    "invest": 1,
    "falling": 1,
    "reuse": 2,
    "unchanged": 2,
    "information—either": 1,
    "best-path": 1,
    "high-scoring": 1,
    "polynomial-time": 1,
    "well-formed": 2,
    "zero": 2,
    "regardless": 1,
    "raphson": 1,
    "brent": 1,
    "bounded-width": 1,
    "arpy": 1,
    "lowerre": 1,
    "reinvigorated": 1,
    "constraint-satisfaction": 1,
    "-queens": 4,
    "minton": 2,
    "selman": 2,
    "simultaneous": 1,
    "renaissance": 1,
    "christos": 1,
    "papadimitriou": 3,
    "koutsoupias": 1,
    "aldous": 1,
    "vazirani": 1,
    "tabu": 3,
    "popularity": 2,
    "glover": 1,
    "laguna": 1,
    "revisited": 2,
    "tage": 1,
    "boyan": 1,
    "moore": 1,
    "quadratic": 4,
    "calculates": 1,
    "restart": 1,
    "gomes": 3,
    "heavy-tailed": 2,
    "completion": 1,
    "hoos": 3,
    "stützle": 2,
    "book-length": 1,
    "coverage": 3,
    "kirkpatrick": 2,
    "borrowed": 1,
    "metropolis": 2,
    ",1953": 1,
    "los": 1,
    "alamo": 1,
    "dinner": 1,
    "party": 1,
    "inspiration": 1,
    "mountaineering": 1,
    "market-based": 1,
    "dia": 1,
    "particle": 1,
    "swarm": 1,
    "yao": 1,
    "mézard": 1,
    "wolf": 1,
    "optimizers": 1,
    "mirjalili": 1,
    "lewis": 1,
    "ornithology": 1,
    "cuckoo": 1,
    "yang": 2,
    "deb": 1,
    "entomology": 1,
    "ant": 1,
    "colony": 2,
    "dorigo": 1,
    "bee": 1,
    "karaboga": 1,
    "basturk": 1,
    "firefly": 1,
    "glowworm": 1,
    "krishnanand": 1,
    "ghose": 1,
    "leonid": 1,
    "kantorovich": 1,
    "simplex": 1,
    "dantzig": 1,
    "karmarkar": 1,
    "interior-point": 1,
    "nesterov": 1,
    "nemirovski": 2,
    "excellent": 3,
    "ben-tal": 1,
    "boyd": 1,
    "vandenberghe": 1,
    "sewall": 1,
    "wright": 1,
    "friedman": 1,
    "rechenberg": 1,
    "airfoil": 1,
    "holland": 2,
    "langton": 1,
    "viewing": 1,
    "conwy": 1,
    "lloyd": 1,
    "clarify": 1,
    "littman": 1,
    "szathmáry": 1,
    "ridley": 1,
    "carroll": 1,
    "juels": 1,
    "wattenberg": 1,
    "baluja": 1,
    "population-based": 1,
    "pelikan": 1,
    "dynamical": 1,
    "rabani": 1,
    "lohn": 1,
    "computer-aided": 1,
    "renner": 1,
    "ekart": 1,
    "stanislawska": 1,
    "ghaheri": 1,
    "format": 1,
    "splicing": 1,
    "spurred": 1,
    "koza": 2,
    "fogel": 2,
    "debate": 1,
    "effectiveness": 1,
    "gecco": 1,
    "langdon": 1,
    "poli": 2,
    "unpredictability": 1,
    "amarel": 1,
    "raph": 1,
    "—which": 1,
    "montanari": 3,
    "top-down": 1,
    "bottom-up": 1,
    "lightest": 1,
    "derivation": 1,
    "felzenszwalb": 1,
    "underwent": 1,
    "revival": 1,
    "jimenez": 1,
    "torras": 1,
    "bonet": 2,
    "geffner": 2,
    "transforming": 1,
    "erdmann": 1,
    "mason": 1,
    "orient": 1,
    "tilting": 1,
    "oriented": 1,
    "barrier": 1,
    "conveyor": 1,
    "insight": 1,
    "wiegley": 1,
    "nourbakhsh": 1,
    "logic-based": 1,
    "goldman": 1,
    "boddy": 1,
    "weld": 1,
    "refined": 1,
    "bryce": 1,
    "kurien": 1,
    "wolfe": 1,
    "eulerian": 1,
    "hierholzer": 1,
    "thorough": 1,
    "yannakakis": 1,
    "path-planning": 1,
    "spoil": 1,
    "koenig": 3,
    "lite": 1,
    "likhachev": 1,
    "realtime": 1,
    "two-player": 1,
    "barto": 1,
    "uncertainty—always": 1,
    "unvisited": 1,
    "state—can": 1,
    "dasgupta": 1,
    "pemberton": 1,
    "sturtevant": 1,
    "bulitko": 1,
    "luby": 1,
    "restarting": 1,
    "letting": 1,
    "fitting": 1,
    "surface—which": 1,
    "joining": 1,
    "opposed": 2,
    "sympathize": 1,
    "appliance": 1,
    "apology": 1,
    "internet": 1,
    "connection.": 1,
    "hughes": 1,
    "indivisible—a": 1,
    "csp": 69,
    "variable/value": 3,
    "violate": 6,
    "csps": 46,
    "5.1defining": 1,
    "rel": 2,
    "tuple": 3,
    "participate": 2,
    "tuples": 5,
    "assignment": 67,
    "unassigned": 5,
    "coloring": 11,
    "tired": 1,
    "territory": 3,
    "mid": 2,
    "terminal": 4,
    "column-wise": 1,
    "row-wise": 2,
    "australia": 17,
    "map-coloring": 9,
    "abbreviation": 1,
    "enumerated": 1,
    "visualize": 1,
    "swathe": 1,
    "searcher": 1,
    "violates": 2,
    "solution—we": 1,
    "constraint—so": 1,
    "assert": 2,
    "another—for": 1,
    "installed": 1,
    "hubcap": 3,
    "install": 2,
    "axle": 8,
    "tighten": 2,
    "nut": 2,
    "affix": 2,
    "precedence": 2,
    "duration": 1,
    "attach": 1,
    "disjunctive": 1,
    ",30": 1,
    "jobshop": 2,
    "finite-domain": 3,
    "deadline": 1,
    "job-scheduling": 1,
    "variables—the": 2,
    "hubble": 2,
    "telescope": 2,
    "finish": 2,
    "continuous-valued": 1,
    "astronomical": 1,
    "continuous-domain": 1,
    "studied—quadratic": 1,
    "second-order": 1,
    "conic": 1,
    "constitute": 1,
    "unary": 8,
    "restricts": 1,
    "australian": 2,
    "tolerate": 1,
    "relates": 1,
    "nsw": 16,
    "higher-order": 6,
    "ternary": 1,
    "confusing": 1,
    "alldiff": 16,
    "sudoku": 16,
    "cryptarithmetic": 5,
    "n-ary": 1,
    "substitution": 1,
    "+10": 1,
    "auxiliary": 3,
    "hypergraph": 3,
    "hypernodes": 1,
    "-ary": 3,
    "constraints—constraints": 1,
    "nary": 2,
    "constraints—which": 1,
    "transformation": 2,
    "error-prone": 1,
    "class-scheduling": 1,
    "teach": 1,
    "prof.": 5,
    "morning": 2,
    "afternoon": 2,
    "p.m.": 1,
    "department": 1,
    "chair": 1,
    "assignments—for": 1,
    "assigning": 5,
    "slot": 2,
    "path-based": 1,
    "cop": 3,
    "propagation": 13,
    "intertwined": 1,
    "preprocessing": 3,
    "enforcing": 4,
    "eliminated": 2,
    "node-consistent": 3,
    "dislike": 1,
    "expecting": 1,
    "arc-consistent": 19,
    "decimal": 1,
    "ac-3": 20,
    "revise": 1,
    "revised": 1,
    "csp—they": 1,
    "solutions—but": 1,
    "arc-consistency": 4,
    "inserted": 1,
    "delete": 4,
    "satisfied": 3,
    "western": 1,
    "northern": 1,
    "tightens": 2,
    "inferred": 1,
    "triple": 2,
    "two-variable": 1,
    "path-consistent": 2,
    "enumerating": 1,
    "-consistency": 7,
    "-consistent": 7,
    "1-consistency": 1,
    "2-consistency": 2,
    "3-consistency": 2,
    "1-consistent": 1,
    "2-consistent": 1,
    "3-consistent": 1,
    "lunch": 1,
    "establishing": 1,
    "inconsistency": 7,
    "atmost": 3,
    "enforce": 1,
    "deleting": 2,
    "deleted": 4,
    "resource-limited": 1,
    "values—such": 1,
    "logistical": 1,
    "vehicles—it": 1,
    "consistency-checking": 1,
    "managed": 1,
    "airline-scheduling": 1,
    "propagating": 2,
    "bounds-consistent": 1,
    "lower-bound": 1,
    "upper-bound": 1,
    "realize": 1,
    "newspaper": 1,
    "pre-filled": 1,
    "surrounded": 1,
    "infer": 2,
    "puzzle—all": 1,
    "lose": 1,
    "pc-2": 2,
    "resourceful": 1,
    "aficionado": 1,
    "naked": 2,
    "triples.": 1,
    "strategies—arc": 1,
    "constraintsolving": 1,
    "5.3backtracking": 1,
    "commutativity": 1,
    "commutative": 1,
    "restored": 1,
    "....": 1,
    "rook": 9,
    "knight": 2,
    "pawn": 4,
    "elect": 3,
    "nassigned": 3,
    "ariable": 3,
    "rder": 2,
    "omain": 2,
    "alues": 2,
    "generalpurpose": 1,
    "nference": 5,
    "impose": 2,
    "arc-": 1,
    "path-": 1,
    "acktrack": 3,
    "retracted": 1,
    "acktracking": 2,
    "supplying": 1,
    "domain-independent": 2,
    "select-unassigned-variable": 1,
    "idea—choosing": 1,
    "fewest": 2,
    "values—is": 1,
    "minimum-remaining-values": 3,
    "fail-first": 2,
    "mrv": 7,
    "immediately—avoiding": 1,
    "pointless": 1,
    "handy": 1,
    "mainland": 5,
    "counterclockwise": 1,
    "tie-breaker": 1,
    "least-constraining-value": 4,
    "eliminates": 3,
    "fail-last": 1,
    "enumerate": 1,
    "forward-checking": 3,
    "backtracks": 3,
    "curved": 1,
    "win": 1,
    "constrains": 1,
    "detects": 3,
    "mac": 4,
    "propagate": 2,
    "hronological": 1,
    "subsection": 1,
    "tasmania": 6,
    "silly—recoloring": 1,
    "resolving": 1,
    "problem—a": 1,
    "backjumping": 17,
    "accumulates": 1,
    "indicator": 1,
    "sharp-eyed": 1,
    "eagle-eyed": 1,
    "pruned": 2,
    "mac—you": 1,
    "variables—": 1,
    "different–and": 1,
    "deeper–notion": 1,
    "skip": 1,
    "conflict-directed": 4,
    "backjump": 2,
    "absorbs": 2,
    "backjumps": 1,
    "conf": 2,
    "waste": 1,
    "no-good": 6,
    "forbid": 1,
    "cache": 1,
    "no-goods": 2,
    "encounter": 1,
    "5.4local": 1,
    "conflicted": 2,
    "rightmost": 1,
    "min-conflicts": 9,
    "dice": 1,
    "two-step": 1,
    "reassignment": 1,
    "onflicts": 2,
    "minimal-conflict": 1,
    "placement": 1,
    "min-": 1,
    "search—allowing": 1,
    "score—can": 1,
    "forbidding": 1,
    "weighting": 1,
    "topography": 1,
    "weekly": 1,
    "infeasible": 1,
    "repair": 1,
    "decompose": 1,
    "—any": 1,
    "independence": 1,
    "ascertained": 1,
    "n/c": 1,
    "decomposition": 22,
    "dividing": 1,
    "delicious": 1,
    "tree-structured": 9,
    "directional": 3,
    "dac": 1,
    "topological": 2,
    "three-level": 1,
    "ree": 3,
    "-csp-s": 3,
    "collapsing": 1,
    "cutset": 10,
    "conditioning": 4,
    "fixing": 1,
    "forest": 1,
    "huge—for": 1,
    "100-boolean-variable": 1,
    "verify": 1,
    "olver": 1,
    "santwa": 2,
    "three-tuple": 1,
    "santq": 1,
    "admits": 1,
    "width": 16,
    "cycle-cutset": 3,
    "symmetry": 7,
    "looked": 1,
    "permuting": 1,
    "symmetry-breaking": 1,
    "alphabetical": 1,
    "interwoven": 1,
    "versus": 1,
    "diophantus": 1,
    "algebraic": 1,
    "generalized": 1,
    "brahmagupta": 1,
    "elimination": 1,
    "gauss": 3,
    "fourier": 1,
    "four-color": 1,
    "planar": 1,
    "guthrie": 1,
    "solution—despite": 1,
    "contrary—until": 1,
    "haken": 2,
    "purist": 1,
    "disappointed": 1,
    "gonthier": 1,
    "appel": 1,
    "sutherland": 1,
    "cad": 1,
    "identification": 1,
    "ugo": 1,
    "sander": 1,
    "peirce": 1,
    "beek": 5,
    "bistarelli": 1,
    "popularized": 2,
    "waltz": 2,
    "polyhedral": 1,
    "line-labeling": 1,
    "ac-4": 1,
    "mohr": 1,
    "experimenting": 1,
    "haralick": 2,
    "elliott": 2,
    "favored": 1,
    "mcgregor": 1,
    "assignment—an": 1,
    "sabin": 1,
    "freuder": 5,
    "convincing": 1,
    "apt": 3,
    "bessière": 1,
    "barták": 2,
    "marriott": 1,
    "stuckey": 1,
    "regin": 1,
    "stergiou": 1,
    "walsh": 1,
    "hoeve": 3,
    "katriel": 2,
    "hentenryck": 1,
    "simonis": 1,
    "agerbeck": 1,
    "-hard": 1,
    "schachzeitung": 1,
    "tatonniren": 1,
    "tâtonner": 1,
    "—to": 1,
    "grope": 1,
    "13-queens": 1,
    "golomb": 1,
    "baumert": 1,
    "bitner": 1,
    "reingold": 1,
    "brelaz": 1,
    "tiebreaker": 1,
    "-coloring": 1,
    "kondrak": 3,
    "subsumed": 1,
    "graph-based": 1,
    "backjumping-based": 1,
    "frost": 2,
    "stallman": 2,
    "sussman": 2,
    "dependency-directed": 1,
    "back-jumping": 2,
    "truth": 1,
    "kleer": 1,
    "reused": 1,
    "backmarking": 2,
    "pairwise": 1,
    "rechecking": 1,
    "subsumes": 2,
    "ginsberg": 1,
    "invalidate": 1,
    "moskewicz": 1,
    "beck": 1,
    "sosic": 1,
    "astounding": 1,
    "n-queens": 1,
    "reappraisal": 1,
    "prevalence": 1,
    "peter": 1,
    "cheeseman": 1,
    "konolige": 1,
    "inferior": 1,
    "pinkas": 1,
    "tsang": 2,
    "offered": 1,
    "aarts": 1,
    "lenstra": 1,
    "relating": 2,
    "originates": 1,
    "hypergraphs": 1,
    "beeri": 1,
    "bayardo": 2,
    "miranker": 1,
    "robertson": 1,
    "seymour": 1,
    "induced": 1,
    "hypertree": 4,
    "elsat": 1,
    "schrag": 1,
    "and-or": 1,
    "mateescu": 1,
    "collin": 1,
    "pearce": 1,
    "hooker": 1,
    "testing—as": 1,
    "time—and": 1,
    "efficacy": 1,
    "lecoutre": 1,
    "rossi": 1,
    "carbonnel": 1,
    "cooper": 1,
    "tractable": 1,
    "fruhwirth": 1,
    "abdennadher": 1,
    "specialist": 1,
    "latest": 1,
    "venue": 1,
    "edge-consistent": 1,
    "patriotic": 1,
    "tasmanian": 1,
    "sulawesi": 1
  },
  "ai_core_terms": [
    "reinforcement learning",
    "attention mechanism",
    "rational agent",
    "convolutional neural network",
    "neural network",
    "markov decision process",
    "bayesian network",
    "perceptron",
    "machine learning",
    "backpropagation"
  ]
}