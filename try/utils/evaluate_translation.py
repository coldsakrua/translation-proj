"""
ç¿»è¯‘è´¨é‡è¯„ä¼°è„šæœ¬
ç”¨äºæ‰¹é‡è¯„ä¼°ç¿»è¯‘ç»“æœ
"""
import json
import os
import sys
from pathlib import Path
from typing import Dict, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from utils.translation_evaluator import TranslationEvaluator, load_reference_translations


def evaluate_single_chunk(chunk_file: str, reference_translations: Optional[Dict] = None):
    """
    è¯„ä¼°å•ä¸ªchunkæ–‡ä»¶
    
    Args:
        chunk_file: chunkæ–‡ä»¶è·¯å¾„
        reference_translations: å‚è€ƒè¯‘æ–‡å­—å…¸ï¼ˆå¯é€‰ï¼‰
    """
    evaluator = TranslationEvaluator(reference_translations)
    result = evaluator.evaluate_chunk_file(chunk_file, reference_translations)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š Chunkè¯„ä¼°ç»“æœ: {chunk_file}")
    print("="*60)
    
    if "error" in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    print(f"\næ€»ä½“åˆ†æ•°: {result['overall_score']}/10")
    
    if "unsupervised_avg" in result:
        print(f"æ— ç›‘ç£æŒ‡æ ‡å¹³å‡åˆ†: {result['unsupervised_avg']}/10")
    if "supervised_avg" in result:
        print(f"æœ‰ç›‘ç£æŒ‡æ ‡å¹³å‡åˆ†: {result['supervised_avg']}/10")
    
    print("\nè¯¦ç»†æŒ‡æ ‡:")
    for metric_name, metric_data in result.get("metrics", {}).items():
        if isinstance(metric_data, dict) and "score" in metric_data:
            print(f"  - {metric_name}: {metric_data['score']}/10")
            if "details" in metric_data:
                print(f"    {metric_data['details']}")
    
    return result


def evaluate_chapter(
    book_id: str,
    chapter_id: int,
    num_chunks: int,
    reference_file: Optional[str] = None
):
    """
    è¯„ä¼°æ•´ä¸ªç« èŠ‚
    
    Args:
        book_id: ä¹¦ç±ID
        chapter_id: ç« èŠ‚ID
        num_chunks: chunkæ•°é‡
        reference_file: å‚è€ƒè¯‘æ–‡æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # åŠ è½½å‚è€ƒè¯‘æ–‡
    reference_translations = None
    if reference_file and os.path.exists(reference_file):
        print(f"ğŸ“– åŠ è½½å‚è€ƒè¯‘æ–‡: {reference_file}")
        reference_translations = load_reference_translations(reference_file)
        print(f"  åŠ è½½äº† {len(reference_translations)} ä¸ªç« èŠ‚çš„å‚è€ƒè¯‘æ–‡")
    
    evaluator = TranslationEvaluator(reference_translations)
    result = evaluator.evaluate_chapter(book_id, chapter_id, num_chunks, reference_translations)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š ç« èŠ‚ {chapter_id} è¯„ä¼°ç»“æœ")
    print("="*60)
    
    if "error" in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    print(f"\nç« èŠ‚å¹³å‡åˆ†: {result['average_score']}/10")
    print(f"è¯„ä¼°chunkæ•°: {result['num_chunks']}")
    
    print("\nå„æŒ‡æ ‡ç»Ÿè®¡:")
    for metric_name, stats in result.get("metric_summary", {}).items():
        print(f"  - {metric_name}:")
        print(f"    å¹³å‡: {stats['average']}/10")
        print(f"    èŒƒå›´: {stats['min']}/10 - {stats['max']}/10")
    
    print("\nå„chunkåˆ†æ•°:")
    for i, score in enumerate(result.get("chunk_scores", [])):
        print(f"  Chunk {i}: {score}/10")
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    output_file = f"output/{book_id}/chapter_{chapter_id}/evaluation_result.json"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… è¯„ä¼°ç»“æœå·²ä¿å­˜: {output_file}")
    
    return result


def evaluate_book(
    book_id: str,
    max_chapters: Optional[int] = None,
    reference_file: Optional[str] = None
):
    """
    è¯„ä¼°æ•´æœ¬ä¹¦
    
    Args:
        book_id: ä¹¦ç±ID
        max_chapters: æœ€å¤§ç« èŠ‚æ•°ï¼ˆå¯é€‰ï¼‰
        reference_file: å‚è€ƒè¯‘æ–‡æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # åŠ è½½å‚è€ƒè¯‘æ–‡
    reference_translations = None
    if reference_file and os.path.exists(reference_file):
        print(f"ğŸ“– åŠ è½½å‚è€ƒè¯‘æ–‡: {reference_file}")
        reference_translations = load_reference_translations(reference_file)
    
    evaluator = TranslationEvaluator(reference_translations)
    
    book_results = []
    chapter_scores = []
    
    # æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚
    book_dir = f"output/{book_id}"
    if not os.path.exists(book_dir):
        print(f"âŒ ä¹¦ç±ç›®å½•ä¸å­˜åœ¨: {book_dir}")
        return
    
    chapters = []
    for item in os.listdir(book_dir):
        if item.startswith("chapter_") and os.path.isdir(os.path.join(book_dir, item)):
            try:
                chapter_id = int(item.split("_")[1])
                chapters.append(chapter_id)
            except:
                pass
    
    chapters.sort()
    
    if max_chapters:
        chapters = chapters[:max_chapters]
    
    print(f"\nğŸ“š å¼€å§‹è¯„ä¼°ä¹¦ç±: {book_id}")
    print(f"   ç« èŠ‚æ•°: {len(chapters)}")
    
    for chapter_id in chapters:
        chapter_dir = os.path.join(book_dir, f"chapter_{chapter_id}")
        
        # ç»Ÿè®¡chunkæ•°é‡
        chunk_files = [f for f in os.listdir(chapter_dir) if f.startswith("chunk_") and f.endswith(".json")]
        num_chunks = len(chunk_files)
        
        if num_chunks == 0:
            continue
        
        print(f"\nè¯„ä¼°ç« èŠ‚ {chapter_id}...")
        result = evaluator.evaluate_chapter(book_id, chapter_id, num_chunks, reference_translations)
        
        if "error" not in result:
            book_results.append(result)
            chapter_scores.append(result["average_score"])
    
    if not book_results:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è¯„ä¼°ç»“æœ")
        return
    
    # ä¹¦ç±æ€»ä½“ç»Ÿè®¡
    print("\n" + "="*60)
    print(f"ğŸ“š ä¹¦ç± {book_id} æ€»ä½“è¯„ä¼°ç»“æœ")
    print("="*60)
    
    overall_avg = sum(chapter_scores) / len(chapter_scores) if chapter_scores else 0
    print(f"\nä¹¦ç±å¹³å‡åˆ†: {overall_avg:.2f}/10")
    print(f"è¯„ä¼°ç« èŠ‚æ•°: {len(book_results)}")
    
    # å„æŒ‡æ ‡æ€»ä½“ç»Ÿè®¡
    all_metrics = {}
    for result in book_results:
        for metric_name, stats in result.get("metric_summary", {}).items():
            if metric_name not in all_metrics:
                all_metrics[metric_name] = []
            all_metrics[metric_name].append(stats["average"])
    
    print("\nå„æŒ‡æ ‡æ€»ä½“å¹³å‡:")
    for metric_name, scores in all_metrics.items():
        avg = sum(scores) / len(scores)
        print(f"  - {metric_name}: {avg:.2f}/10")
    
    # ä¿å­˜ä¹¦ç±è¯„ä¼°ç»“æœ
    book_output_file = f"output/{book_id}/book_evaluation_result.json"
    with open(book_output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "book_id": book_id,
            "overall_score": round(overall_avg, 2),
            "num_chapters": len(book_results),
            "chapter_results": book_results,
            "metric_summary": {k: round(sum(v)/len(v), 2) for k, v in all_metrics.items()}
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ä¹¦ç±è¯„ä¼°ç»“æœå·²ä¿å­˜: {book_output_file}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ç¿»è¯‘è´¨é‡è¯„ä¼°å·¥å…·")
    parser.add_argument("--book", type=str, help="ä¹¦ç±ID")
    parser.add_argument("--chapter", type=int, help="ç« èŠ‚ID")
    parser.add_argument("--chunk", type=str, help="chunkæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--reference", type=str, help="å‚è€ƒè¯‘æ–‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max-chapters", type=int, help="æœ€å¤§ç« èŠ‚æ•°")
    
    args = parser.parse_args()
    
    if args.chunk:
        # è¯„ä¼°å•ä¸ªchunk
        reference_translations = None
        if args.reference:
            reference_translations = load_reference_translations(args.reference)
        evaluate_single_chunk(args.chunk, reference_translations)
    elif args.book and args.chapter is not None:
        # è¯„ä¼°ç« èŠ‚
        # éœ€è¦å…ˆç»Ÿè®¡chunkæ•°é‡
        chapter_dir = f"output/{args.book}/chapter_{args.chapter}"
        if os.path.exists(chapter_dir):
            chunk_files = [f for f in os.listdir(chapter_dir) if f.startswith("chunk_") and f.endswith(".json")]
            num_chunks = len(chunk_files)
            evaluate_chapter(args.book, args.chapter, num_chunks, args.reference)
        else:
            print(f"âŒ ç« èŠ‚ç›®å½•ä¸å­˜åœ¨: {chapter_dir}")
    elif args.book:
        # è¯„ä¼°æ•´æœ¬ä¹¦
        evaluate_book(args.book, args.max_chapters, args.reference)
    else:
        print("è¯·æŒ‡å®šè¦è¯„ä¼°çš„å†…å®¹ï¼š--chunk, --chapter æˆ– --book")
        print("\nç¤ºä¾‹:")
        print("  python evaluate_translation.py --chunk output/YOLO/chapter_1/chunk_000.json")
        print("  python evaluate_translation.py --book YOLO --chapter 1 --reference data/3_ch.json")
        print("  python evaluate_translation.py --book YOLO --reference data/3_ch.json")

