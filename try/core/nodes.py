from typing import Annotated, List, Dict, TypedDict, Union, Optional
from enum import Enum

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
# from langchain_core.pydantic_v1 import BaseModel, Field
from pydantic import BaseModel, Field

from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver

from .get_llm import llm
from rag.es_retriever import retrieve_translation_memory
from .latex_utils import extract_latex, restore_latex, has_latex

from typing import Any

import json
import os
import time

# å°è¯•å¯¼å…¥RateLimitErrorï¼ˆä¸åŒç‰ˆæœ¬çš„openaiå¯èƒ½ä½ç½®ä¸åŒï¼‰
try:
    from openai import RateLimitError
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨å¼‚å¸¸å¤„ç†
    RateLimitError = Exception  # ä½¿ç”¨é€šç”¨Exceptionï¼Œåœ¨ä»£ç ä¸­é€šè¿‡é”™è¯¯æ¶ˆæ¯åˆ¤æ–­
# ============================================
# 1. å®šä¹‰æ•°æ®ç»“æ„ (State & Pydantic Models)
# ============================================

# (A2) é£æ ¼å…ƒæ•°æ®ç»“æ„
class StyleMetadata(BaseModel):
    domain: str = Field(description="æ–‡æœ¬é¢†åŸŸï¼Œå¦‚æ³•å¾‹ã€æ–‡å­¦ã€è¯´å”±")
    tone: str = Field(description="è¯­ä½“é£æ ¼ï¼Œå¦‚æ­£å¼ã€å£è¯­ã€å¹½é»˜")
    complexity: str = Field(description="æ–‡æœ¬å¤æ‚åº¦")

# (B1) æœ¯è¯­æ¡ç›®ç»“æ„
class TermEntry(BaseModel):
    src: str = Field(description="åŸæ–‡è¯æ±‡ï¼ˆè‹±æ–‡ï¼‰")
    type: str = Field(description="ç±»å‹: NER/Term/Idiom/Slang/Acronym/Proper Noun")
    context_meaning: Optional[str] = Field(description="è¯­å¢ƒä¸‹çš„å«ä¹‰ï¼ˆä¸­æ–‡ï¼‰")
    suggested_trans: str = Field(description="å»ºè®®è¯‘æ³•ï¼ˆå¿…é¡»æ˜¯ä¸­æ–‡ç®€ä½“ï¼‰")
    rationale: str = Field(description="ç¿»è¯‘ç†ç”±æˆ–ç­–ç•¥ï¼ˆä¸­æ–‡ï¼‰")

class TermList(BaseModel):
    terms: List[TermEntry]

# (C3) è¯„ä¼°ç»“æœç»“æ„
class QualityReview(BaseModel):
    score: int = Field(description="1-10åˆ†ï¼Œ10åˆ†ä¸ºå®Œç¾")
    critique: str = Field(description="è¯¦ç»†çš„æ‰¹è¯„å’Œä¿®æ”¹å»ºè®®")
    pass_flag: bool = Field(description="æ˜¯å¦è¾¾åˆ°å‡ºç‰ˆæ ‡å‡†")

class Book:
    book_id: str
    meta: dict
    chapters: List["Chapter"]
class Chapter:
    chapter_id: int
    title: str
    chunks: List["Chunk"]
    memory: Dict[str, str]   # æœ¬ç« ç´¯è®¡æ€»ç»“
class Chunk:
    chunk_id: int
    text: str
    translation: Optional[str]

# --- LangGraph å…¨å±€çŠ¶æ€ ---
class TranslationState(BaseModel):
    # ======== æ ¸å¿ƒè¾“å…¥ï¼ˆå¿…é¡»ï¼‰ ========
    book_id: str
    chapter_id: int
    chunk_id: int
    source_text: str
    thread_id: str
    # ===== ä¸Šä¸‹æ–‡ =====
    book_meta: Dict[str, Any] = Field(default_factory=dict)
    chapter_memory: List[str] = Field(default_factory=list)
    global_glossary: Dict[str, Any] = Field(default_factory=dict)      # å…¨ä¹¦æœ¯è¯­è¡¨
    rag_context: List[str] = Field(default_factory=list)              # ES / å¤–éƒ¨æ£€ç´¢ç»“æœ
    # ===== ä¸­é—´ç»“æœ =====
    style_guide: Dict[str, Any] = Field(default_factory=dict)
    raw_terms: List[str] = Field(default_factory=list) # åˆæ­¥è¯†åˆ«çš„éš¾è¯
    glossary: List[Dict[str, Any]] = Field(default_factory=list) # (B3) ç»è¿‡æŸ¥è¯å’Œäººå·¥ç¡®è®¤çš„æœ¯è¯­è¡¨
    # ===== ç¿»è¯‘ç»“æœ =====
    draft_versions: List[str] = Field(default_factory=list) # ç›´è¯‘/æ„è¯‘/é£æ ¼åŒ–ç‰ˆæœ¬
    combined_translation: Optional[str] = None # èåˆåçš„è¯‘æ–‡
    back_translation: Optional[str] = None # å›è¯‘æ–‡
    # ===== æ§åˆ¶ä¿¡å· =====
    need_human_review: bool = True
    critique: Optional[str] = None
    quality_score: Optional[float] = None
    revision_count: int = 0

# ============================================
# 2. èŠ‚ç‚¹å®ç° (Node Functions)
# ============================================

# --- Node A: é£æ ¼ä¸é¢„å¤„ç† ---
def node_analyze_style(state: TranslationState):
    print("\nğŸ”¹ [Phase A] Analyzing Style & Domain...")
    
    chapter_ctx = "\n".join(state.chapter_memory) if state.chapter_memory else "æ— "
    
    prompt = f"""
    åˆ†æä»¥ä¸‹æ–‡æœ¬çš„é¢†åŸŸã€è¯­ä½“é£æ ¼å’Œå¤æ‚åº¦ã€‚
    å‚è€ƒä¸Šæ–‡è„‰ç»œï¼š{chapter_ctx}
    å½“å‰æ–‡æœ¬ï¼š{state.source_text}
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š
    {{
        "domain": "é¢†åŸŸ",
        "tone": "è¯­ä½“é£æ ¼",
        "complexity": "å¤æ‚åº¦"
    }}
    """
    # ç»“æ„åŒ–è¾“å‡º
    try:
        structured_llm = llm.with_structured_output(StyleMetadata)
        res = structured_llm.invoke(prompt)
        print("----------------------------", res)
        style_data = res.model_dump()
    except Exception as e:
        print(f"âš ï¸  Structured output failed: {e}")
        print("   Using default style metadata...")
        # å›é€€åˆ°é»˜è®¤å€¼
        style_data = {
            "domain": "é€šç”¨",
            "tone": "æ­£å¼",
            "complexity": "ä¸­ç­‰"
        }
    
    # ç›´æ¥æ›´æ–°çŠ¶æ€å±æ€§
    state.style_guide = style_data
    return {"style_guide": state.style_guide}

# --- Node B1: æœ¯è¯­è¯†åˆ« (Term Miner) ---
def node_extract_terms(state: TranslationState):
    print("\nğŸ”¹ [Phase B1] Mining Terms & Entities...")
    
    domain = state.style_guide.get('domain', 'æœªçŸ¥é¢†åŸŸ')
    
    prompt = f"""
    ä½ æ˜¯æœ¯è¯­ä¸“å®¶ã€‚è¯·è¯†åˆ«æ–‡æœ¬ä¸­çš„ï¼š
    1. å‘½åå®ä½“ (NER)
    2. é¢†åŸŸæœ¯è¯­ (Domain Terms)
    3. æ–‡åŒ–è´Ÿè½½è¯/ä¿šè¯­ (Idioms/Slang)

    ä»…è¾“å‡ºéœ€è¦æŸ¥è¯æˆ–ç»Ÿä¸€è¯‘åçš„è¯æ±‡åˆ—è¡¨ã€‚
    æ–‡æœ¬ï¼š{state.source_text}
    é¢†åŸŸï¼š{domain}
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™æ–‡æœ¬ï¼š
    {{
        "terms": ["term1", "term2", "term3"]
    }}
    """
    class RawTerms(BaseModel):
        terms: List[str]

    try:
        structured_llm = llm.with_structured_output(RawTerms)
        res = structured_llm.invoke(prompt)
        print("----------------------------", res)
        terms_list = res.terms
    except Exception as e:
        print(f"âš ï¸  Structured output failed: {e}")
        print("   Falling back to manual JSON parsing...")
        # å›é€€æ–¹æ¡ˆï¼šæ™®é€šè°ƒç”¨ + æ‰‹åŠ¨è§£æ
        response = llm.invoke(prompt)
        content = response.content.strip()
        
        # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
        import re
        json_match = re.search(r'\{[^{}]*"terms"[^{}]*\[[^\]]*\][^{}]*\}', content, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹
            json_str = content
            if json_str.startswith('```'):
                json_str = json_str.split('```')[1]
                if json_str.startswith('json'):
                    json_str = json_str[4:]
            json_str = json_str.strip()
        
        try:
            import json
            parsed = json.loads(json_str)
            terms_list = parsed.get("terms", [])
        except json.JSONDecodeError as je:
            print(f"âš ï¸  JSON parsing failed: {je}")
            print(f"   Raw content: {content[:200]}...")
            # æœ€åçš„å›é€€ï¼šå°è¯•ä»æ–‡æœ¬ä¸­æå–å¯èƒ½çš„æœ¯è¯­
            terms_list = []
            # ç®€å•æå–ï¼šæŸ¥æ‰¾å¼•å·ä¸­çš„å†…å®¹æˆ–å¤§å†™å•è¯
            import re
            # æå–å¼•å·ä¸­çš„å†…å®¹
            quoted_terms = re.findall(r'"([^"]+)"', content)
            terms_list.extend(quoted_terms)
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›ç©ºåˆ—è¡¨
            if not terms_list:
                print("   âš ï¸  Could not extract terms, using empty list")
    
    state.raw_terms = terms_list
    return {"raw_terms": state.raw_terms}

# --- Node B2: çŸ¥è¯†æŸ¥è¯ (RAG/Search) ---
def node_search_and_consolidate(state: TranslationState):
    print("\nğŸ”¹ [Phase B2] Searching & Standardizing Terms (RAG)...")
    
    consolidated = []
    
    for term in state.raw_terms:
        search_result = retrieve_translation_memory(term, top_k=3)
        term_prompt = f"""
        You are a terminology expert specializing in English-to-Chinese translation.

        Task: Translate the following English term into Chinese (Simplified Chinese).

        Term: "{term}"
        Source text: "{state.source_text}"

        Retrieved translation memory:
        {search_result}

        IMPORTANT: 
        - The "suggested_trans" field MUST be in Chinese (Simplified Chinese), not any other language.
        - If the term is a proper noun or acronym (like "YOLO"), you may keep it as is or provide a Chinese explanation.
        - The "rationale" field should explain your translation choice in Chinese.

        Output a JSON object with ALL fields:
        {{
        "src": string (the original English term),
        "suggested_trans": string (MUST be in Chinese/Simplified Chinese),
        "type": string (e.g., "Terminology", "Acronym", "Proper Noun"),
        "context_meaning": string (explain the meaning in the context, in Chinese),
        "rationale": string (explain translation rationale, in Chinese)
        }}
        """
        try:
            entry = llm.with_structured_output(TermEntry).invoke(term_prompt)
            consolidated.append(entry.model_dump())
        except Exception as e:
            consolidated.append({
                "src": term,
                "suggested_trans": term,
                "type": "Unknown",
                "context_meaning": "Insufficient context from retrieval.",
                "rationale": f"Fallback due to error: {e}"
            })
    
    state.glossary = consolidated
    return {"glossary": state.glossary}



# --- Node C1: å¤šç­–ç•¥ç¿»è¯‘ä¸èåˆ (The Translator) ---
def node_translate_fusion(state: TranslationState):
    iteration = state.revision_count
    print(f"\nğŸ”¸ [Phase 2] Translation Generation (Iter {iteration+1})...")
    
    # æå–LaTeXå…¬å¼
    source_text_cleaned, latex_dict = extract_latex(state.source_text)
    if latex_dict:
        print(f"  ğŸ“ æ£€æµ‹åˆ° {len(latex_dict)} ä¸ªLaTeXå…¬å¼ï¼Œå·²æå–ä¿æŠ¤")
    
    glossary_text = "\n".join([f"- {t['src']} -> {t['suggested_trans']} ({t['rationale']})" for t in state.glossary])
    style_str = str(state.style_guide)
    prev_feedback = state.critique or "æ— "
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé«˜çº§ç¿»è¯‘å¼•æ“ã€‚è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

    1. **ç†è§£ä¸è§£æ„**ï¼šåˆ†æå¥å­ç»“æ„ã€‚
    2. **å¤šç‰ˆæœ¬ç”Ÿæˆ**ï¼š
    - ç›´è¯‘ç‰ˆ (Literal)
    - æ„è¯‘ç‰ˆ (Liberal)
    3. **èåˆä¸æ¶¦è‰²**ï¼šç»“åˆæœ€ä½³è¡¨è¾¾ï¼Œç”Ÿæˆæœ€ç»ˆè¯‘æ–‡ã€‚

    [çº¦æŸæ¡ä»¶]
    - ä¸¥æ ¼éµå®ˆé£æ ¼ï¼š{style_str}
    - å¼ºåˆ¶ä½¿ç”¨æœ¯è¯­è¡¨ï¼š
    {glossary_text}
    - ä¸Šä¸€è½®åé¦ˆï¼ˆå¦‚æœ‰ï¼‰ï¼š{prev_feedback}
    - æ³¨æ„ï¼šæ–‡æœ¬ä¸­çš„ __LATEX_PLACEHOLDER_X__ æ˜¯LaTeXå…¬å¼å ä½ç¬¦ï¼Œè¯·ä¿æŒåŸæ ·ï¼Œä¸è¦ç¿»è¯‘

    [åŸæ–‡]
    {source_text_cleaned}

    è¯·åªè¾“å‡ºæœ€ç»ˆèåˆåçš„è¯‘æ–‡ã€‚
    """
    
    # æ·»åŠ é‡è¯•æœºåˆ¶
    max_retries = 3
    retry_delay = 2  # ç§’
    for attempt in range(max_retries):
        try:
            response = llm.invoke(prompt)
            translated_text = response.content
            # æ¢å¤LaTeXå…¬å¼
            if latex_dict:
                translated_text = restore_latex(translated_text, latex_dict)
                print(f"  âœ… å·²æ¢å¤LaTeXå…¬å¼")
            state.combined_translation = translated_text
            state.revision_count += 1
            print("----------------------------", translated_text)
            break
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
            error_str = str(e)
            is_rate_limit = "RateLimitError" in str(type(e).__name__) or "rate_limit" in error_str.lower() or "429" in error_str
            
            if is_rate_limit and attempt < max_retries - 1:
                wait_time = retry_delay * (attempt + 1)
                print(f"  âš ï¸  é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            elif attempt < max_retries - 1:
                print(f"  âš ï¸  ç¿»è¯‘é”™è¯¯: {e}ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
            else:
                print(f"  âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨åŸæ–‡ä½œä¸ºç¿»è¯‘")
                # å¦‚æœå¤±è´¥ï¼Œè‡³å°‘æ¢å¤LaTeXå…¬å¼
                state.combined_translation = restore_latex(state.source_text, latex_dict) if latex_dict else state.source_text
                state.revision_count += 1
    
    return {
        "combined_translation": state.combined_translation,
        "revision_count": state.revision_count
    }


# --- Node C2: å›è¯‘ä¸ TEaR è¯„ä¼° ---
def node_tear_evaluation(state: TranslationState):
    print("\nğŸ”¸ [Phase 3] TEaR Evaluation (Back-translation & Scoring)...")
    
    # æå–LaTeXå…¬å¼ï¼ˆä»ç¿»è¯‘ç»“æœä¸­ï¼‰
    translation_cleaned, latex_dict = extract_latex(state.combined_translation)
    if latex_dict:
        print(f"  ğŸ“ æ£€æµ‹åˆ° {len(latex_dict)} ä¸ªLaTeXå…¬å¼ï¼Œå›è¯‘æ—¶å·²æå–ä¿æŠ¤")
    
    bt_prompt = f"""Translate the following text back to the source language (English) strictly.
Note: Text contains __LATEX_PLACEHOLDER_X__ placeholders for LaTeX formulas. Keep these placeholders unchanged, do not translate them.

Text to translate:
{translation_cleaned}"""
    
    # æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†é€Ÿç‡é™åˆ¶
    max_retries = 3
    retry_delay = 2
    back_translation = None
    
    for attempt in range(max_retries):
        try:
            bt_res = llm.invoke(bt_prompt)
            back_translation = bt_res.content
            # æ¢å¤LaTeXå…¬å¼
            if latex_dict:
                back_translation = restore_latex(back_translation, latex_dict)
            state.back_translation = back_translation
            break
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
            error_str = str(e)
            is_rate_limit = "RateLimitError" in str(type(e).__name__) or "rate_limit" in error_str.lower() or "429" in error_str
            
            if is_rate_limit and attempt < max_retries - 1:
                wait_time = retry_delay * (attempt + 1)
                print(f"  âš ï¸  é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            elif attempt < max_retries - 1:
                print(f"  âš ï¸  å›è¯‘é”™è¯¯: {e}ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
            else:
                print(f"  âŒ å›è¯‘å¤±è´¥ï¼Œè·³è¿‡å›è¯‘æ­¥éª¤")
                state.back_translation = state.source_text  # ä½¿ç”¨åŸæ–‡ä½œä¸ºå›è¯‘ç»“æœ
    
    eval_prompt = f"""
    ä½ æ˜¯ç¿»è¯‘è´¨é‡è¯„ä¼°ç³»ç»Ÿã€‚

    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™æ–‡æœ¬ï¼š

    {{
    "score": 0-10 çš„æ•´æ•°,
    "pass_flag": true æˆ– false,
    "critique": "ç®€è¦è¯„ä¼°æ„è§"
    }}

    ã€åŸæ–‡ã€‘
    {state.source_text}

    ã€å½“å‰è¯‘æ–‡ã€‘
    {state.combined_translation}

    ã€å›è¯‘ã€‘
    {state.back_translation}
    """
    try:
        eval_res = llm.with_structured_output(QualityReview).invoke(eval_prompt)
        quality_score = eval_res.score
        critique = eval_res.critique
        pass_flag = eval_res.pass_flag
    except Exception as e:
        print(f"âš ï¸  Structured output failed: {e}")
        print("   Using default quality scores...")
        # å›é€€åˆ°é»˜è®¤å€¼
        quality_score = 7.0
        critique = "è¯„ä¼°ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†"
        pass_flag = True
    
    state.quality_score = quality_score
    state.critique = critique
    
    print(f"   >>> Score: {quality_score}/10 | Pass: {pass_flag}")
    return {
        "back_translation": state.back_translation,
        "quality_score": state.quality_score,
        "critique": state.critique
    }
# --- Node D: æŒä¹…åŒ–ä¿å­˜ ---
def node_persistence(state: TranslationState):
    """ä¿å­˜æœ€ç»ˆç¿»è¯‘ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶"""
    
    # æ—¢ç„¶ state æ˜¯ TranslationState ç±»å‹ï¼Œç›´æ¥ç‚¹å·è®¿é—®æœ€å®‰å…¨
    try:
        book_id = state.book_id
        chapter_id = state.chapter_id
        chunk_id = state.chunk_id
        translation = state.combined_translation
        source_text = state.source_text
        quality_score = state.quality_score
        glossary = state.glossary
    except AttributeError:
        # ä¸‡ä¸€ LangGraph ä¼ è¿›æ¥çš„æ˜¯ä¸ª dictï¼ˆé€šå¸¸ä¸ä¼šï¼Œé™¤éé…ç½®æ”¹äº†ï¼‰
        book_id = state.get("book_id")
        chapter_id = state.get("chapter_id")
        chunk_id = state.get("chunk_id")
        translation = state.get("combined_translation")
        source_text = state.get("source_text")
        quality_score = state.get("quality_score")
        glossary = state.get("glossary")

    print(f"ğŸ’¾ [Persistence] Writing data for Chunk {chunk_id}...")

    # è·¯å¾„æ„é€ 
    base_dir = f"./output/{book_id}/chapter_{chapter_id}"
    os.makedirs(base_dir, exist_ok=True)
    
    # å»ºè®® chunk_id æ ¼å¼åŒ–ä¸º 3 ä½æˆ– 4 ä½æ•°å­—ï¼Œæ–¹ä¾¿æ’åº
    file_path = os.path.join(base_dir, f"chunk_{int(chunk_id):03d}.json")
    
    data_to_save = {
        "chunk_id": chunk_id,
        "source_text": source_text,
        "translation": translation,
        "quality_score": quality_score,
        "glossary": glossary
    }

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data_to_save, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“‚ File saved: {file_path}")
    return {"need_human_review": False}