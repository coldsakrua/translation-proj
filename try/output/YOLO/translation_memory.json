{
  "YOLO_ch0_ck0": {
    "book_id": "YOLO",
    "chapter_id": 0,
    "chunk_id": 0,
    "source_text": "You Only Look Once: Unified, Real-Time Object Detection",
    "translation": "YOLO：统一的、实时目标检测",
    "quality_score": 9.0,
    "saved_at": "2026-01-11T14:46:33.482641",
    "updated_at": "2026-01-11T14:46:33.692330"
  },
  "YOLO_ch1_ck0": {
    "book_id": "YOLO",
    "chapter_id": 1,
    "chunk_id": 0,
    "source_text": "Abstract We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.",
    "translation": "摘要：我们提出了YOLO，一种新的目标检测方法。先前的目标检测工作将分类器重新用于检测任务。相反，我们将目标检测框架化为一个回归问题，用于空间分离的边界框和相关的类别概率。一个单一的神经网络直接从完整图像中预测边界框和类别概率。由于整个检测流程是一个单一网络，它可以在检测性能上直接进行端到端优化。我们的统一架构速度极快。我们的基准YOLO模型以实时处理图像，每秒45帧。网络的一个更小版本，快速YOLO，处理速度惊人，每秒155帧，同时仍然达到其他实时检测器平均精度均值的两倍。与最先进的检测系统相比，YOLO在错误定位上更多，但在背景上预测假阳性的可能性较小。最后，YOLO学习了非常通用的目标表示。当从自然图像泛化到其他领域，如艺术作品时，它超越了其他检测方法，包括DPM和R-CNN。",
    "quality_score": 9.0,
    "saved_at": "2026-01-11T14:48:04.314244",
    "updated_at": "2026-01-11T15:00:48.038698"
  },
  "YOLO_ch2_ck0": {
    "book_id": "YOLO",
    "chapter_id": 2,
    "chunk_id": 0,
    "source_text": "",
    "translation": "YOLO算法的优势在于其速度快，能够在实时目标检测领域达到每秒处理多帧图像的能力。这种快速的检测速度得益于YOLO将目标检测问题视为一个单一的回归问题，直接从图像中预测边界框和类别概率。与传统的目标检测方法相比，YOLO不需要复杂的图像预处理和候选区域提取步骤，从而大大减少了计算量和检测时间。此外，YOLO算法在处理不同尺度和形状的目标时也表现出较好的鲁棒性。尽管在某些情况下，YOLO可能会产生一些假阳性结果，但其在速度和准确性之间的平衡使其成为实时目标检测任务的理想选择。随着技术的不断发展，YOLO算法也在不断优化和完善，以适应更多的应用场景和挑战。",
    "quality_score": 9.0,
    "saved_at": "2026-01-11T15:02:08.417833"
  },
  "YOLO_ch2_ck1": {
    "book_id": "YOLO",
    "chapter_id": 2,
    "chunk_id": 1,
    "source_text": "1. Introduction Humans glance at an image and instantly know what objects are in the image, where they are, and how they interact. The human visual system is fast and accurate, allowing us to perform complex tasks like driving with little conscious thought. Fast, accurate algorithms for object detection would allow computers to drive cars without specialized sensors, enable assistive devices to convey real-time scene information to human users, and unlock the potential for general purpose, responsive robotic systems. Current detection systems repurpose classifiers to perform detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image [10]. More recent approaches like R-CNN use region proposal methods to first generate potential bounding boxes in an image and then run a classifier on these proposed boxes. After classification, post-processing is used to refine the bounding boxes, eliminate duplicate detections, and rescore the boxes based on other objects in the scene [13]. These complex pipelines are slow and hard to optimize because each individual component must be trained separately. We reframe object detection as a single regression problem, straight from image pixels to bounding box coordinates and class probabilities. Using our system, you only look once (YOLO) at an image to predict what objects are present and where they are. YOLO is refreshingly simple: see Figure 1. A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes. YOLO trains on full images and directly optimizes detection performance. This unified model has several benefits over traditional methods of object detection. Figure 1: The YOLO Detection System. Processing images with YOLO is simple and straightforward. Our system (1) resizes the input image to 448 × 448, (2) runs a single convolutional network on the image, and (3) thresholds the resulting detections by the model’s confidence. First, YOLO is extremely fast. Since we frame detection as a regression problem we don’t need a complex pipeline. We simply run our neural network on a new image at test time to predict detections. Our base network runs at 45 frames per second with no batch processing on a Titan X GPU and a fast version runs at more than 150 fps. This means we can process streaming video in real-time with less than 25 milliseconds of latency. Furthermore, YOLO achieves more than twice the mean average precision of other real-time systems. For a demo of our system running in real-time on a webcam please see our project webpage: http://pjreddie.com/yolo/. Second, YOLO reasons globally about the image when making predictions. Unlike sliding window and region proposal-based techniques, YOLO sees the entire image during training and test time so it implicitly encodes contextual information about classes as well as their appearance. Fast R-CNN, a top detection method [14], mistakes background patches in an image for objects because it can’t see the larger context. YOLO makes less than half the number of background errors compared to Fast R-CNN. Third, YOLO learns generalizable representations of objects. When trained on natural images and tested on artwork, YOLO outperforms top detection methods like DPM and R-CNN by a wide margin. Since YOLO is highly generalizable it is less likely to break down when applied to new domains or unexpected inputs. YOLO still lags behind state-of-the-art detection systems in accuracy. While it can quickly identify objects in images it struggles to precisely localize some objects, especially small ones. We examine these tradeoffs further in our experiments. All of our training and testing code is open source. A variety of pretrained models are also available to download.",
    "translation": "摘要：人类只需一瞥图像便能立刻知道图像中有什么物体、它们的位置以及如何相互作用。人类视觉系统快速而准确，使我们能够在几乎不需要意识思考的情况下执行如驾驶等复杂任务。快速、准确、用于目标检测的算法将使计算机无需特殊传感器就能驾驶汽车，使辅助设备能够向人类用户传递实时场景信息，并为通用、响应灵敏的机器人系统打开潜力。当前检测系统重新利用分类器执行检测。为了检测一个物体，这些系统采用该物体的分类器，并在测试图像的不同位置和尺度上对其进行评估。像可变形部件模型（DPM）这样的系统使用滑动窗口方法，在整个图像上均匀间隔的位置运行分类器[10]。更近的方法，如R-CNN，使用区域提议方法首先生成图像中潜在的边界框，然后在这些提议的框上运行分类器。分类后，使用后处理来提炼边界框，消除重复检测，并根据场景中的其他物体重新评分[13]。这些复杂的流程既慢又难以优化，因为每个单独的组件必须分别进行训练。我们将目标检测重新框架化为一个单一的回归问题，直接从图像像素到边界框坐标和类别概率。使用我们的系统，你只需在图像上看一眼（YOLO）即可预测存在哪些物体以及它们的位置。YOLO非常简单：见图1。一个单一的卷积网络同时预测多个边界框和这些框的类别概率。YOLO在完整图像上进行训练，并直接优化检测性能。这种统一模型比传统的目标检测方法有几个好处。图1：YOLO检测系统。使用YOLO处理图像简单直接。我们的系统（1）将输入图像调整为448×448大小，（2）在图像上运行一个卷积网络，（3）根据模型的置信度阈值处理检测结果。首先，YOLO极其快速。由于我们将检测框架化为回归问题，我们不需要复杂的流程。我们只需在测试时在新图像上运行我们的神经网络来预测检测结果。我们的基准网络在没有批量处理的情况下，在Titan X GPU上每秒运行45帧，快速版本运行速度超过150帧/秒。这意味着我们可以实时处理视频流，延迟不到25毫秒。此外，YOLO在其他实时系统的两倍平均精度均值以上。有关我们的系统在网络摄像头上实时运行的演示，请访问我们的项目网页：http://pjreddie.com/yolo/。其次，YOLO在进行预测时对图像进行全局推理。与基于滑动窗口和区域提议的技术不同，YOLO在训练和测试时都能看到整个图像，因此它隐式地编码了关于类别及其外观的上下文信息。Fast R-CNN，一个顶级检测方法[14]，将图像中的背景补丁误认为物体，因为它无法看到更大的上下文。与Fast R-CNN相比，YOLO的背景错误数量不到一半。第三，YOLO学习了对物体的泛化表示。当在自然图像上训练并在艺术作品上测试时，YOLO的性能远远超过顶级检测方法，如DPM和R-CNN。由于YOLO具有高度的泛化性，当应用于新领域或意外输入时，它不太可能崩溃。YOLO在准确性方面仍落后于最先进的检测系统。虽然它能够快速识别图像中的物体，但在精确定位某些物体，特别是小物体方面存在困难。我们在实验中进一步检查了这些权衡。我们所有的训练和测试代码都是开源的。还提供了各种预训练模型供下载。",
    "quality_score": 9.0,
    "saved_at": "2026-01-11T15:03:21.711532",
    "updated_at": "2026-01-11T15:05:36.937738"
  },
  "YOLO_ch3_ck0": {
    "book_id": "YOLO",
    "chapter_id": 3,
    "chunk_id": 0,
    "source_text": "",
    "translation": "摘要：我们提出了计算机科学与技术领域中人工智能和机器学习的一个新方法——YOLO，这是一种新的目标检测方法。在先前的目标检测研究中，分类器被重新用于执行检测任务。与此不同，我们将目标检测框架化为一个回归问题，用于空间分隔的边界框和相关的类别概率。一个统一的神经网络直接从完整图像中预测边界框和类别概率。由于整个检测流程是一个单一网络，它可以在检测性能上直接进行端到端优化。这种方法不仅提高了目标检测的速度，也提高了准确性，使其成为实时目标检测领域中的一个最先进解决方案。",
    "quality_score": 9.0,
    "saved_at": "2026-01-11T15:06:04.924314"
  },
  "YOLO_ch3_ck1": {
    "book_id": "YOLO",
    "chapter_id": 3,
    "chunk_id": 1,
    "source_text": "2. Unified Detection We unify the separate components of object detection into a single neural network. Our network uses features from the entire image to predict each bounding box. It also predicts all bounding boxes across all classes for an image simultaneously. This means our network reasons globally about the full image and all the objects in the image. The YOLO design enables end-to-end training and real-time speeds while maintaining high average precision. Our system divides the input image into an $S\\times S$ grid. If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object. Each grid cell predicts $B$ bounding boxes and confidence scores for those boxes. These confidence scores reflect how confident the model is that the box contains an object and also how accurate it thinks the box is that it predicts. Formally we define confidence as $\\Pr(\\textrm{Object}) * \\textrm{IOU}_{\\textrm{pred}}^{\\textrm{truth}}$. If no object exists in that cell, the confidence scores should be zero. Otherwise we want the confidence score to equal the intersection over union (IOU) between the predicted box and the ground truth. Each bounding box consists of 5 predictions: $x$, $y$, $w$, $h$, and confidence. The $(x,y)$ coordinates represent the center of the box relative to the bounds of the grid cell. The width and height are predicted relative to the whole image. Finally the confidence prediction represents the IOU between the predicted box and any ground truth box. Each grid cell also predicts $C$ conditional class probabilities, $\\Pr(\\textrm{Class}_i | \\textrm{Object})$. These probabilities are conditioned on the grid cell containing an object. We only predict one set of class probabilities per grid cell, regardless of the number of boxes $B$. At test time we multiply the conditional class probabilities and the individual box confidence predictions, $$\\Pr(\\textrm{Class}_i | \\textrm{Object}) * \\Pr(\\textrm{Object}) * \\textrm{IOU}_{\\textrm{pred}}^{\\textrm{truth}} = \\Pr(\\textrm{Class}_i)*\\textrm{IOU}_{\\textrm{pred}}^{\\textrm{truth}}$$ which gives us class-specific confidence scores for each box. These scores encode both the probability of that class appearing in the box and how well the predicted box fits the object. For evaluating YOLO on Pascal VOC, we use $S=7$, $B=2$. Pascal VOC has 20 labelled classes so $C=20$. Our final prediction is a $7\\times 7 \\times 30$ tensor. The Model. Our system models detection as a regression problem. It divides the image into an $S \\times S$ grid and for each grid cell predicts $B$ bounding boxes, confidence for those boxes, and $C$ class probabilities. These predictions are encoded as an $S \\times S \\times (B*5 + C)$ tensor.",
    "translation": "2. 统一检测 我们将目标检测的各个独立组件统一为一个单一的神经网络。我们的网络利用整个图像的特征来预测每个边界框。它还同时预测图像中所有类别的所有边界框。这意味着我们的网络对整个图像和图像中的所有物体进行全局推理。YOLO的设计使得端到端训练和实时速度得以保持，同时保持高平均精度。我们的系统将输入图像划分为一个 $S\\times S$ 网格。如果一个物体的中心落入网格单元，则该网格单元负责检测该物体。每个网格单元预测 $B$ 个边界框和这些框的置信度分数。这些置信度分数反映了模型对框包含物体的置信程度以及它预测的框有多准确。我们正式定义置信度为 $\\Pr(\\textrm{物体}) * \\textrm{IOU}_{\\textrm{预测}}^{\\textrm{真实值}}$。如果该单元中没有物体存在，则置信度分数应为零。否则，我们希望置信度分数等于预测框和真实框之间的交并比（IOU）。每个边界框包括5个预测：$x$、$y$、$w$、$h$ 和置信度。$(x,y)$ 坐标表示框的中心相对于网格单元边界的位置。宽度和高度是相对于整个图像预测的。最后，置信度预测表示预测框和任何真实框之间的交并比。每个网格单元还预测 $C$ 个条件类别概率，$\\Pr(\\textrm{类别}_i | \\textrm{物体})$。这些概率是基于网格单元包含物体的条件。我们每个网格单元只预测一组类别概率，不管边界框的数量 $B$。在测试时，我们将条件类别概率和单个框置信度预测相乘，$$\\Pr(\\textrm{类别}_i | \\textrm{物体}) * \\Pr(\\textrm{物体}) * \\textrm{IOU}_{\\textrm{预测}}^{\\textrm{真实值}} = \\Pr(\\textrm{类别}_i)*\\textrm{IOU}_{\\textrm{预测}}^{\\textrm{真实值}}$$ 这为我们每个框提供了类别特定的置信度分数。这些分数既编码了该类别在框中出现的概率，也编码了预测框与物体的拟合程度。在Pascal VOC上评估YOLO时，我们使用 $S=7$、$B=2$。Pascal VOC有20个标记类别，所以 $C=20$。我们的最终预测是一个 $7\\times 7 \\times 30$ 张量。模型。我们的系统将检测建模为一个回归问题。它将图像划分为一个 $S \\times S$ 网格，并对每个网格单元预测 $B$ 个边界框、这些框的置信度和 $C$ 个类别概率。这些预测被编码为一个 $S \\times S \\times (B*5 + C)$ 张量。",
    "quality_score": 9.0,
    "saved_at": "2026-01-11T15:07:12.488492"
  }
}