{
  "chunk_id": 1,
  "source_text": "1. Introduction Humans glance at an image and instantly know what objects are in the image, where they are, and how they interact. The human visual system is fast and accurate, allowing us to perform complex tasks like driving with little conscious thought. Fast, accurate algorithms for object detection would allow computers to drive cars without specialized sensors, enable assistive devices to convey real-time scene information to human users, and unlock the potential for general purpose, responsive robotic systems. Current detection systems repurpose classifiers to perform detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image [10]. More recent approaches like R-CNN use region proposal methods to first generate potential bounding boxes in an image and then run a classifier on these proposed boxes. After classification, post-processing is used to refine the bounding boxes, eliminate duplicate detections, and rescore the boxes based on other objects in the scene [13]. These complex pipelines are slow and hard to optimize because each individual component must be trained separately. We reframe object detection as a single regression problem, straight from image pixels to bounding box coordinates and class probabilities. Using our system, you only look once (YOLO) at an image to predict what objects are present and where they are. YOLO is refreshingly simple: see Figure 1. A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes. YOLO trains on full images and directly optimizes detection performance. This unified model has several benefits over traditional methods of object detection. Figure 1: The YOLO Detection System. Processing images with YOLO is simple and straightforward. Our system (1) resizes the input image to 448 × 448, (2) runs a single convolutional network on the image, and (3) thresholds the resulting detections by the model’s confidence. First, YOLO is extremely fast. Since we frame detection as a regression problem we don’t need a complex pipeline. We simply run our neural network on a new image at test time to predict detections. Our base network runs at 45 frames per second with no batch processing on a Titan X GPU and a fast version runs at more than 150 fps. This means we can process streaming video in real-time with less than 25 milliseconds of latency. Furthermore, YOLO achieves more than twice the mean average precision of other real-time systems. For a demo of our system running in real-time on a webcam please see our project webpage: http://pjreddie.com/yolo/. Second, YOLO reasons globally about the image when making predictions. Unlike sliding window and region proposal-based techniques, YOLO sees the entire image during training and test time so it implicitly encodes contextual information about classes as well as their appearance. Fast R-CNN, a top detection method [14], mistakes background patches in an image for objects because it can’t see the larger context. YOLO makes less than half the number of background errors compared to Fast R-CNN. Third, YOLO learns generalizable representations of objects. When trained on natural images and tested on artwork, YOLO outperforms top detection methods like DPM and R-CNN by a wide margin. Since YOLO is highly generalizable it is less likely to break down when applied to new domains or unexpected inputs. YOLO still lags behind state-of-the-art detection systems in accuracy. While it can quickly identify objects in images it struggles to precisely localize some objects, especially small ones. We examine these tradeoffs further in our experiments. All of our training and testing code is open source. A variety of pretrained models are also available to download.",
  "translation": "摘要：人类只需一瞥图像便能立刻知道图像中有什么物体、它们的位置以及如何相互作用。人类视觉系统快速而准确，使我们能够在几乎不需要意识思考的情况下执行如驾驶等复杂任务。快速、准确、用于目标检测的算法将使计算机无需特殊传感器就能驾驶汽车，使辅助设备能够向人类用户传递实时场景信息，并为通用、响应灵敏的机器人系统打开潜力。当前检测系统重新利用分类器执行检测。为了检测一个物体，这些系统采用该物体的分类器，并在测试图像的不同位置和尺度上对其进行评估。像可变形部件模型（DPM）这样的系统使用滑动窗口方法，在整个图像上均匀间隔的位置运行分类器[10]。更近的方法，如R-CNN，使用区域提议方法首先生成图像中潜在的边界框，然后在这些提议的框上运行分类器。分类后，使用后处理来提炼边界框，消除重复检测，并根据场景中的其他物体重新评分[13]。这些复杂的流程既慢又难以优化，因为每个单独的组件必须分别进行训练。我们将目标检测重新框架化为一个单一的回归问题，直接从图像像素到边界框坐标和类别概率。使用我们的系统，你只需在图像上看一眼（YOLO）即可预测存在哪些物体以及它们的位置。YOLO非常简单：见图1。一个单一的卷积网络同时预测多个边界框和这些框的类别概率。YOLO在完整图像上进行训练，并直接优化检测性能。这种统一模型比传统的目标检测方法有几个好处。图1：YOLO检测系统。使用YOLO处理图像简单直接。我们的系统（1）将输入图像调整为448×448大小，（2）在图像上运行一个卷积网络，（3）根据模型的置信度阈值处理检测结果。首先，YOLO极其快速。由于我们将检测框架化为回归问题，我们不需要复杂的流程。我们只需在测试时在新图像上运行我们的神经网络来预测检测结果。我们的基准网络在没有批量处理的情况下，在Titan X GPU上每秒运行45帧，快速版本运行速度超过150帧/秒。这意味着我们可以实时处理视频流，延迟不到25毫秒。此外，YOLO在其他实时系统的两倍平均精度均值以上。有关我们的系统在网络摄像头上实时运行的演示，请访问我们的项目网页：http://pjreddie.com/yolo/。其次，YOLO在进行预测时对图像进行全局推理。与基于滑动窗口和区域提议的技术不同，YOLO在训练和测试时都能看到整个图像，因此它隐式地编码了关于类别及其外观的上下文信息。Fast R-CNN，一个顶级检测方法[14]，将图像中的背景补丁误认为物体，因为它无法看到更大的上下文。与Fast R-CNN相比，YOLO的背景错误数量不到一半。第三，YOLO学习了对物体的泛化表示。当在自然图像上训练并在艺术作品上测试时，YOLO的性能远远超过顶级检测方法，如DPM和R-CNN。由于YOLO具有高度的泛化性，当应用于新领域或意外输入时，它不太可能崩溃。YOLO在准确性方面仍落后于最先进的检测系统。虽然它能够快速识别图像中的物体，但在精确定位某些物体，特别是小物体方面存在困难。我们在实验中进一步检查了这些权衡。我们所有的训练和测试代码都是开源的。还提供了各种预训练模型供下载。",
  "quality_score": 9.0,
  "glossary": [
    {
      "src": "object detection",
      "type": "Terminology",
      "context_meaning": "目标检测是一种计算机视觉技术，用于识别图像或视频帧中的特定对象，并确定它们的位置。在本文中，目标检测被描述为一种回归问题，用于预测空间上分离的边界框和相关的类别概率。",
      "suggested_trans": "目标检测",
      "rationale": "根据检索到的翻译记忆，'object detection'的标准翻译是'目标检测'。这个术语是计算机视觉领域的常用术语，因此选择使用这个标准化的翻译。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T03:16:20.213774"
    },
    {
      "src": "deformable parts models",
      "type": "Terminology",
      "context_meaning": "在计算机视觉领域中，'deformable parts models'指的是一种用于目标检测的模型，该模型通过滑动窗口方法，在图像中评估不同位置和尺度下的分类器，以识别图像中的对象。",
      "suggested_trans": "可变形部件模型",
      "rationale": "根据检索到的翻译记忆，'deformable parts models'被翻译为'可变形部件模型'。这个翻译准确地反映了原词组的含义，并且根据上下文，它指的是一种目标检测模型，因此使用这个翻译是合适的。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    },
    {
      "src": "DPM",
      "type": "Acronym",
      "context_meaning": "在文本中，DPM指的是一种先进的目标检测方法，全称为Deformable Parts Model，即可变形部件模型。",
      "suggested_trans": "可变形部件模型",
      "rationale": "DPM是Deformable Parts Model的缩写，中文译为可变形部件模型。这是因为DPM是一种计算机视觉领域中的目标检测算法，其核心思想是利用物体的可变形部件来建模，以提高检测的准确性。在翻译时，我们保留了DPM这一缩写形式，并在括号中提供了对应的中文全称，以便读者理解。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T03:16:20.213774"
    },
    {
      "src": "R-CNN",
      "type": "Acronym",
      "context_meaning": "在文中指的是一种物体检测算法，全称为Regions with Convolutional Neural Networks，是一种将卷积神经网络（CNN）应用于图像区域以进行物体检测的方法。",
      "suggested_trans": "R-CNN",
      "rationale": "R-CNN是一个专有名词和缩写词，通常在学术和技术文献中保留原样，不进行翻译。在中文文献和技术社区中，人们也普遍使用R-CNN这个缩写，因此建议直接使用原词。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T03:16:20.213774"
    },
    {
      "src": "region proposal methods",
      "type": "Terminology",
      "context_meaning": "在计算机视觉领域，特别是在对象检测任务中，'region proposal methods'指的是一种算法技术，它首先在图像中生成可能包含目标的边界框，然后再在这些提出的边界框上运行分类器进行进一步的处理。这种方法有助于减少需要分类的区域数量，提高检测效率。",
      "suggested_trans": "区域提议方法",
      "rationale": "根据检索到的翻译记忆，'region proposal methods'被翻译为'区域提议方法'。这个翻译准确反映了原词组在计算机视觉领域中的含义，即通过算法提出可能包含目标的区域（边界框）。因此，我采用了这个翻译。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    },
    {
      "src": "bounding boxes",
      "type": "Terminology",
      "context_meaning": "在目标检测领域中，bounding boxes指的是用于框定图像中物体的矩形区域，它包含物体的位置和大小信息。",
      "suggested_trans": "边界框",
      "rationale": "根据检索到的翻译记忆，'bounding boxes'被翻译为'边界框'，这个翻译符合目标检测领域的专业术语。因此，我们直接采用这个翻译。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T03:16:20.213774"
    },
    {
      "src": "YOLO",
      "type": "Acronym",
      "context_meaning": "YOLO是一种用于目标检测的新方法，它将目标检测问题视为一个回归问题，直接从整张图像预测边界框和类别概率，整个检测流程是一个单一的神经网络，可以直接针对检测性能进行端到端优化。",
      "suggested_trans": "YOLO",
      "rationale": "YOLO是一个英文缩写，代表'You Only Look Once'，但在技术术语中，通常保留原英文形式。在这段文本中，YOLO指的是一种目标检测的方法，因此直接使用'YOLO'作为翻译即可，不需要将其展开为'你只看一次'。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T03:16:20.213774"
    },
    {
      "src": "convolutional network",
      "type": "Terminology",
      "context_meaning": "在本文中，'convolutional network'指的是一种用于图像识别和对象检测的深度学习模型，它通过卷积层提取图像特征，并预测图像中的对象及其位置。",
      "suggested_trans": "卷积网络",
      "rationale": "根据检索到的翻译记忆，'convolutional network'的翻译为'卷积网络'。这个翻译不仅准确，而且已经被广泛接受和使用。在深度学习和计算机视觉领域，'卷积网络'是一个标准的术语，因此我们选择这个翻译。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    },
    {
      "src": "mean average precision",
      "type": "Terminology",
      "context_meaning": "在给定的文本中，'mean average precision'是指一个衡量对象检测算法性能的指标，它综合考虑了查准率（precision）和查全率（recall）来评估算法的平均表现。",
      "suggested_trans": "平均精度均值",
      "rationale": "根据提供的翻译记忆，'mean average precision'被翻译为'平均精度均值'。这里的'mean'指的是均值，'average'强调平均，'precision'对应于查准率，因此整体翻译为'平均精度均值'能够较好地表达原词组的意思。在计算机视觉领域，该术语用于描述评估算法识别和定位对象的能力，特别是在对象检测任务中。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    },
    {
      "src": "Fast R-CNN",
      "type": "Terminology",
      "context_meaning": "快速R-CNN是一种计算机视觉算法，用于对象检测。它通过区域提议网络生成可能的边界框，然后利用卷积神经网络对这些边界框进行分类。快速R-CNN相较于传统的R-CNN，通过共享卷积特征减少了计算量，提高了检测速度。",
      "suggested_trans": "快速R-CNN",
      "rationale": "根据提供的翻译记忆，'Fast R-CNN'已经被翻译为'快速R-CNN'。这个翻译是准确的，因为它保留了原词的缩写形式，并且'Fast'被翻译为'快速'，符合中文习惯。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    },
    {
      "src": "Titan X GPU",
      "type": "Proper Noun",
      "context_meaning": "Titan X GPU是NVIDIA公司生产的一款高性能图形处理单元（GPU），被广泛应用于深度学习、图像处理和高性能计算等领域。",
      "suggested_trans": "Titan X GPU",
      "rationale": "保留原名即可，不必翻译",
      "original_suggested_trans": "泰坦X GPU",
      "human_reviewed": true,
      "human_modified": true,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    },
    {
      "src": "pretrained models",
      "type": "Terminology",
      "context_meaning": "在深度学习领域，预训练模型指在大量数据上预先训练好的模型，这些模型可以被用于新任务，通过微调来适应新的数据集。",
      "suggested_trans": "预训练模型",
      "rationale": "根据上下文，'pretrained models'指的是在大量数据上预先训练好的模型。'预训练模型'是该术语在中文中的直接翻译，能够准确传达原词的含义，因此在翻译时选择使用这个表达。",
      "human_reviewed": true,
      "human_modified": false,
      "reviewed_at": "2026-01-11T15:05:36.216216"
    }
  ],
  "human_reviewed": true,
  "reviewed_glossary_count": 12,
  "translation_updated_by_glossary": true,
  "translation_updated_at": "2026-01-11T15:05:36.936654"
}